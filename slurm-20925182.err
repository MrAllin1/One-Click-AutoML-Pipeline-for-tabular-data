cpu-bind=MASK - dlcgpu05, task  0  0 [1121549]: mask 0x180030001800300 set
/var/spool/slurm/job20925182/slurm_script: line 11: module: command not found
2025-08-05 21:19:18 [INFO] Using device: cuda
2025-08-05 21:19:18 [INFO] Training TabPFN model...
[I 2025-08-05 21:19:18,878] A new study created in memory with name: no-name-0be1d9b0-1d39-4888-95ed-376080ddd811
2025-08-05 21:19:18 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
[I 2025-08-05 21:21:14,194] Trial 0 finished with value: 0.9407270398052201 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.9407270398052201.
2025-08-05 21:21:14 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
[I 2025-08-05 21:23:36,671] Trial 1 finished with value: 0.9415474303403686 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 21:23:36 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
[I 2025-08-05 21:24:51,983] Trial 2 finished with value: 0.939915931530898 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 21:24:51 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
[I 2025-08-05 21:26:22,626] Trial 3 finished with value: 0.9403807173408154 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 21:26:22 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
[I 2025-08-05 21:28:39,089] Trial 4 finished with value: 0.941036618937641 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 21:28:39 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
[I 2025-08-05 21:30:10,037] Trial 5 finished with value: 0.9405680591660275 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8909729556485984}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 21:30:10 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
2025-08-05 21:30:17 [INFO] ⏸️ Pruned trial 6 at step 1 (R²=0.9303)
[I 2025-08-05 21:30:17,576] Trial 6 pruned. 
2025-08-05 21:30:17 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
2025-08-05 21:30:25 [INFO] ⏸️ Pruned trial 7 at step 1 (R²=0.9304)
[I 2025-08-05 21:30:25,079] Trial 7 pruned. 
2025-08-05 21:30:25 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
2025-08-05 21:30:33 [INFO] ⏸️ Pruned trial 8 at step 1 (R²=0.9319)
[I 2025-08-05 21:30:33,658] Trial 8 pruned. 
2025-08-05 21:30:33 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
2025-08-05 21:30:41 [INFO] ⏸️ Pruned trial 9 at step 1 (R²=0.9309)
[I 2025-08-05 21:30:41,694] Trial 9 pruned. 
2025-08-05 21:30:41 [INFO] 🔍 Trial 10: n_bootstrap=20, sample_frac=0.74
2025-08-05 21:30:50 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.9311)
[I 2025-08-05 21:30:50,154] Trial 10 pruned. 
2025-08-05 21:30:50 [INFO] 🔍 Trial 11: n_bootstrap=17, sample_frac=0.81
2025-08-05 21:30:59 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.9326)
[I 2025-08-05 21:30:59,306] Trial 11 pruned. 
2025-08-05 21:30:59 [INFO] 🔍 Trial 12: n_bootstrap=17, sample_frac=0.81
2025-08-05 21:31:08 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.9327)
[I 2025-08-05 21:31:08,324] Trial 12 pruned. 
2025-08-05 21:31:08 [INFO] 🔍 Trial 13: n_bootstrap=17, sample_frac=0.79
2025-08-05 21:31:17 [INFO] ⏸️ Pruned trial 13 at step 1 (R²=0.9333)
[I 2025-08-05 21:31:17,530] Trial 13 pruned. 
2025-08-05 21:31:17 [INFO] 🔍 Trial 14: n_bootstrap=16, sample_frac=0.71
2025-08-05 21:31:25 [INFO] ⏸️ Pruned trial 14 at step 1 (R²=0.9308)
[I 2025-08-05 21:31:25,852] Trial 14 pruned. 
2025-08-05 21:31:25 [INFO] 🔍 Trial 15: n_bootstrap=19, sample_frac=0.83
2025-08-05 21:31:35 [INFO] ⏸️ Pruned trial 15 at step 1 (R²=0.9323)
[I 2025-08-05 21:31:35,263] Trial 15 pruned. 
2025-08-05 21:31:35 [INFO] 🔍 Trial 16: n_bootstrap=15, sample_frac=0.76
2025-08-05 21:31:43 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.9322)
[I 2025-08-05 21:31:43,897] Trial 16 pruned. 
2025-08-05 21:31:43 [INFO] 🔍 Trial 17: n_bootstrap=18, sample_frac=0.84
2025-08-05 21:31:53 [INFO] ⏸️ Pruned trial 17 at step 1 (R²=0.9327)
[I 2025-08-05 21:31:53,528] Trial 17 pruned. 
2025-08-05 21:31:53 [INFO] 🔍 Trial 18: n_bootstrap=16, sample_frac=0.78
2025-08-05 21:32:02 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.9338)
[I 2025-08-05 21:32:02,247] Trial 18 pruned. 
2025-08-05 21:32:02 [INFO] 🔍 Trial 19: n_bootstrap=19, sample_frac=0.72
2025-08-05 21:32:10 [INFO] ⏸️ Pruned trial 19 at step 1 (R²=0.9308)
[I 2025-08-05 21:32:10,319] Trial 19 pruned. 
2025-08-05 21:32:10 [INFO] 🔍 Trial 20: n_bootstrap=15, sample_frac=0.61
2025-08-05 21:32:17 [INFO] ⏸️ Pruned trial 20 at step 1 (R²=0.9313)
[I 2025-08-05 21:32:17,483] Trial 20 pruned. 
2025-08-05 21:32:17 [INFO] 🔍 Trial 21: n_bootstrap=14, sample_frac=0.88
[I 2025-08-05 21:34:28,514] Trial 21 finished with value: 0.9407565058034427 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8841404752206518}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 21:34:28 [INFO] 🔍 Trial 22: n_bootstrap=13, sample_frac=0.86
2025-08-05 21:34:38 [INFO] ⏸️ Pruned trial 22 at step 1 (R²=0.9339)
[I 2025-08-05 21:34:38,424] Trial 22 pruned. 
2025-08-05 21:34:38 [INFO] 🔍 Trial 23: n_bootstrap=16, sample_frac=0.84
2025-08-05 21:34:48 [INFO] ⏸️ Pruned trial 23 at step 1 (R²=0.9327)
[I 2025-08-05 21:34:48,017] Trial 23 pruned. 
2025-08-05 21:34:48 [INFO] 🔍 Trial 24: n_bootstrap=18, sample_frac=0.79
2025-08-05 21:34:57 [INFO] ⏸️ Pruned trial 24 at step 1 (R²=0.9336)
[I 2025-08-05 21:34:57,269] Trial 24 pruned. 
2025-08-05 21:34:57 [INFO] 🔍 Trial 25: n_bootstrap=14, sample_frac=0.82
2025-08-05 21:35:06 [INFO] ⏸️ Pruned trial 25 at step 1 (R²=0.9317)
[I 2025-08-05 21:35:06,723] Trial 25 pruned. 
2025-08-05 21:35:06 [INFO] 🔍 Trial 26: n_bootstrap=18, sample_frac=0.87
[I 2025-08-05 21:37:48,535] Trial 26 finished with value: 0.9415544920301624 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.8713581762004475}. Best is trial 26 with value: 0.9415544920301624.
2025-08-05 21:37:48 [INFO] 🔍 Trial 27: n_bootstrap=20, sample_frac=0.86
2025-08-05 21:37:58 [INFO] ⏸️ Pruned trial 27 at step 1 (R²=0.9340)
[I 2025-08-05 21:37:58,174] Trial 27 pruned. 
2025-08-05 21:37:58 [INFO] 🔍 Trial 28: n_bootstrap=18, sample_frac=0.74
2025-08-05 21:38:06 [INFO] ⏸️ Pruned trial 28 at step 1 (R²=0.9311)
[I 2025-08-05 21:38:06,655] Trial 28 pruned. 
2025-08-05 21:38:06 [INFO] 🔍 Trial 29: n_bootstrap=17, sample_frac=0.90
[I 2025-08-05 21:40:43,068] Trial 29 finished with value: 0.9417814033337457 and parameters: {'n_bootstrap': 17, 'sample_frac': 0.8995784440661511}. Best is trial 29 with value: 0.9417814033337457.
2025-08-05 21:40:43 [INFO] 🏆 Best Params: {'n_bootstrap': 17, 'sample_frac': 0.8995784440661511}, R²=0.94178
2025-08-05 21:40:43 [INFO] Bootstrap training → dataset=bike_sharing_demand, device=cuda
2025-08-05 21:40:43 [INFO] [1/17] bootstrap sample size=6329
2025-08-05 21:40:53 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_1.pkl
2025-08-05 21:40:53 [INFO] [2/17] bootstrap sample size=6329
2025-08-05 21:41:01 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_2.pkl
2025-08-05 21:41:01 [INFO] [3/17] bootstrap sample size=6329
2025-08-05 21:41:10 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_3.pkl
2025-08-05 21:41:10 [INFO] [4/17] bootstrap sample size=6329
2025-08-05 21:41:20 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_4.pkl
2025-08-05 21:41:20 [INFO] [5/17] bootstrap sample size=6329
2025-08-05 21:41:30 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_5.pkl
2025-08-05 21:41:31 [INFO] [6/17] bootstrap sample size=6329
2025-08-05 21:41:40 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_6.pkl
2025-08-05 21:41:41 [INFO] [7/17] bootstrap sample size=6329
2025-08-05 21:41:49 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_7.pkl
2025-08-05 21:41:49 [INFO] [8/17] bootstrap sample size=6329
2025-08-05 21:41:57 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_8.pkl
2025-08-05 21:41:57 [INFO] [9/17] bootstrap sample size=6329
2025-08-05 21:42:07 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_9.pkl
2025-08-05 21:42:08 [INFO] [10/17] bootstrap sample size=6329
2025-08-05 21:42:16 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_10.pkl
2025-08-05 21:42:16 [INFO] [11/17] bootstrap sample size=6329
2025-08-05 21:42:26 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_11.pkl
2025-08-05 21:42:26 [INFO] [12/17] bootstrap sample size=6329
2025-08-05 21:42:37 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_12.pkl
2025-08-05 21:42:37 [INFO] [13/17] bootstrap sample size=6329
2025-08-05 21:42:45 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_13.pkl
2025-08-05 21:42:45 [INFO] [14/17] bootstrap sample size=6329
2025-08-05 21:42:55 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_14.pkl
2025-08-05 21:42:56 [INFO] [15/17] bootstrap sample size=6329
2025-08-05 21:43:03 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_15.pkl
2025-08-05 21:43:04 [INFO] [16/17] bootstrap sample size=6329
2025-08-05 21:43:14 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_16.pkl
2025-08-05 21:43:14 [INFO] [17/17] bootstrap sample size=6329
2025-08-05 21:43:23 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/bootstrap_17.pkl
2025-08-05 21:43:23 [INFO] 📊 Final OOB R² = 0.94178
2025-08-05 21:43:28 [INFO] Saved ensemble → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/ensemble.pkl
2025-08-05 21:43:28 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-05 21:43:28 [INFO] Total time: 165.4s
2025-08-05 21:43:28 [INFO] TabPFN →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/bike_sharing_demand/ensemble.pkl (R²=0.9418)
2025-08-05 21:43:28 [INFO] Training tree-based model...
2025-08-05 21:43:28 [INFO] AutoML pipeline started
2025-08-05 21:43:28 [INFO] Output directory '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona' is ready and logging is configured.
2025-08-05 21:43:28 [INFO] Merged training data: 7036 rows
2025-08-05 21:43:28 [INFO] Split data into pool (6332 rows) and validation (704 rows)
2025-08-05 21:43:28 [INFO] Feature engineering completed: 11 features
[I 2025-08-05 21:43:28,692] A new study created in memory with name: no-name-e34de91c-186a-48d7-bab7-8d23f8c3296d
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-05 21:44:57,842] Trial 0 finished with value: -0.9420850310429097 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.9420850310429097.
[I 2025-08-05 21:45:09,469] Trial 1 finished with value: -0.919482120906484 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 0 with value: -0.9420850310429097.
[I 2025-08-05 21:45:23,926] Trial 2 finished with value: -0.942145085000307 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 21:45:32,621] Trial 3 finished with value: -0.9360381967367711 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 21:45:51,231] Trial 4 finished with value: -0.9406664018245173 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 21:46:02,680] Trial 5 finished with value: -0.93596421448217 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 21:46:39,205] Trial 6 finished with value: -0.9429075764821212 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 21:46:48,961] Trial 7 finished with value: -0.9256462632126544 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 21:48:14,239] Trial 8 finished with value: -0.9374041351458068 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 21:48:24,350] Trial 9 finished with value: -0.9097722005501373 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 21:48:32,881] Trial 10 finished with value: -0.941098586670725 and parameters: {'learning_rate': 0.24893231508461813, 'depth': 9, 'l2_leaf_reg': 4.318558954489875, 'border_count': 175}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 21:48:43,257] Trial 11 finished with value: -0.9418322571451027 and parameters: {'learning_rate': 0.11386552028513468, 'depth': 10, 'l2_leaf_reg': 1.0763393887328419, 'border_count': 250}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 21:48:58,141] Trial 12 finished with value: -0.942942808864033 and parameters: {'learning_rate': 0.05033186585861864, 'depth': 10, 'l2_leaf_reg': 2.53256400708008, 'border_count': 41}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 21:49:20,449] Trial 13 finished with value: -0.9421694183584254 and parameters: {'learning_rate': 0.04666176218448525, 'depth': 11, 'l2_leaf_reg': 2.880463341431277, 'border_count': 36}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 21:49:37,675] Trial 14 finished with value: -0.9427043615322919 and parameters: {'learning_rate': 0.051527024214005596, 'depth': 8, 'l2_leaf_reg': 2.8449544909574693, 'border_count': 160}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 21:49:53,173] Trial 15 finished with value: -0.9350196331040646 and parameters: {'learning_rate': 0.020546790816083238, 'depth': 7, 'l2_leaf_reg': 5.531162329838407, 'border_count': 195}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 21:49:59,255] Trial 16 finished with value: -0.9407859730704597 and parameters: {'learning_rate': 0.13811007646509937, 'depth': 10, 'l2_leaf_reg': 2.340481892680636, 'border_count': 36}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 21:50:35,801] Trial 17 finished with value: -0.943125410298701 and parameters: {'learning_rate': 0.04071611822052514, 'depth': 11, 'l2_leaf_reg': 3.894752015334281, 'border_count': 141}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:50:58,692] Trial 18 finished with value: -0.9361762970415135 and parameters: {'learning_rate': 0.010907863682082639, 'depth': 9, 'l2_leaf_reg': 3.8101144232990465, 'border_count': 67}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:51:39,975] Trial 19 finished with value: -0.9426848044377918 and parameters: {'learning_rate': 0.03305323034166552, 'depth': 11, 'l2_leaf_reg': 5.608041644328219, 'border_count': 92}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:51:54,852] Trial 20 finished with value: -0.9336406907434831 and parameters: {'learning_rate': 0.020201780497292713, 'depth': 7, 'l2_leaf_reg': 8.675815964448498, 'border_count': 121}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:52:26,149] Trial 21 finished with value: -0.9424345943142839 and parameters: {'learning_rate': 0.0442622424134713, 'depth': 11, 'l2_leaf_reg': 2.0275635855984584, 'border_count': 145}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:53:14,207] Trial 22 finished with value: -0.9411996136795251 and parameters: {'learning_rate': 0.07002993047047383, 'depth': 12, 'l2_leaf_reg': 3.402133768679974, 'border_count': 142}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:53:34,136] Trial 23 finished with value: -0.9429587898588239 and parameters: {'learning_rate': 0.057871436385387075, 'depth': 9, 'l2_leaf_reg': 4.805133980122038, 'border_count': 201}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:53:48,491] Trial 24 finished with value: -0.9426676012168915 and parameters: {'learning_rate': 0.09788764905810535, 'depth': 9, 'l2_leaf_reg': 4.5230067577948505, 'border_count': 200}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:54:10,092] Trial 25 finished with value: -0.9428900225562865 and parameters: {'learning_rate': 0.06016763329060489, 'depth': 10, 'l2_leaf_reg': 4.849869867931115, 'border_count': 182}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:54:25,021] Trial 26 finished with value: -0.9397905891839471 and parameters: {'learning_rate': 0.03738730947894328, 'depth': 7, 'l2_leaf_reg': 5.889228002920342, 'border_count': 54}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:54:44,384] Trial 27 finished with value: -0.9429396323223255 and parameters: {'learning_rate': 0.061388079540134345, 'depth': 9, 'l2_leaf_reg': 4.044490864164882, 'border_count': 104}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 21:54:58,963] Trial 28 finished with value: -0.9431280356061487 and parameters: {'learning_rate': 0.10193738211993074, 'depth': 10, 'l2_leaf_reg': 3.352983792434749, 'border_count': 231}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:55:26,463] Trial 29 finished with value: -0.9394648249420079 and parameters: {'learning_rate': 0.16212942052989116, 'depth': 12, 'l2_leaf_reg': 6.469803623854161, 'border_count': 231}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:55:33,957] Trial 30 finished with value: -0.9405714805423837 and parameters: {'learning_rate': 0.22805828040319062, 'depth': 8, 'l2_leaf_reg': 4.969925751644316, 'border_count': 229}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:55:49,434] Trial 31 finished with value: -0.9423795812722362 and parameters: {'learning_rate': 0.09970028855539532, 'depth': 10, 'l2_leaf_reg': 3.2647467098466447, 'border_count': 213}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:56:27,060] Trial 32 finished with value: -0.9428806086539023 and parameters: {'learning_rate': 0.03768031893458419, 'depth': 11, 'l2_leaf_reg': 1.7885011487259037, 'border_count': 195}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:56:42,353] Trial 33 finished with value: -0.943126135707853 and parameters: {'learning_rate': 0.0868937349679417, 'depth': 9, 'l2_leaf_reg': 3.304026138121671, 'border_count': 243}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:56:53,069] Trial 34 finished with value: -0.9427427989240821 and parameters: {'learning_rate': 0.12326088306155994, 'depth': 9, 'l2_leaf_reg': 4.123214684240512, 'border_count': 240}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:57:05,129] Trial 35 finished with value: -0.9424541556794017 and parameters: {'learning_rate': 0.0885295722362556, 'depth': 8, 'l2_leaf_reg': 3.26740254390009, 'border_count': 216}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:57:15,842] Trial 36 finished with value: -0.9413664596632815 and parameters: {'learning_rate': 0.18049477993564428, 'depth': 9, 'l2_leaf_reg': 5.0374262233132026, 'border_count': 241}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:57:29,084] Trial 37 finished with value: -0.9393299871588138 and parameters: {'learning_rate': 0.06652519784921596, 'depth': 6, 'l2_leaf_reg': 3.7723653658651672, 'border_count': 253}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:57:42,321] Trial 38 finished with value: -0.9417667638232385 and parameters: {'learning_rate': 0.08493730318034638, 'depth': 8, 'l2_leaf_reg': 4.51277132131785, 'border_count': 162}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:58:26,627] Trial 39 finished with value: -0.9428975062331315 and parameters: {'learning_rate': 0.02991120025264205, 'depth': 11, 'l2_leaf_reg': 2.040263775996904, 'border_count': 183}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:58:33,005] Trial 40 finished with value: -0.9388661250899547 and parameters: {'learning_rate': 0.2992799583173479, 'depth': 10, 'l2_leaf_reg': 3.2896559874214337, 'border_count': 224}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:58:53,524] Trial 41 finished with value: -0.9429248582116591 and parameters: {'learning_rate': 0.05298840165656651, 'depth': 10, 'l2_leaf_reg': 2.4143528093565445, 'border_count': 244}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:59:15,845] Trial 42 finished with value: -0.9425791180823625 and parameters: {'learning_rate': 0.040080255021436376, 'depth': 9, 'l2_leaf_reg': 1.6547870712533388, 'border_count': 203}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 21:59:35,751] Trial 43 finished with value: -0.9428335877331607 and parameters: {'learning_rate': 0.05812689266493824, 'depth': 10, 'l2_leaf_reg': 2.923695794306846, 'border_count': 85}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:00:20,118] Trial 44 finished with value: -0.9427175980561865 and parameters: {'learning_rate': 0.02298384347018129, 'depth': 11, 'l2_leaf_reg': 2.4869577114624533, 'border_count': 235}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:00:36,278] Trial 45 finished with value: -0.9424393675889066 and parameters: {'learning_rate': 0.07713745958428486, 'depth': 9, 'l2_leaf_reg': 3.815460530201026, 'border_count': 221}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:00:46,441] Trial 46 finished with value: -0.9423185835289042 and parameters: {'learning_rate': 0.10658292435344957, 'depth': 10, 'l2_leaf_reg': 1.262527844934136, 'border_count': 133}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:01:15,417] Trial 47 finished with value: -0.9396628638481023 and parameters: {'learning_rate': 0.14016359035453274, 'depth': 12, 'l2_leaf_reg': 4.557085536671287, 'border_count': 170}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:01:40,288] Trial 48 finished with value: -0.94270401803817 and parameters: {'learning_rate': 0.04287474209323773, 'depth': 10, 'l2_leaf_reg': 3.020282830969709, 'border_count': 210}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:02:23,918] Trial 49 finished with value: -0.9422522558450602 and parameters: {'learning_rate': 0.024797944516010192, 'depth': 11, 'l2_leaf_reg': 5.299579368404125, 'border_count': 254}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:02:41,682] Trial 50 finished with value: -0.9429848410224052 and parameters: {'learning_rate': 0.05129150172298022, 'depth': 9, 'l2_leaf_reg': 3.6319313660583874, 'border_count': 49}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:03:00,233] Trial 51 finished with value: -0.9428219506750534 and parameters: {'learning_rate': 0.05086898450516008, 'depth': 9, 'l2_leaf_reg': 3.512263065898063, 'border_count': 48}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:03:17,613] Trial 52 finished with value: -0.9421024435034532 and parameters: {'learning_rate': 0.04814333495165513, 'depth': 8, 'l2_leaf_reg': 4.1820418188040165, 'border_count': 61}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:03:41,259] Trial 53 finished with value: -0.9425775534109407 and parameters: {'learning_rate': 0.034003659085575434, 'depth': 9, 'l2_leaf_reg': 2.632879035482573, 'border_count': 79}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:03:54,688] Trial 54 finished with value: -0.9423347046435115 and parameters: {'learning_rate': 0.06368786948011068, 'depth': 8, 'l2_leaf_reg': 3.7454747123193677, 'border_count': 33}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:04:14,534] Trial 55 finished with value: -0.9430651386800506 and parameters: {'learning_rate': 0.0766076480071888, 'depth': 10, 'l2_leaf_reg': 6.0101255975370655, 'border_count': 107}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:04:33,917] Trial 56 finished with value: -0.9428053460574889 and parameters: {'learning_rate': 0.07534041984072042, 'depth': 9, 'l2_leaf_reg': 6.163486909887137, 'border_count': 113}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:04:48,469] Trial 57 finished with value: -0.9428221777631428 and parameters: {'learning_rate': 0.11948456608880467, 'depth': 10, 'l2_leaf_reg': 7.538042161867778, 'border_count': 126}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:05:13,459] Trial 58 finished with value: -0.9425502945739195 and parameters: {'learning_rate': 0.09188882632116548, 'depth': 11, 'l2_leaf_reg': 6.810498748080285, 'border_count': 156}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:05:33,299] Trial 59 finished with value: -0.9429541199139049 and parameters: {'learning_rate': 0.06868771069172894, 'depth': 10, 'l2_leaf_reg': 5.326968766919445, 'border_count': 100}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:05:48,072] Trial 60 finished with value: -0.9404441678766056 and parameters: {'learning_rate': 0.05495985978423373, 'depth': 7, 'l2_leaf_reg': 5.903486082961492, 'border_count': 153}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:06:08,429] Trial 61 finished with value: -0.9430133127224529 and parameters: {'learning_rate': 0.07024631490336256, 'depth': 10, 'l2_leaf_reg': 5.21069730890777, 'border_count': 104}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:06:27,892] Trial 62 finished with value: -0.9427624233465259 and parameters: {'learning_rate': 0.0819995376563252, 'depth': 10, 'l2_leaf_reg': 4.785462189649322, 'border_count': 109}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:06:53,601] Trial 63 finished with value: -0.9419796594453228 and parameters: {'learning_rate': 0.07167441096408604, 'depth': 11, 'l2_leaf_reg': 4.3287968090079225, 'border_count': 135}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:07:07,232] Trial 64 finished with value: -0.9424069591181727 and parameters: {'learning_rate': 0.1002457334812009, 'depth': 9, 'l2_leaf_reg': 5.838125453387559, 'border_count': 87}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:07:30,033] Trial 65 finished with value: -0.9428035341327339 and parameters: {'learning_rate': 0.0418838713109863, 'depth': 9, 'l2_leaf_reg': 5.119059320259712, 'border_count': 122}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:07:51,546] Trial 66 finished with value: -0.9429760520583745 and parameters: {'learning_rate': 0.05721538475099747, 'depth': 10, 'l2_leaf_reg': 6.237011840690992, 'border_count': 72}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 22:08:03,043] Trial 67 finished with value: -0.9431342588656383 and parameters: {'learning_rate': 0.12977656999309892, 'depth': 10, 'l2_leaf_reg': 6.815051080052627, 'border_count': 71}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 22:08:20,606] Trial 68 finished with value: -0.9407991478465565 and parameters: {'learning_rate': 0.14764692288492812, 'depth': 11, 'l2_leaf_reg': 8.064572669937355, 'border_count': 62}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 22:08:30,896] Trial 69 finished with value: -0.9416214428791576 and parameters: {'learning_rate': 0.12812942948326303, 'depth': 10, 'l2_leaf_reg': 7.1332676144181155, 'border_count': 44}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 22:09:01,361] Trial 70 finished with value: -0.9405767156919153 and parameters: {'learning_rate': 0.18819216148186574, 'depth': 12, 'l2_leaf_reg': 9.987768393033573, 'border_count': 81}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 22:09:14,831] Trial 71 finished with value: -0.9423918493261363 and parameters: {'learning_rate': 0.10730454674229138, 'depth': 10, 'l2_leaf_reg': 6.379414148456539, 'border_count': 75}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 22:09:29,502] Trial 72 finished with value: -0.9431724553869149 and parameters: {'learning_rate': 0.09061655070754851, 'depth': 10, 'l2_leaf_reg': 6.637166053315614, 'border_count': 57}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:09:50,292] Trial 73 finished with value: -0.9416226796582267 and parameters: {'learning_rate': 0.08931225875537213, 'depth': 11, 'l2_leaf_reg': 6.781555217188022, 'border_count': 55}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:10:03,279] Trial 74 finished with value: -0.9424568054956659 and parameters: {'learning_rate': 0.1524681257389112, 'depth': 10, 'l2_leaf_reg': 7.855577959535804, 'border_count': 98}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:10:35,277] Trial 75 finished with value: -0.9422461419013828 and parameters: {'learning_rate': 0.08135883873177156, 'depth': 11, 'l2_leaf_reg': 7.051280565422536, 'border_count': 91}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:10:48,363] Trial 76 finished with value: -0.9428545577733068 and parameters: {'learning_rate': 0.11321027429519863, 'depth': 10, 'l2_leaf_reg': 6.618497780058233, 'border_count': 52}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:10:58,624] Trial 77 finished with value: -0.9426015665104407 and parameters: {'learning_rate': 0.13343502574213445, 'depth': 9, 'l2_leaf_reg': 5.654331188521088, 'border_count': 68}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:11:15,159] Trial 78 finished with value: -0.9419372506063353 and parameters: {'learning_rate': 0.06452175076932594, 'depth': 11, 'l2_leaf_reg': 3.0463616934958737, 'border_count': 42}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:11:29,433] Trial 79 finished with value: -0.9428383820113909 and parameters: {'learning_rate': 0.09525717944134543, 'depth': 10, 'l2_leaf_reg': 7.4620707801943285, 'border_count': 62}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:11:39,309] Trial 80 finished with value: -0.889224050085159 and parameters: {'learning_rate': 0.013943116780134197, 'depth': 4, 'l2_leaf_reg': 4.0048314240293745, 'border_count': 106}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:12:02,266] Trial 81 finished with value: -0.9428126977897081 and parameters: {'learning_rate': 0.04640554617523816, 'depth': 10, 'l2_leaf_reg': 6.089649819028433, 'border_count': 73}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:12:23,114] Trial 82 finished with value: -0.9425547718971069 and parameters: {'learning_rate': 0.07283106960318442, 'depth': 10, 'l2_leaf_reg': 6.269874730206288, 'border_count': 93}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:12:43,565] Trial 83 finished with value: -0.9428537346577295 and parameters: {'learning_rate': 0.060556143473870686, 'depth': 9, 'l2_leaf_reg': 6.574484364737053, 'border_count': 118}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 22:13:01,380] Trial 84 finished with value: -0.943229884598642 and parameters: {'learning_rate': 0.05449934549264481, 'depth': 10, 'l2_leaf_reg': 3.543291636846423, 'border_count': 58}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:13:12,321] Trial 85 finished with value: -0.9426832072431612 and parameters: {'learning_rate': 0.10678906550059873, 'depth': 10, 'l2_leaf_reg': 3.5864566774984783, 'border_count': 50}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:13:36,486] Trial 86 finished with value: -0.9423335418750725 and parameters: {'learning_rate': 0.08255613548956028, 'depth': 11, 'l2_leaf_reg': 3.2209920365384903, 'border_count': 141}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:13:57,667] Trial 87 finished with value: -0.9426158956820011 and parameters: {'learning_rate': 0.038656758609665, 'depth': 9, 'l2_leaf_reg': 3.9599373465884122, 'border_count': 60}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:14:16,886] Trial 88 finished with value: -0.942846759454714 and parameters: {'learning_rate': 0.05318549632296007, 'depth': 10, 'l2_leaf_reg': 2.7764896343126493, 'border_count': 247}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:14:33,200] Trial 89 finished with value: -0.9405470727933704 and parameters: {'learning_rate': 0.031106757226604862, 'depth': 8, 'l2_leaf_reg': 8.840158603959413, 'border_count': 38}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:14:48,902] Trial 90 finished with value: -0.9424300788862601 and parameters: {'learning_rate': 0.06666992463008417, 'depth': 9, 'l2_leaf_reg': 2.151746346146333, 'border_count': 180}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:15:09,142] Trial 91 finished with value: -0.9429522796551687 and parameters: {'learning_rate': 0.05651233368664576, 'depth': 10, 'l2_leaf_reg': 6.853356290767176, 'border_count': 67}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:15:29,392] Trial 92 finished with value: -0.9429690034783336 and parameters: {'learning_rate': 0.0472823396712481, 'depth': 10, 'l2_leaf_reg': 6.075829480462228, 'border_count': 56}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:16:04,600] Trial 93 finished with value: -0.9412227647501858 and parameters: {'learning_rate': 0.07843879804411949, 'depth': 12, 'l2_leaf_reg': 3.4767743521360535, 'border_count': 72}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:16:18,970] Trial 94 finished with value: -0.9421490171985646 and parameters: {'learning_rate': 0.11442366792795264, 'depth': 10, 'l2_leaf_reg': 7.289608220287802, 'border_count': 80}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:16:35,633] Trial 95 finished with value: -0.9420007137564822 and parameters: {'learning_rate': 0.08784067553619183, 'depth': 11, 'l2_leaf_reg': 5.74245736817175, 'border_count': 47}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:16:48,310] Trial 96 finished with value: -0.9423191542335732 and parameters: {'learning_rate': 0.09883090965406585, 'depth': 8, 'l2_leaf_reg': 5.442065163185126, 'border_count': 86}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:17:05,874] Trial 97 finished with value: -0.9427212523565147 and parameters: {'learning_rate': 0.04413581712336465, 'depth': 9, 'l2_leaf_reg': 4.620611894714477, 'border_count': 32}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 22:17:30,279] Trial 98 finished with value: -0.9432778819343897 and parameters: {'learning_rate': 0.035517987785120005, 'depth': 10, 'l2_leaf_reg': 4.33299092921435, 'border_count': 66}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:17:54,153] Trial 99 finished with value: -0.9429484621274125 and parameters: {'learning_rate': 0.035125663557533736, 'depth': 10, 'l2_leaf_reg': 4.423656928370156, 'border_count': 64}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:18:35,289] Trial 100 finished with value: -0.9428114598843784 and parameters: {'learning_rate': 0.025409591576293796, 'depth': 11, 'l2_leaf_reg': 3.8426427952551063, 'border_count': 149}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:18:58,147] Trial 101 finished with value: -0.9429104634174699 and parameters: {'learning_rate': 0.04019229055268166, 'depth': 10, 'l2_leaf_reg': 4.176910313977138, 'border_count': 57}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:19:18,477] Trial 102 finished with value: -0.942961237939658 and parameters: {'learning_rate': 0.049423408095883865, 'depth': 10, 'l2_leaf_reg': 3.149775383908324, 'border_count': 75}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:19:31,281] Trial 103 finished with value: -0.939134035841008 and parameters: {'learning_rate': 0.0585825127844495, 'depth': 6, 'l2_leaf_reg': 3.3766436949465577, 'border_count': 67}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:19:53,826] Trial 104 finished with value: -0.9429165303118641 and parameters: {'learning_rate': 0.032175557928832484, 'depth': 10, 'l2_leaf_reg': 4.689664771442583, 'border_count': 46}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:20:12,375] Trial 105 finished with value: -0.9427519644007406 and parameters: {'learning_rate': 0.0690200314389651, 'depth': 9, 'l2_leaf_reg': 5.205363090856304, 'border_count': 234}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:20:27,278] Trial 106 finished with value: -0.943014166616595 and parameters: {'learning_rate': 0.07593739056281919, 'depth': 10, 'l2_leaf_reg': 3.649946989589488, 'border_count': 52}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:20:43,018] Trial 107 finished with value: -0.9417937321418751 and parameters: {'learning_rate': 0.07563427000783991, 'depth': 11, 'l2_leaf_reg': 2.7601791575064043, 'border_count': 41}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:20:55,560] Trial 108 finished with value: -0.9425610218235851 and parameters: {'learning_rate': 0.09447654932980647, 'depth': 10, 'l2_leaf_reg': 4.293811052104646, 'border_count': 54}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:21:14,813] Trial 109 finished with value: -0.9422682990220691 and parameters: {'learning_rate': 0.061637346338844656, 'depth': 9, 'l2_leaf_reg': 3.7006642267437058, 'border_count': 190}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:21:37,587] Trial 110 finished with value: -0.9422161568153312 and parameters: {'learning_rate': 0.08603774076882283, 'depth': 11, 'l2_leaf_reg': 3.4487176428763218, 'border_count': 167}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:21:59,381] Trial 111 finished with value: -0.9425965256036231 and parameters: {'learning_rate': 0.0367959953998531, 'depth': 10, 'l2_leaf_reg': 3.6517961190539077, 'border_count': 51}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:22:21,521] Trial 112 finished with value: -0.9431369631075869 and parameters: {'learning_rate': 0.053833905920568755, 'depth': 10, 'l2_leaf_reg': 6.32293449511947, 'border_count': 79}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:22:40,867] Trial 113 finished with value: -0.942942784409257 and parameters: {'learning_rate': 0.07321194969174849, 'depth': 10, 'l2_leaf_reg': 3.9247323735019646, 'border_count': 102}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:23:02,814] Trial 114 finished with value: -0.9428633390853897 and parameters: {'learning_rate': 0.053249734896678544, 'depth': 10, 'l2_leaf_reg': 6.4901572802605925, 'border_count': 58}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:23:19,980] Trial 115 finished with value: -0.9423574192136629 and parameters: {'learning_rate': 0.06510363826951646, 'depth': 10, 'l2_leaf_reg': 3.001841811974714, 'border_count': 112}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:23:41,970] Trial 116 finished with value: -0.9423380345084726 and parameters: {'learning_rate': 0.02919397346072728, 'depth': 9, 'l2_leaf_reg': 4.869293463263759, 'border_count': 65}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:24:05,669] Trial 117 finished with value: -0.9428062735065369 and parameters: {'learning_rate': 0.04535174683928676, 'depth': 10, 'l2_leaf_reg': 4.121685852851939, 'border_count': 77}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:24:27,057] Trial 118 finished with value: -0.9429736729040112 and parameters: {'learning_rate': 0.12272841530239693, 'depth': 11, 'l2_leaf_reg': 5.9242103126212005, 'border_count': 94}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:24:48,914] Trial 119 finished with value: -0.9431927166231345 and parameters: {'learning_rate': 0.04973416505091599, 'depth': 9, 'l2_leaf_reg': 6.7149024098668235, 'border_count': 85}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:25:15,331] Trial 120 finished with value: -0.9428783975502899 and parameters: {'learning_rate': 0.04159770073796744, 'depth': 10, 'l2_leaf_reg': 6.968457977748343, 'border_count': 89}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:25:33,166] Trial 121 finished with value: -0.9431471992421183 and parameters: {'learning_rate': 0.07823014481681492, 'depth': 9, 'l2_leaf_reg': 6.6647862066540915, 'border_count': 71}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:25:46,161] Trial 122 finished with value: -0.9423164002937664 and parameters: {'learning_rate': 0.10124743297701463, 'depth': 8, 'l2_leaf_reg': 6.657588205168641, 'border_count': 81}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:26:03,994] Trial 123 finished with value: -0.942802772302777 and parameters: {'learning_rate': 0.0800564829455161, 'depth': 9, 'l2_leaf_reg': 6.359457004955955, 'border_count': 82}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:26:20,677] Trial 124 finished with value: -0.9428167719492236 and parameters: {'learning_rate': 0.08848842106156932, 'depth': 9, 'l2_leaf_reg': 7.314061893815277, 'border_count': 69}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:26:41,112] Trial 125 finished with value: -0.9426080994679872 and parameters: {'learning_rate': 0.07122685311797354, 'depth': 10, 'l2_leaf_reg': 6.714688246803224, 'border_count': 95}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:26:55,145] Trial 126 finished with value: -0.942259855635626 and parameters: {'learning_rate': 0.11205606297018973, 'depth': 9, 'l2_leaf_reg': 6.905125423264679, 'border_count': 86}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:27:11,680] Trial 127 finished with value: -0.9421733238403436 and parameters: {'learning_rate': 0.09294567345250399, 'depth': 10, 'l2_leaf_reg': 6.021334482495175, 'border_count': 241}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:27:49,487] Trial 128 finished with value: -0.9423923031497614 and parameters: {'learning_rate': 0.06259501399825497, 'depth': 11, 'l2_leaf_reg': 7.7789893362749645, 'border_count': 106}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:28:14,982] Trial 129 finished with value: -0.9430059524188994 and parameters: {'learning_rate': 0.04943379021265671, 'depth': 10, 'l2_leaf_reg': 6.377333539324442, 'border_count': 127}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 22:28:33,023] Trial 130 finished with value: -0.9432855629248562 and parameters: {'learning_rate': 0.07796570568432348, 'depth': 9, 'l2_leaf_reg': 6.509637576100484, 'border_count': 138}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:28:50,737] Trial 131 finished with value: -0.9429528760926467 and parameters: {'learning_rate': 0.07779193279689399, 'depth': 9, 'l2_leaf_reg': 5.569498823220516, 'border_count': 119}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:29:06,350] Trial 132 finished with value: -0.9428914357906695 and parameters: {'learning_rate': 0.10426475691304454, 'depth': 9, 'l2_leaf_reg': 6.567130347964062, 'border_count': 143}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:29:27,789] Trial 133 finished with value: -0.9429498565221636 and parameters: {'learning_rate': 0.07019858740767233, 'depth': 10, 'l2_leaf_reg': 7.194948680112485, 'border_count': 131}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:29:48,177] Trial 134 finished with value: -0.9427815615597552 and parameters: {'learning_rate': 0.05511002867282696, 'depth': 9, 'l2_leaf_reg': 6.22800975701849, 'border_count': 138}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:30:06,802] Trial 135 finished with value: -0.942565454607665 and parameters: {'learning_rate': 0.08355105831893535, 'depth': 10, 'l2_leaf_reg': 6.737580892285387, 'border_count': 148}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:30:23,093] Trial 136 finished with value: -0.9429126145183947 and parameters: {'learning_rate': 0.07594761542842202, 'depth': 9, 'l2_leaf_reg': 5.7458025554307, 'border_count': 71}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:30:41,021] Trial 137 finished with value: -0.9426575092578686 and parameters: {'learning_rate': 0.09233243289913749, 'depth': 10, 'l2_leaf_reg': 6.496377376235971, 'border_count': 155}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:30:53,592] Trial 138 finished with value: -0.9424835310686976 and parameters: {'learning_rate': 0.0838171356601687, 'depth': 8, 'l2_leaf_reg': 7.010344801621821, 'border_count': 64}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:31:10,645] Trial 139 finished with value: -0.9425251219069601 and parameters: {'learning_rate': 0.06602752717727155, 'depth': 10, 'l2_leaf_reg': 3.220749409375599, 'border_count': 74}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:31:19,948] Trial 140 finished with value: -0.9414494133535743 and parameters: {'learning_rate': 0.1662324813118718, 'depth': 9, 'l2_leaf_reg': 7.411313806945813, 'border_count': 59}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:31:45,198] Trial 141 finished with value: -0.9429386555294903 and parameters: {'learning_rate': 0.05124377499623269, 'depth': 10, 'l2_leaf_reg': 6.3928997083840455, 'border_count': 126}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:32:11,385] Trial 142 finished with value: -0.9429005447200032 and parameters: {'learning_rate': 0.04427469599043805, 'depth': 10, 'l2_leaf_reg': 6.120510083246771, 'border_count': 128}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:32:35,395] Trial 143 finished with value: -0.9424091254435469 and parameters: {'learning_rate': 0.04799422745196114, 'depth': 10, 'l2_leaf_reg': 6.291123032548472, 'border_count': 123}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:33:03,890] Trial 144 finished with value: -0.9427824151548034 and parameters: {'learning_rate': 0.038875205192210334, 'depth': 10, 'l2_leaf_reg': 6.01105435995857, 'border_count': 140}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:33:31,245] Trial 145 finished with value: -0.9423732233560911 and parameters: {'learning_rate': 0.034044689306740296, 'depth': 10, 'l2_leaf_reg': 6.91196289423486, 'border_count': 133}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:34:04,385] Trial 146 finished with value: -0.9427397784365825 and parameters: {'learning_rate': 0.0570202944380588, 'depth': 11, 'l2_leaf_reg': 7.108119889072677, 'border_count': 78}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:34:25,425] Trial 147 finished with value: -0.9424991308848686 and parameters: {'learning_rate': 0.06143131818149311, 'depth': 10, 'l2_leaf_reg': 3.4797887731622725, 'border_count': 225}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:34:47,637] Trial 148 finished with value: -0.9429119142209933 and parameters: {'learning_rate': 0.05190911947599111, 'depth': 9, 'l2_leaf_reg': 6.38075404442762, 'border_count': 116}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:34:59,456] Trial 149 finished with value: -0.9418915688140016 and parameters: {'learning_rate': 0.1322969090415345, 'depth': 10, 'l2_leaf_reg': 3.745639383504758, 'border_count': 249}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 22:35:01,863] A new study created in memory with name: no-name-1c2e9a87-669a-450a-882c-3cb813a0001b
[I 2025-08-05 22:35:17,584] Trial 0 finished with value: -0.9358323247514468 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.9358323247514468.
[I 2025-08-05 22:35:20,599] Trial 1 finished with value: -0.9064751894816988 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.9358323247514468.
[I 2025-08-05 22:35:31,119] Trial 2 finished with value: -0.9386360144747428 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:35:36,550] Trial 3 finished with value: -0.9303290569351471 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:35:51,882] Trial 4 finished with value: -0.9303133884712121 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:35:55,042] Trial 5 finished with value: -0.8544275616296588 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:03,595] Trial 6 finished with value: -0.9352955368669097 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:06,726] Trial 7 finished with value: -0.840740931036518 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:11,248] Trial 8 finished with value: -0.9071091862428273 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:25,729] Trial 9 finished with value: -0.933741776643824 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:28,565] Trial 10 finished with value: -0.9363597177561258 and parameters: {'learning_rate': 0.13388899274129873, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.7846562513261506, 'bagging_fraction': 0.721539898400351, 'reg_alpha': 4.344469108550396, 'reg_lambda': 0.010039786460205695}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:30,927] Trial 11 finished with value: -0.9352133014197529 and parameters: {'learning_rate': 0.17061837680423544, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.7930679183446125, 'bagging_fraction': 0.7171781358782056, 'reg_alpha': 4.188416507348498, 'reg_lambda': 0.008427137829973095}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:35,210] Trial 12 finished with value: -0.9370543645493743 and parameters: {'learning_rate': 0.1252539331847696, 'num_leaves': 119, 'max_depth': 8, 'min_child_samples': 15, 'feature_fraction': 0.760313173810765, 'bagging_fraction': 0.70412092456293, 'reg_alpha': 5.610661224399163e-05, 'reg_lambda': 0.01686118861017418}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:41,061] Trial 13 finished with value: -0.9382938176495343 and parameters: {'learning_rate': 0.09547520802157841, 'num_leaves': 122, 'max_depth': 9, 'min_child_samples': 30, 'feature_fraction': 0.7259348037363833, 'bagging_fraction': 0.8304278626461433, 'reg_alpha': 4.6852145960758174e-05, 'reg_lambda': 0.030276821312472436}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 22:36:46,404] Trial 14 finished with value: -0.9391376167980623 and parameters: {'learning_rate': 0.07544873381168117, 'num_leaves': 95, 'max_depth': 10, 'min_child_samples': 32, 'feature_fraction': 0.8649174147658507, 'bagging_fraction': 0.8633753186051892, 'reg_alpha': 7.828404334305551e-07, 'reg_lambda': 1.6413474196163053e-05}. Best is trial 14 with value: -0.9391376167980623.
[I 2025-08-05 22:36:52,240] Trial 15 finished with value: -0.9386518630652123 and parameters: {'learning_rate': 0.08019736966659374, 'num_leaves': 80, 'max_depth': 11, 'min_child_samples': 38, 'feature_fraction': 0.8620313930247292, 'bagging_fraction': 0.8383609747044727, 'reg_alpha': 5.482417813288472e-07, 'reg_lambda': 1.2069191644341846e-08}. Best is trial 14 with value: -0.9391376167980623.
[I 2025-08-05 22:36:58,224] Trial 16 finished with value: -0.9377470366565971 and parameters: {'learning_rate': 0.07277037581026277, 'num_leaves': 82, 'max_depth': 11, 'min_child_samples': 46, 'feature_fraction': 0.8805304594988683, 'bagging_fraction': 0.8429080872801051, 'reg_alpha': 1.103217333805366e-08, 'reg_lambda': 1.4298887258730937e-08}. Best is trial 14 with value: -0.9391376167980623.
[I 2025-08-05 22:37:02,936] Trial 17 finished with value: -0.9392903590852875 and parameters: {'learning_rate': 0.08866125118089212, 'num_leaves': 89, 'max_depth': 11, 'min_child_samples': 24, 'feature_fraction': 0.992704701660188, 'bagging_fraction': 0.9041308029382291, 'reg_alpha': 3.784188519300372e-07, 'reg_lambda': 1.4441197528339097e-08}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 22:37:07,367] Trial 18 finished with value: -0.9383805005420875 and parameters: {'learning_rate': 0.10643375865859607, 'num_leaves': 90, 'max_depth': 13, 'min_child_samples': 25, 'feature_fraction': 0.9995275195880237, 'bagging_fraction': 0.9070821469417789, 'reg_alpha': 5.814069983326867e-07, 'reg_lambda': 4.09223724608313e-06}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 22:37:10,609] Trial 19 finished with value: -0.9372928990771137 and parameters: {'learning_rate': 0.19840774893517626, 'num_leaves': 166, 'max_depth': 10, 'min_child_samples': 22, 'feature_fraction': 0.9448890776027741, 'bagging_fraction': 0.9134336554829188, 'reg_alpha': 8.990994523866224e-08, 'reg_lambda': 0.00022163473160045644}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 22:37:18,480] Trial 20 finished with value: -0.9381493291981198 and parameters: {'learning_rate': 0.041843890469109725, 'num_leaves': 37, 'max_depth': 13, 'min_child_samples': 50, 'feature_fraction': 0.8380549877235325, 'bagging_fraction': 0.7807851013064275, 'reg_alpha': 0.00042162894510326974, 'reg_lambda': 0.0011132716012388656}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 22:37:24,729] Trial 21 finished with value: -0.9382176435795024 and parameters: {'learning_rate': 0.07368156611132125, 'num_leaves': 95, 'max_depth': 10, 'min_child_samples': 41, 'feature_fraction': 0.8589517181763427, 'bagging_fraction': 0.8720669794373067, 'reg_alpha': 9.126583215501419e-07, 'reg_lambda': 2.932791619952162e-08}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 22:37:30,659] Trial 22 finished with value: -0.9393197152980373 and parameters: {'learning_rate': 0.08095518480259396, 'num_leaves': 73, 'max_depth': 11, 'min_child_samples': 31, 'feature_fraction': 0.9251147764908157, 'bagging_fraction': 0.7852009740611057, 'reg_alpha': 1.1879001646291583e-07, 'reg_lambda': 1.0050960158345228e-08}. Best is trial 22 with value: -0.9393197152980373.
[I 2025-08-05 22:37:37,523] Trial 23 finished with value: -0.9391112380967274 and parameters: {'learning_rate': 0.059240884942971896, 'num_leaves': 109, 'max_depth': 10, 'min_child_samples': 22, 'feature_fraction': 0.9312404495902853, 'bagging_fraction': 0.7629131725299532, 'reg_alpha': 9.395699080914442e-08, 'reg_lambda': 1.8962942178825404e-06}. Best is trial 22 with value: -0.9393197152980373.
[I 2025-08-05 22:37:41,450] Trial 24 finished with value: -0.9395822963651197 and parameters: {'learning_rate': 0.10778592671166555, 'num_leaves': 61, 'max_depth': 13, 'min_child_samples': 31, 'feature_fraction': 0.9851899024509025, 'bagging_fraction': 0.7887957332693476, 'reg_alpha': 1.0584596216672896e-07, 'reg_lambda': 1.0081402798277421e-07}. Best is trial 24 with value: -0.9395822963651197.
[I 2025-08-05 22:37:45,133] Trial 25 finished with value: -0.9372158266429611 and parameters: {'learning_rate': 0.14145556446180368, 'num_leaves': 48, 'max_depth': 14, 'min_child_samples': 59, 'feature_fraction': 0.9786689607083605, 'bagging_fraction': 0.6709821158612296, 'reg_alpha': 1.606457901282244e-08, 'reg_lambda': 7.636974371947272e-08}. Best is trial 24 with value: -0.9395822963651197.
[I 2025-08-05 22:37:49,447] Trial 26 finished with value: -0.9399258312624517 and parameters: {'learning_rate': 0.09957543478569024, 'num_leaves': 65, 'max_depth': 13, 'min_child_samples': 28, 'feature_fraction': 0.9223884211161939, 'bagging_fraction': 0.7936347090519561, 'reg_alpha': 8.277723185778568e-08, 'reg_lambda': 3.416245730281718e-08}. Best is trial 26 with value: -0.9399258312624517.
[I 2025-08-05 22:37:53,138] Trial 27 finished with value: -0.93822463948998 and parameters: {'learning_rate': 0.11189626912133305, 'num_leaves': 30, 'max_depth': 13, 'min_child_samples': 48, 'feature_fraction': 0.9145942595193253, 'bagging_fraction': 0.7934594537884057, 'reg_alpha': 5.570907652570733e-08, 'reg_lambda': 9.69364939394014e-08}. Best is trial 26 with value: -0.9399258312624517.
[I 2025-08-05 22:37:56,696] Trial 28 finished with value: -0.9386851235869397 and parameters: {'learning_rate': 0.15646306800202422, 'num_leaves': 70, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.9492122723181817, 'bagging_fraction': 0.791870495386907, 'reg_alpha': 3.572651935413191e-06, 'reg_lambda': 3.5107060432680136e-06}. Best is trial 26 with value: -0.9399258312624517.
[I 2025-08-05 22:38:03,928] Trial 29 finished with value: -0.940229361438551 and parameters: {'learning_rate': 0.03248873723539237, 'num_leaves': 27, 'max_depth': 12, 'min_child_samples': 31, 'feature_fraction': 0.9057757750324127, 'bagging_fraction': 0.667795884634778, 'reg_alpha': 1.105217367695826e-07, 'reg_lambda': 9.2063093507131e-08}. Best is trial 29 with value: -0.940229361438551.
[I 2025-08-05 22:38:11,961] Trial 30 finished with value: -0.9377234088725122 and parameters: {'learning_rate': 0.03580770217284296, 'num_leaves': 26, 'max_depth': 12, 'min_child_samples': 66, 'feature_fraction': 0.8280573305037836, 'bagging_fraction': 0.6800005880881586, 'reg_alpha': 3.2961158326960234e-08, 'reg_lambda': 7.606009819443854e-07}. Best is trial 29 with value: -0.940229361438551.
[I 2025-08-05 22:38:23,453] Trial 31 finished with value: -0.9406841204422504 and parameters: {'learning_rate': 0.025418382687662035, 'num_leaves': 57, 'max_depth': 12, 'min_child_samples': 29, 'feature_fraction': 0.9074927932645798, 'bagging_fraction': 0.640221170996667, 'reg_alpha': 9.30089964424005e-08, 'reg_lambda': 6.645254492681197e-08}. Best is trial 31 with value: -0.9406841204422504.
[I 2025-08-05 22:38:35,144] Trial 32 finished with value: -0.9407802360459827 and parameters: {'learning_rate': 0.020488981456792527, 'num_leaves': 47, 'max_depth': 14, 'min_child_samples': 31, 'feature_fraction': 0.9089379155645243, 'bagging_fraction': 0.6240633959161376, 'reg_alpha': 1.735933982308285e-07, 'reg_lambda': 1.365832943500582e-07}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 22:38:45,734] Trial 33 finished with value: -0.9393493018207615 and parameters: {'learning_rate': 0.022192689867975957, 'num_leaves': 42, 'max_depth': 14, 'min_child_samples': 43, 'feature_fraction': 0.9046442881610571, 'bagging_fraction': 0.6096905896771859, 'reg_alpha': 2.476965113393979e-06, 'reg_lambda': 2.709572509762068e-07}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 22:38:55,149] Trial 34 finished with value: -0.939252423002402 and parameters: {'learning_rate': 0.018609576794590695, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 34, 'feature_fraction': 0.836726891130765, 'bagging_fraction': 0.6491225946823016, 'reg_alpha': 2.2404451529478362e-07, 'reg_lambda': 4.678834163459716e-08}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 22:39:00,988] Trial 35 finished with value: -0.9389949962154247 and parameters: {'learning_rate': 0.03325255721697557, 'num_leaves': 19, 'max_depth': 12, 'min_child_samples': 27, 'feature_fraction': 0.8995582282887592, 'bagging_fraction': 0.5830617308602539, 'reg_alpha': 1.0240160435877175e-08, 'reg_lambda': 2.626566773361515e-07}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 22:39:10,303] Trial 36 finished with value: -0.9414279581870597 and parameters: {'learning_rate': 0.027582314726127974, 'num_leaves': 42, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.9356175081930885, 'bagging_fraction': 0.6180192191856357, 'reg_alpha': 1.8194127844478728e-06, 'reg_lambda': 1.5030766348639562e-06}. Best is trial 36 with value: -0.9414279581870597.
[I 2025-08-05 22:39:18,933] Trial 37 finished with value: -0.9417902265749312 and parameters: {'learning_rate': 0.029551432366818276, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.9527979513972848, 'bagging_fraction': 0.6082041083331982, 'reg_alpha': 1.839540243414165e-06, 'reg_lambda': 1.2412290940965426e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:39:29,907] Trial 38 finished with value: -0.9411554880377537 and parameters: {'learning_rate': 0.017793714923269734, 'num_leaves': 42, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.9440541379222797, 'bagging_fraction': 0.5013339806386407, 'reg_alpha': 1.0491591910252639e-05, 'reg_lambda': 4.380753011507096e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:39:41,751] Trial 39 finished with value: -0.940888691395142 and parameters: {'learning_rate': 0.01593244524866308, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9582664347831222, 'bagging_fraction': 0.5200172892774267, 'reg_alpha': 1.2060167102548226e-05, 'reg_lambda': 5.572454712924675e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:39:52,800] Trial 40 finished with value: -0.9410448718538481 and parameters: {'learning_rate': 0.016577358530439255, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9549192626806521, 'bagging_fraction': 0.5022489289105885, 'reg_alpha': 0.0002615038412915418, 'reg_lambda': 5.6810579360492794e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:40:02,787] Trial 41 finished with value: -0.9406980544541378 and parameters: {'learning_rate': 0.017107517739663066, 'num_leaves': 36, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9557207725989134, 'bagging_fraction': 0.5066085019066588, 'reg_alpha': 0.0002651361683944071, 'reg_lambda': 0.0001063483463457663}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:40:08,695] Trial 42 finished with value: -0.9347579784956845 and parameters: {'learning_rate': 0.01482994561337221, 'num_leaves': 15, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.9699897623816666, 'bagging_fraction': 0.564286035042707, 'reg_alpha': 1.044965849488448e-05, 'reg_lambda': 4.095625882071673e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:40:19,039] Trial 43 finished with value: -0.9411529516479682 and parameters: {'learning_rate': 0.0272321530264781, 'num_leaves': 56, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.9621113717037826, 'bagging_fraction': 0.507182386329085, 'reg_alpha': 5.370645816430037e-05, 'reg_lambda': 0.0009173840234092669}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:40:35,043] Trial 44 finished with value: -0.934671370765944 and parameters: {'learning_rate': 0.027348194987809802, 'num_leaves': 55, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.5007250058963767, 'bagging_fraction': 0.5463215536736619, 'reg_alpha': 0.0004536772969541355, 'reg_lambda': 0.0006667011413596759}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:40:52,211] Trial 45 finished with value: -0.9305989355323178 and parameters: {'learning_rate': 0.04873691578976296, 'num_leaves': 150, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.6608583747057708, 'bagging_fraction': 0.580460474209689, 'reg_alpha': 4.7211493977100184e-05, 'reg_lambda': 0.003015537486351291}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:41:25,910] Trial 46 finished with value: -0.9380381153095009 and parameters: {'learning_rate': 0.01196235369432732, 'num_leaves': 214, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.932828117314998, 'bagging_fraction': 0.5026642369227838, 'reg_alpha': 0.000132918012488016, 'reg_lambda': 7.52139355173863e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:41:29,790] Trial 47 finished with value: -0.9080781814279175 and parameters: {'learning_rate': 0.02713021919386878, 'num_leaves': 8, 'max_depth': 5, 'min_child_samples': 94, 'feature_fraction': 0.5764779065133137, 'bagging_fraction': 0.5306300475259297, 'reg_alpha': 0.0011136998875651031, 'reg_lambda': 0.05378130377146102}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:41:46,028] Trial 48 finished with value: -0.9362269091040423 and parameters: {'learning_rate': 0.020656432392174854, 'num_leaves': 104, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.9714632145831618, 'bagging_fraction': 0.558282717877489, 'reg_alpha': 1.6278623696190164e-06, 'reg_lambda': 0.24873336187090317}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:41:57,241] Trial 49 finished with value: -0.941248261775919 and parameters: {'learning_rate': 0.029267408073804388, 'num_leaves': 72, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.8888518717361471, 'bagging_fraction': 0.5985740086544475, 'reg_alpha': 0.009885089249127793, 'reg_lambda': 1.214528944303415e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:42:17,102] Trial 50 finished with value: -0.9367872517627915 and parameters: {'learning_rate': 0.02859764349536189, 'num_leaves': 253, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.885422621206246, 'bagging_fraction': 0.6005441065092483, 'reg_alpha': 0.010667593630787783, 'reg_lambda': 9.393624153570897e-07}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:42:26,453] Trial 51 finished with value: -0.9407839940562269 and parameters: {'learning_rate': 0.0389892131665008, 'num_leaves': 72, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.9441041125913971, 'bagging_fraction': 0.5254312608215007, 'reg_alpha': 2.348818776153583e-05, 'reg_lambda': 8.85325127545241e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:42:39,754] Trial 52 finished with value: -0.9410508084819378 and parameters: {'learning_rate': 0.017923685594281806, 'num_leaves': 53, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.9976982229003776, 'bagging_fraction': 0.6006055940422969, 'reg_alpha': 0.007997338081599673, 'reg_lambda': 2.97631700042988e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:42:51,052] Trial 53 finished with value: -0.9410502291341812 and parameters: {'learning_rate': 0.024170495956602034, 'num_leaves': 54, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.9886129427109516, 'bagging_fraction': 0.5982458766516078, 'reg_alpha': 0.06069925456844537, 'reg_lambda': 0.0002122567066046376}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:43:03,357] Trial 54 finished with value: -0.9395055932382379 and parameters: {'learning_rate': 0.030315094213408268, 'num_leaves': 83, 'max_depth': 13, 'min_child_samples': 25, 'feature_fraction': 0.9990519139240002, 'bagging_fraction': 0.618254320502799, 'reg_alpha': 0.0074826671146528655, 'reg_lambda': 1.695231698812241e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:43:20,676] Trial 55 finished with value: -0.9391781602326947 and parameters: {'learning_rate': 0.013339499329131636, 'num_leaves': 66, 'max_depth': 13, 'min_child_samples': 20, 'feature_fraction': 0.7717047516591609, 'bagging_fraction': 0.5807497702910516, 'reg_alpha': 0.08339888649480151, 'reg_lambda': 2.453993542900561e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:43:30,816] Trial 56 finished with value: -0.9405941226929395 and parameters: {'learning_rate': 0.019040308955270657, 'num_leaves': 34, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.8116881409924636, 'bagging_fraction': 0.5496263084746699, 'reg_alpha': 0.021736317067727044, 'reg_lambda': 0.001245869919736421}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:43:39,967] Trial 57 finished with value: -0.9393500074331002 and parameters: {'learning_rate': 0.03879697273376695, 'num_leaves': 49, 'max_depth': 13, 'min_child_samples': 24, 'feature_fraction': 0.7254655500314888, 'bagging_fraction': 0.6529150678286154, 'reg_alpha': 0.9151336436729196, 'reg_lambda': 8.751787782783505e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:43:52,846] Trial 58 finished with value: -0.9402163476231655 and parameters: {'learning_rate': 0.02223200289486612, 'num_leaves': 75, 'max_depth': 12, 'min_child_samples': 13, 'feature_fraction': 0.9746206788599002, 'bagging_fraction': 0.7002328409375498, 'reg_alpha': 0.002496340297897863, 'reg_lambda': 0.00013425401921537887}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:43:58,210] Trial 59 finished with value: -0.9330464639300784 and parameters: {'learning_rate': 0.04714380640073784, 'num_leaves': 18, 'max_depth': 6, 'min_child_samples': 71, 'feature_fraction': 0.8778123371452727, 'bagging_fraction': 0.7366140415208658, 'reg_alpha': 4.804303510982372e-06, 'reg_lambda': 6.298245854416226}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:44:13,073] Trial 60 finished with value: -0.9398477714883813 and parameters: {'learning_rate': 0.010472739166202503, 'num_leaves': 63, 'max_depth': 9, 'min_child_samples': 19, 'feature_fraction': 0.9350699437350039, 'bagging_fraction': 0.5962713014637445, 'reg_alpha': 0.27252629699878106, 'reg_lambda': 2.4564061034354106e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:44:23,775] Trial 61 finished with value: -0.9410292655197324 and parameters: {'learning_rate': 0.024217081433350763, 'num_leaves': 53, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.985560484353206, 'bagging_fraction': 0.6244418758740675, 'reg_alpha': 0.03506997695868906, 'reg_lambda': 0.0004891693812902077}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:44:33,880] Trial 62 finished with value: -0.9408481590094666 and parameters: {'learning_rate': 0.02535915537085988, 'num_leaves': 52, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.9658125527588133, 'bagging_fraction': 0.5949940018003871, 'reg_alpha': 0.005837417163241207, 'reg_lambda': 0.00021977622423524293}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:44:40,808] Trial 63 finished with value: -0.9401084921326179 and parameters: {'learning_rate': 0.05548124008520944, 'num_leaves': 80, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.9383186819293876, 'bagging_fraction': 0.5639650426327242, 'reg_alpha': 0.0011181506163954985, 'reg_lambda': 0.004404786892593394}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:44:49,815] Trial 64 finished with value: -0.9410305948360291 and parameters: {'learning_rate': 0.035250277573057806, 'num_leaves': 60, 'max_depth': 14, 'min_child_samples': 23, 'feature_fraction': 0.9884821415694035, 'bagging_fraction': 0.5230876333541195, 'reg_alpha': 0.00010522612634101224, 'reg_lambda': 1.716253252437858e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:44:58,489] Trial 65 finished with value: -0.9415221480410473 and parameters: {'learning_rate': 0.02973125240148336, 'num_leaves': 41, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.9989516455010894, 'bagging_fraction': 0.5428483969629028, 'reg_alpha': 0.057216745349472735, 'reg_lambda': 0.00025804929460616465}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:45:04,662] Trial 66 finished with value: -0.9402248291910554 and parameters: {'learning_rate': 0.043101125456723406, 'num_leaves': 41, 'max_depth': 13, 'min_child_samples': 36, 'feature_fraction': 0.966205218702277, 'bagging_fraction': 0.5414862263582935, 'reg_alpha': 0.3778575408772894, 'reg_lambda': 0.001616010703981843}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:45:11,916] Trial 67 finished with value: -0.938369957257251 and parameters: {'learning_rate': 0.01840435560614111, 'num_leaves': 22, 'max_depth': 11, 'min_child_samples': 26, 'feature_fraction': 0.9981867572004042, 'bagging_fraction': 0.5702679200028696, 'reg_alpha': 2.2762943469330862e-05, 'reg_lambda': 3.17443080124801e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:45:25,683] Trial 68 finished with value: -0.9383397221737788 and parameters: {'learning_rate': 0.03143760290498216, 'num_leaves': 194, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.9246974124145739, 'bagging_fraction': 0.5355426475907419, 'reg_alpha': 1.7764939352811158e-06, 'reg_lambda': 4.320122928600514e-07}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:45:35,934] Trial 69 finished with value: -0.9365617225844387 and parameters: {'learning_rate': 0.028899476532791527, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 87, 'feature_fraction': 0.8606154683379011, 'bagging_fraction': 0.5173098032175094, 'reg_alpha': 7.697737483297444e-06, 'reg_lambda': 1.1139174047495622e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:45:51,626] Trial 70 finished with value: -0.9358340384715879 and parameters: {'learning_rate': 0.020797579182067243, 'num_leaves': 100, 'max_depth': 13, 'min_child_samples': 22, 'feature_fraction': 0.9518304052683318, 'bagging_fraction': 0.9935245282369738, 'reg_alpha': 9.30699889481333, 'reg_lambda': 5.227655785267302e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:01,464] Trial 71 finished with value: -0.9417099257658424 and parameters: {'learning_rate': 0.02562425521094912, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.9771612098370345, 'bagging_fraction': 0.6334339241047626, 'reg_alpha': 0.058856899198349334, 'reg_lambda': 0.00029636913220294244}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:09,907] Trial 72 finished with value: -0.9415959949301824 and parameters: {'learning_rate': 0.035568302370797514, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.9452703762489151, 'bagging_fraction': 0.6363865356566889, 'reg_alpha': 0.02256179178734538, 'reg_lambda': 0.0007258173371299605}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:17,567] Trial 73 finished with value: -0.9412437186039837 and parameters: {'learning_rate': 0.03527300033504935, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.8952596920404443, 'bagging_fraction': 0.6385363493018672, 'reg_alpha': 0.2212686569959798, 'reg_lambda': 0.002764312306117732}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:25,277] Trial 74 finished with value: -0.9416134346459095 and parameters: {'learning_rate': 0.03506542529696509, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9189882487498834, 'bagging_fraction': 0.6350063341457729, 'reg_alpha': 0.19117251291037346, 'reg_lambda': 0.0003550676992463446}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:30,339] Trial 75 finished with value: -0.9380835269816847 and parameters: {'learning_rate': 0.03564121206770721, 'num_leaves': 14, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.8919886230028756, 'bagging_fraction': 0.6379706258846081, 'reg_alpha': 0.1527664171814712, 'reg_lambda': 0.0022948049593900046}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:36,047] Trial 76 finished with value: -0.9403881144044071 and parameters: {'learning_rate': 0.041175297834593574, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 27, 'feature_fraction': 0.8708653791254122, 'bagging_fraction': 0.6571684316259844, 'reg_alpha': 1.034790711290251, 'reg_lambda': 0.000327363769194104}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:42,442] Trial 77 finished with value: -0.9398240590129714 and parameters: {'learning_rate': 0.03361278574210592, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.9180168740253157, 'bagging_fraction': 0.6923928569586306, 'reg_alpha': 0.03682129108256342, 'reg_lambda': 0.007187119041228315}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:50,036] Trial 78 finished with value: -0.9384571671114363 and parameters: {'learning_rate': 0.03804424737328183, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 52, 'feature_fraction': 0.8947998733429902, 'bagging_fraction': 0.626576762464837, 'reg_alpha': 0.1661027290931875, 'reg_lambda': 0.03533987286488324}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:46:58,508] Trial 79 finished with value: -0.9390174271998347 and parameters: {'learning_rate': 0.03065541710029634, 'num_leaves': 67, 'max_depth': 8, 'min_child_samples': 22, 'feature_fraction': 0.8422884338658384, 'bagging_fraction': 0.685277514147042, 'reg_alpha': 1.0043379496101699, 'reg_lambda': 0.0164969221190406}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:47:04,625] Trial 80 finished with value: -0.9381100310983008 and parameters: {'learning_rate': 0.05092378661690799, 'num_leaves': 36, 'max_depth': 12, 'min_child_samples': 59, 'feature_fraction': 0.9228655704965926, 'bagging_fraction': 0.666391630591921, 'reg_alpha': 0.5695719008946426, 'reg_lambda': 0.0005143141349202528}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 22:47:11,202] Trial 81 finished with value: -0.9418288677397963 and parameters: {'learning_rate': 0.04546279311257447, 'num_leaves': 46, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.941666701161769, 'bagging_fraction': 0.6118642664387898, 'reg_alpha': 0.021749542597992465, 'reg_lambda': 8.096570967798265e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:47:18,127] Trial 82 finished with value: -0.9413747245258364 and parameters: {'learning_rate': 0.04591933827905851, 'num_leaves': 48, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.9134346797660532, 'bagging_fraction': 0.6118309448354052, 'reg_alpha': 0.041585276815809064, 'reg_lambda': 0.00012675530437792945}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:47:25,016] Trial 83 finished with value: -0.9417416862626578 and parameters: {'learning_rate': 0.04543298712488206, 'num_leaves': 47, 'max_depth': 13, 'min_child_samples': 19, 'feature_fraction': 0.9800875882414494, 'bagging_fraction': 0.6141967221606958, 'reg_alpha': 0.017303993261789625, 'reg_lambda': 9.079186451802048e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:47:31,664] Trial 84 finished with value: -0.9413861649318612 and parameters: {'learning_rate': 0.0452009478515881, 'num_leaves': 47, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.9814486995824696, 'bagging_fraction': 0.6144915460696456, 'reg_alpha': 0.020233905159067776, 'reg_lambda': 7.794833484215587e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:47:37,077] Trial 85 finished with value: -0.9401439214863432 and parameters: {'learning_rate': 0.06710930227069696, 'num_leaves': 60, 'max_depth': 13, 'min_child_samples': 29, 'feature_fraction': 0.9844448297570059, 'bagging_fraction': 0.6303030921551039, 'reg_alpha': 0.004291123627855172, 'reg_lambda': 8.700614312458632e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:47:41,819] Trial 86 finished with value: -0.941273720971205 and parameters: {'learning_rate': 0.05858249125827002, 'num_leaves': 29, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.9732206071602314, 'bagging_fraction': 0.5863446705012324, 'reg_alpha': 0.020216994653673326, 'reg_lambda': 7.559864753576245e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:47:50,177] Trial 87 finished with value: -0.938601815053536 and parameters: {'learning_rate': 0.05428092102479892, 'num_leaves': 166, 'max_depth': 13, 'min_child_samples': 24, 'feature_fraction': 0.9484170913074125, 'bagging_fraction': 0.6452533746008096, 'reg_alpha': 0.12626662954182333, 'reg_lambda': 0.00018315435349542376}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:47:56,329] Trial 88 finished with value: -0.9412697174612022 and parameters: {'learning_rate': 0.04441257777787204, 'num_leaves': 48, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.957500428464932, 'bagging_fraction': 0.613069254109234, 'reg_alpha': 0.02034622790231323, 'reg_lambda': 0.0003356422923075626}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:03,188] Trial 89 finished with value: -0.9389076846062199 and parameters: {'learning_rate': 0.06317956456366983, 'num_leaves': 120, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.9788364609892463, 'bagging_fraction': 0.7140103891383276, 'reg_alpha': 0.08250530097292245, 'reg_lambda': 0.0008259446408430205}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:06,095] Trial 90 finished with value: -0.9023511304597781 and parameters: {'learning_rate': 0.039954535581386515, 'num_leaves': 231, 'max_depth': 3, 'min_child_samples': 26, 'feature_fraction': 0.9374744479738298, 'bagging_fraction': 0.6738731867412078, 'reg_alpha': 2.488820172124153, 'reg_lambda': 6.625094996066022e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:11,566] Trial 91 finished with value: -0.9411156293804227 and parameters: {'learning_rate': 0.04696478986248002, 'num_leaves': 37, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.9105618789285764, 'bagging_fraction': 0.6146219746799967, 'reg_alpha': 0.03301420039080733, 'reg_lambda': 0.00011238770900379432}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:17,954] Trial 92 finished with value: -0.941052870580822 and parameters: {'learning_rate': 0.04383527335446995, 'num_leaves': 47, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.9590731678623642, 'bagging_fraction': 0.6619533957876103, 'reg_alpha': 0.056336777764661755, 'reg_lambda': 0.00015173300017751307}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:23,705] Trial 93 finished with value: -0.9397391513701171 and parameters: {'learning_rate': 0.03286818779531348, 'num_leaves': 23, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.9795234884625362, 'bagging_fraction': 0.6106637417524885, 'reg_alpha': 0.013515752566790919, 'reg_lambda': 1.2690152102347626e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:29,430] Trial 94 finished with value: -0.9409824905861346 and parameters: {'learning_rate': 0.05172631407658755, 'num_leaves': 47, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9327231098388252, 'bagging_fraction': 0.5896578274163666, 'reg_alpha': 0.0015769694138772267, 'reg_lambda': 0.00033279080793392014}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:37,319] Trial 95 finished with value: -0.9415416386513902 and parameters: {'learning_rate': 0.03718478831103735, 'num_leaves': 59, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9444535949798054, 'bagging_fraction': 0.6326828400462451, 'reg_alpha': 0.04668563284560682, 'reg_lambda': 0.0005723319172989484}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:42,045] Trial 96 finished with value: -0.9340696988406583 and parameters: {'learning_rate': 0.0371714228551595, 'num_leaves': 13, 'max_depth': 15, 'min_child_samples': 100, 'feature_fraction': 0.9475961154398244, 'bagging_fraction': 0.5720047102061454, 'reg_alpha': 0.09483191530599723, 'reg_lambda': 0.0004800790192202235}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:48:52,037] Trial 97 finished with value: -0.9408497245713402 and parameters: {'learning_rate': 0.0262437303664068, 'num_leaves': 57, 'max_depth': 14, 'min_child_samples': 22, 'feature_fraction': 0.9653077959643738, 'bagging_fraction': 0.6511582857789295, 'reg_alpha': 0.003962703643542552, 'reg_lambda': 0.001675594093571268}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:49:03,047] Trial 98 finished with value: -0.9383587836440175 and parameters: {'learning_rate': 0.0332633624479184, 'num_leaves': 131, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.989412351148449, 'bagging_fraction': 0.6323715253851381, 'reg_alpha': 0.018030568562337992, 'reg_lambda': 0.0006975825354721934}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:49:12,278] Trial 99 finished with value: -0.9411705580860739 and parameters: {'learning_rate': 0.022680094789917234, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.9265237266493138, 'bagging_fraction': 0.5553032631512244, 'reg_alpha': 0.05821274415421943, 'reg_lambda': 0.005077864388067773}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:49:20,163] Trial 100 finished with value: -0.9401829095848147 and parameters: {'learning_rate': 0.04150061331642383, 'num_leaves': 64, 'max_depth': 14, 'min_child_samples': 33, 'feature_fraction': 0.9408358432352684, 'bagging_fraction': 0.965477610711941, 'reg_alpha': 0.4602214679327334, 'reg_lambda': 0.0002767179831287173}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:49:25,844] Trial 101 finished with value: -0.9410521396698972 and parameters: {'learning_rate': 0.04548470560670436, 'num_leaves': 31, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.9150890520695728, 'bagging_fraction': 0.6210795006363646, 'reg_alpha': 0.03212639737329704, 'reg_lambda': 4.682997408566125e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:49:34,663] Trial 102 finished with value: -0.941580660385284 and parameters: {'learning_rate': 0.028007183827138002, 'num_leaves': 51, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9696721708379259, 'bagging_fraction': 0.6085868175272102, 'reg_alpha': 0.013496190189730587, 'reg_lambda': 0.00012883426256462107}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:49:42,192] Trial 103 finished with value: -0.9417033305689244 and parameters: {'learning_rate': 0.029722357464833236, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9779433642003886, 'bagging_fraction': 0.6454218581761882, 'reg_alpha': 0.011782236321882867, 'reg_lambda': 0.0008540316457848248}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:49:51,551] Trial 104 finished with value: -0.9409681530166436 and parameters: {'learning_rate': 0.027676206321740424, 'num_leaves': 59, 'max_depth': 12, 'min_child_samples': 16, 'feature_fraction': 0.9668409692347048, 'bagging_fraction': 0.6501515275898682, 'reg_alpha': 0.012043012271468041, 'reg_lambda': 0.0009990401845226182}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:01,274] Trial 105 finished with value: -0.9404763718712145 and parameters: {'learning_rate': 0.031681971619297096, 'num_leaves': 76, 'max_depth': 13, 'min_child_samples': 11, 'feature_fraction': 0.9548276124561582, 'bagging_fraction': 0.6410225261412424, 'reg_alpha': 2.978251555215324e-07, 'reg_lambda': 0.00046881215230706457}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:09,784] Trial 106 finished with value: -0.9416391293851442 and parameters: {'learning_rate': 0.029124691109022244, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.9770015007825816, 'bagging_fraction': 0.6806648316134859, 'reg_alpha': 1.032636184109934e-06, 'reg_lambda': 0.0014831720335725504}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:18,506] Trial 107 finished with value: -0.9410545467730806 and parameters: {'learning_rate': 0.030517048310321968, 'num_leaves': 52, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.97356842847626, 'bagging_fraction': 0.6774725983957607, 'reg_alpha': 0.005985852859831901, 'reg_lambda': 0.0017419447653584203}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:25,204] Trial 108 finished with value: -0.939779191354661 and parameters: {'learning_rate': 0.02444395407605811, 'num_leaves': 26, 'max_depth': 11, 'min_child_samples': 14, 'feature_fraction': 0.9953915540024075, 'bagging_fraction': 0.6061885657922471, 'reg_alpha': 1.0051448300402312e-06, 'reg_lambda': 0.0011951129358538715}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:32,816] Trial 109 finished with value: -0.9407485755094921 and parameters: {'learning_rate': 0.029001532446848305, 'num_leaves': 33, 'max_depth': 12, 'min_child_samples': 10, 'feature_fraction': 0.947966795944733, 'bagging_fraction': 0.6904571457761418, 'reg_alpha': 0.10334781538672401, 'reg_lambda': 0.0032586581576772933}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:40,952] Trial 110 finished with value: -0.9376953943429474 and parameters: {'learning_rate': 0.03723418265462467, 'num_leaves': 39, 'max_depth': 7, 'min_child_samples': 18, 'feature_fraction': 0.6357810297899738, 'bagging_fraction': 0.657633061123459, 'reg_alpha': 0.2284321957946056, 'reg_lambda': 0.000216072364598582}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:47,898] Trial 111 finished with value: -0.9416210208264155 and parameters: {'learning_rate': 0.03457022570422576, 'num_leaves': 44, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.957614275037941, 'bagging_fraction': 0.630020568461294, 'reg_alpha': 5.337028192628446e-07, 'reg_lambda': 0.0007092416014047398}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:50:56,316] Trial 112 finished with value: -0.9405515773749501 and parameters: {'learning_rate': 0.035434780645906834, 'num_leaves': 68, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9625441309633914, 'bagging_fraction': 0.6304081880463005, 'reg_alpha': 0.06005684079582378, 'reg_lambda': 0.0006057484725072105}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 22:51:04,560] Trial 113 finished with value: -0.9418609628706509 and parameters: {'learning_rate': 0.030389720447187185, 'num_leaves': 43, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.9770251728706926, 'bagging_fraction': 0.6462416258255956, 'reg_alpha': 1.6557878613974955e-07, 'reg_lambda': 0.00033929563481297084}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:51:12,967] Trial 114 finished with value: -0.9413680203657748 and parameters: {'learning_rate': 0.025857823028328755, 'num_leaves': 45, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.979320997731518, 'bagging_fraction': 0.643072347651638, 'reg_alpha': 5.26339804826714e-07, 'reg_lambda': 0.0008490005128119421}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:51:20,964] Trial 115 finished with value: -0.9412920388614905 and parameters: {'learning_rate': 0.0343769077609445, 'num_leaves': 52, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.9688579293958346, 'bagging_fraction': 0.6647669383284569, 'reg_alpha': 1.795353092537743e-07, 'reg_lambda': 0.00034532123979391036}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:51:26,568] Trial 116 finished with value: -0.9391439082204867 and parameters: {'learning_rate': 0.03228323138335701, 'num_leaves': 19, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.9531283792884417, 'bagging_fraction': 0.6246617498018386, 'reg_alpha': 2.397467889508964e-08, 'reg_lambda': 0.0019523033725672902}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:51:33,801] Trial 117 finished with value: -0.9400646391646603 and parameters: {'learning_rate': 0.03996362062611078, 'num_leaves': 36, 'max_depth': 12, 'min_child_samples': 24, 'feature_fraction': 0.6833577066194692, 'bagging_fraction': 0.6022923240285515, 'reg_alpha': 4.2974108140456055e-08, 'reg_lambda': 0.0012410410412828443}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:51:44,125] Trial 118 finished with value: -0.9416945055285035 and parameters: {'learning_rate': 0.02692368790080795, 'num_leaves': 62, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.9409165783026651, 'bagging_fraction': 0.6380056241982917, 'reg_alpha': 4.7079778534244607e-07, 'reg_lambda': 0.004440606439939018}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:52:03,617] Trial 119 finished with value: -0.9343276172455705 and parameters: {'learning_rate': 0.02650050302539038, 'num_leaves': 112, 'max_depth': 13, 'min_child_samples': 15, 'feature_fraction': 0.592208809351627, 'bagging_fraction': 0.591476409259345, 'reg_alpha': 6.711268213705858e-07, 'reg_lambda': 0.013103747025439557}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:52:07,934] Trial 120 finished with value: -0.9210573851199966 and parameters: {'learning_rate': 0.023427601557237738, 'num_leaves': 28, 'max_depth': 4, 'min_child_samples': 19, 'feature_fraction': 0.9897599749457483, 'bagging_fraction': 0.5786290897205896, 'reg_alpha': 1.282524695335608e-06, 'reg_lambda': 0.006746900995491931}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:52:16,967] Trial 121 finished with value: -0.94127541843452 and parameters: {'learning_rate': 0.030667805098881357, 'num_leaves': 61, 'max_depth': 13, 'min_child_samples': 13, 'feature_fraction': 0.942129526721237, 'bagging_fraction': 0.6325305939558561, 'reg_alpha': 2.198754661361339e-06, 'reg_lambda': 0.003874530200580619}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:52:26,483] Trial 122 finished with value: -0.9413896260756489 and parameters: {'learning_rate': 0.028241300105073863, 'num_leaves': 56, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9307033640581501, 'bagging_fraction': 0.6472543150995906, 'reg_alpha': 4.242755882196157e-07, 'reg_lambda': 0.0001461223172526605}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:52:32,901] Trial 123 finished with value: -0.941247807481067 and parameters: {'learning_rate': 0.03833347063033471, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9705321612697254, 'bagging_fraction': 0.6209803469720319, 'reg_alpha': 3.085183633554746e-06, 'reg_lambda': 0.0005143547070621311}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:52:40,142] Trial 124 finished with value: -0.9412342451120536 and parameters: {'learning_rate': 0.036577066163174354, 'num_leaves': 50, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.9596151408090733, 'bagging_fraction': 0.6581006580016445, 'reg_alpha': 2.067831920041956e-07, 'reg_lambda': 1.6825993301779986e-07}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:52:51,835] Trial 125 finished with value: -0.9397025836413431 and parameters: {'learning_rate': 0.02526830066598765, 'num_leaves': 56, 'max_depth': 12, 'min_child_samples': 10, 'feature_fraction': 0.7466158401204286, 'bagging_fraction': 0.6722792060475365, 'reg_alpha': 6.60777103821436e-08, 'reg_lambda': 0.000791291981403811}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:02,248] Trial 126 finished with value: -0.9411621864720908 and parameters: {'learning_rate': 0.02121422747032016, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.9447210412452486, 'bagging_fraction': 0.6366715978832949, 'reg_alpha': 9.051406788473839e-07, 'reg_lambda': 0.002713511306481763}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:11,385] Trial 127 finished with value: -0.9361719293741062 and parameters: {'learning_rate': 0.033175091960517496, 'num_leaves': 86, 'max_depth': 13, 'min_child_samples': 79, 'feature_fraction': 0.9790842642658001, 'bagging_fraction': 0.7630914453565837, 'reg_alpha': 2.465366696320277e-07, 'reg_lambda': 0.00043332873549089033}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:21,386] Trial 128 finished with value: -0.9408686498135443 and parameters: {'learning_rate': 0.029308590272084163, 'num_leaves': 64, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.9251222988544505, 'bagging_fraction': 0.6990021638695283, 'reg_alpha': 3.9783041987243557e-07, 'reg_lambda': 0.005179009969465581}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:26,587] Trial 129 finished with value: -0.9411111452103237 and parameters: {'learning_rate': 0.04200610663746894, 'num_leaves': 33, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.9546872691387122, 'bagging_fraction': 0.6010662240717591, 'reg_alpha': 1.2367850399403483e-07, 'reg_lambda': 0.00019671283454689745}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:36,701] Trial 130 finished with value: -0.9385842573803401 and parameters: {'learning_rate': 0.027100829371521713, 'num_leaves': 50, 'max_depth': 14, 'min_child_samples': 44, 'feature_fraction': 0.9859214025493073, 'bagging_fraction': 0.6073308635855272, 'reg_alpha': 0.008951194496075954, 'reg_lambda': 0.0018507308016440904}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:44,367] Trial 131 finished with value: -0.9412409836478656 and parameters: {'learning_rate': 0.02990708093409143, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9909384601875043, 'bagging_fraction': 0.6225195736397969, 'reg_alpha': 0.02918961246178873, 'reg_lambda': 0.0002806476371681514}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:51,321] Trial 132 finished with value: -0.9415079543144405 and parameters: {'learning_rate': 0.031661021397864544, 'num_leaves': 39, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.9986304378469958, 'bagging_fraction': 0.6417727475789076, 'reg_alpha': 0.014129570354046437, 'reg_lambda': 0.0011272964632993308}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:53:58,655] Trial 133 finished with value: -0.9411804247630821 and parameters: {'learning_rate': 0.03504560259712822, 'num_leaves': 44, 'max_depth': 12, 'min_child_samples': 19, 'feature_fraction': 0.9733415307373128, 'bagging_fraction': 0.6328961754219576, 'reg_alpha': 0.056452685223699166, 'reg_lambda': 0.00010987308141226382}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:54:06,594] Trial 134 finished with value: -0.9409029490951151 and parameters: {'learning_rate': 0.02844571450063856, 'num_leaves': 35, 'max_depth': 14, 'min_child_samples': 23, 'feature_fraction': 0.9998945077642134, 'bagging_fraction': 0.6833744723044677, 'reg_alpha': 0.02482421569675005, 'reg_lambda': 0.00021298974403867178}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:54:14,162] Trial 135 finished with value: -0.94120930963908 and parameters: {'learning_rate': 0.03330040935938463, 'num_leaves': 53, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.9608698104934336, 'bagging_fraction': 0.6556973227824444, 'reg_alpha': 0.13797788572181546, 'reg_lambda': 0.0006382144273361707}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:54:25,618] Trial 136 finished with value: -0.9403533083814827 and parameters: {'learning_rate': 0.023870972595473418, 'num_leaves': 69, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.9401039674202992, 'bagging_fraction': 0.8210752755618793, 'reg_alpha': 0.043472623565982325, 'reg_lambda': 3.5325580721419037e-05}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:54:33,296] Trial 137 finished with value: -0.9410761542794365 and parameters: {'learning_rate': 0.030501328134081455, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 21, 'feature_fraction': 0.9796665055916361, 'bagging_fraction': 0.5871684302714105, 'reg_alpha': 0.0023666405791397697, 'reg_lambda': 0.0003106523884792572}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:54:43,641] Trial 138 finished with value: -0.9414493018591384 and parameters: {'learning_rate': 0.025889026009336805, 'num_leaves': 59, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9690350467328342, 'bagging_fraction': 0.6172477346776644, 'reg_alpha': 0.07713234276207356, 'reg_lambda': 0.00922748052818966}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:54:48,834] Trial 139 finished with value: -0.9400266394302376 and parameters: {'learning_rate': 0.03956783657135613, 'num_leaves': 24, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.9504327419193417, 'bagging_fraction': 0.6638644105395825, 'reg_alpha': 0.014712362486547888, 'reg_lambda': 0.10999329448669808}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:54:55,915] Trial 140 finished with value: -0.9363846343644002 and parameters: {'learning_rate': 0.05036998138889732, 'num_leaves': 48, 'max_depth': 12, 'min_child_samples': 67, 'feature_fraction': 0.9055340116028376, 'bagging_fraction': 0.5724766119586, 'reg_alpha': 0.004591934265030492, 'reg_lambda': 8.750334821955049e-05}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:02,620] Trial 141 finished with value: -0.940733516002133 and parameters: {'learning_rate': 0.03239390716412573, 'num_leaves': 30, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.9915405888075072, 'bagging_fraction': 0.6481180208819163, 'reg_alpha': 0.012658397118357572, 'reg_lambda': 0.001292021556851783}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:13,790] Trial 142 finished with value: -0.9380232988165828 and parameters: {'learning_rate': 0.030533592538732477, 'num_leaves': 138, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9994938749965926, 'bagging_fraction': 0.639347241377714, 'reg_alpha': 0.006469708298942156, 'reg_lambda': 0.0009390740654258066}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:21,025] Trial 143 finished with value: -0.9410670777633984 and parameters: {'learning_rate': 0.027972984708103076, 'num_leaves': 37, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.9806345713329271, 'bagging_fraction': 0.7365911777421843, 'reg_alpha': 0.024727106068662574, 'reg_lambda': 0.00015623205508511406}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:27,906] Trial 144 finished with value: -0.9415307585091431 and parameters: {'learning_rate': 0.03656184571563131, 'num_leaves': 43, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.9666078635252431, 'bagging_fraction': 0.6271938198312466, 'reg_alpha': 0.00898506824122446, 'reg_lambda': 0.0024570529627921576}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:35,029] Trial 145 finished with value: -0.941582768978902 and parameters: {'learning_rate': 0.03541240759375283, 'num_leaves': 44, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.9619285570616701, 'bagging_fraction': 0.6274223230483524, 'reg_alpha': 0.04287394188041347, 'reg_lambda': 0.0024230665731424816}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:42,130] Trial 146 finished with value: -0.9416116347204422 and parameters: {'learning_rate': 0.0362643898700982, 'num_leaves': 53, 'max_depth': 10, 'min_child_samples': 11, 'feature_fraction': 0.9363441417551431, 'bagging_fraction': 0.6287022303972769, 'reg_alpha': 0.0007139930954215022, 'reg_lambda': 0.0026980289248545587}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:48,203] Trial 147 finished with value: -0.9414930271596763 and parameters: {'learning_rate': 0.04254012696751035, 'num_leaves': 51, 'max_depth': 10, 'min_child_samples': 12, 'feature_fraction': 0.9318850942507745, 'bagging_fraction': 0.6161127476279856, 'reg_alpha': 0.0007935852921869855, 'reg_lambda': 0.0053810662406549295}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:55:55,799] Trial 148 finished with value: -0.9409230928233004 and parameters: {'learning_rate': 0.03455793222523523, 'num_leaves': 62, 'max_depth': 10, 'min_child_samples': 10, 'feature_fraction': 0.9188501834144309, 'bagging_fraction': 0.6063217533334329, 'reg_alpha': 6.905310387720419e-07, 'reg_lambda': 0.025364272800144045}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 22:56:02,655] Trial 149 finished with value: -0.9414163894102263 and parameters: {'learning_rate': 0.03736612206934189, 'num_leaves': 54, 'max_depth': 11, 'min_child_samples': 14, 'feature_fraction': 0.9372837132416338, 'bagging_fraction': 0.6281087084943482, 'reg_alpha': 9.598713210631733e-05, 'reg_lambda': 0.003301085087415755}. Best is trial 113 with value: -0.9418609628706509.
2025-08-05 22:56:03 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.9375011304354043, 'val_lightgbm': 0.9281419377538525, 'val_ensemble': 0.9351304650969318}
2025-08-05 22:56:03 [INFO] Selected best model 'catboost' with validation R²=0.9375
2025-08-05 22:56:03 [INFO] Retraining best model 'catboost' on full dataset
2025-08-05 22:56:06 [INFO] Retraining completed in 2.49s
2025-08-05 22:56:06 [INFO] Saved final model to '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/final_catboost.pkl'
2025-08-05 22:56:06 [INFO] Tree-based → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/final_catboost.pkl (R²=0.9375)
2025-08-05 22:56:06 [INFO] Training TabNet model...
[I 2025-08-05 22:56:06,536] A new study created in memory with name: no-name-9ae485b2-7dde-4a92-89f8-e598d3cfef2c
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 22:57:07,600] Trial 0 finished with value: 0.5914509551132727 and parameters: {'n_d': 29, 'n_a': 40, 'n_steps': 8, 'gamma': 1.7505582427000208, 'lambda_sparse': 7.841986548967896e-05, 'lr': 0.0025860062465667914, 'weight_decay': 1.204731467901492e-06}. Best is trial 0 with value: 0.5914509551132727.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 22:57:51,856] Trial 1 finished with value: 0.527439633365973 and parameters: {'n_d': 49, 'n_a': 11, 'n_steps': 7, 'gamma': 1.9016261264565562, 'lambda_sparse': 0.0014962223108876457, 'lr': 0.0013919337984563105, 'weight_decay': 6.5226802853553504e-06}. Best is trial 0 with value: 0.5914509551132727.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 22:58:27,748] Trial 2 finished with value: 0.7596150200346317 and parameters: {'n_d': 59, 'n_a': 47, 'n_steps': 3, 'gamma': 1.4863766438407184, 'lambda_sparse': 1.6273872911968624e-05, 'lr': 0.0004045419261824289, 'weight_decay': 5.108790216117533e-06}. Best is trial 2 with value: 0.7596150200346317.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 22:59:11,372] Trial 3 finished with value: 0.7817952906268311 and parameters: {'n_d': 59, 'n_a': 22, 'n_steps': 6, 'gamma': 1.9976444874688704, 'lambda_sparse': 2.283663884607983e-05, 'lr': 0.019188201227738136, 'weight_decay': 9.693779904032918e-05}. Best is trial 3 with value: 0.7817952906268311.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:00:18,658] Trial 4 finished with value: 0.4220543160667455 and parameters: {'n_d': 18, 'n_a': 39, 'n_steps': 9, 'gamma': 1.6394417803609327, 'lambda_sparse': 3.822990554917343e-05, 'lr': 0.0005917721824949253, 'weight_decay': 2.6113849112792474e-06}. Best is trial 3 with value: 0.7817952906268311.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:00:47,502] Trial 5 finished with value: 0.8136969179894218 and parameters: {'n_d': 17, 'n_a': 55, 'n_steps': 3, 'gamma': 1.6642668376606617, 'lambda_sparse': 1.8225548742658185e-05, 'lr': 0.0021211463439714277, 'weight_decay': 9.238224844563985e-06}. Best is trial 5 with value: 0.8136969179894218.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:01:24,982] Trial 6 finished with value: 0.8497371298471195 and parameters: {'n_d': 21, 'n_a': 58, 'n_steps': 4, 'gamma': 1.7709842461392333, 'lambda_sparse': 0.0016732290922412726, 'lr': 0.001568640771522644, 'weight_decay': 2.053090892336398e-06}. Best is trial 6 with value: 0.8497371298471195.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:02:00,814] Trial 7 finished with value: 0.8512867369833628 and parameters: {'n_d': 19, 'n_a': 24, 'n_steps': 5, 'gamma': 1.639103576702738, 'lambda_sparse': 0.0008067130277239072, 'lr': 0.05570555668260976, 'weight_decay': 0.0001208617058162107}. Best is trial 7 with value: 0.8512867369833628.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:02:57,114] Trial 8 finished with value: 0.5484798140147936 and parameters: {'n_d': 13, 'n_a': 19, 'n_steps': 8, 'gamma': 1.829351356204847, 'lambda_sparse': 1.8422654351355545e-05, 'lr': 0.0026894314569821266, 'weight_decay': 0.0007310563547884098}. Best is trial 7 with value: 0.8512867369833628.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:03:29,911] Trial 9 finished with value: 0.9058614343471811 and parameters: {'n_d': 17, 'n_a': 60, 'n_steps': 5, 'gamma': 1.2579660991306114, 'lambda_sparse': 0.003447784028027607, 'lr': 0.05311961571733579, 'weight_decay': 1.7793369438867987e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:04:38,500] Trial 10 finished with value: 0.8695216320732904 and parameters: {'n_d': 40, 'n_a': 64, 'n_steps': 10, 'gamma': 1.1241699070593407, 'lambda_sparse': 0.009280643839774894, 'lr': 0.014272220947807215, 'weight_decay': 2.6358018209522585e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:05:38,471] Trial 11 finished with value: 0.878368832308256 and parameters: {'n_d': 40, 'n_a': 63, 'n_steps': 10, 'gamma': 1.1775363750995709, 'lambda_sparse': 0.008455131486297304, 'lr': 0.017680743261234467, 'weight_decay': 2.5735724050110026e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:06:23,401] Trial 12 finished with value: 0.8901579041458303 and parameters: {'n_d': 37, 'n_a': 51, 'n_steps': 6, 'gamma': 1.18528519739499, 'lambda_sparse': 0.009775054189290018, 'lr': 0.0774120912835683, 'weight_decay': 3.174202429851093e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:06:58,950] Trial 13 finished with value: 0.851056181747352 and parameters: {'n_d': 31, 'n_a': 48, 'n_steps': 5, 'gamma': 1.3127912233783654, 'lambda_sparse': 0.0036911387038218784, 'lr': 0.09998035362979124, 'weight_decay': 6.980688328149267e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:07:44,589] Trial 14 finished with value: 0.42939704893729325 and parameters: {'n_d': 8, 'n_a': 52, 'n_steps': 6, 'gamma': 1.3247225277015848, 'lambda_sparse': 0.00024709322902744847, 'lr': 0.00014247111941476174, 'weight_decay': 1.581634602221583e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:08:12,126] Trial 15 finished with value: 0.8711107178298416 and parameters: {'n_d': 50, 'n_a': 45, 'n_steps': 5, 'gamma': 1.0008409515940073, 'lambda_sparse': 0.0036226849042828124, 'lr': 0.008462754503176573, 'weight_decay': 0.000356521533331208}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:08:56,038] Trial 16 finished with value: 0.8269360550830885 and parameters: {'n_d': 28, 'n_a': 32, 'n_steps': 7, 'gamma': 1.3740089757525769, 'lambda_sparse': 0.0003040163490335885, 'lr': 0.040979643650880165, 'weight_decay': 5.602213814005963e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:09:29,893] Trial 17 finished with value: 0.8897096867923819 and parameters: {'n_d': 37, 'n_a': 58, 'n_steps': 4, 'gamma': 1.1847951133934336, 'lambda_sparse': 0.003878363378823689, 'lr': 0.007538935604930976, 'weight_decay': 0.00017303066388998334}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:10:12,660] Trial 18 finished with value: 0.892171322082878 and parameters: {'n_d': 46, 'n_a': 33, 'n_steps': 6, 'gamma': 1.0433002428069462, 'lambda_sparse': 0.0007063814256668568, 'lr': 0.08305183510908805, 'weight_decay': 1.3767499278827023e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:10:42,481] Trial 19 finished with value: 0.8858780222506659 and parameters: {'n_d': 47, 'n_a': 32, 'n_steps': 4, 'gamma': 1.0035439484689932, 'lambda_sparse': 0.00060576222696805, 'lr': 0.03065454631623859, 'weight_decay': 1.2527840392159792e-05}. Best is trial 9 with value: 0.9058614343471811.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:11:27,174] A new study created in memory with name: no-name-03688944-7fb9-4c6a-9186-cf2c58b9da92
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:12:23,022] Trial 0 finished with value: 0.8792262410856487 and parameters: {'n_d': 35, 'n_a': 63, 'n_steps': 7, 'gamma': 1.9758707965412983, 'lambda_sparse': 0.0018551409167943435, 'lr': 0.034429883048931034, 'weight_decay': 0.0001509169487014938}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:12:57,245] Trial 1 finished with value: 0.4899986335775819 and parameters: {'n_d': 20, 'n_a': 29, 'n_steps': 4, 'gamma': 1.3765957965382078, 'lambda_sparse': 0.00010889366158479372, 'lr': 0.000131486552598735, 'weight_decay': 0.00021580639795505118}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:13:25,606] Trial 2 finished with value: 0.8737661309126484 and parameters: {'n_d': 50, 'n_a': 30, 'n_steps': 3, 'gamma': 1.3277046062436444, 'lambda_sparse': 0.0004219576542275314, 'lr': 0.0012458135246913155, 'weight_decay': 2.9053267745138147e-06}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:14:11,135] Trial 3 finished with value: 0.4944606812205611 and parameters: {'n_d': 35, 'n_a': 39, 'n_steps': 6, 'gamma': 1.369491449080946, 'lambda_sparse': 0.003973418208432818, 'lr': 0.00026962159019873683, 'weight_decay': 6.370429704543944e-06}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:15:01,899] Trial 4 finished with value: 0.7989324783890597 and parameters: {'n_d': 17, 'n_a': 26, 'n_steps': 7, 'gamma': 1.5929524259564813, 'lambda_sparse': 2.7514812341761273e-05, 'lr': 0.006112579556156853, 'weight_decay': 0.00045623095596576056}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:16:01,332] Trial 5 finished with value: 0.8514357159499144 and parameters: {'n_d': 41, 'n_a': 37, 'n_steps': 10, 'gamma': 1.1269589696033993, 'lambda_sparse': 6.94738443483316e-05, 'lr': 0.06187795301039147, 'weight_decay': 0.000162402764093754}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:16:46,933] Trial 6 finished with value: 0.42210365328833166 and parameters: {'n_d': 24, 'n_a': 17, 'n_steps': 6, 'gamma': 1.7333800350382957, 'lambda_sparse': 1.0227907305307097e-05, 'lr': 0.00040863534126177824, 'weight_decay': 1.7388590594850174e-06}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:17:21,130] Trial 7 finished with value: 0.6116060588573347 and parameters: {'n_d': 19, 'n_a': 20, 'n_steps': 4, 'gamma': 1.0672514032369316, 'lambda_sparse': 0.00034522552233346484, 'lr': 0.00034360104068248176, 'weight_decay': 0.0002750829865602243}. Best is trial 0 with value: 0.8792262410856487.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:17:52,263] Trial 8 finished with value: 0.9196555249619764 and parameters: {'n_d': 18, 'n_a': 33, 'n_steps': 3, 'gamma': 1.2698534362520493, 'lambda_sparse': 1.1451046020347807e-05, 'lr': 0.011761097072606863, 'weight_decay': 1.893441510522123e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:18:32,853] Trial 9 finished with value: 0.5617902410800977 and parameters: {'n_d': 44, 'n_a': 26, 'n_steps': 5, 'gamma': 1.4388090100765374, 'lambda_sparse': 0.0008181157397952949, 'lr': 0.00022497109760469117, 'weight_decay': 0.00028656937776788037}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:19:37,094] Trial 10 finished with value: 0.8870067959454958 and parameters: {'n_d': 63, 'n_a': 49, 'n_steps': 9, 'gamma': 1.1933507777059904, 'lambda_sparse': 0.009164562013450827, 'lr': 0.011230146834493368, 'weight_decay': 2.4333893375306375e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:20:44,221] Trial 11 finished with value: 0.9045494130983482 and parameters: {'n_d': 64, 'n_a': 50, 'n_steps': 9, 'gamma': 1.2090145088596032, 'lambda_sparse': 0.005588908699565119, 'lr': 0.01020756467480403, 'weight_decay': 2.030938421675463e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:21:47,361] Trial 12 finished with value: 0.8786386422200295 and parameters: {'n_d': 63, 'n_a': 49, 'n_steps': 8, 'gamma': 1.2285690697493863, 'lambda_sparse': 0.00011401816740387484, 'lr': 0.02029719753751891, 'weight_decay': 3.2136505973776025e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:23:04,258] Trial 13 finished with value: 0.8378752249650072 and parameters: {'n_d': 11, 'n_a': 9, 'n_steps': 10, 'gamma': 1.0055019013132631, 'lambda_sparse': 0.0012489409152759599, 'lr': 0.0025178061483784446, 'weight_decay': 2.326101104950842e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:24:12,819] Trial 14 finished with value: 0.6974761864834353 and parameters: {'n_d': 28, 'n_a': 48, 'n_steps': 8, 'gamma': 1.5685320605511477, 'lambda_sparse': 0.008615756035360066, 'lr': 0.005281483146764807, 'weight_decay': 1.0321208035385903e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:24:54,974] Trial 15 finished with value: 0.9134643030464501 and parameters: {'n_d': 54, 'n_a': 59, 'n_steps': 3, 'gamma': 1.2066723206113217, 'lambda_sparse': 1.4606758210754066e-05, 'lr': 0.09693132060527541, 'weight_decay': 4.450214599177705e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:25:21,833] Trial 16 finished with value: 0.8632019228937335 and parameters: {'n_d': 53, 'n_a': 64, 'n_steps': 3, 'gamma': 1.2982658450673785, 'lambda_sparse': 1.1821222235628635e-05, 'lr': 0.09024780025800257, 'weight_decay': 8.818270502873167e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:26:10,454] Trial 17 finished with value: 0.9070948898265816 and parameters: {'n_d': 54, 'n_a': 58, 'n_steps': 4, 'gamma': 1.6965728906027655, 'lambda_sparse': 2.8903754758548938e-05, 'lr': 0.03616818593127528, 'weight_decay': 9.104830251842348e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:26:58,358] Trial 18 finished with value: 0.9100366355079031 and parameters: {'n_d': 10, 'n_a': 42, 'n_steps': 5, 'gamma': 1.4952456449404359, 'lambda_sparse': 2.8340883580854787e-05, 'lr': 0.030607647323536245, 'weight_decay': 5.926711242927116e-05}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:27:30,222] Trial 19 finished with value: 0.8784859089526329 and parameters: {'n_d': 29, 'n_a': 44, 'n_steps': 3, 'gamma': 1.1248912836336606, 'lambda_sparse': 5.5013994196235195e-05, 'lr': 0.0011714068736767983, 'weight_decay': 5.73637346473077e-06}. Best is trial 8 with value: 0.9196555249619764.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:27:58,807] A new study created in memory with name: no-name-d6721d77-87cd-4d4d-a66f-a000e6b2d7d3
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:28:56,271] Trial 0 finished with value: 0.48216949882723315 and parameters: {'n_d': 56, 'n_a': 17, 'n_steps': 8, 'gamma': 1.7982211957596084, 'lambda_sparse': 0.00014298983575049243, 'lr': 0.0007627385935400988, 'weight_decay': 0.00030325150887689336}. Best is trial 0 with value: 0.48216949882723315.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:29:47,412] Trial 1 finished with value: 0.9077156901568776 and parameters: {'n_d': 33, 'n_a': 16, 'n_steps': 7, 'gamma': 1.8608920303368306, 'lambda_sparse': 2.8956422369258087e-05, 'lr': 0.02965611674027827, 'weight_decay': 1.63906218243833e-05}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:30:21,192] Trial 2 finished with value: 0.8722540999804537 and parameters: {'n_d': 28, 'n_a': 21, 'n_steps': 5, 'gamma': 1.5480158348032846, 'lambda_sparse': 2.9476784326376355e-05, 'lr': 0.021441411728804417, 'weight_decay': 0.0002796426106957042}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:30:54,915] Trial 3 finished with value: 0.9033011082253726 and parameters: {'n_d': 23, 'n_a': 26, 'n_steps': 4, 'gamma': 1.3437451771621616, 'lambda_sparse': 0.0002428673851597796, 'lr': 0.016478012839801978, 'weight_decay': 2.631552081404096e-05}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:31:29,253] Trial 4 finished with value: 0.8649996749748347 and parameters: {'n_d': 55, 'n_a': 29, 'n_steps': 4, 'gamma': 1.5088519721527396, 'lambda_sparse': 0.004307471040534086, 'lr': 0.0013417964312874694, 'weight_decay': 2.10214538345072e-06}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:32:09,049] Trial 5 finished with value: 0.5754743504457833 and parameters: {'n_d': 8, 'n_a': 35, 'n_steps': 5, 'gamma': 1.912566498226565, 'lambda_sparse': 0.0008699108225465354, 'lr': 0.000665257055663987, 'weight_decay': 0.00011204054288230808}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:33:06,217] Trial 6 finished with value: 0.7849007470955522 and parameters: {'n_d': 37, 'n_a': 22, 'n_steps': 8, 'gamma': 1.6772294659909306, 'lambda_sparse': 1.3343765669315662e-05, 'lr': 0.008991165789961569, 'weight_decay': 9.725822321373437e-05}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:33:45,490] Trial 7 finished with value: 0.872857950203752 and parameters: {'n_d': 31, 'n_a': 43, 'n_steps': 5, 'gamma': 1.8071280822836333, 'lambda_sparse': 0.0006534395588658226, 'lr': 0.008738528135782674, 'weight_decay': 5.57877133549711e-05}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:34:31,027] Trial 8 finished with value: 0.8707576439528666 and parameters: {'n_d': 59, 'n_a': 49, 'n_steps': 6, 'gamma': 1.3028122613984991, 'lambda_sparse': 0.000524320176523257, 'lr': 0.015479142287447257, 'weight_decay': 7.036216770857055e-06}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:35:47,369] Trial 9 finished with value: -1.236166364332615 and parameters: {'n_d': 11, 'n_a': 37, 'n_steps': 10, 'gamma': 1.7841048963888588, 'lambda_sparse': 0.00993858592312918, 'lr': 0.0001356124162665449, 'weight_decay': 5.976260244800989e-06}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:36:31,116] Trial 10 finished with value: 0.8563095784440344 and parameters: {'n_d': 44, 'n_a': 8, 'n_steps': 8, 'gamma': 1.9995915147312744, 'lambda_sparse': 6.216078982597178e-05, 'lr': 0.09130355247217321, 'weight_decay': 0.0009860034344591744}. Best is trial 1 with value: 0.9077156901568776.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:37:05,989] Trial 11 finished with value: 0.9201958797329377 and parameters: {'n_d': 19, 'n_a': 61, 'n_steps': 3, 'gamma': 1.0067391166966217, 'lambda_sparse': 0.0001336428628593549, 'lr': 0.054185196218520755, 'weight_decay': 1.6974931195907073e-05}. Best is trial 11 with value: 0.9201958797329377.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:37:24,226] Trial 12 finished with value: 0.896948195470772 and parameters: {'n_d': 19, 'n_a': 63, 'n_steps': 3, 'gamma': 1.031312854673616, 'lambda_sparse': 7.735641851986802e-05, 'lr': 0.07268295964053388, 'weight_decay': 1.8230860267686222e-05}. Best is trial 11 with value: 0.9201958797329377.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:38:13,493] Trial 13 finished with value: 0.9223522229082657 and parameters: {'n_d': 41, 'n_a': 63, 'n_steps': 7, 'gamma': 1.00961343699665, 'lambda_sparse': 1.3187372279631267e-05, 'lr': 0.04277915428305283, 'weight_decay': 9.687787690054491e-06}. Best is trial 13 with value: 0.9223522229082657.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:39:19,936] Trial 14 finished with value: 0.8994084274459794 and parameters: {'n_d': 45, 'n_a': 63, 'n_steps': 10, 'gamma': 1.0163634735429568, 'lambda_sparse': 1.0572841192737897e-05, 'lr': 0.003261908969812419, 'weight_decay': 1.0841181404356092e-06}. Best is trial 13 with value: 0.9223522229082657.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:40:09,230] Trial 15 finished with value: 0.9102839245504122 and parameters: {'n_d': 43, 'n_a': 53, 'n_steps': 7, 'gamma': 1.196684159929509, 'lambda_sparse': 0.0027824366331045272, 'lr': 0.048534613161970844, 'weight_decay': 7.53842553688991e-06}. Best is trial 13 with value: 0.9223522229082657.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:40:35,893] Trial 16 finished with value: 0.9134906476585032 and parameters: {'n_d': 18, 'n_a': 55, 'n_steps': 3, 'gamma': 1.15380897992236, 'lambda_sparse': 3.281593126073704e-05, 'lr': 0.003661283801677541, 'weight_decay': 3.1926557809053775e-06}. Best is trial 13 with value: 0.9223522229082657.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:41:37,529] Trial 17 finished with value: 0.906614455547242 and parameters: {'n_d': 50, 'n_a': 55, 'n_steps': 9, 'gamma': 1.1130283828385052, 'lambda_sparse': 0.0001067256980881488, 'lr': 0.007779779541549732, 'weight_decay': 1.1208724018204165e-05}. Best is trial 13 with value: 0.9223522229082657.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:42:18,645] Trial 18 finished with value: 0.8884320162140221 and parameters: {'n_d': 26, 'n_a': 64, 'n_steps': 6, 'gamma': 1.3173088008631622, 'lambda_sparse': 0.0014273379363328646, 'lr': 0.04318148674358083, 'weight_decay': 3.519236400778542e-05}. Best is trial 13 with value: 0.9223522229082657.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:42:51,192] Trial 19 finished with value: 0.9193485376590652 and parameters: {'n_d': 38, 'n_a': 47, 'n_steps': 4, 'gamma': 1.4025083986958187, 'lambda_sparse': 0.0001591518326662303, 'lr': 0.09265399997486809, 'weight_decay': 3.6940404924966883e-06}. Best is trial 13 with value: 0.9223522229082657.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:43:44,311] A new study created in memory with name: no-name-f32f627d-b457-4663-a69c-13a6ab1c39e7
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:44:11,382] Trial 0 finished with value: 0.693355413409492 and parameters: {'n_d': 15, 'n_a': 28, 'n_steps': 3, 'gamma': 1.8881131372584024, 'lambda_sparse': 0.0002009242464762025, 'lr': 0.0006006574941631068, 'weight_decay': 0.0005546040443940922}. Best is trial 0 with value: 0.693355413409492.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:44:54,887] Trial 1 finished with value: 0.9105136376956624 and parameters: {'n_d': 52, 'n_a': 18, 'n_steps': 6, 'gamma': 1.0681277683359571, 'lambda_sparse': 0.00010299057045229814, 'lr': 0.056561490854080666, 'weight_decay': 5.127174481529922e-05}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:46:02,159] Trial 2 finished with value: 0.2507700051441937 and parameters: {'n_d': 54, 'n_a': 13, 'n_steps': 10, 'gamma': 1.1669236057459869, 'lambda_sparse': 0.00031953819522959054, 'lr': 0.0003740623954071979, 'weight_decay': 0.00011408595874317631}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:46:34,783] Trial 3 finished with value: 0.9067694433135043 and parameters: {'n_d': 58, 'n_a': 64, 'n_steps': 4, 'gamma': 1.7018103408098637, 'lambda_sparse': 2.8487525855108484e-05, 'lr': 0.02156274014247349, 'weight_decay': 3.099155514720976e-06}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:47:25,856] Trial 4 finished with value: 0.884515797268524 and parameters: {'n_d': 8, 'n_a': 35, 'n_steps': 7, 'gamma': 1.8930847460691012, 'lambda_sparse': 7.638674751368527e-05, 'lr': 0.07008497937337455, 'weight_decay': 2.531608062266313e-06}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:48:31,353] Trial 5 finished with value: 0.833572298929983 and parameters: {'n_d': 17, 'n_a': 35, 'n_steps': 8, 'gamma': 1.6982880725183, 'lambda_sparse': 0.0008815094757498639, 'lr': 0.05792123323887133, 'weight_decay': 0.0005104442366025968}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:49:08,340] Trial 6 finished with value: 0.4357708498647984 and parameters: {'n_d': 57, 'n_a': 23, 'n_steps': 4, 'gamma': 1.8212538782220364, 'lambda_sparse': 2.1168942878068778e-05, 'lr': 0.0001493448547711873, 'weight_decay': 4.005865660634693e-05}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:50:00,499] Trial 7 finished with value: 0.8641475858357541 and parameters: {'n_d': 58, 'n_a': 15, 'n_steps': 7, 'gamma': 1.3789356583532875, 'lambda_sparse': 8.224831705016705e-05, 'lr': 0.020555783713445706, 'weight_decay': 8.690925016649822e-06}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:51:02,132] Trial 8 finished with value: 0.7620471290977882 and parameters: {'n_d': 44, 'n_a': 15, 'n_steps': 8, 'gamma': 1.7239528920999372, 'lambda_sparse': 0.008399918688328425, 'lr': 0.007129540085182324, 'weight_decay': 4.502111090495489e-05}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:51:44,311] Trial 9 finished with value: 0.8535834891141809 and parameters: {'n_d': 27, 'n_a': 9, 'n_steps': 3, 'gamma': 1.2490350971999753, 'lambda_sparse': 4.441323078745368e-05, 'lr': 0.001612862991691301, 'weight_decay': 1.9196886255015543e-05}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:52:29,889] Trial 10 finished with value: 0.9002073871315301 and parameters: {'n_d': 38, 'n_a': 51, 'n_steps': 5, 'gamma': 1.0265352676223218, 'lambda_sparse': 0.0016874310996569063, 'lr': 0.0037376335689639478, 'weight_decay': 0.0001483942796915674}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:53:09,622] Trial 11 finished with value: 0.8874142670513867 and parameters: {'n_d': 49, 'n_a': 61, 'n_steps': 5, 'gamma': 1.5357607091081444, 'lambda_sparse': 1.2826185878543638e-05, 'lr': 0.016461094552732963, 'weight_decay': 1.045252006802786e-06}. Best is trial 1 with value: 0.9105136376956624.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:53:48,711] Trial 12 finished with value: 0.9121730257133064 and parameters: {'n_d': 60, 'n_a': 47, 'n_steps': 5, 'gamma': 1.4878174572712262, 'lambda_sparse': 2.8936317241192495e-05, 'lr': 0.025236963466439027, 'weight_decay': 6.48425468983185e-06}. Best is trial 12 with value: 0.9121730257133064.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:54:34,261] Trial 13 finished with value: 0.8796350196534917 and parameters: {'n_d': 63, 'n_a': 48, 'n_steps': 6, 'gamma': 1.4761097627645658, 'lambda_sparse': 0.00018131116817123648, 'lr': 0.09546660139841871, 'weight_decay': 9.902557731019217e-06}. Best is trial 12 with value: 0.9121730257133064.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:55:10,137] Trial 14 finished with value: 0.8996443889993757 and parameters: {'n_d': 44, 'n_a': 46, 'n_steps': 6, 'gamma': 1.0524745739898531, 'lambda_sparse': 1.0336070470598609e-05, 'lr': 0.008703415434508243, 'weight_decay': 0.00012382254762019067}. Best is trial 12 with value: 0.9121730257133064.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:55:52,117] Trial 15 finished with value: 0.9165639870726857 and parameters: {'n_d': 31, 'n_a': 41, 'n_steps': 5, 'gamma': 1.3068332558167142, 'lambda_sparse': 7.034512568990962e-05, 'lr': 0.04155269554373681, 'weight_decay': 6.93023230827394e-06}. Best is trial 15 with value: 0.9165639870726857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:56:23,512] Trial 16 finished with value: 0.8869317620305537 and parameters: {'n_d': 31, 'n_a': 41, 'n_steps': 5, 'gamma': 1.3413887214193638, 'lambda_sparse': 0.0007127925657221427, 'lr': 0.037857008632670275, 'weight_decay': 4.809748903438853e-06}. Best is trial 15 with value: 0.9165639870726857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:57:03,116] Trial 17 finished with value: 0.8880152186592987 and parameters: {'n_d': 26, 'n_a': 55, 'n_steps': 4, 'gamma': 1.577143348921141, 'lambda_sparse': 4.048725803851081e-05, 'lr': 0.003367732641588715, 'weight_decay': 1.1832779301522903e-06}. Best is trial 15 with value: 0.9165639870726857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:58:09,881] Trial 18 finished with value: 0.805839459629613 and parameters: {'n_d': 36, 'n_a': 42, 'n_steps': 9, 'gamma': 1.4047718379804561, 'lambda_sparse': 2.0166532741711612e-05, 'lr': 0.0098118906841502, 'weight_decay': 1.5035836072246907e-05}. Best is trial 15 with value: 0.9165639870726857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:58:51,398] Trial 19 finished with value: 0.9128576538692502 and parameters: {'n_d': 22, 'n_a': 30, 'n_steps': 5, 'gamma': 1.266812483866969, 'lambda_sparse': 4.811327761248867e-05, 'lr': 0.03245544959265182, 'weight_decay': 5.450102278908659e-06}. Best is trial 15 with value: 0.9165639870726857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:59:46,632] A new study created in memory with name: no-name-92989924-89a5-4593-8dd0-dbee64f930fa
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:00:25,430] Trial 0 finished with value: 0.9180559252723102 and parameters: {'n_d': 58, 'n_a': 58, 'n_steps': 3, 'gamma': 1.8201025869679919, 'lambda_sparse': 0.0003533208067479377, 'lr': 0.021407078544200236, 'weight_decay': 1.7339054326591126e-05}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:01:12,120] Trial 1 finished with value: 0.8949277348098733 and parameters: {'n_d': 34, 'n_a': 44, 'n_steps': 5, 'gamma': 1.6817732424238772, 'lambda_sparse': 7.477321700306009e-05, 'lr': 0.04464995996349754, 'weight_decay': 0.00034249990118738195}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:01:52,549] Trial 2 finished with value: 0.759693903340979 and parameters: {'n_d': 57, 'n_a': 49, 'n_steps': 4, 'gamma': 1.1155764571679687, 'lambda_sparse': 0.0006375114058852255, 'lr': 0.00035478843521589515, 'weight_decay': 3.029520754087383e-06}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:03:06,388] Trial 3 finished with value: 0.4027285147651015 and parameters: {'n_d': 18, 'n_a': 22, 'n_steps': 9, 'gamma': 1.2032734815197732, 'lambda_sparse': 0.0005955709865692383, 'lr': 0.00044484504265000904, 'weight_decay': 0.00032469586000211516}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:03:38,752] Trial 4 finished with value: 0.8774507391086758 and parameters: {'n_d': 62, 'n_a': 11, 'n_steps': 3, 'gamma': 1.2426772193428086, 'lambda_sparse': 2.9476236022127593e-05, 'lr': 0.04782781486148152, 'weight_decay': 0.00036429506917285315}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:04:47,315] Trial 5 finished with value: 0.8640477545449202 and parameters: {'n_d': 31, 'n_a': 12, 'n_steps': 9, 'gamma': 1.9721245715583424, 'lambda_sparse': 0.0020561308347942695, 'lr': 0.06297115864244934, 'weight_decay': 1.901885453573145e-05}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:05:46,254] Trial 6 finished with value: 0.8755783795337205 and parameters: {'n_d': 45, 'n_a': 17, 'n_steps': 8, 'gamma': 1.4089415615718155, 'lambda_sparse': 6.27975432208598e-05, 'lr': 0.025444082002699507, 'weight_decay': 0.0006078396496458709}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:06:26,487] Trial 7 finished with value: 0.6979810279417198 and parameters: {'n_d': 52, 'n_a': 14, 'n_steps': 4, 'gamma': 1.8986057385943251, 'lambda_sparse': 0.0037521062044742442, 'lr': 0.0008213096636060999, 'weight_decay': 0.00024412969630207068}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:07:30,696] Trial 8 finished with value: 0.5333334734281516 and parameters: {'n_d': 52, 'n_a': 31, 'n_steps': 10, 'gamma': 1.9610866806118308, 'lambda_sparse': 0.00010824579328904004, 'lr': 0.0020539189646139326, 'weight_decay': 1.008252241986939e-05}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:07:57,406] Trial 9 finished with value: 0.9130025264526646 and parameters: {'n_d': 46, 'n_a': 42, 'n_steps': 3, 'gamma': 1.3331430240068782, 'lambda_sparse': 0.0013214998360321713, 'lr': 0.01048483652100379, 'weight_decay': 0.00012827079185179926}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:08:41,534] Trial 10 finished with value: 0.8672314665996073 and parameters: {'n_d': 15, 'n_a': 62, 'n_steps': 6, 'gamma': 1.6413926093469604, 'lambda_sparse': 1.2239770369470529e-05, 'lr': 0.006172380911703331, 'weight_decay': 5.68521416526702e-05}. Best is trial 0 with value: 0.9180559252723102.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:09:09,311] Trial 11 finished with value: 0.9244202737618721 and parameters: {'n_d': 42, 'n_a': 62, 'n_steps': 3, 'gamma': 1.4867878343631236, 'lambda_sparse': 0.00903838149970879, 'lr': 0.00954879076038467, 'weight_decay': 6.366591409627382e-05}. Best is trial 11 with value: 0.9244202737618721.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:09:53,066] Trial 12 finished with value: 0.8423810700520875 and parameters: {'n_d': 25, 'n_a': 62, 'n_steps': 6, 'gamma': 1.5811155561776267, 'lambda_sparse': 0.007787429796462475, 'lr': 0.009183761329184154, 'weight_decay': 6.272928015038822e-06}. Best is trial 11 with value: 0.9244202737618721.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:10:26,980] Trial 13 finished with value: 0.8563701836724124 and parameters: {'n_d': 41, 'n_a': 54, 'n_steps': 4, 'gamma': 1.7985906972006085, 'lambda_sparse': 0.00019913116981093453, 'lr': 0.0024733316772651884, 'weight_decay': 3.487724144515841e-05}. Best is trial 11 with value: 0.9244202737618721.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:10:55,227] Trial 14 finished with value: 0.9311610247226305 and parameters: {'n_d': 62, 'n_a': 56, 'n_steps': 3, 'gamma': 1.4896174393211423, 'lambda_sparse': 0.009975157737979861, 'lr': 0.01558218424477653, 'weight_decay': 1.1800729225014267e-06}. Best is trial 14 with value: 0.9311610247226305.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:11:46,347] Trial 15 finished with value: 0.7761397817267166 and parameters: {'n_d': 39, 'n_a': 34, 'n_steps': 7, 'gamma': 1.4802923067763791, 'lambda_sparse': 0.009462463507420577, 'lr': 0.00443959354641815, 'weight_decay': 1.5088373401413304e-06}. Best is trial 14 with value: 0.9311610247226305.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:12:13,118] Trial 16 finished with value: 0.8282468096358031 and parameters: {'n_d': 26, 'n_a': 54, 'n_steps': 5, 'gamma': 1.5180222770764271, 'lambda_sparse': 0.003628273360656855, 'lr': 0.09841401752710528, 'weight_decay': 7.844916977480072e-05}. Best is trial 14 with value: 0.9311610247226305.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:12:53,516] Trial 17 finished with value: 0.502101572788096 and parameters: {'n_d': 9, 'n_a': 48, 'n_steps': 5, 'gamma': 1.034631745812572, 'lambda_sparse': 0.0043720497696267185, 'lr': 0.00013300165675473103, 'weight_decay': 1.2373101154370588e-06}. Best is trial 14 with value: 0.9311610247226305.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:13:23,672] Trial 18 finished with value: 0.9282052051323527 and parameters: {'n_d': 64, 'n_a': 40, 'n_steps': 3, 'gamma': 1.3594188990942948, 'lambda_sparse': 0.0014508696004870037, 'lr': 0.021367067267983802, 'weight_decay': 3.334114050213319e-06}. Best is trial 14 with value: 0.9311610247226305.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:14:23,404] Trial 19 finished with value: 0.877662887845831 and parameters: {'n_d': 63, 'n_a': 25, 'n_steps': 7, 'gamma': 1.3398624893170883, 'lambda_sparse': 0.0011521725822114257, 'lr': 0.021656730111124668, 'weight_decay': 3.277553131870535e-06}. Best is trial 14 with value: 0.9311610247226305.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:15:21,495] A new study created in memory with name: no-name-de3570cf-8ec6-4379-a969-4cff7a74ed6a
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:15:55,339] Trial 0 finished with value: 0.9019646011507173 and parameters: {'n_d': 40, 'n_a': 37, 'n_steps': 4, 'gamma': 1.2459211977109974, 'lambda_sparse': 0.00030033320627015586, 'lr': 0.0600571827729622, 'weight_decay': 7.216566633941023e-06}. Best is trial 0 with value: 0.9019646011507173.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:16:36,351] Trial 1 finished with value: 0.8683549323839423 and parameters: {'n_d': 48, 'n_a': 10, 'n_steps': 6, 'gamma': 1.872765157670199, 'lambda_sparse': 0.0063250789055466754, 'lr': 0.01973491670548062, 'weight_decay': 0.000941086744954072}. Best is trial 0 with value: 0.9019646011507173.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:17:10,415] Trial 2 finished with value: 0.8659482818223605 and parameters: {'n_d': 46, 'n_a': 46, 'n_steps': 4, 'gamma': 1.8551499392160966, 'lambda_sparse': 9.573510447862027e-05, 'lr': 0.0016581919533536404, 'weight_decay': 1.796305679994121e-06}. Best is trial 0 with value: 0.9019646011507173.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:17:38,540] Trial 3 finished with value: 0.9005839263701286 and parameters: {'n_d': 15, 'n_a': 64, 'n_steps': 3, 'gamma': 1.9300900564990253, 'lambda_sparse': 0.00010532093479533982, 'lr': 0.014018606540974426, 'weight_decay': 0.0009421894434852489}. Best is trial 0 with value: 0.9019646011507173.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:18:30,071] Trial 4 finished with value: 0.7984929972207317 and parameters: {'n_d': 17, 'n_a': 24, 'n_steps': 7, 'gamma': 1.4327925782914748, 'lambda_sparse': 0.0038635641323959357, 'lr': 0.0029803855415197495, 'weight_decay': 0.00010561059162871648}. Best is trial 0 with value: 0.9019646011507173.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:19:27,343] Trial 5 finished with value: 0.5527454387939768 and parameters: {'n_d': 41, 'n_a': 21, 'n_steps': 8, 'gamma': 1.596871311097368, 'lambda_sparse': 0.0015646962827645331, 'lr': 0.0018317937353056668, 'weight_decay': 2.510348862058543e-06}. Best is trial 0 with value: 0.9019646011507173.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:20:18,268] Trial 6 finished with value: 0.9053452861275111 and parameters: {'n_d': 59, 'n_a': 26, 'n_steps': 7, 'gamma': 1.1849010714872614, 'lambda_sparse': 0.00010542180728252466, 'lr': 0.03678453670109423, 'weight_decay': 4.727158359961015e-06}. Best is trial 6 with value: 0.9053452861275111.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:21:09,386] Trial 7 finished with value: 0.8600660433017682 and parameters: {'n_d': 52, 'n_a': 26, 'n_steps': 6, 'gamma': 1.5386336734228387, 'lambda_sparse': 1.4503063854030744e-05, 'lr': 0.01045165064844977, 'weight_decay': 6.297985956426587e-06}. Best is trial 6 with value: 0.9053452861275111.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:22:10,231] Trial 8 finished with value: 0.47571445101198995 and parameters: {'n_d': 46, 'n_a': 18, 'n_steps': 7, 'gamma': 1.956311279241105, 'lambda_sparse': 7.483038146437564e-05, 'lr': 0.0006906928530639366, 'weight_decay': 1.4247860334495883e-05}. Best is trial 6 with value: 0.9053452861275111.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:23:18,047] Trial 9 finished with value: 0.8195690326755846 and parameters: {'n_d': 64, 'n_a': 48, 'n_steps': 8, 'gamma': 1.706289774338701, 'lambda_sparse': 1.3989699283517636e-05, 'lr': 0.012249939589029634, 'weight_decay': 1.5151723558652085e-05}. Best is trial 6 with value: 0.9053452861275111.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:24:31,679] Trial 10 finished with value: -0.03627290809662864 and parameters: {'n_d': 62, 'n_a': 35, 'n_steps': 10, 'gamma': 1.008047974802324, 'lambda_sparse': 0.0006844634772909832, 'lr': 0.00016707298213505768, 'weight_decay': 7.877091684658949e-05}. Best is trial 6 with value: 0.9053452861275111.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:24:53,690] Trial 11 finished with value: 0.8878604296833402 and parameters: {'n_d': 30, 'n_a': 36, 'n_steps': 4, 'gamma': 1.2240520081946633, 'lambda_sparse': 0.00030636749974537376, 'lr': 0.09513058432194087, 'weight_decay': 5.183702319822191e-06}. Best is trial 6 with value: 0.9053452861275111.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:25:31,259] Trial 12 finished with value: 0.9262598642354722 and parameters: {'n_d': 33, 'n_a': 45, 'n_steps': 5, 'gamma': 1.2580418782350211, 'lambda_sparse': 0.0002983634096148944, 'lr': 0.06816795755251974, 'weight_decay': 1.223202929685386e-06}. Best is trial 12 with value: 0.9262598642354722.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:26:02,866] Trial 13 finished with value: 0.8937612053610422 and parameters: {'n_d': 30, 'n_a': 55, 'n_steps': 5, 'gamma': 1.26629764392068, 'lambda_sparse': 3.9223163265961196e-05, 'lr': 0.0341089435549163, 'weight_decay': 1.0258184128624638e-06}. Best is trial 12 with value: 0.9262598642354722.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:27:06,022] Trial 14 finished with value: 0.9284616966712138 and parameters: {'n_d': 25, 'n_a': 31, 'n_steps': 9, 'gamma': 1.0229923169125301, 'lambda_sparse': 0.0007497048629951661, 'lr': 0.04419621724516134, 'weight_decay': 1.0544156030953289e-06}. Best is trial 14 with value: 0.9284616966712138.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:28:21,566] Trial 15 finished with value: 0.9128061666674642 and parameters: {'n_d': 24, 'n_a': 44, 'n_steps': 10, 'gamma': 1.0407770104978, 'lambda_sparse': 0.0009939349691420046, 'lr': 0.09214020934057746, 'weight_decay': 1.0808194461208709e-06}. Best is trial 14 with value: 0.9284616966712138.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:29:18,036] Trial 16 finished with value: 0.9044259272614074 and parameters: {'n_d': 9, 'n_a': 53, 'n_steps': 9, 'gamma': 1.1065407963825793, 'lambda_sparse': 0.0017387716921624288, 'lr': 0.006993140053751851, 'weight_decay': 5.240456745551476e-05}. Best is trial 14 with value: 0.9284616966712138.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:29:45,712] Trial 17 finished with value: 0.8665063097327199 and parameters: {'n_d': 31, 'n_a': 33, 'n_steps': 5, 'gamma': 1.4037889389978317, 'lambda_sparse': 0.00043231380541469054, 'lr': 0.03630261816964029, 'weight_decay': 0.00021906815279842707}. Best is trial 14 with value: 0.9284616966712138.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:30:55,612] Trial 18 finished with value: 0.794229784555429 and parameters: {'n_d': 22, 'n_a': 63, 'n_steps': 9, 'gamma': 1.3274026072041811, 'lambda_sparse': 0.0002071870314325016, 'lr': 0.0057572977346357, 'weight_decay': 2.5590304284162238e-06}. Best is trial 14 with value: 0.9284616966712138.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:31:38,403] Trial 19 finished with value: 0.7917994919409563 and parameters: {'n_d': 36, 'n_a': 41, 'n_steps': 5, 'gamma': 1.1100917815418585, 'lambda_sparse': 0.0029113035382228826, 'lr': 0.0004768460482095079, 'weight_decay': 1.4355852565719243e-05}. Best is trial 14 with value: 0.9284616966712138.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:33:01,011] A new study created in memory with name: no-name-0cdb93ac-9e58-4356-94cb-de1488c4bfd4
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:33:42,098] Trial 0 finished with value: 0.7193688701296408 and parameters: {'n_d': 42, 'n_a': 56, 'n_steps': 5, 'gamma': 1.5293657360360942, 'lambda_sparse': 0.0005426777112826647, 'lr': 0.0006366628855929075, 'weight_decay': 0.0006012474491945972}. Best is trial 0 with value: 0.7193688701296408.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:34:16,446] Trial 1 finished with value: 0.7224318236151104 and parameters: {'n_d': 47, 'n_a': 46, 'n_steps': 4, 'gamma': 1.0816533964867778, 'lambda_sparse': 0.0015709290900941604, 'lr': 0.0005385078828376695, 'weight_decay': 0.0005061628560445652}. Best is trial 1 with value: 0.7224318236151104.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:34:50,586] Trial 2 finished with value: 0.8627936814883553 and parameters: {'n_d': 48, 'n_a': 17, 'n_steps': 4, 'gamma': 1.7868328052677511, 'lambda_sparse': 0.007795464193714034, 'lr': 0.08523327338657319, 'weight_decay': 5.241200985387393e-05}. Best is trial 2 with value: 0.8627936814883553.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:35:14,246] Trial 3 finished with value: 0.8831425984521188 and parameters: {'n_d': 32, 'n_a': 46, 'n_steps': 3, 'gamma': 1.7442473986154945, 'lambda_sparse': 0.002495998096680654, 'lr': 0.02309052209892816, 'weight_decay': 7.656948965346273e-05}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:35:59,437] Trial 4 finished with value: 0.33063646395614554 and parameters: {'n_d': 35, 'n_a': 33, 'n_steps': 6, 'gamma': 1.6622750592358266, 'lambda_sparse': 0.00038830979781837586, 'lr': 0.00018284779390075542, 'weight_decay': 0.0003673201368099733}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:36:38,652] Trial 5 finished with value: 0.865184306981289 and parameters: {'n_d': 30, 'n_a': 18, 'n_steps': 5, 'gamma': 1.1040872930599956, 'lambda_sparse': 0.0016601079971743273, 'lr': 0.0020640520078172397, 'weight_decay': 0.0002030434792903136}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:37:05,424] Trial 6 finished with value: 0.6428866425754758 and parameters: {'n_d': 48, 'n_a': 12, 'n_steps': 3, 'gamma': 1.4209549481290575, 'lambda_sparse': 0.005924676920885366, 'lr': 0.0005191070736732754, 'weight_decay': 0.0001920882321154486}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:37:37,625] Trial 7 finished with value: 0.8619979934746941 and parameters: {'n_d': 59, 'n_a': 57, 'n_steps': 4, 'gamma': 1.668476155892876, 'lambda_sparse': 0.0006225323435945812, 'lr': 0.004384090314606887, 'weight_decay': 0.00022206205789507548}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:38:44,170] Trial 8 finished with value: -0.25517575355970634 and parameters: {'n_d': 23, 'n_a': 26, 'n_steps': 10, 'gamma': 1.6953959669742804, 'lambda_sparse': 0.00046740556745755913, 'lr': 0.00010652573103569763, 'weight_decay': 2.359951563233295e-06}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:39:39,598] Trial 9 finished with value: -0.817200068060536 and parameters: {'n_d': 37, 'n_a': 15, 'n_steps': 8, 'gamma': 1.6043288818614028, 'lambda_sparse': 2.6613904925406094e-05, 'lr': 0.00017198747838528076, 'weight_decay': 0.00022984589645956598}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:40:32,123] Trial 10 finished with value: 0.8730310050816055 and parameters: {'n_d': 14, 'n_a': 42, 'n_steps': 8, 'gamma': 1.9445832535894616, 'lambda_sparse': 7.703527497972051e-05, 'lr': 0.039262359818039605, 'weight_decay': 7.3465476872343e-06}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:41:27,010] Trial 11 finished with value: 0.8242705078615935 and parameters: {'n_d': 12, 'n_a': 44, 'n_steps': 8, 'gamma': 1.9197010795069855, 'lambda_sparse': 5.887386664194796e-05, 'lr': 0.040525786180352755, 'weight_decay': 5.101463607500767e-06}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:42:22,023] Trial 12 finished with value: 0.7887732919648787 and parameters: {'n_d': 11, 'n_a': 43, 'n_steps': 8, 'gamma': 1.9933641588293776, 'lambda_sparse': 9.67663539829625e-05, 'lr': 0.01517694467861291, 'weight_decay': 1.4099327781675066e-05}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:43:22,596] Trial 13 finished with value: 0.8215817938349386 and parameters: {'n_d': 22, 'n_a': 34, 'n_steps': 9, 'gamma': 1.8412480372820588, 'lambda_sparse': 0.00011967056169636964, 'lr': 0.01808680312159597, 'weight_decay': 3.912756043831021e-05}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:44:12,727] Trial 14 finished with value: 0.8698153141177426 and parameters: {'n_d': 21, 'n_a': 64, 'n_steps': 7, 'gamma': 1.3264333728568962, 'lambda_sparse': 1.2462859054650493e-05, 'lr': 0.009008813674413042, 'weight_decay': 1.259944158459093e-05}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:44:58,481] Trial 15 finished with value: 0.8628794764107728 and parameters: {'n_d': 15, 'n_a': 52, 'n_steps': 6, 'gamma': 1.8334369558739338, 'lambda_sparse': 0.0016126858632605145, 'lr': 0.07580631800965477, 'weight_decay': 7.424994746679567e-05}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:46:14,523] Trial 16 finished with value: 0.6927974420360282 and parameters: {'n_d': 63, 'n_a': 27, 'n_steps': 10, 'gamma': 1.9509970753154695, 'lambda_sparse': 0.00016608337923299923, 'lr': 0.0284872390963117, 'weight_decay': 1.4890214627536682e-05}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:46:59,507] Trial 17 finished with value: 0.7313197774602371 and parameters: {'n_d': 26, 'n_a': 40, 'n_steps': 7, 'gamma': 1.762555991871783, 'lambda_sparse': 4.1626275907262536e-05, 'lr': 0.006064334930493389, 'weight_decay': 1.1298790502371671e-06}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:47:29,186] Trial 18 finished with value: 0.8375845529895383 and parameters: {'n_d': 8, 'n_a': 49, 'n_steps': 3, 'gamma': 1.3096804875600943, 'lambda_sparse': 0.004413717953527887, 'lr': 0.0014742140088147716, 'weight_decay': 4.490959967982575e-06}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:48:26,431] Trial 19 finished with value: 0.8566526069929502 and parameters: {'n_d': 17, 'n_a': 37, 'n_steps': 9, 'gamma': 1.8889963451078629, 'lambda_sparse': 0.00018111077775890302, 'lr': 0.04442345406250478, 'weight_decay': 7.50857713757945e-05}. Best is trial 3 with value: 0.8831425984521188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:48:52,878] A new study created in memory with name: no-name-1f3e9421-3c3b-4ff8-a8cb-e10e9be371b9
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:50:08,811] Trial 0 finished with value: 0.909970749873348 and parameters: {'n_d': 16, 'n_a': 59, 'n_steps': 10, 'gamma': 1.0109203586184674, 'lambda_sparse': 0.0013694607704700795, 'lr': 0.0038038123905321636, 'weight_decay': 4.407844745160171e-05}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:50:46,078] Trial 1 finished with value: 0.8736204293021086 and parameters: {'n_d': 34, 'n_a': 55, 'n_steps': 5, 'gamma': 1.8874095998163378, 'lambda_sparse': 0.007346666510552416, 'lr': 0.040195032184137156, 'weight_decay': 0.0002655715221901186}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:51:20,260] Trial 2 finished with value: 0.8546960677532547 and parameters: {'n_d': 40, 'n_a': 36, 'n_steps': 4, 'gamma': 1.277788802420487, 'lambda_sparse': 0.0005777155619966711, 'lr': 0.0010491846478389057, 'weight_decay': 6.345066815278256e-06}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:52:17,523] Trial 3 finished with value: 0.7693565249176663 and parameters: {'n_d': 16, 'n_a': 22, 'n_steps': 10, 'gamma': 1.367915675019396, 'lambda_sparse': 1.9267516638200425e-05, 'lr': 0.07280279342103418, 'weight_decay': 0.0006538353656191869}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:53:03,245] Trial 4 finished with value: 0.8412547842919544 and parameters: {'n_d': 50, 'n_a': 55, 'n_steps': 6, 'gamma': 1.5436855958661706, 'lambda_sparse': 0.007338666787593086, 'lr': 0.017119992015994526, 'weight_decay': 0.00011630081412510036}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:54:11,623] Trial 5 finished with value: 0.7680807547450008 and parameters: {'n_d': 55, 'n_a': 45, 'n_steps': 10, 'gamma': 1.2241954222019862, 'lambda_sparse': 0.003665769555718284, 'lr': 0.006127974633807711, 'weight_decay': 1.2728179569748088e-05}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:54:50,211] Trial 6 finished with value: 0.8923895008013735 and parameters: {'n_d': 32, 'n_a': 9, 'n_steps': 5, 'gamma': 1.5164051347000655, 'lambda_sparse': 0.0018846266759217868, 'lr': 0.07290757660057018, 'weight_decay': 2.710409030244675e-05}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:55:59,580] Trial 7 finished with value: -0.8182072847581754 and parameters: {'n_d': 56, 'n_a': 24, 'n_steps': 10, 'gamma': 1.4887558830243648, 'lambda_sparse': 0.0011945512147389955, 'lr': 0.00019502827552683226, 'weight_decay': 4.5965203976350877e-05}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:57:08,840] Trial 8 finished with value: -1.1013403265420596 and parameters: {'n_d': 18, 'n_a': 8, 'n_steps': 10, 'gamma': 1.521476803076037, 'lambda_sparse': 0.0019467432063274073, 'lr': 0.00026995751139810337, 'weight_decay': 6.299029457689964e-05}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:57:42,663] Trial 9 finished with value: 0.8809340691163637 and parameters: {'n_d': 18, 'n_a': 31, 'n_steps': 4, 'gamma': 1.2864217686553525, 'lambda_sparse': 0.00454801473542297, 'lr': 0.017051799449418238, 'weight_decay': 0.0007470712623655724}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:58:39,981] Trial 10 finished with value: 0.8373654423865617 and parameters: {'n_d': 8, 'n_a': 64, 'n_steps': 8, 'gamma': 1.0205287387323418, 'lambda_sparse': 9.824329921221927e-05, 'lr': 0.0014405320369427958, 'weight_decay': 2.382565954256587e-06}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:59:29,428] Trial 11 finished with value: 0.7350032799774215 and parameters: {'n_d': 30, 'n_a': 9, 'n_steps': 7, 'gamma': 1.7455405607983963, 'lambda_sparse': 0.0001797361270199896, 'lr': 0.0036494943135107942, 'weight_decay': 1.6384960080608704e-05}. Best is trial 0 with value: 0.909970749873348.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:00:26,151] Trial 12 finished with value: 0.9227390585871469 and parameters: {'n_d': 27, 'n_a': 46, 'n_steps': 8, 'gamma': 1.0058561213910768, 'lambda_sparse': 0.0005770681530890856, 'lr': 0.010176722693644513, 'weight_decay': 2.423449334945447e-05}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:01:23,372] Trial 13 finished with value: 0.9166546784923577 and parameters: {'n_d': 25, 'n_a': 48, 'n_steps': 8, 'gamma': 1.027822145438798, 'lambda_sparse': 0.00039598446924919863, 'lr': 0.008433850973274695, 'weight_decay': 1.1645884392614438e-06}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:02:20,013] Trial 14 finished with value: 0.8875465753509898 and parameters: {'n_d': 27, 'n_a': 45, 'n_steps': 8, 'gamma': 1.131604131714866, 'lambda_sparse': 0.00034313069282230027, 'lr': 0.011735278326583944, 'weight_decay': 1.105890160275247e-06}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:03:16,944] Trial 15 finished with value: 0.771263471579386 and parameters: {'n_d': 44, 'n_a': 45, 'n_steps': 8, 'gamma': 1.1059338665677605, 'lambda_sparse': 9.201206920682121e-05, 'lr': 0.001084059821597697, 'weight_decay': 4.311273573870142e-06}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:04:08,409] Trial 16 finished with value: 0.8911218229234186 and parameters: {'n_d': 25, 'n_a': 50, 'n_steps': 7, 'gamma': 1.1252530259448257, 'lambda_sparse': 2.715169711600479e-05, 'lr': 0.009046257780003808, 'weight_decay': 1.0089411451393692e-06}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:05:10,823] Trial 17 finished with value: 0.7585967841173836 and parameters: {'n_d': 23, 'n_a': 40, 'n_steps': 9, 'gamma': 1.7597682198055646, 'lambda_sparse': 0.0005640652055904107, 'lr': 0.027324774441129292, 'weight_decay': 7.01024477359687e-06}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:05:56,351] Trial 18 finished with value: 0.78892684273052 and parameters: {'n_d': 63, 'n_a': 35, 'n_steps': 6, 'gamma': 1.3678323370497, 'lambda_sparse': 0.00015195814852773004, 'lr': 0.0020769396456002884, 'weight_decay': 0.000148232869035558}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:06:56,999] Trial 19 finished with value: 0.5382765120996167 and parameters: {'n_d': 9, 'n_a': 50, 'n_steps': 9, 'gamma': 1.1959532369288541, 'lambda_sparse': 5.253330012818285e-05, 'lr': 0.0004309918560176009, 'weight_decay': 2.5517576550255055e-06}. Best is trial 12 with value: 0.9227390585871469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:08:19,086] A new study created in memory with name: no-name-a0cd0ab3-7a7b-4ba5-a7f3-d8240fc33f6f
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:08:53,313] Trial 0 finished with value: 0.6245816728010802 and parameters: {'n_d': 45, 'n_a': 33, 'n_steps': 4, 'gamma': 1.0273746835716948, 'lambda_sparse': 0.0002518078112161661, 'lr': 0.00028593840095792795, 'weight_decay': 2.2654816558605787e-05}. Best is trial 0 with value: 0.6245816728010802.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:09:31,482] Trial 1 finished with value: 0.8606843827554171 and parameters: {'n_d': 51, 'n_a': 61, 'n_steps': 4, 'gamma': 1.6312434338902173, 'lambda_sparse': 0.005155856575225032, 'lr': 0.0020949391150421777, 'weight_decay': 2.6871656709820957e-05}. Best is trial 1 with value: 0.8606843827554171.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:10:42,366] Trial 2 finished with value: -0.2879447241297586 and parameters: {'n_d': 8, 'n_a': 37, 'n_steps': 10, 'gamma': 1.853359381411532, 'lambda_sparse': 0.0058432124196512196, 'lr': 0.0004615947838737166, 'weight_decay': 6.184089785981774e-05}. Best is trial 1 with value: 0.8606843827554171.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:11:11,589] Trial 3 finished with value: 0.6636065658223416 and parameters: {'n_d': 11, 'n_a': 13, 'n_steps': 3, 'gamma': 1.6303947192781285, 'lambda_sparse': 0.006020546119046864, 'lr': 0.000875673759802723, 'weight_decay': 7.240976043098363e-05}. Best is trial 1 with value: 0.8606843827554171.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:12:03,904] Trial 4 finished with value: 0.6615299134641932 and parameters: {'n_d': 62, 'n_a': 58, 'n_steps': 8, 'gamma': 1.8799409488363181, 'lambda_sparse': 3.555109703381764e-05, 'lr': 0.002927219034450945, 'weight_decay': 0.0006894157935913414}. Best is trial 1 with value: 0.8606843827554171.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:13:00,666] Trial 5 finished with value: 0.5700908277252295 and parameters: {'n_d': 17, 'n_a': 25, 'n_steps': 8, 'gamma': 1.1749380046693467, 'lambda_sparse': 0.0029519913266373107, 'lr': 0.0006829230216241497, 'weight_decay': 1.8629701042317253e-06}. Best is trial 1 with value: 0.8606843827554171.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:14:03,949] Trial 6 finished with value: 0.22181957397687901 and parameters: {'n_d': 56, 'n_a': 21, 'n_steps': 9, 'gamma': 1.9873456993334486, 'lambda_sparse': 8.085379566433637e-05, 'lr': 0.0004891412168317731, 'weight_decay': 6.69174128663795e-05}. Best is trial 1 with value: 0.8606843827554171.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:15:12,766] Trial 7 finished with value: 0.7460030765565886 and parameters: {'n_d': 45, 'n_a': 27, 'n_steps': 10, 'gamma': 1.0014298554196248, 'lambda_sparse': 0.00322105585034544, 'lr': 0.0010783394009189773, 'weight_decay': 2.7227058205260434e-05}. Best is trial 1 with value: 0.8606843827554171.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:16:03,722] Trial 8 finished with value: 0.8931026849323209 and parameters: {'n_d': 45, 'n_a': 57, 'n_steps': 7, 'gamma': 1.826071192491014, 'lambda_sparse': 0.0002300701130183459, 'lr': 0.030280109288210223, 'weight_decay': 2.3886265703963745e-06}. Best is trial 8 with value: 0.8931026849323209.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:16:36,402] Trial 9 finished with value: 0.23011779714573644 and parameters: {'n_d': 15, 'n_a': 9, 'n_steps': 4, 'gamma': 1.8028133585515755, 'lambda_sparse': 0.005000172675235733, 'lr': 0.00012510803300918886, 'weight_decay': 8.404096517886788e-06}. Best is trial 8 with value: 0.8931026849323209.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:17:20,039] Trial 10 finished with value: 0.8334762071038848 and parameters: {'n_d': 29, 'n_a': 48, 'n_steps': 6, 'gamma': 1.4070948073221388, 'lambda_sparse': 0.0007067600738017317, 'lr': 0.040318294181989116, 'weight_decay': 1.4419821444814414e-06}. Best is trial 8 with value: 0.8931026849323209.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:18:04,342] Trial 11 finished with value: 0.8955071138989839 and parameters: {'n_d': 46, 'n_a': 61, 'n_steps': 6, 'gamma': 1.5741307408141023, 'lambda_sparse': 0.0006150730603533372, 'lr': 0.03156743831479051, 'weight_decay': 8.71384260274972e-06}. Best is trial 11 with value: 0.8955071138989839.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:18:35,919] Trial 12 finished with value: 0.8746501819964436 and parameters: {'n_d': 33, 'n_a': 50, 'n_steps': 6, 'gamma': 1.4656532044663106, 'lambda_sparse': 0.0006352068775842653, 'lr': 0.031718835267180535, 'weight_decay': 5.780353283522992e-06}. Best is trial 11 with value: 0.8955071138989839.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:19:25,168] Trial 13 finished with value: 0.804855050489657 and parameters: {'n_d': 41, 'n_a': 64, 'n_steps': 7, 'gamma': 1.6616960610349933, 'lambda_sparse': 0.00015351663501355107, 'lr': 0.012172411045279687, 'weight_decay': 5.62444797734234e-06}. Best is trial 11 with value: 0.8955071138989839.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:20:14,791] Trial 14 finished with value: 0.910203912905631 and parameters: {'n_d': 25, 'n_a': 51, 'n_steps': 7, 'gamma': 1.2436033072626609, 'lambda_sparse': 0.0009088011042045171, 'lr': 0.015023775288677012, 'weight_decay': 2.7778376839578625e-06}. Best is trial 14 with value: 0.910203912905631.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:20:52,887] Trial 15 finished with value: 0.9132077981611056 and parameters: {'n_d': 24, 'n_a': 46, 'n_steps': 5, 'gamma': 1.2841482825670518, 'lambda_sparse': 0.0010389053809469273, 'lr': 0.00951441956897721, 'weight_decay': 8.559020861405108e-06}. Best is trial 15 with value: 0.9132077981611056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:21:30,319] Trial 16 finished with value: 0.9103211225997222 and parameters: {'n_d': 24, 'n_a': 44, 'n_steps': 5, 'gamma': 1.2978145757794544, 'lambda_sparse': 0.0013193807201656287, 'lr': 0.008240555863642378, 'weight_decay': 3.280820446595496e-06}. Best is trial 15 with value: 0.9132077981611056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:22:10,214] Trial 17 finished with value: 0.8903511891824718 and parameters: {'n_d': 22, 'n_a': 42, 'n_steps': 5, 'gamma': 1.2976169834541136, 'lambda_sparse': 0.0020648541352587028, 'lr': 0.008936783199743049, 'weight_decay': 0.00019617588181627775}. Best is trial 15 with value: 0.9132077981611056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:22:49,934] Trial 18 finished with value: 0.9038984443169036 and parameters: {'n_d': 35, 'n_a': 41, 'n_steps': 5, 'gamma': 1.364318289109042, 'lambda_sparse': 0.0018532655468515636, 'lr': 0.008801175883185307, 'weight_decay': 4.206235565375375e-06}. Best is trial 15 with value: 0.9132077981611056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:23:16,550] Trial 19 finished with value: 0.9110866224759109 and parameters: {'n_d': 22, 'n_a': 43, 'n_steps': 3, 'gamma': 1.1410466351876185, 'lambda_sparse': 1.2057900134459457e-05, 'lr': 0.07666663636911845, 'weight_decay': 1.380873151054435e-05}. Best is trial 15 with value: 0.9132077981611056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:24:07,034] A new study created in memory with name: no-name-d569a746-f3be-4d71-936f-abcc658937f3
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:24:46,569] Trial 0 finished with value: 0.9108108890664759 and parameters: {'n_d': 26, 'n_a': 41, 'n_steps': 7, 'gamma': 1.1028471941949192, 'lambda_sparse': 7.5782054141326e-05, 'lr': 0.0840453790385555, 'weight_decay': 6.567559508541765e-06}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:25:42,118] Trial 1 finished with value: 0.7928148953755279 and parameters: {'n_d': 26, 'n_a': 31, 'n_steps': 8, 'gamma': 1.563378758747536, 'lambda_sparse': 0.00131547731977834, 'lr': 0.008468771754178562, 'weight_decay': 0.00015474800723506125}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:26:40,210] Trial 2 finished with value: 0.8152665854288772 and parameters: {'n_d': 45, 'n_a': 16, 'n_steps': 8, 'gamma': 1.6591325255766032, 'lambda_sparse': 4.041847494496589e-05, 'lr': 0.02068699162519316, 'weight_decay': 3.430502606593111e-06}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:27:41,118] Trial 3 finished with value: 0.33574980446800506 and parameters: {'n_d': 61, 'n_a': 13, 'n_steps': 9, 'gamma': 1.2592188366694754, 'lambda_sparse': 2.9273506815719596e-05, 'lr': 0.0003155051785881957, 'weight_decay': 0.00018973849673732437}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:28:38,463] Trial 4 finished with value: 0.8557093943829048 and parameters: {'n_d': 31, 'n_a': 38, 'n_steps': 10, 'gamma': 1.125564801687078, 'lambda_sparse': 0.0015796485586028136, 'lr': 0.09086912059552657, 'weight_decay': 0.0003538653778407303}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:29:11,275] Trial 5 finished with value: 0.5514565405829597 and parameters: {'n_d': 56, 'n_a': 37, 'n_steps': 4, 'gamma': 1.7388554196123047, 'lambda_sparse': 0.00024932561603234173, 'lr': 0.00021719966256681628, 'weight_decay': 6.558306459174168e-06}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:30:13,507] Trial 6 finished with value: 0.32294202761457 and parameters: {'n_d': 29, 'n_a': 59, 'n_steps': 9, 'gamma': 1.5271939946759736, 'lambda_sparse': 0.003451847295295331, 'lr': 0.0002602623941307719, 'weight_decay': 3.5585132711674278e-06}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:30:59,026] Trial 7 finished with value: 0.17516485296801265 and parameters: {'n_d': 24, 'n_a': 19, 'n_steps': 6, 'gamma': 1.6147206132316407, 'lambda_sparse': 0.000250709461491053, 'lr': 0.00014275318824388472, 'weight_decay': 0.00011372058932522556}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:31:37,850] Trial 8 finished with value: 0.8585074097067857 and parameters: {'n_d': 11, 'n_a': 38, 'n_steps': 7, 'gamma': 1.3788670035730428, 'lambda_sparse': 0.0008521587492034265, 'lr': 0.016566675910491987, 'weight_decay': 2.0793443522996333e-06}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:32:12,409] Trial 9 finished with value: 0.8448453229050075 and parameters: {'n_d': 54, 'n_a': 17, 'n_steps': 8, 'gamma': 1.2384606015901527, 'lambda_sparse': 0.004880418177213147, 'lr': 0.03391765939526643, 'weight_decay': 0.0009522259853320542}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:32:40,369] Trial 10 finished with value: 0.8421902302109485 and parameters: {'n_d': 10, 'n_a': 58, 'n_steps': 3, 'gamma': 1.9921183848227946, 'lambda_sparse': 7.448909024590825e-05, 'lr': 0.0020929825734071067, 'weight_decay': 1.8875919627553712e-05}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:33:28,719] Trial 11 finished with value: 0.8929124684635662 and parameters: {'n_d': 8, 'n_a': 47, 'n_steps': 6, 'gamma': 1.3399471665834568, 'lambda_sparse': 1.1891045963450773e-05, 'lr': 0.06905810687334792, 'weight_decay': 1.3338035295076534e-06}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:34:06,695] Trial 12 finished with value: 0.9067312333360509 and parameters: {'n_d': 18, 'n_a': 50, 'n_steps': 5, 'gamma': 1.0227805160672796, 'lambda_sparse': 1.0305316939134641e-05, 'lr': 0.0970866280767165, 'weight_decay': 1.0486382810987245e-06}. Best is trial 0 with value: 0.9108108890664759.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:34:46,458] Trial 13 finished with value: 0.9108511665518123 and parameters: {'n_d': 19, 'n_a': 51, 'n_steps': 5, 'gamma': 1.019192078331455, 'lambda_sparse': 1.2328119305760117e-05, 'lr': 0.003149586124012648, 'weight_decay': 1.9524816730846573e-05}. Best is trial 13 with value: 0.9108511665518123.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:35:26,351] Trial 14 finished with value: 0.9024163421371516 and parameters: {'n_d': 35, 'n_a': 48, 'n_steps': 5, 'gamma': 1.0326292016210323, 'lambda_sparse': 9.402390153890671e-05, 'lr': 0.0023742681736301746, 'weight_decay': 2.2459719417281776e-05}. Best is trial 13 with value: 0.9108511665518123.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:36:09,533] Trial 15 finished with value: 0.8010712707785153 and parameters: {'n_d': 19, 'n_a': 27, 'n_steps': 5, 'gamma': 1.160716742372557, 'lambda_sparse': 2.6446442668361498e-05, 'lr': 0.0008950356590444926, 'weight_decay': 1.0899971251596695e-05}. Best is trial 13 with value: 0.9108511665518123.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:36:51,602] Trial 16 finished with value: 0.9151488163808957 and parameters: {'n_d': 41, 'n_a': 64, 'n_steps': 3, 'gamma': 1.0055237350911466, 'lambda_sparse': 8.58933188375313e-05, 'lr': 0.006379374163713983, 'weight_decay': 5.686305786346456e-05}. Best is trial 16 with value: 0.9151488163808957.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:37:25,927] Trial 17 finished with value: 0.9193001064499184 and parameters: {'n_d': 43, 'n_a': 64, 'n_steps': 3, 'gamma': 1.4278210639201494, 'lambda_sparse': 0.00015076900843215846, 'lr': 0.0060313849598134, 'weight_decay': 5.5192214729251323e-05}. Best is trial 17 with value: 0.9193001064499184.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:37:53,958] Trial 18 finished with value: 0.8995007786960364 and parameters: {'n_d': 43, 'n_a': 64, 'n_steps': 3, 'gamma': 1.8879901405485287, 'lambda_sparse': 0.0003913610470604516, 'lr': 0.007078450962407861, 'weight_decay': 6.690204707904565e-05}. Best is trial 17 with value: 0.9193001064499184.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:38:27,756] Trial 19 finished with value: 0.8714933290102849 and parameters: {'n_d': 43, 'n_a': 64, 'n_steps': 4, 'gamma': 1.4406410192698778, 'lambda_sparse': 0.00011775976305596151, 'lr': 0.0012133201549467613, 'weight_decay': 5.158432446177662e-05}. Best is trial 17 with value: 0.9193001064499184.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-06 01:39:11 [INFO] TabNet →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/tabnet (mean R²=0.9181)
2025-08-06 01:39:11 [INFO] Ensemble weights: TabPFN=0.337, Tree=0.335, TabNet=0.328
2025-08-06 01:39:11 [INFO] Loading individual models into memory...
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-06 01:39:15 [INFO] Saved weighted ensemble to /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand_rona/final_model.pkl
