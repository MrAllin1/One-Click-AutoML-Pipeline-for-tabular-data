cpu-bind=MASK - dlcgpu18, task  0  0 [29101]: mask 0x3c0000003c0000 set
/var/spool/slurm/job20929153/slurm_script: line 11: module: command not found
2025-08-06 11:36:03 [INFO] Using device: cuda
2025-08-06 11:36:03 [INFO] Training TabPFN model...
[I 2025-08-06 11:36:03,265] A new study created in memory with name: no-name-a513d25e-f750-400b-a323-050e2269edb7
2025-08-06 11:36:03 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
[I 2025-08-06 11:36:47,396] Trial 0 finished with value: 0.9947661253436134 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.9947661253436134.
2025-08-06 11:36:47 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
[I 2025-08-06 11:37:49,818] Trial 1 finished with value: 0.9946630211389406 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 0 with value: 0.9947661253436134.
2025-08-06 11:37:49 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
[I 2025-08-06 11:38:24,800] Trial 2 finished with value: 0.9945498334389935 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 0 with value: 0.9947661253436134.
2025-08-06 11:38:24 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
[I 2025-08-06 11:39:04,747] Trial 3 finished with value: 0.9946654872672674 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 0 with value: 0.9947661253436134.
2025-08-06 11:39:04 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
[I 2025-08-06 11:40:07,444] Trial 4 finished with value: 0.9948113973201834 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:40:07 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
2025-08-06 11:40:11 [INFO] ⏸️ Pruned trial 5 at step 1 (R²=0.9994)
[I 2025-08-06 11:40:11,763] Trial 5 pruned. 
2025-08-06 11:40:11 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
[I 2025-08-06 11:41:13,834] Trial 6 finished with value: 0.9946090669017689 and parameters: {'n_bootstrap': 19, 'sample_frac': 0.6637017332034828}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:41:13 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
[I 2025-08-06 11:41:53,591] Trial 7 finished with value: 0.9946226267964412 and parameters: {'n_bootstrap': 12, 'sample_frac': 0.6550213529560301}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:41:53 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
[I 2025-08-06 11:42:41,667] Trial 8 finished with value: 0.9947054510229377 and parameters: {'n_bootstrap': 13, 'sample_frac': 0.7574269294896714}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:42:41 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
[I 2025-08-06 11:43:29,317] Trial 9 finished with value: 0.9947570850691764 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.6873687420594126}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:43:29 [INFO] 🔍 Trial 10: n_bootstrap=17, sample_frac=0.82
2025-08-06 11:43:33 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.9995)
[I 2025-08-06 11:43:33,303] Trial 10 pruned. 
2025-08-06 11:43:33 [INFO] 🔍 Trial 11: n_bootstrap=15, sample_frac=0.83
2025-08-06 11:43:37 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.9995)
[I 2025-08-06 11:43:37,178] Trial 11 pruned. 
2025-08-06 11:43:37 [INFO] 🔍 Trial 12: n_bootstrap=16, sample_frac=0.87
2025-08-06 11:43:41 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.9994)
[I 2025-08-06 11:43:41,465] Trial 12 pruned. 
2025-08-06 11:43:41 [INFO] 🔍 Trial 13: n_bootstrap=20, sample_frac=0.72
[I 2025-08-06 11:44:53,210] Trial 13 finished with value: 0.9946675070334579 and parameters: {'n_bootstrap': 20, 'sample_frac': 0.7177358676307897}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:44:53 [INFO] 🔍 Trial 14: n_bootstrap=15, sample_frac=0.60
[I 2025-08-06 11:45:39,145] Trial 14 finished with value: 0.9946951933808392 and parameters: {'n_bootstrap': 15, 'sample_frac': 0.6039530197390021}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:45:39 [INFO] 🔍 Trial 15: n_bootstrap=17, sample_frac=0.81
2025-08-06 11:45:42 [INFO] ⏸️ Pruned trial 15 at step 1 (R²=0.9995)
[I 2025-08-06 11:45:42,992] Trial 15 pruned. 
2025-08-06 11:45:43 [INFO] 🔍 Trial 16: n_bootstrap=13, sample_frac=0.85
2025-08-06 11:45:47 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.9994)
[I 2025-08-06 11:45:47,002] Trial 16 pruned. 
2025-08-06 11:45:47 [INFO] 🔍 Trial 17: n_bootstrap=16, sample_frac=0.79
2025-08-06 11:45:50 [INFO] ⏸️ Pruned trial 17 at step 1 (R²=0.9995)
[I 2025-08-06 11:45:50,758] Trial 17 pruned. 
2025-08-06 11:45:50 [INFO] 🔍 Trial 18: n_bootstrap=14, sample_frac=0.90
2025-08-06 11:45:55 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.9995)
[I 2025-08-06 11:45:55,147] Trial 18 pruned. 
2025-08-06 11:45:55 [INFO] 🔍 Trial 19: n_bootstrap=17, sample_frac=0.74
[I 2025-08-06 11:46:56,859] Trial 19 finished with value: 0.9946799546784977 and parameters: {'n_bootstrap': 17, 'sample_frac': 0.7365866415929077}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:46:56 [INFO] 🔍 Trial 20: n_bootstrap=14, sample_frac=0.84
2025-08-06 11:47:00 [INFO] ⏸️ Pruned trial 20 at step 1 (R²=0.9994)
[I 2025-08-06 11:47:00,801] Trial 20 pruned. 
2025-08-06 11:47:00 [INFO] 🔍 Trial 21: n_bootstrap=14, sample_frac=0.71
2025-08-06 11:47:04 [INFO] ⏸️ Pruned trial 21 at step 1 (R²=0.9995)
[I 2025-08-06 11:47:04,355] Trial 21 pruned. 
2025-08-06 11:47:04 [INFO] 🔍 Trial 22: n_bootstrap=13, sample_frac=0.78
2025-08-06 11:47:08 [INFO] ⏸️ Pruned trial 22 at step 1 (R²=0.9995)
[I 2025-08-06 11:47:08,340] Trial 22 pruned. 
2025-08-06 11:47:08 [INFO] 🔍 Trial 23: n_bootstrap=15, sample_frac=0.69
[I 2025-08-06 11:47:58,756] Trial 23 finished with value: 0.9947556410146937 and parameters: {'n_bootstrap': 15, 'sample_frac': 0.6883526733161716}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:47:58 [INFO] 🔍 Trial 24: n_bootstrap=12, sample_frac=0.75
2025-08-06 11:48:02 [INFO] ⏸️ Pruned trial 24 at step 1 (R²=0.9995)
[I 2025-08-06 11:48:02,499] Trial 24 pruned. 
2025-08-06 11:48:02 [INFO] 🔍 Trial 25: n_bootstrap=16, sample_frac=0.62
[I 2025-08-06 11:48:53,478] Trial 25 finished with value: 0.9947190355102992 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.6188127426802384}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:48:53 [INFO] 🔍 Trial 26: n_bootstrap=15, sample_frac=0.87
2025-08-06 11:48:57 [INFO] ⏸️ Pruned trial 26 at step 1 (R²=0.9994)
[I 2025-08-06 11:48:57,536] Trial 26 pruned. 
2025-08-06 11:48:57 [INFO] 🔍 Trial 27: n_bootstrap=12, sample_frac=0.80
2025-08-06 11:49:01 [INFO] ⏸️ Pruned trial 27 at step 1 (R²=0.9995)
[I 2025-08-06 11:49:01,288] Trial 27 pruned. 
2025-08-06 11:49:01 [INFO] 🔍 Trial 28: n_bootstrap=18, sample_frac=0.69
[I 2025-08-06 11:50:02,552] Trial 28 finished with value: 0.9945716551586714 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.6910338902665674}. Best is trial 4 with value: 0.9948113973201834.
2025-08-06 11:50:02 [INFO] 🔍 Trial 29: n_bootstrap=18, sample_frac=0.73
2025-08-06 11:50:06 [INFO] ⏸️ Pruned trial 29 at step 1 (R²=0.9995)
[I 2025-08-06 11:50:06,071] Trial 29 pruned. 
2025-08-06 11:50:06 [INFO] 🏆 Best Params: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}, R²=0.99481
2025-08-06 11:50:06 [INFO] Bootstrap training → dataset=brazilian_houses, device=cuda
2025-08-06 11:50:06 [INFO] [1/16] bootstrap sample size=3421
2025-08-06 11:50:10 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_1.pkl
2025-08-06 11:50:10 [INFO] [2/16] bootstrap sample size=3421
2025-08-06 11:50:14 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_2.pkl
2025-08-06 11:50:14 [INFO] [3/16] bootstrap sample size=3421
2025-08-06 11:50:18 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_3.pkl
2025-08-06 11:50:18 [INFO] [4/16] bootstrap sample size=3421
2025-08-06 11:50:22 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_4.pkl
2025-08-06 11:50:22 [INFO] [5/16] bootstrap sample size=3421
2025-08-06 11:50:26 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_5.pkl
2025-08-06 11:50:26 [INFO] [6/16] bootstrap sample size=3421
2025-08-06 11:50:30 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_6.pkl
2025-08-06 11:50:30 [INFO] [7/16] bootstrap sample size=3421
2025-08-06 11:50:34 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_7.pkl
2025-08-06 11:50:35 [INFO] [8/16] bootstrap sample size=3421
2025-08-06 11:50:39 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_8.pkl
2025-08-06 11:50:39 [INFO] [9/16] bootstrap sample size=3421
2025-08-06 11:50:43 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_9.pkl
2025-08-06 11:50:43 [INFO] [10/16] bootstrap sample size=3421
2025-08-06 11:50:47 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_10.pkl
2025-08-06 11:50:47 [INFO] [11/16] bootstrap sample size=3421
2025-08-06 11:50:51 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_11.pkl
2025-08-06 11:50:51 [INFO] [12/16] bootstrap sample size=3421
2025-08-06 11:50:55 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_12.pkl
2025-08-06 11:50:55 [INFO] [13/16] bootstrap sample size=3421
2025-08-06 11:50:59 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_13.pkl
2025-08-06 11:50:59 [INFO] [14/16] bootstrap sample size=3421
2025-08-06 11:51:03 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_14.pkl
2025-08-06 11:51:03 [INFO] [15/16] bootstrap sample size=3421
2025-08-06 11:51:07 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_15.pkl
2025-08-06 11:51:07 [INFO] [16/16] bootstrap sample size=3421
2025-08-06 11:51:12 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/bootstrap_16.pkl
2025-08-06 11:51:12 [INFO] 📊 Final OOB R² = 0.99481
2025-08-06 11:51:15 [INFO] Saved ensemble → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/ensemble.pkl
2025-08-06 11:51:15 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-06 11:51:15 [INFO] Total time: 69.7s
2025-08-06 11:51:15 [INFO] TabPFN →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/brazilian_houses/ensemble.pkl (R²=0.9948)
2025-08-06 11:51:15 [INFO] Training tree-based model...
2025-08-06 11:51:15 [INFO] AutoML pipeline started
2025-08-06 11:51:15 [INFO] Output directory '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona' is ready and logging is configured.
2025-08-06 11:51:15 [INFO] Merged training data: 4212 rows
2025-08-06 11:51:15 [INFO] Split data into pool (3790 rows) and validation (422 rows)
2025-08-06 11:51:15 [INFO] Feature engineering completed: 11 features
[I 2025-08-06 11:51:15,877] A new study created in memory with name: no-name-55643dfa-475a-4709-a765-374f31369f28
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-06 11:54:15,691] Trial 0 finished with value: -0.9830612446660296 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.9830612446660296.
[I 2025-08-06 11:54:24,381] Trial 1 finished with value: -0.9888740677795781 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-06 11:55:35,819] Trial 2 finished with value: -0.9844131707527499 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-06 11:55:42,256] Trial 3 finished with value: -0.9875646494125891 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-06 11:55:56,973] Trial 4 finished with value: -0.9857845286914062 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-06 11:56:05,132] Trial 5 finished with value: -0.9882095727768767 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-06 11:57:29,778] Trial 6 finished with value: -0.983355054504821 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-06 11:57:36,061] Trial 7 finished with value: -0.9891723970988948 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-06 12:00:05,405] Trial 8 finished with value: -0.9787649489967307 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-06 12:00:11,624] Trial 9 finished with value: -0.9890264646974869 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-06 12:00:16,738] Trial 10 finished with value: -0.9846699366865703 and parameters: {'learning_rate': 0.2552948136610821, 'depth': 7, 'l2_leaf_reg': 6.215107140682327, 'border_count': 36}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-06 12:00:21,777] Trial 11 finished with value: -0.9856480668107046 and parameters: {'learning_rate': 0.11386552028513468, 'depth': 4, 'l2_leaf_reg': 7.6878249427006295, 'border_count': 34}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-06 12:00:33,842] Trial 12 finished with value: -0.987193965492055 and parameters: {'learning_rate': 0.02131175919937471, 'depth': 7, 'l2_leaf_reg': 6.714957031037731, 'border_count': 170}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-06 12:00:40,405] Trial 13 finished with value: -0.9892486566616215 and parameters: {'learning_rate': 0.05491899012584811, 'depth': 4, 'l2_leaf_reg': 9.338493890692899, 'border_count': 78}. Best is trial 13 with value: -0.9892486566616215.
[I 2025-08-06 12:00:49,383] Trial 14 finished with value: -0.9881261698662263 and parameters: {'learning_rate': 0.06271124466425858, 'depth': 6, 'l2_leaf_reg': 9.554836484635672, 'border_count': 79}. Best is trial 13 with value: -0.9892486566616215.
[I 2025-08-06 12:01:04,983] Trial 15 finished with value: -0.9845506545608348 and parameters: {'learning_rate': 0.11519240087159174, 'depth': 9, 'l2_leaf_reg': 8.787983927901438, 'border_count': 62}. Best is trial 13 with value: -0.9892486566616215.
[I 2025-08-06 12:01:11,714] Trial 16 finished with value: -0.9899199320720229 and parameters: {'learning_rate': 0.04704643856781044, 'depth': 4, 'l2_leaf_reg': 5.043875815493685, 'border_count': 108}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:01:21,108] Trial 17 finished with value: -0.9886157762422559 and parameters: {'learning_rate': 0.04299159344815616, 'depth': 6, 'l2_leaf_reg': 4.9431715074202085, 'border_count': 110}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:01:31,025] Trial 18 finished with value: -0.9895998320933137 and parameters: {'learning_rate': 0.11561513904055767, 'depth': 6, 'l2_leaf_reg': 3.9276183289831463, 'border_count': 135}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:01:40,807] Trial 19 finished with value: -0.9872271720693492 and parameters: {'learning_rate': 0.26369018334394767, 'depth': 6, 'l2_leaf_reg': 3.913972053768391, 'border_count': 178}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:01:58,081] Trial 20 finished with value: -0.9868889974875408 and parameters: {'learning_rate': 0.13118618358879097, 'depth': 8, 'l2_leaf_reg': 5.4245808762372265, 'border_count': 141}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:02:04,900] Trial 21 finished with value: -0.9888440983540973 and parameters: {'learning_rate': 0.056667833645229634, 'depth': 4, 'l2_leaf_reg': 4.136091875403359, 'border_count': 95}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:02:12,979] Trial 22 finished with value: -0.9888092922887941 and parameters: {'learning_rate': 0.03495597071590568, 'depth': 5, 'l2_leaf_reg': 2.988016042438531, 'border_count': 123}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:02:24,303] Trial 23 finished with value: -0.9875103168648508 and parameters: {'learning_rate': 0.16624339820308198, 'depth': 7, 'l2_leaf_reg': 8.403430812183041, 'border_count': 93}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:02:31,946] Trial 24 finished with value: -0.988966025956415 and parameters: {'learning_rate': 0.08902635280281779, 'depth': 5, 'l2_leaf_reg': 5.334907331464369, 'border_count': 147}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:02:40,156] Trial 25 finished with value: -0.9869027635764869 and parameters: {'learning_rate': 0.04920332711565596, 'depth': 6, 'l2_leaf_reg': 5.922666336816717, 'border_count': 53}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:02:46,707] Trial 26 finished with value: -0.989551346486736 and parameters: {'learning_rate': 0.17665845012530415, 'depth': 4, 'l2_leaf_reg': 4.527544405036116, 'border_count': 107}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:02:55,103] Trial 27 finished with value: -0.9886665477586934 and parameters: {'learning_rate': 0.17874908286272934, 'depth': 5, 'l2_leaf_reg': 4.291562172687347, 'border_count': 182}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:03:05,076] Trial 28 finished with value: -0.9890307332974073 and parameters: {'learning_rate': 0.22042554420520363, 'depth': 6, 'l2_leaf_reg': 2.2196208754278413, 'border_count': 197}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:03:12,116] Trial 29 finished with value: -0.9893403714778121 and parameters: {'learning_rate': 0.12644890036298762, 'depth': 4, 'l2_leaf_reg': 3.3677981070036513, 'border_count': 151}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:03:24,291] Trial 30 finished with value: -0.9886994175452533 and parameters: {'learning_rate': 0.1998424663219883, 'depth': 7, 'l2_leaf_reg': 4.606184156177052, 'border_count': 129}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:03:31,387] Trial 31 finished with value: -0.9898760818361817 and parameters: {'learning_rate': 0.13360557464541079, 'depth': 4, 'l2_leaf_reg': 3.5269241579943778, 'border_count': 159}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:03:39,373] Trial 32 finished with value: -0.9884711925014498 and parameters: {'learning_rate': 0.09525674311720078, 'depth': 5, 'l2_leaf_reg': 1.7684683207332768, 'border_count': 107}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:03:45,881] Trial 33 finished with value: -0.9898492228691321 and parameters: {'learning_rate': 0.29617315369159336, 'depth': 4, 'l2_leaf_reg': 3.151894961641595, 'border_count': 160}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:03:54,307] Trial 34 finished with value: -0.9894046871757738 and parameters: {'learning_rate': 0.14910999270278194, 'depth': 5, 'l2_leaf_reg': 3.363970091218451, 'border_count': 158}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-06 12:04:01,678] Trial 35 finished with value: -0.9912749589890518 and parameters: {'learning_rate': 0.10262523980364108, 'depth': 4, 'l2_leaf_reg': 2.618080916894446, 'border_count': 196}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:04:09,137] Trial 36 finished with value: -0.9894313680821238 and parameters: {'learning_rate': 0.06637088038450864, 'depth': 4, 'l2_leaf_reg': 1.1562256315519184, 'border_count': 228}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:04:46,144] Trial 37 finished with value: -0.9851497433824834 and parameters: {'learning_rate': 0.03783235435214252, 'depth': 9, 'l2_leaf_reg': 2.1606625031814826, 'border_count': 192}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:04:54,994] Trial 38 finished with value: -0.988781595211775 and parameters: {'learning_rate': 0.28029656436703526, 'depth': 5, 'l2_leaf_reg': 2.3603387125583275, 'border_count': 255}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:05:02,355] Trial 39 finished with value: -0.9905835584560612 and parameters: {'learning_rate': 0.09967369743653258, 'depth': 4, 'l2_leaf_reg': 1.6824399155666263, 'border_count': 210}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:03,944] Trial 40 finished with value: -0.9828918759739119 and parameters: {'learning_rate': 0.09765723519629871, 'depth': 11, 'l2_leaf_reg': 1.6137794177875469, 'border_count': 233}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:11,002] Trial 41 finished with value: -0.9902188802049592 and parameters: {'learning_rate': 0.14632978137200253, 'depth': 4, 'l2_leaf_reg': 2.9782990472695077, 'border_count': 162}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:18,188] Trial 42 finished with value: -0.9903284782591808 and parameters: {'learning_rate': 0.07713582695477122, 'depth': 4, 'l2_leaf_reg': 2.533345117695543, 'border_count': 210}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:26,899] Trial 43 finished with value: -0.9898155063521452 and parameters: {'learning_rate': 0.0748334310474749, 'depth': 5, 'l2_leaf_reg': 2.7580485985712784, 'border_count': 214}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:34,049] Trial 44 finished with value: -0.9904400657537634 and parameters: {'learning_rate': 0.08613907326243302, 'depth': 4, 'l2_leaf_reg': 1.7821883308729478, 'border_count': 208}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:41,309] Trial 45 finished with value: -0.9900035573115487 and parameters: {'learning_rate': 0.08352081515252029, 'depth': 4, 'l2_leaf_reg': 1.812731097726318, 'border_count': 208}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:50,121] Trial 46 finished with value: -0.9884387292722783 and parameters: {'learning_rate': 0.09872370683183171, 'depth': 5, 'l2_leaf_reg': 1.0567185223553839, 'border_count': 239}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:07:57,337] Trial 47 finished with value: -0.9910155436484696 and parameters: {'learning_rate': 0.07718283286866867, 'depth': 4, 'l2_leaf_reg': 2.5333108108441276, 'border_count': 200}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:08:06,060] Trial 48 finished with value: -0.9892412260653641 and parameters: {'learning_rate': 0.06963778588914839, 'depth': 5, 'l2_leaf_reg': 2.4087432503165256, 'border_count': 219}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:08:13,272] Trial 49 finished with value: -0.9903883592626059 and parameters: {'learning_rate': 0.060924473428840144, 'depth': 4, 'l2_leaf_reg': 1.8705795459258323, 'border_count': 204}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:08:52,622] Trial 50 finished with value: -0.9850701257185775 and parameters: {'learning_rate': 0.10645501074520745, 'depth': 9, 'l2_leaf_reg': 1.3457301493587808, 'border_count': 199}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:08:59,871] Trial 51 finished with value: -0.9901291743995616 and parameters: {'learning_rate': 0.06041869597748931, 'depth': 4, 'l2_leaf_reg': 2.0165423024795235, 'border_count': 203}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:09:07,171] Trial 52 finished with value: -0.9902296642705952 and parameters: {'learning_rate': 0.07257543392730571, 'depth': 4, 'l2_leaf_reg': 2.561870640508954, 'border_count': 242}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:09:15,578] Trial 53 finished with value: -0.9887578893046556 and parameters: {'learning_rate': 0.0830551642184434, 'depth': 5, 'l2_leaf_reg': 1.5408111770251711, 'border_count': 186}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:09:22,851] Trial 54 finished with value: -0.9906509282511087 and parameters: {'learning_rate': 0.053873047784201974, 'depth': 4, 'l2_leaf_reg': 1.9450121852618725, 'border_count': 221}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:09:29,580] Trial 55 finished with value: -0.9894396901121814 and parameters: {'learning_rate': 0.05142512487606263, 'depth': 4, 'l2_leaf_reg': 1.8645019047354299, 'border_count': 176}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:09:38,441] Trial 56 finished with value: -0.9891697354237283 and parameters: {'learning_rate': 0.04047131582012417, 'depth': 5, 'l2_leaf_reg': 1.3341049623833388, 'border_count': 223}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:09:45,512] Trial 57 finished with value: -0.9884949709261331 and parameters: {'learning_rate': 0.011609930160367014, 'depth': 4, 'l2_leaf_reg': 2.177588313105877, 'border_count': 188}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:09:54,314] Trial 58 finished with value: -0.9894423758755269 and parameters: {'learning_rate': 0.029126146979250485, 'depth': 5, 'l2_leaf_reg': 1.546806937436294, 'border_count': 219}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:13:14,103] Trial 59 finished with value: -0.9817527346970207 and parameters: {'learning_rate': 0.06103520728119887, 'depth': 12, 'l2_leaf_reg': 2.917557519145487, 'border_count': 172}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:13:21,479] Trial 60 finished with value: -0.9887987432619582 and parameters: {'learning_rate': 0.04469964582841724, 'depth': 4, 'l2_leaf_reg': 1.022917573570061, 'border_count': 234}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:13:28,782] Trial 61 finished with value: -0.9902163012657897 and parameters: {'learning_rate': 0.07873102149786142, 'depth': 4, 'l2_leaf_reg': 2.3932796534129412, 'border_count': 208}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:13:36,018] Trial 62 finished with value: -0.9907817476122951 and parameters: {'learning_rate': 0.08638158175645762, 'depth': 4, 'l2_leaf_reg': 2.651332398103982, 'border_count': 211}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:13:42,957] Trial 63 finished with value: -0.99007251295722 and parameters: {'learning_rate': 0.10824296663951714, 'depth': 4, 'l2_leaf_reg': 2.0128337904720897, 'border_count': 196}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:13:51,771] Trial 64 finished with value: -0.9899970346861812 and parameters: {'learning_rate': 0.08906364469061084, 'depth': 5, 'l2_leaf_reg': 3.814657302619673, 'border_count': 226}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:13:58,986] Trial 65 finished with value: -0.9905604196207577 and parameters: {'learning_rate': 0.0595415354706779, 'depth': 4, 'l2_leaf_reg': 2.730260568640568, 'border_count': 203}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:14:09,934] Trial 66 finished with value: -0.9895716704567585 and parameters: {'learning_rate': 0.0540847194678496, 'depth': 6, 'l2_leaf_reg': 2.5933301166925893, 'border_count': 215}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:14:17,350] Trial 67 finished with value: -0.9905390544280804 and parameters: {'learning_rate': 0.11859158872377654, 'depth': 4, 'l2_leaf_reg': 2.7906983735983637, 'border_count': 242}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:14:26,291] Trial 68 finished with value: -0.9896224717231952 and parameters: {'learning_rate': 0.11449055856467757, 'depth': 5, 'l2_leaf_reg': 3.3209450002082512, 'border_count': 245}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:14:37,244] Trial 69 finished with value: -0.9876989365294216 and parameters: {'learning_rate': 0.014888463560777308, 'depth': 6, 'l2_leaf_reg': 3.661721529788761, 'border_count': 255}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:14:44,594] Trial 70 finished with value: -0.9903639042998357 and parameters: {'learning_rate': 0.06722930320465444, 'depth': 4, 'l2_leaf_reg': 2.900930983197482, 'border_count': 231}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:14:50,967] Trial 71 finished with value: -0.9904722263893266 and parameters: {'learning_rate': 0.12357650909738935, 'depth': 4, 'l2_leaf_reg': 2.7052642540682883, 'border_count': 221}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:14:58,270] Trial 72 finished with value: -0.9912418879437265 and parameters: {'learning_rate': 0.1314005112680107, 'depth': 4, 'l2_leaf_reg': 3.169590735976461, 'border_count': 222}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:15:05,416] Trial 73 finished with value: -0.9905188706983907 and parameters: {'learning_rate': 0.14632998622110432, 'depth': 4, 'l2_leaf_reg': 3.1794315395389976, 'border_count': 249}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:15:13,961] Trial 74 finished with value: -0.9896378594856566 and parameters: {'learning_rate': 0.09523524242132046, 'depth': 5, 'l2_leaf_reg': 3.1692293121125683, 'border_count': 190}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:16:22,498] Trial 75 finished with value: -0.9841848841930814 and parameters: {'learning_rate': 0.13471663940552486, 'depth': 10, 'l2_leaf_reg': 4.070703871987812, 'border_count': 236}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:16:29,959] Trial 76 finished with value: -0.9912141690090707 and parameters: {'learning_rate': 0.16321769011026604, 'depth': 4, 'l2_leaf_reg': 3.5415407476409344, 'border_count': 226}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:16:37,082] Trial 77 finished with value: -0.9911406998278297 and parameters: {'learning_rate': 0.2063717003569693, 'depth': 4, 'l2_leaf_reg': 3.5619766944767877, 'border_count': 199}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:16:45,515] Trial 78 finished with value: -0.9894428215951299 and parameters: {'learning_rate': 0.19239476410409145, 'depth': 5, 'l2_leaf_reg': 4.379075511061603, 'border_count': 181}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:16:52,413] Trial 79 finished with value: -0.9901155238150879 and parameters: {'learning_rate': 0.23110974822492386, 'depth': 4, 'l2_leaf_reg': 3.6140876963404014, 'border_count': 227}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:00,918] Trial 80 finished with value: -0.9899860041701805 and parameters: {'learning_rate': 0.15807335682179727, 'depth': 5, 'l2_leaf_reg': 7.240204839770766, 'border_count': 195}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:07,952] Trial 81 finished with value: -0.9907814406134487 and parameters: {'learning_rate': 0.2018288804355402, 'depth': 4, 'l2_leaf_reg': 2.2111254966048373, 'border_count': 202}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:14,464] Trial 82 finished with value: -0.9897019707135826 and parameters: {'learning_rate': 0.20371892590117957, 'depth': 4, 'l2_leaf_reg': 2.4185975127366675, 'border_count': 214}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:21,373] Trial 83 finished with value: -0.9902347888915418 and parameters: {'learning_rate': 0.25172629463237217, 'depth': 4, 'l2_leaf_reg': 2.162266078667419, 'border_count': 200}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:28,415] Trial 84 finished with value: -0.9907346139514406 and parameters: {'learning_rate': 0.16299139993529788, 'depth': 4, 'l2_leaf_reg': 3.4419542004956143, 'border_count': 216}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:35,660] Trial 85 finished with value: -0.9903768550782065 and parameters: {'learning_rate': 0.18235464592777523, 'depth': 4, 'l2_leaf_reg': 3.491966327899771, 'border_count': 217}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:42,896] Trial 86 finished with value: -0.9905793926190147 and parameters: {'learning_rate': 0.16592023751672846, 'depth': 4, 'l2_leaf_reg': 4.764402912829105, 'border_count': 224}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:51,642] Trial 87 finished with value: -0.9901731441239277 and parameters: {'learning_rate': 0.20811979774119307, 'depth': 5, 'l2_leaf_reg': 3.7840020821123943, 'border_count': 205}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:17:58,733] Trial 88 finished with value: -0.990603982497178 and parameters: {'learning_rate': 0.22507804108026577, 'depth': 4, 'l2_leaf_reg': 5.822341971277818, 'border_count': 183}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:18:19,931] Trial 89 finished with value: -0.9860190828910523 and parameters: {'learning_rate': 0.1359208053871254, 'depth': 8, 'l2_leaf_reg': 3.0442868691664633, 'border_count': 230}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:18:28,604] Trial 90 finished with value: -0.9895960762814017 and parameters: {'learning_rate': 0.1574276302243018, 'depth': 5, 'l2_leaf_reg': 4.02550779553221, 'border_count': 192}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:18:35,613] Trial 91 finished with value: -0.9907056581721886 and parameters: {'learning_rate': 0.24306760125650667, 'depth': 4, 'l2_leaf_reg': 3.228575046533984, 'border_count': 211}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:18:42,549] Trial 92 finished with value: -0.990775999861601 and parameters: {'learning_rate': 0.24426441214152317, 'depth': 4, 'l2_leaf_reg': 3.2897055257161005, 'border_count': 212}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:18:49,839] Trial 93 finished with value: -0.990441308831523 and parameters: {'learning_rate': 0.24427549943950425, 'depth': 4, 'l2_leaf_reg': 3.2783838400358603, 'border_count': 209}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:18:56,854] Trial 94 finished with value: -0.9901963278715276 and parameters: {'learning_rate': 0.28677572853637595, 'depth': 4, 'l2_leaf_reg': 3.4183800946591214, 'border_count': 212}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:19:03,973] Trial 95 finished with value: -0.9911339245526849 and parameters: {'learning_rate': 0.19073066265821512, 'depth': 4, 'l2_leaf_reg': 4.24410743345012, 'border_count': 199}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-06 12:19:11,145] Trial 96 finished with value: -0.9915853113835247 and parameters: {'learning_rate': 0.18457985778167543, 'depth': 4, 'l2_leaf_reg': 3.7995310639985314, 'border_count': 200}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:19:19,356] Trial 97 finished with value: -0.9891529095667126 and parameters: {'learning_rate': 0.19398840970186768, 'depth': 5, 'l2_leaf_reg': 4.262009072031541, 'border_count': 166}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:19:26,527] Trial 98 finished with value: -0.9911424510728752 and parameters: {'learning_rate': 0.17919760192331344, 'depth': 4, 'l2_leaf_reg': 5.25842324125762, 'border_count': 197}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:19:33,659] Trial 99 finished with value: -0.9910098672531781 and parameters: {'learning_rate': 0.1824048136411049, 'depth': 4, 'l2_leaf_reg': 3.775106815754635, 'border_count': 198}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:19:42,114] Trial 100 finished with value: -0.9891632345456612 and parameters: {'learning_rate': 0.17482816962670344, 'depth': 5, 'l2_leaf_reg': 5.186138156623258, 'border_count': 175}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:19:49,268] Trial 101 finished with value: -0.9900835663444777 and parameters: {'learning_rate': 0.18566035453745927, 'depth': 4, 'l2_leaf_reg': 4.506755853893747, 'border_count': 186}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:19:56,011] Trial 102 finished with value: -0.9906774411329506 and parameters: {'learning_rate': 0.21373102361692814, 'depth': 4, 'l2_leaf_reg': 4.726112336751238, 'border_count': 199}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:02,875] Trial 103 finished with value: -0.9909303663399198 and parameters: {'learning_rate': 0.15001661995864954, 'depth': 4, 'l2_leaf_reg': 4.214816334568546, 'border_count': 195}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:10,002] Trial 104 finished with value: -0.9900202010476452 and parameters: {'learning_rate': 0.14190547334987139, 'depth': 4, 'l2_leaf_reg': 4.1652341991807855, 'border_count': 194}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:16,860] Trial 105 finished with value: -0.9901812925297765 and parameters: {'learning_rate': 0.10592999784148338, 'depth': 4, 'l2_leaf_reg': 3.8102262927912895, 'border_count': 191}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:23,932] Trial 106 finished with value: -0.9902078976862159 and parameters: {'learning_rate': 0.1742388860862839, 'depth': 4, 'l2_leaf_reg': 5.737601716070634, 'border_count': 182}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:37,875] Trial 107 finished with value: -0.9879364541722279 and parameters: {'learning_rate': 0.1460645659892246, 'depth': 7, 'l2_leaf_reg': 3.674163874060443, 'border_count': 205}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:44,309] Trial 108 finished with value: -0.9902275487982871 and parameters: {'learning_rate': 0.12028210740808096, 'depth': 4, 'l2_leaf_reg': 6.164802961512898, 'border_count': 196}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:52,753] Trial 109 finished with value: -0.9899795950475181 and parameters: {'learning_rate': 0.15535036084347517, 'depth': 5, 'l2_leaf_reg': 5.034389230862326, 'border_count': 188}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:20:59,932] Trial 110 finished with value: -0.9915691875452491 and parameters: {'learning_rate': 0.12761763897649395, 'depth': 4, 'l2_leaf_reg': 4.374256114675471, 'border_count': 201}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:07,093] Trial 111 finished with value: -0.9911666856807182 and parameters: {'learning_rate': 0.13092131586397324, 'depth': 4, 'l2_leaf_reg': 3.978029213080267, 'border_count': 199}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:14,187] Trial 112 finished with value: -0.9903851388584444 and parameters: {'learning_rate': 0.1305805158557615, 'depth': 4, 'l2_leaf_reg': 3.958992252052686, 'border_count': 179}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:21,049] Trial 113 finished with value: -0.9904582975863108 and parameters: {'learning_rate': 0.2670497710820697, 'depth': 4, 'l2_leaf_reg': 4.433736236354906, 'border_count': 200}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:27,703] Trial 114 finished with value: -0.9893738008383808 and parameters: {'learning_rate': 0.16913548414303625, 'depth': 4, 'l2_leaf_reg': 4.243402071215975, 'border_count': 171}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:34,819] Trial 115 finished with value: -0.9903075697641522 and parameters: {'learning_rate': 0.12782917882814074, 'depth': 4, 'l2_leaf_reg': 4.680131310391002, 'border_count': 187}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:41,848] Trial 116 finished with value: -0.9906372975050644 and parameters: {'learning_rate': 0.14950121130021293, 'depth': 4, 'l2_leaf_reg': 4.932651471816018, 'border_count': 205}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:50,409] Trial 117 finished with value: -0.9899310950422564 and parameters: {'learning_rate': 0.13888362947789493, 'depth': 5, 'l2_leaf_reg': 3.853693773949847, 'border_count': 196}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:21:57,215] Trial 118 finished with value: -0.9899735007205963 and parameters: {'learning_rate': 0.19049864945271433, 'depth': 4, 'l2_leaf_reg': 5.594827529957806, 'border_count': 193}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:04,338] Trial 119 finished with value: -0.9907395885249077 and parameters: {'learning_rate': 0.11164560232424234, 'depth': 4, 'l2_leaf_reg': 3.6351601678898224, 'border_count': 200}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:12,630] Trial 120 finished with value: -0.9903550127214299 and parameters: {'learning_rate': 0.15394479941773132, 'depth': 5, 'l2_leaf_reg': 5.266067660918778, 'border_count': 205}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:19,910] Trial 121 finished with value: -0.9910009566851787 and parameters: {'learning_rate': 0.09327427994074522, 'depth': 4, 'l2_leaf_reg': 3.035464421561083, 'border_count': 220}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:27,230] Trial 122 finished with value: -0.9913818104092407 and parameters: {'learning_rate': 0.10535653013936488, 'depth': 4, 'l2_leaf_reg': 3.9370937982574583, 'border_count': 224}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:34,601] Trial 123 finished with value: -0.990792131200837 and parameters: {'learning_rate': 0.09544561174493321, 'depth': 4, 'l2_leaf_reg': 3.078808596264404, 'border_count': 218}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:42,023] Trial 124 finished with value: -0.9907239467275539 and parameters: {'learning_rate': 0.10422982352378066, 'depth': 4, 'l2_leaf_reg': 3.9569521653762436, 'border_count': 237}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:49,477] Trial 125 finished with value: -0.9902183913601055 and parameters: {'learning_rate': 0.12115856877466238, 'depth': 4, 'l2_leaf_reg': 2.8888103078635154, 'border_count': 227}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:22:56,857] Trial 126 finished with value: -0.9900469757053523 and parameters: {'learning_rate': 0.08974613495232578, 'depth': 4, 'l2_leaf_reg': 3.503392624426021, 'border_count': 217}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:04,103] Trial 127 finished with value: -0.9907768119232893 and parameters: {'learning_rate': 0.1027987554624808, 'depth': 4, 'l2_leaf_reg': 3.729303112567547, 'border_count': 222}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:11,461] Trial 128 finished with value: -0.9908192269303978 and parameters: {'learning_rate': 0.1787432435223434, 'depth': 4, 'l2_leaf_reg': 4.049626078297425, 'border_count': 231}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:18,633] Trial 129 finished with value: -0.9874516828808592 and parameters: {'learning_rate': 0.11209306473388103, 'depth': 5, 'l2_leaf_reg': 4.588542601189678, 'border_count': 49}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:25,475] Trial 130 finished with value: -0.9912420371809793 and parameters: {'learning_rate': 0.21350817389225069, 'depth': 4, 'l2_leaf_reg': 3.506915794126192, 'border_count': 223}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:31,914] Trial 131 finished with value: -0.9896198262594218 and parameters: {'learning_rate': 0.22186406401851347, 'depth': 4, 'l2_leaf_reg': 9.968809662341299, 'border_count': 224}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:38,970] Trial 132 finished with value: -0.9905594835617177 and parameters: {'learning_rate': 0.19828159796751144, 'depth': 4, 'l2_leaf_reg': 3.556746598027792, 'border_count': 247}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:46,246] Trial 133 finished with value: -0.9907856835601041 and parameters: {'learning_rate': 0.12930009339711337, 'depth': 4, 'l2_leaf_reg': 3.0477990504064723, 'border_count': 207}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:23:53,456] Trial 134 finished with value: -0.9914197605899879 and parameters: {'learning_rate': 0.1694978129159271, 'depth': 4, 'l2_leaf_reg': 4.318161114703478, 'border_count': 214}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:24:00,772] Trial 135 finished with value: -0.9909326431247936 and parameters: {'learning_rate': 0.16580264733487687, 'depth': 4, 'l2_leaf_reg': 4.300267666748139, 'border_count': 213}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:24:58,246] Trial 136 finished with value: -0.9852002145022318 and parameters: {'learning_rate': 0.18250227551450093, 'depth': 10, 'l2_leaf_reg': 4.014152673339721, 'border_count': 199}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:25:05,096] Trial 137 finished with value: -0.9900550287208851 and parameters: {'learning_rate': 0.22005497594453366, 'depth': 4, 'l2_leaf_reg': 4.450973464363474, 'border_count': 241}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:25:11,360] Trial 138 finished with value: -0.9897910026222696 and parameters: {'learning_rate': 0.2095763863048089, 'depth': 4, 'l2_leaf_reg': 4.823661268130083, 'border_count': 118}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:25:31,977] Trial 139 finished with value: -0.9884109867228685 and parameters: {'learning_rate': 0.16531957529312666, 'depth': 8, 'l2_leaf_reg': 8.112575781570754, 'border_count': 208}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:25:40,626] Trial 140 finished with value: -0.988945743749054 and parameters: {'learning_rate': 0.23432831327536596, 'depth': 5, 'l2_leaf_reg': 3.479775140432754, 'border_count': 203}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:25:47,737] Trial 141 finished with value: -0.9900417593356299 and parameters: {'learning_rate': 0.02224958974429549, 'depth': 4, 'l2_leaf_reg': 3.8396985094320364, 'border_count': 220}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:25:54,413] Trial 142 finished with value: -0.9898516110356039 and parameters: {'learning_rate': 0.1878635077025203, 'depth': 4, 'l2_leaf_reg': 3.3012027543483033, 'border_count': 227}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:01,622] Trial 143 finished with value: -0.9909431033475882 and parameters: {'learning_rate': 0.13871790247166313, 'depth': 4, 'l2_leaf_reg': 3.6502745375799317, 'border_count': 216}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:08,694] Trial 144 finished with value: -0.9912024236928744 and parameters: {'learning_rate': 0.11881195965301379, 'depth': 4, 'l2_leaf_reg': 3.140638007805917, 'border_count': 210}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:15,615] Trial 145 finished with value: -0.9903424643574119 and parameters: {'learning_rate': 0.12037979694825224, 'depth': 4, 'l2_leaf_reg': 4.119703133019705, 'border_count': 190}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:22,887] Trial 146 finished with value: -0.9906436559529892 and parameters: {'learning_rate': 0.17489616599290786, 'depth': 4, 'l2_leaf_reg': 2.8301700936614713, 'border_count': 210}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:30,251] Trial 147 finished with value: -0.9902950100598717 and parameters: {'learning_rate': 0.16044701867724714, 'depth': 4, 'l2_leaf_reg': 3.8555038746206645, 'border_count': 233}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:37,511] Trial 148 finished with value: -0.9911192538619119 and parameters: {'learning_rate': 0.13789206680925087, 'depth': 4, 'l2_leaf_reg': 3.387250076215124, 'border_count': 202}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:44,712] Trial 149 finished with value: -0.991272629489116 and parameters: {'learning_rate': 0.12628352981764476, 'depth': 4, 'l2_leaf_reg': 2.5493662799731456, 'border_count': 202}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-06 12:26:45,452] A new study created in memory with name: no-name-eacc6682-3d82-4da4-b2a2-fcb2dd213248
[I 2025-08-06 12:26:54,991] Trial 0 finished with value: -0.9850958115930564 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-06 12:26:56,677] Trial 1 finished with value: -0.983554004732287 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-06 12:27:02,880] Trial 2 finished with value: -0.9848042409738558 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-06 12:27:05,811] Trial 3 finished with value: -0.9843401704056666 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-06 12:27:14,810] Trial 4 finished with value: -0.9840948084419894 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-06 12:27:17,518] Trial 5 finished with value: -0.9833209189317458 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-06 12:27:24,545] Trial 6 finished with value: -0.9841295500163006 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-06 12:27:27,181] Trial 7 finished with value: -0.9852105685685585 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-06 12:27:30,644] Trial 8 finished with value: -0.9839736933490055 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-06 12:27:40,829] Trial 9 finished with value: -0.9835814150871492 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-06 12:27:41,538] Trial 10 finished with value: -0.9821927149365139 and parameters: {'learning_rate': 0.1696879465047447, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.7102020040921988, 'bagging_fraction': 0.6901464801259053, 'reg_alpha': 5.475583883351959, 'reg_lambda': 0.012278672550406735}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-06 12:27:52,187] Trial 11 finished with value: -0.9854330315284197 and parameters: {'learning_rate': 0.023612213425042897, 'num_leaves': 84, 'max_depth': 11, 'min_child_samples': 50, 'feature_fraction': 0.5106977741957487, 'bagging_fraction': 0.6769474312859594, 'reg_alpha': 4.077391468444027e-08, 'reg_lambda': 2.8339857425759094}. Best is trial 11 with value: -0.9854330315284197.
[I 2025-08-06 12:27:55,449] Trial 12 finished with value: -0.9834680834592187 and parameters: {'learning_rate': 0.017375334315313847, 'num_leaves': 70, 'max_depth': 11, 'min_child_samples': 38, 'feature_fraction': 0.7066877922057526, 'bagging_fraction': 0.6929964536410342, 'reg_alpha': 5.011953391371097, 'reg_lambda': 0.015293497883219966}. Best is trial 11 with value: -0.9854330315284197.
[I 2025-08-06 12:28:01,429] Trial 13 finished with value: -0.9859322713126835 and parameters: {'learning_rate': 0.08170216566351561, 'num_leaves': 74, 'max_depth': 10, 'min_child_samples': 37, 'feature_fraction': 0.5313382495460985, 'bagging_fraction': 0.7574852070104715, 'reg_alpha': 1.0741482674311923e-08, 'reg_lambda': 0.012925569907645785}. Best is trial 13 with value: -0.9859322713126835.
[I 2025-08-06 12:28:06,100] Trial 14 finished with value: -0.9867867518897562 and parameters: {'learning_rate': 0.09706314692140564, 'num_leaves': 95, 'max_depth': 10, 'min_child_samples': 20, 'feature_fraction': 0.5065701578589041, 'bagging_fraction': 0.805551721718827, 'reg_alpha': 1.3277235692639058e-08, 'reg_lambda': 9.207736961357908}. Best is trial 14 with value: -0.9867867518897562.
[I 2025-08-06 12:28:09,192] Trial 15 finished with value: -0.9858215334541173 and parameters: {'learning_rate': 0.0952567704737395, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 18, 'feature_fraction': 0.5951601664395402, 'bagging_fraction': 0.8295143024044869, 'reg_alpha': 1.2555970917650801e-08, 'reg_lambda': 0.09652712124824227}. Best is trial 14 with value: -0.9867867518897562.
[I 2025-08-06 12:28:11,652] Trial 16 finished with value: -0.9862188459377738 and parameters: {'learning_rate': 0.08721996044676585, 'num_leaves': 16, 'max_depth': 6, 'min_child_samples': 25, 'feature_fraction': 0.5026527562028454, 'bagging_fraction': 0.7912554411220166, 'reg_alpha': 3.2148894967806533e-07, 'reg_lambda': 0.002132721853912506}. Best is trial 14 with value: -0.9867867518897562.
[I 2025-08-06 12:28:13,872] Trial 17 finished with value: -0.9872797837594737 and parameters: {'learning_rate': 0.16640556451022465, 'num_leaves': 8, 'max_depth': 6, 'min_child_samples': 25, 'feature_fraction': 0.5002348369942121, 'bagging_fraction': 0.8465376210505953, 'reg_alpha': 5.565463586618742e-07, 'reg_lambda': 0.000662062419286776}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-06 12:28:16,799] Trial 18 finished with value: -0.9867884210248381 and parameters: {'learning_rate': 0.18930075101573227, 'num_leaves': 109, 'max_depth': 7, 'min_child_samples': 26, 'feature_fraction': 0.5964137372667864, 'bagging_fraction': 0.9069968527889158, 'reg_alpha': 6.124765019459823e-05, 'reg_lambda': 9.502723948810397}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-06 12:28:19,674] Trial 19 finished with value: -0.9856926554095423 and parameters: {'learning_rate': 0.1994505198099203, 'num_leaves': 34, 'max_depth': 6, 'min_child_samples': 25, 'feature_fraction': 0.5850170424663035, 'bagging_fraction': 0.9134336554829188, 'reg_alpha': 0.00010490127974903605, 'reg_lambda': 0.21956774205104937}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-06 12:28:22,962] Trial 20 finished with value: -0.9863042574079518 and parameters: {'learning_rate': 0.1394393349665469, 'num_leaves': 108, 'max_depth': 7, 'min_child_samples': 48, 'feature_fraction': 0.6505152466626335, 'bagging_fraction': 0.8854014330392775, 'reg_alpha': 0.00012702142020136917, 'reg_lambda': 4.968024444828976e-06}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-06 12:28:27,880] Trial 21 finished with value: -0.9873843170652185 and parameters: {'learning_rate': 0.11980668545099626, 'num_leaves': 169, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.5575244364272848, 'bagging_fraction': 0.8621383194962051, 'reg_alpha': 6.120507414183693e-07, 'reg_lambda': 3.910490313439891}. Best is trial 21 with value: -0.9873843170652185.
[I 2025-08-06 12:28:31,886] Trial 22 finished with value: -0.9873962169890118 and parameters: {'learning_rate': 0.13390499764355238, 'num_leaves': 167, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.5747304286519771, 'bagging_fraction': 0.8768909561654321, 'reg_alpha': 4.4337140247952704e-07, 'reg_lambda': 8.876628301054751}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-06 12:28:38,824] Trial 23 finished with value: -0.986445106352277 and parameters: {'learning_rate': 0.12784342713816071, 'num_leaves': 165, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.5635435705366558, 'bagging_fraction': 0.863041576426429, 'reg_alpha': 8.770825153388619e-07, 'reg_lambda': 0.09015550012932438}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-06 12:28:42,232] Trial 24 finished with value: -0.9859535223582798 and parameters: {'learning_rate': 0.11634939113748385, 'num_leaves': 169, 'max_depth': 9, 'min_child_samples': 16, 'feature_fraction': 0.6258720382546296, 'bagging_fraction': 0.9762067146120206, 'reg_alpha': 1.51029692338442e-07, 'reg_lambda': 0.5844619370737302}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-06 12:28:45,322] Trial 25 finished with value: -0.9859002517285523 and parameters: {'learning_rate': 0.06625869567185537, 'num_leaves': 214, 'max_depth': 5, 'min_child_samples': 28, 'feature_fraction': 0.545367506305898, 'bagging_fraction': 0.7559790938635295, 'reg_alpha': 1.7154441705014054e-06, 'reg_lambda': 1.1574612736518413e-08}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-06 12:28:48,243] Trial 26 finished with value: -0.9875292389089779 and parameters: {'learning_rate': 0.1396583434103578, 'num_leaves': 154, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.7798274948837373, 'bagging_fraction': 0.8543954637858238, 'reg_alpha': 1.646406340941009e-05, 'reg_lambda': 0.00027256522613180686}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-06 12:28:50,562] Trial 27 finished with value: -0.9861419840446768 and parameters: {'learning_rate': 0.14237310201538045, 'num_leaves': 158, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.8235453728708663, 'bagging_fraction': 0.9329396417213827, 'reg_alpha': 1.9907775481841456e-05, 'reg_lambda': 0.004320430752821306}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-06 12:28:55,472] Trial 28 finished with value: -0.985656058925683 and parameters: {'learning_rate': 0.11022955088098459, 'num_leaves': 187, 'max_depth': 13, 'min_child_samples': 31, 'feature_fraction': 0.7750701530559109, 'bagging_fraction': 0.8757914141339567, 'reg_alpha': 0.0005968994109134424, 'reg_lambda': 7.87701300552545e-05}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-06 12:28:59,755] Trial 29 finished with value: -0.9846375588583071 and parameters: {'learning_rate': 0.07104275119013423, 'num_leaves': 250, 'max_depth': 8, 'min_child_samples': 65, 'feature_fraction': 0.741724658826805, 'bagging_fraction': 0.9532962576261433, 'reg_alpha': 1.486136376273211e-07, 'reg_lambda': 1.4135188249861919}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-06 12:29:04,411] Trial 30 finished with value: -0.9858112098028785 and parameters: {'learning_rate': 0.03842745754146896, 'num_leaves': 125, 'max_depth': 10, 'min_child_samples': 19, 'feature_fraction': 0.849546226415591, 'bagging_fraction': 0.7964679771167982, 'reg_alpha': 2.635739731538385e-06, 'reg_lambda': 0.30910203656894697}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-06 12:29:08,568] Trial 31 finished with value: -0.9879990328860193 and parameters: {'learning_rate': 0.15618089007816505, 'num_leaves': 153, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.5684344567882854, 'bagging_fraction': 0.8474479025082922, 'reg_alpha': 6.143281937219954e-08, 'reg_lambda': 0.0010686824862189725}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:11,562] Trial 32 finished with value: -0.9874897487995069 and parameters: {'learning_rate': 0.15874745936136636, 'num_leaves': 187, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.7444967265387155, 'bagging_fraction': 0.8959659863362562, 'reg_alpha': 4.7922735794173125e-08, 'reg_lambda': 0.00014207003101464417}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:13,985] Trial 33 finished with value: -0.9859417978951456 and parameters: {'learning_rate': 0.15351070471870026, 'num_leaves': 192, 'max_depth': 8, 'min_child_samples': 20, 'feature_fraction': 0.7568451644319717, 'bagging_fraction': 0.8991713143814992, 'reg_alpha': 8.413937049327848e-08, 'reg_lambda': 8.752610537412802e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:15,591] Trial 34 finished with value: -0.9869141341839761 and parameters: {'learning_rate': 0.10544549966140175, 'num_leaves': 152, 'max_depth': 5, 'min_child_samples': 15, 'feature_fraction': 0.6784614859528049, 'bagging_fraction': 0.7755273932830261, 'reg_alpha': 7.969180414392415e-08, 'reg_lambda': 3.7788032716352305e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:18,021] Trial 35 finished with value: -0.9872697682878464 and parameters: {'learning_rate': 0.16308733916834112, 'num_leaves': 223, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8611472869134348, 'bagging_fraction': 0.8224499888525351, 'reg_alpha': 5.153304095570123e-06, 'reg_lambda': 0.00022102295400946057}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:22,995] Trial 36 finished with value: -0.9855402238219059 and parameters: {'learning_rate': 0.07694241512968658, 'num_leaves': 181, 'max_depth': 8, 'min_child_samples': 31, 'feature_fraction': 0.9267635526278051, 'bagging_fraction': 0.7266367682142773, 'reg_alpha': 3.8885478350505913e-08, 'reg_lambda': 0.001494841711599115}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:26,752] Trial 37 finished with value: -0.9850545985943013 and parameters: {'learning_rate': 0.05797253248356863, 'num_leaves': 231, 'max_depth': 6, 'min_child_samples': 43, 'feature_fraction': 0.7374821279913889, 'bagging_fraction': 0.927676545065034, 'reg_alpha': 1.985346685505641e-07, 'reg_lambda': 1.7005350852014366e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:28,528] Trial 38 finished with value: -0.9846497122909987 and parameters: {'learning_rate': 0.1293301361489344, 'num_leaves': 123, 'max_depth': 4, 'min_child_samples': 67, 'feature_fraction': 0.8130472788619331, 'bagging_fraction': 0.5013339806386407, 'reg_alpha': 1.9585985092618524e-05, 'reg_lambda': 0.0002480235864678539}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:30,472] Trial 39 finished with value: -0.9857606091594502 and parameters: {'learning_rate': 0.1956018137717553, 'num_leaves': 145, 'max_depth': 7, 'min_child_samples': 22, 'feature_fraction': 0.9899226356996809, 'bagging_fraction': 0.9630947936090172, 'reg_alpha': 8.878948278543989e-07, 'reg_lambda': 3.586764912589282e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:32,759] Trial 40 finished with value: -0.9861483532402211 and parameters: {'learning_rate': 0.04823714040678821, 'num_leaves': 200, 'max_depth': 4, 'min_child_samples': 32, 'feature_fraction': 0.6164032825930349, 'bagging_fraction': 0.8455193484576664, 'reg_alpha': 0.0006121496593029671, 'reg_lambda': 4.3052016214873256e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:36,326] Trial 41 finished with value: -0.9865794002314029 and parameters: {'learning_rate': 0.12736882276726205, 'num_leaves': 180, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.5543932613164914, 'bagging_fraction': 0.8619141949295612, 'reg_alpha': 1.3835144728584246e-06, 'reg_lambda': 4.308564258342925}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:39,508] Trial 42 finished with value: -0.9864899707571642 and parameters: {'learning_rate': 0.11640543831565052, 'num_leaves': 169, 'max_depth': 8, 'min_child_samples': 11, 'feature_fraction': 0.64851332992864, 'bagging_fraction': 0.887105135671054, 'reg_alpha': 4.151554040019469e-07, 'reg_lambda': 0.05702044679692784}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:41,608] Trial 43 finished with value: -0.9862233792450693 and parameters: {'learning_rate': 0.15319460975861438, 'num_leaves': 138, 'max_depth': 9, 'min_child_samples': 15, 'feature_fraction': 0.785517566476569, 'bagging_fraction': 0.8574320686468996, 'reg_alpha': 8.940710679335368e-06, 'reg_lambda': 0.9883732589095742}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:49,454] Trial 44 finished with value: -0.9868981763819231 and parameters: {'learning_rate': 0.09696556666025834, 'num_leaves': 159, 'max_depth': 11, 'min_child_samples': 10, 'feature_fraction': 0.6714746757944438, 'bagging_fraction': 0.8150557744500045, 'reg_alpha': 3.3011828431753455e-08, 'reg_lambda': 0.000476608710759108}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:54,414] Trial 45 finished with value: -0.9860571625314061 and parameters: {'learning_rate': 0.17593167061879617, 'num_leaves': 176, 'max_depth': 10, 'min_child_samples': 60, 'feature_fraction': 0.5752124059107432, 'bagging_fraction': 0.9279885353236574, 'reg_alpha': 7.339348514738463e-08, 'reg_lambda': 0.031355207515892373}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:29:56,316] Trial 46 finished with value: -0.9840973573572528 and parameters: {'learning_rate': 0.13876286943444374, 'num_leaves': 197, 'max_depth': 5, 'min_child_samples': 92, 'feature_fraction': 0.6083811284380387, 'bagging_fraction': 0.8759438685792194, 'reg_alpha': 2.8647682482129344e-06, 'reg_lambda': 0.0037985902638350256}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:00,548] Trial 47 finished with value: -0.9856961992260367 and parameters: {'learning_rate': 0.039003521725171166, 'num_leaves': 149, 'max_depth': 8, 'min_child_samples': 22, 'feature_fraction': 0.9153163866399331, 'bagging_fraction': 0.6088435881640017, 'reg_alpha': 2.340559173163026e-08, 'reg_lambda': 0.0010420611415106447}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:05,516] Trial 48 finished with value: -0.9859231856306682 and parameters: {'learning_rate': 0.028707747283418756, 'num_leaves': 133, 'max_depth': 7, 'min_child_samples': 17, 'feature_fraction': 0.638569301262528, 'bagging_fraction': 0.7309306946570661, 'reg_alpha': 3.981335059637075e-07, 'reg_lambda': 3.4199189046230976e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:10,414] Trial 49 finished with value: -0.9850878184182384 and parameters: {'learning_rate': 0.08644262967346897, 'num_leaves': 209, 'max_depth': 9, 'min_child_samples': 71, 'feature_fraction': 0.5322849656343382, 'bagging_fraction': 0.9967411011074679, 'reg_alpha': 0.006820610536238465, 'reg_lambda': 8.49747687871126e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:12,196] Trial 50 finished with value: -0.9868086545759398 and parameters: {'learning_rate': 0.17611677471844353, 'num_leaves': 116, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.7010928088414482, 'bagging_fraction': 0.8311428059899459, 'reg_alpha': 7.633786478083986e-06, 'reg_lambda': 1.4187206847345547e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:14,143] Trial 51 finished with value: -0.9859528247099071 and parameters: {'learning_rate': 0.15794745050281928, 'num_leaves': 159, 'max_depth': 6, 'min_child_samples': 23, 'feature_fraction': 0.5290889479515248, 'bagging_fraction': 0.8452467592363159, 'reg_alpha': 7.964377944743309e-07, 'reg_lambda': 0.0006874711021097879}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:16,805] Trial 52 finished with value: -0.9860303203515295 and parameters: {'learning_rate': 0.12091008150921699, 'num_leaves': 171, 'max_depth': 7, 'min_child_samples': 18, 'feature_fraction': 0.5728600724279137, 'bagging_fraction': 0.9043299205858639, 'reg_alpha': 3.0737742058414563e-07, 'reg_lambda': 0.0001756704386077031}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:19,912] Trial 53 finished with value: -0.9869744370261804 and parameters: {'learning_rate': 0.10450368357430939, 'num_leaves': 144, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.5282116926663796, 'bagging_fraction': 0.7805890581570856, 'reg_alpha': 3.6763545437465525e-05, 'reg_lambda': 0.0065828901954720735}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:24,182] Trial 54 finished with value: -0.9861739657720145 and parameters: {'learning_rate': 0.17346430749328517, 'num_leaves': 51, 'max_depth': 14, 'min_child_samples': 27, 'feature_fraction': 0.5586372355187991, 'bagging_fraction': 0.8437207969732806, 'reg_alpha': 6.651653534495644e-08, 'reg_lambda': 4.211720601546369}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:30,098] Trial 55 finished with value: -0.9867922566082991 and parameters: {'learning_rate': 0.14695326196203293, 'num_leaves': 151, 'max_depth': 10, 'min_child_samples': 10, 'feature_fraction': 0.5137239743203557, 'bagging_fraction': 0.8912459499674709, 'reg_alpha': 6.279820835382187e-07, 'reg_lambda': 0.0018549568812067433}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:31,803] Trial 56 finished with value: -0.9866797631801487 and parameters: {'learning_rate': 0.13303901645539085, 'num_leaves': 189, 'max_depth': 5, 'min_child_samples': 20, 'feature_fraction': 0.5922201819706935, 'bagging_fraction': 0.9164243485538224, 'reg_alpha': 2.542834341437061e-07, 'reg_lambda': 2.0516877237188335e-07}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:34,064] Trial 57 finished with value: -0.9870198212294377 and parameters: {'learning_rate': 0.18261644280272346, 'num_leaves': 162, 'max_depth': 4, 'min_child_samples': 17, 'feature_fraction': 0.5036768786693336, 'bagging_fraction': 0.8062873092440409, 'reg_alpha': 2.2527525222606647e-08, 'reg_lambda': 3.7150222972156575e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:38,507] Trial 58 finished with value: -0.9860048656918409 and parameters: {'learning_rate': 0.0944728525336205, 'num_leaves': 26, 'max_depth': 11, 'min_child_samples': 35, 'feature_fraction': 0.7610439157522915, 'bagging_fraction': 0.8658528332085295, 'reg_alpha': 2.076340832487175e-06, 'reg_lambda': 0.0005207068844824646}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:39,717] Trial 59 finished with value: -0.9865971119045289 and parameters: {'learning_rate': 0.16143840835512058, 'num_leaves': 102, 'max_depth': 3, 'min_child_samples': 13, 'feature_fraction': 0.7168195167847097, 'bagging_fraction': 0.8478687831381345, 'reg_alpha': 0.8980992068116294, 'reg_lambda': 0.2676367874653128}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:50,171] Trial 60 finished with value: -0.9856623108711224 and parameters: {'learning_rate': 0.01789528035385612, 'num_leaves': 130, 'max_depth': 9, 'min_child_samples': 24, 'feature_fraction': 0.6057841410755372, 'bagging_fraction': 0.7701032823057072, 'reg_alpha': 1.5471825695098408e-07, 'reg_lambda': 0.00015132472931856096}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:52,374] Trial 61 finished with value: -0.987249451222706 and parameters: {'learning_rate': 0.16415773876964443, 'num_leaves': 228, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.8406984342342535, 'bagging_fraction': 0.8168930520458646, 'reg_alpha': 5.983644109070899e-06, 'reg_lambda': 0.00033998519690463236}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:54,196] Trial 62 finished with value: -0.9865416072114511 and parameters: {'learning_rate': 0.14246319567203172, 'num_leaves': 227, 'max_depth': 7, 'min_child_samples': 13, 'feature_fraction': 0.8778707736338811, 'bagging_fraction': 0.8296414708519048, 'reg_alpha': 3.752611972213392e-06, 'reg_lambda': 9.557392762464854e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:30:57,824] Trial 63 finished with value: -0.9874602794736784 and parameters: {'learning_rate': 0.11459526526004513, 'num_leaves': 177, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.899379129967788, 'bagging_fraction': 0.8731130182292134, 'reg_alpha': 1.3777214736498081e-06, 'reg_lambda': 0.001025087767541426}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:00,336] Trial 64 finished with value: -0.9859176475700137 and parameters: {'learning_rate': 0.11446406057269488, 'num_leaves': 181, 'max_depth': 8, 'min_child_samples': 17, 'feature_fraction': 0.9494792080665542, 'bagging_fraction': 0.9427867879597246, 'reg_alpha': 8.368323337946462e-07, 'reg_lambda': 0.022639786869083935}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:03,356] Trial 65 finished with value: -0.9856585946906307 and parameters: {'learning_rate': 0.19949171709945593, 'num_leaves': 173, 'max_depth': 8, 'min_child_samples': 29, 'feature_fraction': 0.904103923644936, 'bagging_fraction': 0.8816719309217209, 'reg_alpha': 1.2198078484296486e-07, 'reg_lambda': 0.008641979786038092}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:06,912] Trial 66 finished with value: -0.9860189781020375 and parameters: {'learning_rate': 0.10389105384747896, 'num_leaves': 205, 'max_depth': 9, 'min_child_samples': 21, 'feature_fraction': 0.6687902451328799, 'bagging_fraction': 0.8689175929385188, 'reg_alpha': 1.0684253104097143e-08, 'reg_lambda': 0.0008642450619887948}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:11,005] Trial 67 finished with value: -0.9861847685604086 and parameters: {'learning_rate': 0.12171848546992174, 'num_leaves': 193, 'max_depth': 6, 'min_child_samples': 50, 'feature_fraction': 0.5438477398750303, 'bagging_fraction': 0.9131552692974101, 'reg_alpha': 1.4654780335936827e-05, 'reg_lambda': 0.0034467067500832936}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:16,141] Trial 68 finished with value: -0.9853973892607086 and parameters: {'learning_rate': 0.07480295181373106, 'num_leaves': 139, 'max_depth': 8, 'min_child_samples': 41, 'feature_fraction': 0.7251951364720742, 'bagging_fraction': 0.9010767403359924, 'reg_alpha': 1.697523636802676e-06, 'reg_lambda': 1.5659781171024014e-08}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:19,178] Trial 69 finished with value: -0.9867531723113971 and parameters: {'learning_rate': 0.14822118386328037, 'num_leaves': 165, 'max_depth': 10, 'min_child_samples': 13, 'feature_fraction': 0.8281519289712604, 'bagging_fraction': 0.796585054492928, 'reg_alpha': 0.00013888114874143444, 'reg_lambda': 0.5679888110580483}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:22,329] Trial 70 finished with value: -0.9864671799655558 and parameters: {'learning_rate': 0.1313812129415191, 'num_leaves': 156, 'max_depth': 8, 'min_child_samples': 19, 'feature_fraction': 0.569625359318856, 'bagging_fraction': 0.9536606871826898, 'reg_alpha': 6.235727706877531e-08, 'reg_lambda': 2.5222853747444245}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:24,488] Trial 71 finished with value: -0.98763484664321 and parameters: {'learning_rate': 0.16615763927474433, 'num_leaves': 215, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8904522637914591, 'bagging_fraction': 0.8213260229096735, 'reg_alpha': 3.905895197493586e-06, 'reg_lambda': 0.00026270614529808436}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-06 12:31:28,121] Trial 72 finished with value: -0.9883720183415127 and parameters: {'learning_rate': 0.18056080344222483, 'num_leaves': 219, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.9521349495066572, 'bagging_fraction': 0.8514734970258908, 'reg_alpha': 1.0536122334861126e-06, 'reg_lambda': 8.751163903031449}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:30,519] Trial 73 finished with value: -0.9882622567663993 and parameters: {'learning_rate': 0.18947338820982654, 'num_leaves': 184, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.9514951125821989, 'bagging_fraction': 0.8510858430078347, 'reg_alpha': 1.325861121917445e-06, 'reg_lambda': 3.7338263475247464}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:32,024] Trial 74 finished with value: -0.9864516976157051 and parameters: {'learning_rate': 0.18279017669887043, 'num_leaves': 247, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.9510566336291827, 'bagging_fraction': 0.8381791698312648, 'reg_alpha': 1.310691897260012e-05, 'reg_lambda': 7.043898119289713}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:34,133] Trial 75 finished with value: -0.9870540187218367 and parameters: {'learning_rate': 0.18703605351195268, 'num_leaves': 237, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.9983139247218186, 'bagging_fraction': 0.8918860917327313, 'reg_alpha': 1.1723806622667706e-06, 'reg_lambda': 1.5374411649423436}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:36,096] Trial 76 finished with value: -0.9865323826029837 and parameters: {'learning_rate': 0.15266555836306253, 'num_leaves': 214, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.9711370693829077, 'bagging_fraction': 0.8568036302327512, 'reg_alpha': 3.6870060183813194e-06, 'reg_lambda': 9.809340707206351}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:38,745] Trial 77 finished with value: -0.9882840864322608 and parameters: {'learning_rate': 0.167989453276013, 'num_leaves': 219, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.9390785208970333, 'bagging_fraction': 0.8748692354636461, 'reg_alpha': 6.79197189722548e-05, 'reg_lambda': 6.176871920301797}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:40,545] Trial 78 finished with value: -0.9871286829583414 and parameters: {'learning_rate': 0.19956551678515083, 'num_leaves': 214, 'max_depth': 5, 'min_child_samples': 10, 'feature_fraction': 0.9422722954431024, 'bagging_fraction': 0.8082334276932376, 'reg_alpha': 4.907350346881099e-05, 'reg_lambda': 0.8358838734471404}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:42,059] Trial 79 finished with value: -0.9859171759735805 and parameters: {'learning_rate': 0.16880366538215555, 'num_leaves': 237, 'max_depth': 6, 'min_child_samples': 18, 'feature_fraction': 0.8815792648366843, 'bagging_fraction': 0.8229112254685218, 'reg_alpha': 0.00042237334918299825, 'reg_lambda': 0.15291416422679163}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:43,443] Trial 80 finished with value: -0.9860310239541258 and parameters: {'learning_rate': 0.14240377193769863, 'num_leaves': 221, 'max_depth': 5, 'min_child_samples': 15, 'feature_fraction': 0.9030975144765824, 'bagging_fraction': 0.7846633980001139, 'reg_alpha': 2.6487959770736792e-05, 'reg_lambda': 0.0013543553804423213}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:45,577] Trial 81 finished with value: -0.987027257449423 and parameters: {'learning_rate': 0.15688606738383584, 'num_leaves': 203, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.9734569619826393, 'bagging_fraction': 0.8770316127038411, 'reg_alpha': 0.0002294452437106921, 'reg_lambda': 5.441769114380621}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:47,397] Trial 82 finished with value: -0.9876129141957783 and parameters: {'learning_rate': 0.17355902085004823, 'num_leaves': 197, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.9296398247956568, 'bagging_fraction': 0.8552453664424593, 'reg_alpha': 7.51698379964411e-06, 'reg_lambda': 1.9147608687847522}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:49,186] Trial 83 finished with value: -0.9873435715156083 and parameters: {'learning_rate': 0.17857255775523181, 'num_leaves': 187, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.9292056559705985, 'bagging_fraction': 0.858352400720043, 'reg_alpha': 3.328594287281763e-05, 'reg_lambda': 1.2976012895129139}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:50,690] Trial 84 finished with value: -0.9860509978946667 and parameters: {'learning_rate': 0.16757129710382335, 'num_leaves': 194, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.8974825262665204, 'bagging_fraction': 0.8372744626077447, 'reg_alpha': 8.979587488315609e-05, 'reg_lambda': 6.422778759791608e-05}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:52,642] Trial 85 finished with value: -0.9877487904680982 and parameters: {'learning_rate': 0.18823068170686336, 'num_leaves': 219, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.8651742987767396, 'bagging_fraction': 0.9200313349924366, 'reg_alpha': 9.520889463047119e-06, 'reg_lambda': 2.4587418914523433}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:54,340] Trial 86 finished with value: -0.9858245347285071 and parameters: {'learning_rate': 0.18773561604706263, 'num_leaves': 221, 'max_depth': 6, 'min_child_samples': 21, 'feature_fraction': 0.86452808750862, 'bagging_fraction': 0.9162718186552167, 'reg_alpha': 0.0013596737832744714, 'reg_lambda': 2.5320593089472863}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:55,463] Trial 87 finished with value: -0.9857860535467683 and parameters: {'learning_rate': 0.1527729932512767, 'num_leaves': 208, 'max_depth': 5, 'min_child_samples': 14, 'feature_fraction': 0.9300367873538115, 'bagging_fraction': 0.8948389189246599, 'reg_alpha': 1.0916662503326015e-05, 'reg_lambda': 0.6287606671262345}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:57,011] Trial 88 finished with value: -0.9870330253803836 and parameters: {'learning_rate': 0.17004357154521146, 'num_leaves': 254, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.963503554161085, 'bagging_fraction': 0.9221968761904931, 'reg_alpha': 4.579623874356345e-06, 'reg_lambda': 3.5778883824665404}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:31:58,824] Trial 89 finished with value: -0.9859024215739247 and parameters: {'learning_rate': 0.18973735449369364, 'num_leaves': 239, 'max_depth': 7, 'min_child_samples': 18, 'feature_fraction': 0.919346750005544, 'bagging_fraction': 0.9415955285115627, 'reg_alpha': 8.815066075388036e-06, 'reg_lambda': 0.37715871583687205}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:01,054] Trial 90 finished with value: -0.985960636240884 and parameters: {'learning_rate': 0.12539133153062804, 'num_leaves': 215, 'max_depth': 6, 'min_child_samples': 23, 'feature_fraction': 0.8025408728226828, 'bagging_fraction': 0.9708549146617322, 'reg_alpha': 2.0732125854209135e-05, 'reg_lambda': 2.131087274257325}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:03,744] Trial 91 finished with value: -0.9876174505285494 and parameters: {'learning_rate': 0.14004998569338126, 'num_leaves': 201, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.867022960046228, 'bagging_fraction': 0.8490517343323919, 'reg_alpha': 5.39999332705708e-05, 'reg_lambda': 0.00031407930332873234}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:06,201] Trial 92 finished with value: -0.9873837599382128 and parameters: {'learning_rate': 0.1376834719836902, 'num_leaves': 201, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8682244664874781, 'bagging_fraction': 0.8528765614206484, 'reg_alpha': 5.374580325087787e-05, 'reg_lambda': 0.0001207187206281133}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:07,733] Trial 93 finished with value: -0.9858674332111063 and parameters: {'learning_rate': 0.16373168802738516, 'num_leaves': 220, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.9371913824555923, 'bagging_fraction': 0.8863823648627102, 'reg_alpha': 7.10109171697503e-05, 'reg_lambda': 0.0003475488697519553}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:09,531] Trial 94 finished with value: -0.9870543495820682 and parameters: {'learning_rate': 0.17933530232950273, 'num_leaves': 198, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.852877911236438, 'bagging_fraction': 0.8257967098944745, 'reg_alpha': 0.00024602664289478905, 'reg_lambda': 2.518124379799025e-05}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:11,489] Trial 95 finished with value: -0.9858931859971379 and parameters: {'learning_rate': 0.14795587895837034, 'num_leaves': 232, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.9836207789487175, 'bagging_fraction': 0.8671174387976363, 'reg_alpha': 0.0001507341628641645, 'reg_lambda': 5.8928167970700434e-05}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:14,275] Trial 96 finished with value: -0.9838578548169528 and parameters: {'learning_rate': 0.13674233157982535, 'num_leaves': 204, 'max_depth': 5, 'min_child_samples': 100, 'feature_fraction': 0.9590336391267404, 'bagging_fraction': 0.9058119674998661, 'reg_alpha': 2.8991502167587784e-06, 'reg_lambda': 6.434805708119112}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:16,144] Trial 97 finished with value: -0.9871678764261981 and parameters: {'learning_rate': 0.17404231927055225, 'num_leaves': 189, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.9114909129225703, 'bagging_fraction': 0.8362971887180022, 'reg_alpha': 3.685966776566466e-05, 'reg_lambda': 9.219678855776368e-06}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:18,382] Trial 98 finished with value: -0.9857896750399465 and parameters: {'learning_rate': 0.15849338055121334, 'num_leaves': 184, 'max_depth': 7, 'min_child_samples': 20, 'feature_fraction': 0.8911840817576969, 'bagging_fraction': 0.851414672767248, 'reg_alpha': 6.246031222380552e-06, 'reg_lambda': 0.0002413093394746176}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:21,477] Trial 99 finished with value: -0.9860214125257825 and parameters: {'learning_rate': 0.010911699880692119, 'num_leaves': 210, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8750267111639118, 'bagging_fraction': 0.7431710301685029, 'reg_alpha': 1.7311544376987395e-08, 'reg_lambda': 3.3215173227581625}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:22,933] Trial 100 finished with value: -0.9858194883588756 and parameters: {'learning_rate': 0.19117358198975445, 'num_leaves': 217, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.8360354839324343, 'bagging_fraction': 0.8111350291850622, 'reg_alpha': 0.07217022334431497, 'reg_lambda': 1.3731838290708787}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:26,262] Trial 101 finished with value: -0.9840555756134324 and parameters: {'learning_rate': 0.14401524892916054, 'num_leaves': 181, 'max_depth': 8, 'min_child_samples': 87, 'feature_fraction': 0.9186098260965798, 'bagging_fraction': 0.8735342950848686, 'reg_alpha': 2.3807084394942185e-06, 'reg_lambda': 0.0009790719992020256}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:32,507] Trial 102 finished with value: -0.9872734725699008 and parameters: {'learning_rate': 0.042351464472852686, 'num_leaves': 196, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.7807899444601023, 'bagging_fraction': 0.8686441322488634, 'reg_alpha': 1.3546628212702861e-06, 'reg_lambda': 0.0004602459630211886}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:35,592] Trial 103 finished with value: -0.9866327709361149 and parameters: {'learning_rate': 0.11414596323375277, 'num_leaves': 190, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8192837895549286, 'bagging_fraction': 0.888237946956316, 'reg_alpha': 1.9221342519544934e-05, 'reg_lambda': 0.00013082089737038994}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:38,232] Trial 104 finished with value: -0.9862678414420014 and parameters: {'learning_rate': 0.058209145808434136, 'num_leaves': 224, 'max_depth': 7, 'min_child_samples': 17, 'feature_fraction': 0.8887734856175724, 'bagging_fraction': 0.9353855123489151, 'reg_alpha': 5.032325134147054e-07, 'reg_lambda': 4.818744413020787}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:44,151] Trial 105 finished with value: -0.987405196727356 and parameters: {'learning_rate': 0.03533844536780055, 'num_leaves': 175, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8530793392469461, 'bagging_fraction': 0.8801863388263699, 'reg_alpha': 1.154414337534388e-05, 'reg_lambda': 0.002714382979894179}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:46,066] Trial 106 finished with value: -0.9861536872877016 and parameters: {'learning_rate': 0.1302858019198548, 'num_leaves': 210, 'max_depth': 6, 'min_child_samples': 19, 'feature_fraction': 0.9431093057488996, 'bagging_fraction': 0.8430804352587453, 'reg_alpha': 5.31519080046963e-06, 'reg_lambda': 0.00020124844504448207}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:47,926] Trial 107 finished with value: -0.9857740251647188 and parameters: {'learning_rate': 0.16013321254442803, 'num_leaves': 232, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.905919648958518, 'bagging_fraction': 0.568330849459986, 'reg_alpha': 2.783778474475233e-07, 'reg_lambda': 0.0003054625797331225}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:50,858] Trial 108 finished with value: -0.9862417043981877 and parameters: {'learning_rate': 0.19863944369846537, 'num_leaves': 175, 'max_depth': 9, 'min_child_samples': 12, 'feature_fraction': 0.6871359479674568, 'bagging_fraction': 0.7010548938708235, 'reg_alpha': 4.6760035486985113e-08, 'reg_lambda': 0.0005825727705708118}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:53,041] Trial 109 finished with value: -0.9866691356024407 and parameters: {'learning_rate': 0.10811765760906121, 'num_leaves': 207, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.793123636899939, 'bagging_fraction': 0.901234460339287, 'reg_alpha': 1.260677076913496e-06, 'reg_lambda': 6.67029054262157}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:54,139] Trial 110 finished with value: -0.9858402577827278 and parameters: {'learning_rate': 0.1736985038846044, 'num_leaves': 197, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.9592583730020339, 'bagging_fraction': 0.8591137908386869, 'reg_alpha': 1.0611283860000166e-07, 'reg_lambda': 1.9059643143644949}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:32:59,325] Trial 111 finished with value: -0.9873408039557189 and parameters: {'learning_rate': 0.034350007754329594, 'num_leaves': 178, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8559188363635856, 'bagging_fraction': 0.8760964433983144, 'reg_alpha': 1.1528185237877021e-05, 'reg_lambda': 0.002215497996025671}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:06,653] Trial 112 finished with value: -0.9871901701997062 and parameters: {'learning_rate': 0.02924132953701179, 'num_leaves': 184, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.8433598915415192, 'bagging_fraction': 0.8798717087445956, 'reg_alpha': 2.701196684221842e-05, 'reg_lambda': 0.0003212895424181401}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:12,395] Trial 113 finished with value: -0.9864071917475288 and parameters: {'learning_rate': 0.02052812207917615, 'num_leaves': 167, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.892557715928591, 'bagging_fraction': 0.7962272925776894, 'reg_alpha': 8.605354804120228e-06, 'reg_lambda': 0.001269904668857182}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:15,634] Trial 114 finished with value: -0.983612605034548 and parameters: {'learning_rate': 0.03616590180532698, 'num_leaves': 154, 'max_depth': 5, 'min_child_samples': 77, 'feature_fraction': 0.8738043551547168, 'bagging_fraction': 0.8225342691653069, 'reg_alpha': 2.9675549055990344e-06, 'reg_lambda': 0.0024983913243621504}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:23,328] Trial 115 finished with value: -0.9865773509950427 and parameters: {'learning_rate': 0.025295239230530772, 'num_leaves': 164, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.7688440974584132, 'bagging_fraction': 0.8532740128702133, 'reg_alpha': 1.974657541397223e-06, 'reg_lambda': 0.0006480603312875129}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:25,634] Trial 116 finished with value: -0.985544268339704 and parameters: {'learning_rate': 0.0446141689262171, 'num_leaves': 148, 'max_depth': 6, 'min_child_samples': 18, 'feature_fraction': 0.9251893845060142, 'bagging_fraction': 0.8344827278361224, 'reg_alpha': 1.5895076116055237e-05, 'reg_lambda': 0.008183840802134721}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:29,220] Trial 117 finished with value: -0.9855375077388429 and parameters: {'learning_rate': 0.03361111988499305, 'num_leaves': 172, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.979468897543487, 'bagging_fraction': 0.6557598047692232, 'reg_alpha': 8.41812100355881e-05, 'reg_lambda': 0.005485440734960973}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:33,861] Trial 118 finished with value: -0.9851708445210358 and parameters: {'learning_rate': 0.15082447844100622, 'num_leaves': 201, 'max_depth': 9, 'min_child_samples': 60, 'feature_fraction': 0.9360682394647946, 'bagging_fraction': 0.8639907193209992, 'reg_alpha': 4.729374453027869e-05, 'reg_lambda': 0.0032522465842771946}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:36,247] Trial 119 finished with value: -0.9872563379965241 and parameters: {'learning_rate': 0.1798900908655116, 'num_leaves': 192, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8319081896834432, 'bagging_fraction': 0.9104880017097084, 'reg_alpha': 4.7872513467296835e-06, 'reg_lambda': 0.0746977388840696}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:37,451] Trial 120 finished with value: -0.9858503757620749 and parameters: {'learning_rate': 0.16474246563687905, 'num_leaves': 161, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.953900530089215, 'bagging_fraction': 0.9237073755497494, 'reg_alpha': 2.832952298578779e-08, 'reg_lambda': 0.8684143603881638}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:43,490] Trial 121 finished with value: -0.985543242520982 and parameters: {'learning_rate': 0.051891276873630786, 'num_leaves': 175, 'max_depth': 8, 'min_child_samples': 46, 'feature_fraction': 0.7378478436075724, 'bagging_fraction': 0.8860323875025592, 'reg_alpha': 1.9655993740899745e-07, 'reg_lambda': 8.718082799769919}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:46,227] Trial 122 finished with value: -0.9873540787494728 and parameters: {'learning_rate': 0.13560220776174295, 'num_leaves': 185, 'max_depth': 8, 'min_child_samples': 11, 'feature_fraction': 0.8827419100919413, 'bagging_fraction': 0.8954039443627659, 'reg_alpha': 6.37930007059764e-07, 'reg_lambda': 2.6365591724411908}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:48,919] Trial 123 finished with value: -0.9874662900718963 and parameters: {'learning_rate': 0.14424388392969326, 'num_leaves': 170, 'max_depth': 9, 'min_child_samples': 13, 'feature_fraction': 0.908998170061243, 'bagging_fraction': 0.8494905389164883, 'reg_alpha': 1.1312128585505417e-06, 'reg_lambda': 5.4027683848136885}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:51,833] Trial 124 finished with value: -0.9874810669730489 and parameters: {'learning_rate': 0.12215469465346798, 'num_leaves': 179, 'max_depth': 9, 'min_child_samples': 13, 'feature_fraction': 0.8608679356498566, 'bagging_fraction': 0.8425021702704366, 'reg_alpha': 8.977608448472212e-07, 'reg_lambda': 4.227194631965389}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:54,164] Trial 125 finished with value: -0.986738917353982 and parameters: {'learning_rate': 0.12146986881304495, 'num_leaves': 216, 'max_depth': 9, 'min_child_samples': 16, 'feature_fraction': 0.9106233993717794, 'bagging_fraction': 0.8469297393515793, 'reg_alpha': 9.450014494559664e-07, 'reg_lambda': 4.114599250296689}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:56,291] Trial 126 finished with value: -0.9873156924791846 and parameters: {'learning_rate': 0.14364839926900574, 'num_leaves': 180, 'max_depth': 9, 'min_child_samples': 12, 'feature_fraction': 0.8953670763922372, 'bagging_fraction': 0.8186163981416041, 'reg_alpha': 2.0460705828202426e-06, 'reg_lambda': 5.530006663664815}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:33:59,078] Trial 127 finished with value: -0.9871360762238179 and parameters: {'learning_rate': 0.12614385604460113, 'num_leaves': 225, 'max_depth': 10, 'min_child_samples': 13, 'feature_fraction': 0.9258085462596127, 'bagging_fraction': 0.8380783870203995, 'reg_alpha': 3.6217031856721414e-07, 'reg_lambda': 1.9859966559378204}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:34:01,321] Trial 128 finished with value: -0.9858051078194501 and parameters: {'learning_rate': 0.1507810365244716, 'num_leaves': 137, 'max_depth': 9, 'min_child_samples': 17, 'feature_fraction': 0.9412485484973263, 'bagging_fraction': 0.8034167968716979, 'reg_alpha': 3.936585252578998e-06, 'reg_lambda': 1.2149909906017755}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:34:04,180] Trial 129 finished with value: -0.9866947507361719 and parameters: {'learning_rate': 0.09951726387766904, 'num_leaves': 170, 'max_depth': 10, 'min_child_samples': 14, 'feature_fraction': 0.8672638067099725, 'bagging_fraction': 0.830182777745884, 'reg_alpha': 6.279058462730546e-07, 'reg_lambda': 9.563277133413873}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:34:08,552] Trial 130 finished with value: -0.9862641191819964 and parameters: {'learning_rate': 0.1865019170214644, 'num_leaves': 157, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.966865538096542, 'bagging_fraction': 0.8668870902961702, 'reg_alpha': 1.085518457383021e-06, 'reg_lambda': 4.112549061968329}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-06 12:34:11,857] Trial 131 finished with value: -0.9887257100865543 and parameters: {'learning_rate': 0.15996571729914286, 'num_leaves': 187, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8451145350830436, 'bagging_fraction': 0.8534027490356716, 'reg_alpha': 1.1152289964280488e-05, 'reg_lambda': 2.933063018415669}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:14,420] Trial 132 finished with value: -0.9884637300745709 and parameters: {'learning_rate': 0.15727092408443485, 'num_leaves': 193, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.845715281773433, 'bagging_fraction': 0.8573666901472738, 'reg_alpha': 6.899864936389022e-06, 'reg_lambda': 3.005388714025817}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:16,159] Trial 133 finished with value: -0.9875617234541313 and parameters: {'learning_rate': 0.15783984133163872, 'num_leaves': 193, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.8124982071179696, 'bagging_fraction': 0.8527539600503208, 'reg_alpha': 8.889312622017128e-06, 'reg_lambda': 3.091638148501508}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:18,301] Trial 134 finished with value: -0.987878891281041 and parameters: {'learning_rate': 0.16863234852745335, 'num_leaves': 205, 'max_depth': 6, 'min_child_samples': 11, 'feature_fraction': 0.8094303249405582, 'bagging_fraction': 0.8570487874786616, 'reg_alpha': 6.018838081225705e-06, 'reg_lambda': 2.915180506646019}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:20,034] Trial 135 finished with value: -0.9879082754256796 and parameters: {'learning_rate': 0.1696842962136095, 'num_leaves': 204, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.8168904734017227, 'bagging_fraction': 0.85868582001333, 'reg_alpha': 8.632831419918828e-06, 'reg_lambda': 0.4179247241394508}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:21,943] Trial 136 finished with value: -0.9873501975223217 and parameters: {'learning_rate': 0.16254690536317845, 'num_leaves': 204, 'max_depth': 5, 'min_child_samples': 11, 'feature_fraction': 0.8071800384166216, 'bagging_fraction': 0.8573718600108947, 'reg_alpha': 7.706910091538227e-06, 'reg_lambda': 0.4571994983076578}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:23,601] Trial 137 finished with value: -0.9867183011297239 and parameters: {'learning_rate': 0.1764699671157065, 'num_leaves': 211, 'max_depth': 6, 'min_child_samples': 15, 'feature_fraction': 0.7972683565590029, 'bagging_fraction': 0.8276142394408348, 'reg_alpha': 2.489330528808308e-05, 'reg_lambda': 0.15765135066692273}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:26,015] Trial 138 finished with value: -0.9886559012004108 and parameters: {'learning_rate': 0.16672146290288006, 'num_leaves': 199, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.8083809319192852, 'bagging_fraction': 0.8617619101070222, 'reg_alpha': 1.5764809593565324e-05, 'reg_lambda': 2.6170230584599885}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:29,224] Trial 139 finished with value: -0.9856183170300996 and parameters: {'learning_rate': 0.16986582529295227, 'num_leaves': 196, 'max_depth': 6, 'min_child_samples': 55, 'feature_fraction': 0.8099369970729468, 'bagging_fraction': 0.8612799371439551, 'reg_alpha': 5.947500264087335e-06, 'reg_lambda': 0.8436378092701915}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:31,506] Trial 140 finished with value: -0.9881307682876264 and parameters: {'learning_rate': 0.18985603741680018, 'num_leaves': 219, 'max_depth': 5, 'min_child_samples': 10, 'feature_fraction': 0.8205162078599963, 'bagging_fraction': 0.8462471181325845, 'reg_alpha': 1.5081835763504502e-05, 'reg_lambda': 2.859603639863942}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:33,148] Trial 141 finished with value: -0.9880867157962079 and parameters: {'learning_rate': 0.18731746597956328, 'num_leaves': 201, 'max_depth': 5, 'min_child_samples': 10, 'feature_fraction': 0.8279990300264535, 'bagging_fraction': 0.8491059128018922, 'reg_alpha': 1.248641241170372e-05, 'reg_lambda': 2.7624102274008715}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:34,784] Trial 142 finished with value: -0.9882186834991152 and parameters: {'learning_rate': 0.19941737850776578, 'num_leaves': 219, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8253427050740976, 'bagging_fraction': 0.8391409191339402, 'reg_alpha': 1.4153344279228911e-05, 'reg_lambda': 1.718107125138791}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:36,442] Trial 143 finished with value: -0.988338173416281 and parameters: {'learning_rate': 0.1871087329303521, 'num_leaves': 219, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8243212311130194, 'bagging_fraction': 0.8359829144511499, 'reg_alpha': 1.5838707933746045e-05, 'reg_lambda': 1.4963524984869228}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:37,952] Trial 144 finished with value: -0.9871553604133135 and parameters: {'learning_rate': 0.1994687894843345, 'num_leaves': 219, 'max_depth': 4, 'min_child_samples': 12, 'feature_fraction': 0.8208404128021505, 'bagging_fraction': 0.8151595385108533, 'reg_alpha': 1.342402305199359e-05, 'reg_lambda': 1.6345646111897778}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:39,336] Trial 145 finished with value: -0.986896794486156 and parameters: {'learning_rate': 0.18709322269597117, 'num_leaves': 228, 'max_depth': 3, 'min_child_samples': 15, 'feature_fraction': 0.8390463102886908, 'bagging_fraction': 0.839147584650339, 'reg_alpha': 2.0149050776934845e-05, 'reg_lambda': 1.0833385051814302}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:41,116] Trial 146 finished with value: -0.988036451266959 and parameters: {'learning_rate': 0.18855922798017352, 'num_leaves': 213, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8289022409345873, 'bagging_fraction': 0.8304083959327659, 'reg_alpha': 3.227456270659735e-05, 'reg_lambda': 0.6358750048846704}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:42,725] Trial 147 finished with value: -0.9874339244374071 and parameters: {'learning_rate': 0.1889579909844495, 'num_leaves': 241, 'max_depth': 4, 'min_child_samples': 12, 'feature_fraction': 0.8288290630002791, 'bagging_fraction': 0.8308119256193388, 'reg_alpha': 1.617099529548929e-05, 'reg_lambda': 0.7837856372061922}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:43,923] Trial 148 finished with value: -0.9859307502306853 and parameters: {'learning_rate': 0.18852095305794078, 'num_leaves': 207, 'max_depth': 4, 'min_child_samples': 14, 'feature_fraction': 0.7880032420618206, 'bagging_fraction': 0.8677161659688943, 'reg_alpha': 2.905350539660205e-05, 'reg_lambda': 0.4575342777990121}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-06 12:34:45,731] Trial 149 finished with value: -0.9863422291127042 and parameters: {'learning_rate': 0.19842011651053057, 'num_leaves': 233, 'max_depth': 5, 'min_child_samples': 17, 'feature_fraction': 0.843413973279858, 'bagging_fraction': 0.8408176539547692, 'reg_alpha': 3.715086010488598e-05, 'reg_lambda': 2.5823796717805303}. Best is trial 131 with value: -0.9887257100865543.
2025-08-06 12:34:46 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.9947816916685762, 'val_lightgbm': 0.993543410756154, 'val_ensemble': 0.9952995853659523}
2025-08-06 12:34:46 [INFO] Selected best model 'ensemble' with validation R²=0.9953
2025-08-06 12:34:46 [INFO] Retraining best model 'ensemble' on full dataset
2025-08-06 12:34:48 [INFO] Retraining completed in 1.57s
2025-08-06 12:34:48 [INFO] Saved final model to '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/final_ensemble.pkl'
2025-08-06 12:34:48 [INFO] Tree-based → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/final_ensemble.pkl (R²=0.9953)
2025-08-06 12:34:48 [INFO] Training TabNet model...
[I 2025-08-06 12:34:48,065] A new study created in memory with name: no-name-5fca7e5f-a226-47f2-860c-4143c05a865d
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:35:11,600] Trial 0 finished with value: 0.8950868834618051 and parameters: {'n_d': 55, 'n_a': 42, 'n_steps': 6, 'gamma': 1.2113087408012837, 'lambda_sparse': 0.0036269816933339745, 'lr': 0.061537639953476365, 'weight_decay': 7.31747915101107e-05}. Best is trial 0 with value: 0.8950868834618051.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:35:45,617] Trial 1 finished with value: 0.9126374389560322 and parameters: {'n_d': 8, 'n_a': 15, 'n_steps': 10, 'gamma': 1.5247806889072109, 'lambda_sparse': 0.008043543080413884, 'lr': 0.06811637235325715, 'weight_decay': 1.0492964916760294e-05}. Best is trial 1 with value: 0.9126374389560322.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:36:05,398] Trial 2 finished with value: 0.8917353127380089 and parameters: {'n_d': 60, 'n_a': 26, 'n_steps': 3, 'gamma': 1.6703209769013614, 'lambda_sparse': 1.195262827454471e-05, 'lr': 0.0007071992103617809, 'weight_decay': 0.0003755736350476417}. Best is trial 1 with value: 0.9126374389560322.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:36:50,431] Trial 3 finished with value: 0.9093978030472027 and parameters: {'n_d': 8, 'n_a': 39, 'n_steps': 10, 'gamma': 1.111116294898661, 'lambda_sparse': 0.00011014947656684952, 'lr': 0.03158197782084971, 'weight_decay': 8.832427039017618e-05}. Best is trial 1 with value: 0.9126374389560322.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:37:28,767] Trial 4 finished with value: 0.7677443661201915 and parameters: {'n_d': 30, 'n_a': 26, 'n_steps': 8, 'gamma': 1.5927286469518718, 'lambda_sparse': 3.524525745958899e-05, 'lr': 0.0006375474577027486, 'weight_decay': 2.1027850066848154e-05}. Best is trial 1 with value: 0.9126374389560322.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:37:56,998] Trial 5 finished with value: 0.9103266920083829 and parameters: {'n_d': 40, 'n_a': 54, 'n_steps': 8, 'gamma': 1.942739785621861, 'lambda_sparse': 0.00032534672134420546, 'lr': 0.04547872483967805, 'weight_decay': 0.000807230169519034}. Best is trial 1 with value: 0.9126374389560322.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:38:29,725] Trial 6 finished with value: 0.8924850776637046 and parameters: {'n_d': 22, 'n_a': 57, 'n_steps': 10, 'gamma': 1.6883086583948654, 'lambda_sparse': 0.00026195520316811636, 'lr': 0.06276815531433592, 'weight_decay': 0.0003788155924654705}. Best is trial 1 with value: 0.9126374389560322.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:38:53,417] Trial 7 finished with value: 0.940849855433217 and parameters: {'n_d': 58, 'n_a': 20, 'n_steps': 5, 'gamma': 1.1723235188243963, 'lambda_sparse': 0.0005096367695229615, 'lr': 0.04054257099756988, 'weight_decay': 0.00030555053607334145}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:39:11,441] Trial 8 finished with value: 0.8426448990972556 and parameters: {'n_d': 58, 'n_a': 28, 'n_steps': 4, 'gamma': 1.442707718486511, 'lambda_sparse': 0.0016195330500492608, 'lr': 0.015903912225419873, 'weight_decay': 0.0008763711219671065}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:39:37,213] Trial 9 finished with value: 0.9221221854429712 and parameters: {'n_d': 22, 'n_a': 56, 'n_steps': 5, 'gamma': 1.8501925515955968, 'lambda_sparse': 0.0062645090226120005, 'lr': 0.02457505185804087, 'weight_decay': 0.0005492335529572385}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:40:12,071] Trial 10 finished with value: 0.8897703472811249 and parameters: {'n_d': 40, 'n_a': 10, 'n_steps': 7, 'gamma': 1.2964163785660137, 'lambda_sparse': 0.000897153490229781, 'lr': 0.00492455268038576, 'weight_decay': 1.2621614213332745e-06}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:40:37,469] Trial 11 finished with value: 0.9072796197209432 and parameters: {'n_d': 26, 'n_a': 63, 'n_steps': 5, 'gamma': 1.9598118966220786, 'lambda_sparse': 0.0009752655054718465, 'lr': 0.0071658727221869025, 'weight_decay': 0.00014213729311508266}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:41:03,775] Trial 12 finished with value: 0.7012197541718475 and parameters: {'n_d': 48, 'n_a': 48, 'n_steps': 5, 'gamma': 1.0143688621041573, 'lambda_sparse': 0.0062606064069311695, 'lr': 0.00015753068052967652, 'weight_decay': 0.00017024493931971208}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:41:20,028] Trial 13 finished with value: 0.7955904210000587 and parameters: {'n_d': 19, 'n_a': 19, 'n_steps': 3, 'gamma': 1.7938829827760645, 'lambda_sparse': 0.0002500656275611584, 'lr': 0.012405652098444644, 'weight_decay': 6.324367092855166e-06}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:41:45,975] Trial 14 finished with value: 0.8963826549011273 and parameters: {'n_d': 49, 'n_a': 35, 'n_steps': 5, 'gamma': 1.3423335149913933, 'lambda_sparse': 0.002267588945396778, 'lr': 0.0017805177653304688, 'weight_decay': 0.0002774680502056607}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:42:16,500] Trial 15 finished with value: 0.9068715602426816 and parameters: {'n_d': 32, 'n_a': 47, 'n_steps': 6, 'gamma': 1.806165140973018, 'lambda_sparse': 7.242825525967848e-05, 'lr': 0.015748875253636566, 'weight_decay': 4.469303509482431e-05}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:42:37,210] Trial 16 finished with value: 0.9152340755405162 and parameters: {'n_d': 18, 'n_a': 33, 'n_steps': 4, 'gamma': 1.44070652371054, 'lambda_sparse': 0.0005957585933969558, 'lr': 0.027593361206685187, 'weight_decay': 0.0009576614018689377}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:43:00,945] Trial 17 finished with value: 0.8819658310970775 and parameters: {'n_d': 63, 'n_a': 19, 'n_steps': 4, 'gamma': 1.1538864624580134, 'lambda_sparse': 0.009689436393067673, 'lr': 0.0023304943617575027, 'weight_decay': 0.00036502726451211444}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:43:30,429] Trial 18 finished with value: 0.9311713351757797 and parameters: {'n_d': 37, 'n_a': 64, 'n_steps': 7, 'gamma': 1.8236612323229413, 'lambda_sparse': 0.0029773614661391273, 'lr': 0.09988056292796328, 'weight_decay': 2.4696737299767987e-05}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:43:56,686] Trial 19 finished with value: 0.8776602180311844 and parameters: {'n_d': 47, 'n_a': 64, 'n_steps': 8, 'gamma': 1.021370633871069, 'lambda_sparse': 0.0026743814126242234, 'lr': 0.08830414898405935, 'weight_decay': 4.7231675416032525e-06}. Best is trial 7 with value: 0.940849855433217.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:44:23,309] A new study created in memory with name: no-name-8e628b13-3085-435a-a3aa-d29b0b6b53da
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:44:43,771] Trial 0 finished with value: 0.8695387483018511 and parameters: {'n_d': 24, 'n_a': 51, 'n_steps': 3, 'gamma': 1.4524448100272243, 'lambda_sparse': 0.00046856810345652025, 'lr': 0.000438287595718472, 'weight_decay': 1.664568292519887e-05}. Best is trial 0 with value: 0.8695387483018511.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:45:10,787] Trial 1 finished with value: 0.9227192572506094 and parameters: {'n_d': 26, 'n_a': 23, 'n_steps': 5, 'gamma': 1.2192840117616779, 'lambda_sparse': 0.000392608682794241, 'lr': 0.035140958498630755, 'weight_decay': 0.0009114765190984028}. Best is trial 1 with value: 0.9227192572506094.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:45:33,079] Trial 2 finished with value: 0.7392042909207677 and parameters: {'n_d': 19, 'n_a': 38, 'n_steps': 4, 'gamma': 1.964457126351205, 'lambda_sparse': 7.999867214939154e-05, 'lr': 0.0001510092547542811, 'weight_decay': 7.883198760745493e-05}. Best is trial 1 with value: 0.9227192572506094.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:45:52,904] Trial 3 finished with value: 0.8800677383307736 and parameters: {'n_d': 9, 'n_a': 32, 'n_steps': 3, 'gamma': 1.556091681448786, 'lambda_sparse': 1.5241982080033832e-05, 'lr': 0.0005735235465622911, 'weight_decay': 1.8088212688726818e-06}. Best is trial 1 with value: 0.9227192572506094.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:46:13,452] Trial 4 finished with value: 0.905808834537601 and parameters: {'n_d': 35, 'n_a': 21, 'n_steps': 3, 'gamma': 1.052381165629496, 'lambda_sparse': 4.040069628786192e-05, 'lr': 0.0014761139552634313, 'weight_decay': 8.983198232943847e-05}. Best is trial 1 with value: 0.9227192572506094.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:46:59,449] Trial 5 finished with value: 0.8132293265324677 and parameters: {'n_d': 40, 'n_a': 31, 'n_steps': 10, 'gamma': 1.9265860370342582, 'lambda_sparse': 2.402877155520838e-05, 'lr': 0.0013478356303483344, 'weight_decay': 2.783868729798257e-05}. Best is trial 1 with value: 0.9227192572506094.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:47:35,922] Trial 6 finished with value: 0.9429331222980454 and parameters: {'n_d': 48, 'n_a': 17, 'n_steps': 9, 'gamma': 1.5761874048930857, 'lambda_sparse': 0.00010867140890585338, 'lr': 0.09816807196647356, 'weight_decay': 1.9412694105241535e-05}. Best is trial 6 with value: 0.9429331222980454.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:47:53,908] Trial 7 finished with value: 0.9459839950569287 and parameters: {'n_d': 44, 'n_a': 34, 'n_steps': 3, 'gamma': 1.6994620919295076, 'lambda_sparse': 0.006482161512259427, 'lr': 0.05976223738255671, 'weight_decay': 5.9083710141577165e-05}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:48:37,284] Trial 8 finished with value: 0.9155856397120786 and parameters: {'n_d': 25, 'n_a': 47, 'n_steps': 10, 'gamma': 1.9779850892549873, 'lambda_sparse': 2.726927431062367e-05, 'lr': 0.027855281567951997, 'weight_decay': 2.426485522530624e-06}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:49:09,020] Trial 9 finished with value: 0.8200493622950933 and parameters: {'n_d': 49, 'n_a': 51, 'n_steps': 7, 'gamma': 1.7633983296607494, 'lambda_sparse': 0.00011671942527671192, 'lr': 0.0016265290437753126, 'weight_decay': 0.0001773161862972689}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:49:38,886] Trial 10 finished with value: 0.918781492688867 and parameters: {'n_d': 62, 'n_a': 62, 'n_steps': 6, 'gamma': 1.7153542176238754, 'lambda_sparse': 0.00875759782502726, 'lr': 0.009777212691147832, 'weight_decay': 0.0006027963381793141}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:50:16,120] Trial 11 finished with value: 0.9457624568789064 and parameters: {'n_d': 52, 'n_a': 9, 'n_steps': 8, 'gamma': 1.4651488751669157, 'lambda_sparse': 0.004401260313540681, 'lr': 0.0964296716071743, 'weight_decay': 7.774458541015959e-06}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:50:45,864] Trial 12 finished with value: 0.9416146017976856 and parameters: {'n_d': 61, 'n_a': 8, 'n_steps': 8, 'gamma': 1.3607326167350224, 'lambda_sparse': 0.008307376781006232, 'lr': 0.067852898115997, 'weight_decay': 6.489136652887544e-06}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:51:20,932] Trial 13 finished with value: 0.9103821215214993 and parameters: {'n_d': 53, 'n_a': 43, 'n_steps': 7, 'gamma': 1.70577141647407, 'lambda_sparse': 0.0016984989814865527, 'lr': 0.00778742676203329, 'weight_decay': 7.700465425058561e-06}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:51:46,386] Trial 14 finished with value: 0.8847983120562068 and parameters: {'n_d': 39, 'n_a': 10, 'n_steps': 5, 'gamma': 1.3097746175958846, 'lambda_sparse': 0.001843309844298141, 'lr': 0.014425892243490373, 'weight_decay': 5.763764602666039e-06}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:52:22,960] Trial 15 finished with value: 0.9141309709978865 and parameters: {'n_d': 55, 'n_a': 62, 'n_steps': 8, 'gamma': 1.8199663553119159, 'lambda_sparse': 0.002783042527447968, 'lr': 0.04171270054233419, 'weight_decay': 9.7367572179407e-05}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:52:53,029] Trial 16 finished with value: 0.8453257958776356 and parameters: {'n_d': 45, 'n_a': 26, 'n_steps': 6, 'gamma': 1.6157295212317533, 'lambda_sparse': 0.003475832304444201, 'lr': 0.005154456793582423, 'weight_decay': 0.00027470543468957777}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:53:36,651] Trial 17 finished with value: 0.9042932076243688 and parameters: {'n_d': 33, 'n_a': 15, 'n_steps': 9, 'gamma': 1.4267634915403584, 'lambda_sparse': 0.0009279664017434357, 'lr': 0.019383527500283538, 'weight_decay': 1.1628527909292953e-06}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:54:00,408] Trial 18 finished with value: 0.9179525847151415 and parameters: {'n_d': 55, 'n_a': 39, 'n_steps': 5, 'gamma': 1.1800588081330217, 'lambda_sparse': 0.004276908807191975, 'lr': 0.08379250181394213, 'weight_decay': 4.805364946254653e-05}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:54:38,632] Trial 19 finished with value: 0.8883142020540208 and parameters: {'n_d': 44, 'n_a': 29, 'n_steps': 8, 'gamma': 1.8374130152717574, 'lambda_sparse': 0.0008718501264743029, 'lr': 0.0035762424554638744, 'weight_decay': 1.081558768914454e-05}. Best is trial 7 with value: 0.9459839950569287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:55:01,584] A new study created in memory with name: no-name-0f0a79e6-bee6-4390-92c2-ffee10a138de
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:55:28,203] Trial 0 finished with value: 0.7226695606724474 and parameters: {'n_d': 44, 'n_a': 55, 'n_steps': 5, 'gamma': 1.152671947717688, 'lambda_sparse': 0.0006263670871026226, 'lr': 0.00024596356653223386, 'weight_decay': 2.080293707783649e-05}. Best is trial 0 with value: 0.7226695606724474.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:56:08,404] Trial 1 finished with value: 0.9345564766046872 and parameters: {'n_d': 31, 'n_a': 36, 'n_steps': 9, 'gamma': 1.501436114766575, 'lambda_sparse': 0.0009566605315501612, 'lr': 0.06057419111190122, 'weight_decay': 3.6604291672997655e-05}. Best is trial 1 with value: 0.9345564766046872.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:56:39,239] Trial 2 finished with value: 0.9013529580990989 and parameters: {'n_d': 56, 'n_a': 42, 'n_steps': 10, 'gamma': 1.2171820051013293, 'lambda_sparse': 0.0003480613034606578, 'lr': 0.021416237643584232, 'weight_decay': 0.0005095250749762327}. Best is trial 1 with value: 0.9345564766046872.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:57:11,313] Trial 3 finished with value: -2.459170672237911 and parameters: {'n_d': 40, 'n_a': 14, 'n_steps': 6, 'gamma': 1.3530813643994097, 'lambda_sparse': 0.0002142529778531978, 'lr': 0.00011412300179494966, 'weight_decay': 0.0004438508787255763}. Best is trial 1 with value: 0.9345564766046872.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:57:40,690] Trial 4 finished with value: 0.09628440199117494 and parameters: {'n_d': 49, 'n_a': 56, 'n_steps': 6, 'gamma': 1.064273546536147, 'lambda_sparse': 0.00027071470726593345, 'lr': 0.0001298925152230566, 'weight_decay': 0.00046089288920515836}. Best is trial 1 with value: 0.9345564766046872.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:58:23,822] Trial 5 finished with value: -0.9849808003367377 and parameters: {'n_d': 60, 'n_a': 34, 'n_steps': 9, 'gamma': 1.9214437216411788, 'lambda_sparse': 1.8325232502076692e-05, 'lr': 0.0003800920677237966, 'weight_decay': 0.000474471406461434}. Best is trial 1 with value: 0.9345564766046872.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:58:48,808] Trial 6 finished with value: 0.9265332308342591 and parameters: {'n_d': 41, 'n_a': 40, 'n_steps': 7, 'gamma': 1.0832039181090094, 'lambda_sparse': 2.1445530622486727e-05, 'lr': 0.05325240887803552, 'weight_decay': 3.467432665381405e-05}. Best is trial 1 with value: 0.9345564766046872.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:59:13,870] Trial 7 finished with value: 0.9116954322435699 and parameters: {'n_d': 21, 'n_a': 55, 'n_steps': 5, 'gamma': 1.0359766382637203, 'lambda_sparse': 0.00033980686157549325, 'lr': 0.019818423213584423, 'weight_decay': 0.0007047467343948297}. Best is trial 1 with value: 0.9345564766046872.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 12:59:51,604] Trial 8 finished with value: 0.949091784052992 and parameters: {'n_d': 43, 'n_a': 61, 'n_steps': 8, 'gamma': 1.1065956263321242, 'lambda_sparse': 0.0033877273366425455, 'lr': 0.08275064094076622, 'weight_decay': 0.00011530447805282075}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:00:16,624] Trial 9 finished with value: 0.926860672966734 and parameters: {'n_d': 47, 'n_a': 59, 'n_steps': 5, 'gamma': 1.0826771207596604, 'lambda_sparse': 0.004815255761822047, 'lr': 0.0643344567541717, 'weight_decay': 6.473130076660006e-06}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:00:35,087] Trial 10 finished with value: 0.900983691491311 and parameters: {'n_d': 9, 'n_a': 19, 'n_steps': 3, 'gamma': 1.618783835455051, 'lambda_sparse': 0.00797231009472058, 'lr': 0.0019029971323306384, 'weight_decay': 1.2231298841733878e-06}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:01:11,603] Trial 11 finished with value: 0.923238714522876 and parameters: {'n_d': 29, 'n_a': 29, 'n_steps': 8, 'gamma': 1.6309110023474624, 'lambda_sparse': 0.0018009440243233693, 'lr': 0.0070286505358240926, 'weight_decay': 8.579138353004966e-05}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:01:42,025] Trial 12 finished with value: 0.9286278630678971 and parameters: {'n_d': 32, 'n_a': 44, 'n_steps': 10, 'gamma': 1.4316384435060463, 'lambda_sparse': 0.001690864434323691, 'lr': 0.07770806934111177, 'weight_decay': 0.00012339345785783565}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:02:18,944] Trial 13 finished with value: 0.9062566524150584 and parameters: {'n_d': 23, 'n_a': 23, 'n_steps': 8, 'gamma': 1.6130039720665619, 'lambda_sparse': 0.0014299648239764087, 'lr': 0.0027179603479779734, 'weight_decay': 1.2532460311998828e-05}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:02:52,807] Trial 14 finished with value: 0.9147038121594694 and parameters: {'n_d': 34, 'n_a': 47, 'n_steps': 8, 'gamma': 1.7956839062607375, 'lambda_sparse': 5.514499012073517e-05, 'lr': 0.018445091795611875, 'weight_decay': 0.00010197286269589017}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:03:28,850] Trial 15 finished with value: 0.9121414545164102 and parameters: {'n_d': 18, 'n_a': 8, 'n_steps': 9, 'gamma': 1.3054788966648403, 'lambda_sparse': 0.0028152273326176374, 'lr': 0.008930034307242726, 'weight_decay': 5.0002353383764844e-05}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:04:10,446] Trial 16 finished with value: 0.842748336630631 and parameters: {'n_d': 54, 'n_a': 63, 'n_steps': 9, 'gamma': 1.4905602392836272, 'lambda_sparse': 0.0008751716097200493, 'lr': 0.0009398487152321777, 'weight_decay': 4.2883882813767785e-06}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:04:35,603] Trial 17 finished with value: 0.923850781211158 and parameters: {'n_d': 29, 'n_a': 32, 'n_steps': 7, 'gamma': 1.7400994533864445, 'lambda_sparse': 0.00010199609723368685, 'lr': 0.032250232772139606, 'weight_decay': 0.0001863718753384501}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:05:17,907] Trial 18 finished with value: 0.9450028668947216 and parameters: {'n_d': 37, 'n_a': 48, 'n_steps': 10, 'gamma': 1.2832271065144074, 'lambda_sparse': 0.004295490138176104, 'lr': 0.09174544338622102, 'weight_decay': 0.0002038832343511799}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:05:56,862] Trial 19 finished with value: 0.8858306014264905 and parameters: {'n_d': 38, 'n_a': 49, 'n_steps': 10, 'gamma': 1.2337961878236283, 'lambda_sparse': 0.00898121059038825, 'lr': 0.008336337500446543, 'weight_decay': 0.00021504622056617824}. Best is trial 8 with value: 0.949091784052992.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:06:54,814] A new study created in memory with name: no-name-74977bc8-99e2-4d05-8d9d-777fc82935f7
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:07:24,744] Trial 0 finished with value: 0.7475542604291011 and parameters: {'n_d': 57, 'n_a': 55, 'n_steps': 6, 'gamma': 1.8507335817942616, 'lambda_sparse': 2.052733484299994e-05, 'lr': 0.00033875515237049105, 'weight_decay': 4.2572036194934885e-05}. Best is trial 0 with value: 0.7475542604291011.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:08:03,840] Trial 1 finished with value: 0.8902605421155418 and parameters: {'n_d': 53, 'n_a': 48, 'n_steps': 10, 'gamma': 1.1065149811384365, 'lambda_sparse': 0.0023932294775931393, 'lr': 0.008560444726886185, 'weight_decay': 0.0006846168238147989}. Best is trial 1 with value: 0.8902605421155418.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:08:37,596] Trial 2 finished with value: 0.8869948284485568 and parameters: {'n_d': 15, 'n_a': 39, 'n_steps': 7, 'gamma': 1.163465284281752, 'lambda_sparse': 0.009142587783692528, 'lr': 0.0007265338611506314, 'weight_decay': 4.1261481833024865e-05}. Best is trial 1 with value: 0.8902605421155418.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:08:55,008] Trial 3 finished with value: 0.9082509411006668 and parameters: {'n_d': 24, 'n_a': 50, 'n_steps': 3, 'gamma': 1.3103397922427686, 'lambda_sparse': 7.049658666402773e-05, 'lr': 0.0018635922132554537, 'weight_decay': 0.00017815850112891943}. Best is trial 3 with value: 0.9082509411006668.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:09:18,052] Trial 4 finished with value: 0.9178991906424188 and parameters: {'n_d': 60, 'n_a': 49, 'n_steps': 4, 'gamma': 1.7497986004550823, 'lambda_sparse': 0.0011238472431043093, 'lr': 0.0024261873935120847, 'weight_decay': 1.9521828417619488e-05}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:09:40,530] Trial 5 finished with value: 0.9111859595729019 and parameters: {'n_d': 15, 'n_a': 20, 'n_steps': 5, 'gamma': 1.3822740806769285, 'lambda_sparse': 9.308861978417724e-05, 'lr': 0.0030744783190888147, 'weight_decay': 0.0001098907690976171}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:10:04,591] Trial 6 finished with value: 0.8980325165296701 and parameters: {'n_d': 54, 'n_a': 34, 'n_steps': 8, 'gamma': 1.0041120741597998, 'lambda_sparse': 0.00010834066177250502, 'lr': 0.03628080398632256, 'weight_decay': 5.119440997225336e-05}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:10:23,181] Trial 7 finished with value: 0.7612074450033078 and parameters: {'n_d': 21, 'n_a': 15, 'n_steps': 3, 'gamma': 1.5491877408261168, 'lambda_sparse': 1.9654105334064362e-05, 'lr': 0.00011568831568754935, 'weight_decay': 9.534260113172826e-06}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:10:44,077] Trial 8 finished with value: 0.9169189556392033 and parameters: {'n_d': 29, 'n_a': 29, 'n_steps': 3, 'gamma': 1.9827015484067463, 'lambda_sparse': 0.0006352166447054264, 'lr': 0.003915096847826647, 'weight_decay': 4.832803708527278e-06}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:11:15,531] Trial 9 finished with value: 0.8953362304009593 and parameters: {'n_d': 40, 'n_a': 12, 'n_steps': 7, 'gamma': 1.7518283238310004, 'lambda_sparse': 0.0007425637131383641, 'lr': 0.009728140683042731, 'weight_decay': 0.00040355016448053116}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:11:37,845] Trial 10 finished with value: 0.8660693293958494 and parameters: {'n_d': 64, 'n_a': 58, 'n_steps': 5, 'gamma': 1.6287811176346307, 'lambda_sparse': 0.0029467627555786755, 'lr': 0.046438272193878735, 'weight_decay': 1.5148636701186996e-06}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:11:59,346] Trial 11 finished with value: 0.9018620097584982 and parameters: {'n_d': 35, 'n_a': 33, 'n_steps': 4, 'gamma': 1.9248618342685875, 'lambda_sparse': 0.0005252466004948791, 'lr': 0.009291579917058765, 'weight_decay': 6.050396415055277e-06}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:12:17,610] Trial 12 finished with value: 0.9057994351627267 and parameters: {'n_d': 39, 'n_a': 26, 'n_steps': 3, 'gamma': 1.9577477781365937, 'lambda_sparse': 0.001777836555651934, 'lr': 0.0011462720317413511, 'weight_decay': 6.175217033257557e-06}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:12:41,302] Trial 13 finished with value: 0.9138778540532689 and parameters: {'n_d': 30, 'n_a': 42, 'n_steps': 4, 'gamma': 1.7190319034177177, 'lambda_sparse': 0.00027662738773418584, 'lr': 0.005137877496478699, 'weight_decay': 1.0507603809090447e-06}. Best is trial 4 with value: 0.9178991906424188.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:13:09,052] Trial 14 finished with value: 0.9381900626731825 and parameters: {'n_d': 47, 'n_a': 63, 'n_steps': 5, 'gamma': 1.8056094129402924, 'lambda_sparse': 0.0009970859450106418, 'lr': 0.02347575300959595, 'weight_decay': 1.529920705762502e-05}. Best is trial 14 with value: 0.9381900626731825.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:13:33,900] Trial 15 finished with value: 0.9294161061038576 and parameters: {'n_d': 46, 'n_a': 64, 'n_steps': 5, 'gamma': 1.7564405459013532, 'lambda_sparse': 0.006030703232700356, 'lr': 0.02341902873246902, 'weight_decay': 1.5958305698513207e-05}. Best is trial 14 with value: 0.9381900626731825.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:13:51,677] Trial 16 finished with value: 0.8837943275035722 and parameters: {'n_d': 47, 'n_a': 63, 'n_steps': 6, 'gamma': 1.4729937936247772, 'lambda_sparse': 0.00737058666506991, 'lr': 0.09386399345713674, 'weight_decay': 1.3441244011571047e-05}. Best is trial 14 with value: 0.9381900626731825.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:14:29,636] Trial 17 finished with value: 0.934761270588513 and parameters: {'n_d': 46, 'n_a': 62, 'n_steps': 9, 'gamma': 1.831510657747223, 'lambda_sparse': 0.005169329907658098, 'lr': 0.02279850439382553, 'weight_decay': 2.9609022304564247e-06}. Best is trial 14 with value: 0.9381900626731825.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:15:11,773] Trial 18 finished with value: 0.9158037339986311 and parameters: {'n_d': 47, 'n_a': 55, 'n_steps': 9, 'gamma': 1.5971896483227241, 'lambda_sparse': 0.00359209006599655, 'lr': 0.020592789349864124, 'weight_decay': 2.5313317944182883e-06}. Best is trial 14 with value: 0.9381900626731825.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:15:43,986] Trial 19 finished with value: 0.9493843475519544 and parameters: {'n_d': 43, 'n_a': 46, 'n_steps': 10, 'gamma': 1.8185815095341509, 'lambda_sparse': 0.00025162378053401944, 'lr': 0.09141931642978272, 'weight_decay': 2.8738720631961954e-06}. Best is trial 19 with value: 0.9493843475519544.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:16:23,445] A new study created in memory with name: no-name-116bfc24-9a01-4984-aaa4-a9557857bef2
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:16:50,014] Trial 0 finished with value: 0.860601800417832 and parameters: {'n_d': 30, 'n_a': 9, 'n_steps': 9, 'gamma': 1.0212941770666664, 'lambda_sparse': 0.003496990017471731, 'lr': 0.03394370405631278, 'weight_decay': 8.965390850361834e-05}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:17:04,766] Trial 1 finished with value: 0.6650787232696141 and parameters: {'n_d': 36, 'n_a': 57, 'n_steps': 6, 'gamma': 1.6098617095939025, 'lambda_sparse': 3.1096630545721554e-05, 'lr': 0.028522157507812132, 'weight_decay': 1.57301740392087e-06}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:17:27,693] Trial 2 finished with value: -0.11955219333865119 and parameters: {'n_d': 50, 'n_a': 18, 'n_steps': 7, 'gamma': 1.1500029939577558, 'lambda_sparse': 0.00038022775025373665, 'lr': 0.000546212191732365, 'weight_decay': 2.4836515398633583e-06}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:17:42,976] Trial 3 finished with value: -2.138297534760696 and parameters: {'n_d': 15, 'n_a': 24, 'n_steps': 7, 'gamma': 1.1172334538246305, 'lambda_sparse': 0.003307275469574596, 'lr': 0.0010489423725683292, 'weight_decay': 1.0509496620151434e-06}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:17:59,880] Trial 4 finished with value: -6.008330016407394 and parameters: {'n_d': 30, 'n_a': 45, 'n_steps': 9, 'gamma': 1.986045952649212, 'lambda_sparse': 1.2496740505322136e-05, 'lr': 0.0002802506849294044, 'weight_decay': 2.793967986790924e-06}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:18:26,810] Trial 5 finished with value: 0.589918865816045 and parameters: {'n_d': 44, 'n_a': 30, 'n_steps': 9, 'gamma': 1.2235080048535405, 'lambda_sparse': 8.687616502840214e-05, 'lr': 0.0008073111429802722, 'weight_decay': 2.3218622810293904e-06}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:18:38,023] Trial 6 finished with value: -0.3967226602885179 and parameters: {'n_d': 54, 'n_a': 55, 'n_steps': 3, 'gamma': 1.2298576078927805, 'lambda_sparse': 0.00010491061591092184, 'lr': 0.0005380866764060771, 'weight_decay': 1.3854446227562904e-05}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:18:49,525] Trial 7 finished with value: 0.7235907906079321 and parameters: {'n_d': 44, 'n_a': 60, 'n_steps': 3, 'gamma': 1.8346681201567967, 'lambda_sparse': 0.0027803131828777992, 'lr': 0.0012601531635215, 'weight_decay': 0.00016063483250878803}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:18:59,286] Trial 8 finished with value: -844.5453660524479 and parameters: {'n_d': 13, 'n_a': 36, 'n_steps': 10, 'gamma': 1.0916753735182572, 'lambda_sparse': 0.009006101899048415, 'lr': 0.00024766604102180207, 'weight_decay': 0.00039355614685108623}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:19:30,893] Trial 9 finished with value: 0.8298980045901078 and parameters: {'n_d': 58, 'n_a': 34, 'n_steps': 7, 'gamma': 1.940496264109579, 'lambda_sparse': 1.859093333861761e-05, 'lr': 0.001709626205992665, 'weight_decay': 0.00013730298970033057}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:19:38,198] Trial 10 finished with value: -16.912411566633246 and parameters: {'n_d': 27, 'n_a': 8, 'n_steps': 5, 'gamma': 1.4070020162332022, 'lambda_sparse': 0.0006789039024365111, 'lr': 0.062476611084142965, 'weight_decay': 2.6573565156021443e-05}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:20:02,351] Trial 11 finished with value: 0.7808282736921037 and parameters: {'n_d': 58, 'n_a': 8, 'n_steps': 8, 'gamma': 1.6795437683223273, 'lambda_sparse': 0.001274423580780121, 'lr': 0.007810789484188413, 'weight_decay': 0.00010618294207943872}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:20:11,325] Trial 12 finished with value: -2.6281016190499447 and parameters: {'n_d': 62, 'n_a': 45, 'n_steps': 5, 'gamma': 1.3917662736379146, 'lambda_sparse': 0.00012683133064708756, 'lr': 0.006194373752823433, 'weight_decay': 8.952563037432077e-05}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:20:22,072] Trial 13 finished with value: -0.8155309201253411 and parameters: {'n_d': 22, 'n_a': 18, 'n_steps': 8, 'gamma': 1.9985763801135288, 'lambda_sparse': 1.050355013450526e-05, 'lr': 0.016085082071321276, 'weight_decay': 0.0009374574583465792}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:20:57,544] Trial 14 finished with value: 0.7852146723423911 and parameters: {'n_d': 40, 'n_a': 17, 'n_steps': 10, 'gamma': 1.7753274113061985, 'lambda_sparse': 0.00753966778821036, 'lr': 0.0027886184500362197, 'weight_decay': 4.490392231126583e-05}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:21:11,579] Trial 15 finished with value: -37.99009805335636 and parameters: {'n_d': 64, 'n_a': 45, 'n_steps': 8, 'gamma': 1.5164012300358887, 'lambda_sparse': 3.821711414083855e-05, 'lr': 0.0001047172989718749, 'weight_decay': 0.0002628655200650604}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:21:21,615] Trial 16 finished with value: -0.2510581803576113 and parameters: {'n_d': 33, 'n_a': 34, 'n_steps': 6, 'gamma': 1.3805183931476581, 'lambda_sparse': 0.0002572947815975176, 'lr': 0.07866589434486519, 'weight_decay': 2.328250156800065e-05}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:21:42,791] Trial 17 finished with value: 0.3490816053454726 and parameters: {'n_d': 26, 'n_a': 26, 'n_steps': 9, 'gamma': 1.8647217365673432, 'lambda_sparse': 0.0012678253657298555, 'lr': 0.0027081351753998097, 'weight_decay': 8.349539332207796e-06}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:21:50,042] Trial 18 finished with value: -1.3363848167675747 and parameters: {'n_d': 21, 'n_a': 38, 'n_steps': 5, 'gamma': 1.0009708777718702, 'lambda_sparse': 4.462464053340344e-05, 'lr': 0.01977858702922946, 'weight_decay': 6.870128902740955e-05}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:22:06,672] Trial 19 finished with value: 0.6814977481807858 and parameters: {'n_d': 8, 'n_a': 50, 'n_steps': 7, 'gamma': 1.5735733109767671, 'lambda_sparse': 0.00024849954030349303, 'lr': 0.006446357062401891, 'weight_decay': 0.0007197023391299325}. Best is trial 0 with value: 0.860601800417832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:22:37,049] A new study created in memory with name: no-name-c13d2e30-7ad1-4b25-8479-63cc98d90131
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:22:56,844] Trial 0 finished with value: 0.8517738433369203 and parameters: {'n_d': 19, 'n_a': 18, 'n_steps': 5, 'gamma': 1.0671489165014214, 'lambda_sparse': 1.017208132083867e-05, 'lr': 0.031993867728243516, 'weight_decay': 0.0001595004662475633}. Best is trial 0 with value: 0.8517738433369203.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:23:35,476] Trial 1 finished with value: 0.8810741026064469 and parameters: {'n_d': 52, 'n_a': 54, 'n_steps': 8, 'gamma': 1.3166397374156313, 'lambda_sparse': 1.1651469651388044e-05, 'lr': 0.0017233175657771261, 'weight_decay': 4.488156251026233e-06}. Best is trial 1 with value: 0.8810741026064469.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:24:04,332] Trial 2 finished with value: 0.948527237287679 and parameters: {'n_d': 35, 'n_a': 41, 'n_steps': 7, 'gamma': 1.2413587834221018, 'lambda_sparse': 0.0025692739668110275, 'lr': 0.047357887277794844, 'weight_decay': 0.00016783449766973282}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:24:29,550] Trial 3 finished with value: 0.8925404066685683 and parameters: {'n_d': 46, 'n_a': 18, 'n_steps': 5, 'gamma': 1.457012467178842, 'lambda_sparse': 9.806554109698305e-05, 'lr': 0.005883373800336248, 'weight_decay': 0.0009044589220081478}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:24:47,713] Trial 4 finished with value: 0.8512618080414623 and parameters: {'n_d': 32, 'n_a': 59, 'n_steps': 3, 'gamma': 1.2988096072242845, 'lambda_sparse': 0.008420204954453838, 'lr': 0.000414283635626718, 'weight_decay': 0.00010575582891010644}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:25:09,982] Trial 5 finished with value: 0.8901678147165687 and parameters: {'n_d': 64, 'n_a': 55, 'n_steps': 5, 'gamma': 1.2374289034214352, 'lambda_sparse': 0.0040604965712874195, 'lr': 0.0021443753146871813, 'weight_decay': 0.00015722798321396672}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:25:34,537] Trial 6 finished with value: 0.474950694896213 and parameters: {'n_d': 27, 'n_a': 36, 'n_steps': 4, 'gamma': 1.7008347520023017, 'lambda_sparse': 1.8197491807158954e-05, 'lr': 0.00013639166979880404, 'weight_decay': 0.00017206436026180052}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:25:55,358] Trial 7 finished with value: 0.9042663183440989 and parameters: {'n_d': 33, 'n_a': 64, 'n_steps': 5, 'gamma': 1.0979235328663512, 'lambda_sparse': 0.0004806542507157267, 'lr': 0.07036347266810568, 'weight_decay': 0.00023932217778019764}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:26:36,030] Trial 8 finished with value: 0.22134080298189307 and parameters: {'n_d': 8, 'n_a': 29, 'n_steps': 8, 'gamma': 1.7050597158648548, 'lambda_sparse': 3.691996472946314e-05, 'lr': 0.0006911187703985762, 'weight_decay': 0.0004760584195077831}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:27:20,022] Trial 9 finished with value: 0.8397558725883252 and parameters: {'n_d': 50, 'n_a': 19, 'n_steps': 9, 'gamma': 1.2642170107592023, 'lambda_sparse': 0.005294175897457878, 'lr': 0.0016914142283408198, 'weight_decay': 2.3840164139726086e-06}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:28:07,686] Trial 10 finished with value: 0.9118268613192311 and parameters: {'n_d': 43, 'n_a': 44, 'n_steps': 10, 'gamma': 1.9538120181998893, 'lambda_sparse': 0.0009537128184328681, 'lr': 0.013306475532413679, 'weight_decay': 2.0394306148200617e-05}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:28:53,276] Trial 11 finished with value: 0.9119836799047244 and parameters: {'n_d': 44, 'n_a': 46, 'n_steps': 10, 'gamma': 1.9678683764235212, 'lambda_sparse': 0.001111675172855841, 'lr': 0.016938386327702414, 'weight_decay': 2.328683243649141e-05}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:29:17,976] Trial 12 finished with value: 0.931571726813946 and parameters: {'n_d': 40, 'n_a': 44, 'n_steps': 7, 'gamma': 1.9601415018839043, 'lambda_sparse': 0.0015212969628403488, 'lr': 0.0993025873475965, 'weight_decay': 2.4231744079617052e-05}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:29:40,598] Trial 13 finished with value: 0.8998116914583933 and parameters: {'n_d': 25, 'n_a': 32, 'n_steps': 7, 'gamma': 1.6520679807947174, 'lambda_sparse': 0.0019696775442095984, 'lr': 0.07296299224713323, 'weight_decay': 4.558372711936204e-05}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:30:06,648] Trial 14 finished with value: 0.9342518328145097 and parameters: {'n_d': 38, 'n_a': 42, 'n_steps': 7, 'gamma': 1.4994520601160604, 'lambda_sparse': 0.0002512016710366815, 'lr': 0.09755714845269062, 'weight_decay': 9.361267792315074e-06}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:30:35,281] Trial 15 finished with value: 0.8949549934837872 and parameters: {'n_d': 57, 'n_a': 27, 'n_steps': 6, 'gamma': 1.5095594942858166, 'lambda_sparse': 0.00015592944614725216, 'lr': 0.024728118642382512, 'weight_decay': 7.626057199989652e-06}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:31:13,524] Trial 16 finished with value: 0.9203382161642981 and parameters: {'n_d': 17, 'n_a': 9, 'n_steps': 8, 'gamma': 1.482183476900684, 'lambda_sparse': 0.0002616848661483444, 'lr': 0.038794520361890905, 'weight_decay': 1.1196802751794587e-06}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:31:43,529] Trial 17 finished with value: 0.9249045937047838 and parameters: {'n_d': 37, 'n_a': 48, 'n_steps': 6, 'gamma': 1.1832710199901086, 'lambda_sparse': 5.981287140226315e-05, 'lr': 0.010068477498488522, 'weight_decay': 5.810622432747585e-05}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:32:15,888] Trial 18 finished with value: 0.9153481915281204 and parameters: {'n_d': 28, 'n_a': 39, 'n_steps': 7, 'gamma': 1.3912650520145524, 'lambda_sparse': 0.00040494840379871324, 'lr': 0.0061770871974875805, 'weight_decay': 1.1274653157184098e-05}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:32:38,608] Trial 19 finished with value: 0.8513977839067193 and parameters: {'n_d': 20, 'n_a': 39, 'n_steps': 9, 'gamma': 1.5833471166435238, 'lambda_sparse': 0.0027925443123652445, 'lr': 0.05236804686799012, 'weight_decay': 6.922625309129328e-05}. Best is trial 2 with value: 0.948527237287679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:33:11,563] A new study created in memory with name: no-name-262e7fec-b618-4127-b28d-a6eed7c3ba7a
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:33:29,360] Trial 0 finished with value: 0.8994655873074369 and parameters: {'n_d': 42, 'n_a': 15, 'n_steps': 4, 'gamma': 1.9671773764800675, 'lambda_sparse': 0.0013265515946087394, 'lr': 0.09955246682038653, 'weight_decay': 0.0006962883111693479}. Best is trial 0 with value: 0.8994655873074369.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:33:52,348] Trial 1 finished with value: 0.9038300078724054 and parameters: {'n_d': 56, 'n_a': 31, 'n_steps': 3, 'gamma': 1.515815807591838, 'lambda_sparse': 1.915783668556895e-05, 'lr': 0.001997947392574648, 'weight_decay': 6.9339738222986275e-06}. Best is trial 1 with value: 0.9038300078724054.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:34:33,932] Trial 2 finished with value: 0.8709229203178083 and parameters: {'n_d': 33, 'n_a': 26, 'n_steps': 9, 'gamma': 1.6677708976437307, 'lambda_sparse': 1.4713924421520399e-05, 'lr': 0.0037545795126956417, 'weight_decay': 0.0003048071605057595}. Best is trial 1 with value: 0.9038300078724054.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:34:58,705] Trial 3 finished with value: 0.8701813606405908 and parameters: {'n_d': 9, 'n_a': 47, 'n_steps': 6, 'gamma': 1.24498139503556, 'lambda_sparse': 0.0006041699889081835, 'lr': 0.04578631105601844, 'weight_decay': 8.348350503604072e-06}. Best is trial 1 with value: 0.9038300078724054.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:35:46,759] Trial 4 finished with value: -6.973536352587349 and parameters: {'n_d': 25, 'n_a': 37, 'n_steps': 10, 'gamma': 1.8918012333224485, 'lambda_sparse': 0.005123134278401081, 'lr': 0.0001117858053062949, 'weight_decay': 0.00036871695222429393}. Best is trial 1 with value: 0.9038300078724054.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:36:13,357] Trial 5 finished with value: 0.852331786891113 and parameters: {'n_d': 37, 'n_a': 58, 'n_steps': 5, 'gamma': 1.6425476284773606, 'lambda_sparse': 0.0018932396861391255, 'lr': 0.0011100087290580565, 'weight_decay': 2.0192554090883356e-06}. Best is trial 1 with value: 0.9038300078724054.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:36:37,664] Trial 6 finished with value: 0.8620625946652936 and parameters: {'n_d': 29, 'n_a': 33, 'n_steps': 5, 'gamma': 1.3615095434397388, 'lambda_sparse': 0.0004180407811849704, 'lr': 0.0005356447826723665, 'weight_decay': 1.1213366636776326e-06}. Best is trial 1 with value: 0.9038300078724054.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:37:07,527] Trial 7 finished with value: 0.9218120823948979 and parameters: {'n_d': 25, 'n_a': 55, 'n_steps': 6, 'gamma': 1.2682270228986021, 'lambda_sparse': 0.001425765023247802, 'lr': 0.0022523357136629424, 'weight_decay': 5.674103636105601e-06}. Best is trial 7 with value: 0.9218120823948979.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:37:47,394] Trial 8 finished with value: 0.9091557166495567 and parameters: {'n_d': 55, 'n_a': 43, 'n_steps': 9, 'gamma': 1.4382643730192386, 'lambda_sparse': 1.5131175612586315e-05, 'lr': 0.0021483696656184503, 'weight_decay': 0.0001514632107373756}. Best is trial 7 with value: 0.9218120823948979.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:38:11,858] Trial 9 finished with value: 0.9309707134135701 and parameters: {'n_d': 54, 'n_a': 21, 'n_steps': 6, 'gamma': 1.8940725443368538, 'lambda_sparse': 0.004478357822318976, 'lr': 0.035270210235071826, 'weight_decay': 0.00010670776733733439}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:38:45,149] Trial 10 finished with value: 0.8469654567129528 and parameters: {'n_d': 63, 'n_a': 10, 'n_steps': 8, 'gamma': 1.074942361131908, 'lambda_sparse': 0.008982293981140966, 'lr': 0.02018878133037205, 'weight_decay': 5.446611578513644e-05}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:39:20,061] Trial 11 finished with value: 0.8365972287242767 and parameters: {'n_d': 17, 'n_a': 59, 'n_steps': 7, 'gamma': 1.0337240858450363, 'lambda_sparse': 8.229729191788142e-05, 'lr': 0.009437737031510832, 'weight_decay': 2.8129570688569936e-05}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:39:53,525] Trial 12 finished with value: 0.8935475502277571 and parameters: {'n_d': 46, 'n_a': 20, 'n_steps': 7, 'gamma': 1.789068161963558, 'lambda_sparse': 0.0024995739263923835, 'lr': 0.00715279648037999, 'weight_decay': 3.615283438502846e-05}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:40:24,449] Trial 13 finished with value: 0.7120483274978764 and parameters: {'n_d': 22, 'n_a': 51, 'n_steps': 6, 'gamma': 1.221437327379387, 'lambda_sparse': 8.910373940929351e-05, 'lr': 0.000422966629056057, 'weight_decay': 5.735948545453349e-06}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:40:49,639] Trial 14 finished with value: 0.8726263866020516 and parameters: {'n_d': 46, 'n_a': 25, 'n_steps': 5, 'gamma': 1.2489662055815294, 'lambda_sparse': 0.003959267664805657, 'lr': 0.020508293254038155, 'weight_decay': 1.702060733259466e-05}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:41:09,985] Trial 15 finished with value: 0.8724523211402989 and parameters: {'n_d': 15, 'n_a': 40, 'n_steps': 3, 'gamma': 1.6056618845952262, 'lambda_sparse': 0.0008409334657013717, 'lr': 0.006320094090737016, 'weight_decay': 7.3088251288485e-05}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:41:46,950] Trial 16 finished with value: 0.9224343908594748 and parameters: {'n_d': 53, 'n_a': 50, 'n_steps': 8, 'gamma': 1.8187745383400624, 'lambda_sparse': 0.0002236230855149479, 'lr': 0.019714328357865792, 'weight_decay': 0.00010843536068042093}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:42:22,815] Trial 17 finished with value: 0.9235258760751867 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 8, 'gamma': 1.8063899803636363, 'lambda_sparse': 0.00018731297928201496, 'lr': 0.029908436182294815, 'weight_decay': 0.00012203460911341484}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:42:49,988] Trial 18 finished with value: 0.8488698518939997 and parameters: {'n_d': 64, 'n_a': 9, 'n_steps': 8, 'gamma': 1.9988774359152313, 'lambda_sparse': 0.00018219293340538602, 'lr': 0.09543685347178947, 'weight_decay': 0.00021653411207928362}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:43:35,661] Trial 19 finished with value: 0.9278274606365634 and parameters: {'n_d': 59, 'n_a': 23, 'n_steps': 10, 'gamma': 1.7358215396817862, 'lambda_sparse': 4.1649674504225775e-05, 'lr': 0.04300692918333272, 'weight_decay': 0.0009766208155888203}. Best is trial 9 with value: 0.9309707134135701.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:44:09,545] A new study created in memory with name: no-name-db55014e-6d0c-4890-a649-9d18797af3d5
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:44:33,761] Trial 0 finished with value: 0.9301479181470897 and parameters: {'n_d': 33, 'n_a': 22, 'n_steps': 4, 'gamma': 1.4735929062320536, 'lambda_sparse': 5.0276726437827634e-05, 'lr': 0.0031243391214668278, 'weight_decay': 5.457247611015905e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:44:56,846] Trial 1 finished with value: 0.9103929956247845 and parameters: {'n_d': 16, 'n_a': 12, 'n_steps': 4, 'gamma': 1.8007604800999215, 'lambda_sparse': 4.539760575255555e-05, 'lr': 0.002217847085082669, 'weight_decay': 5.612365218252063e-05}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:45:26,497] Trial 2 finished with value: 0.9265959975480864 and parameters: {'n_d': 20, 'n_a': 45, 'n_steps': 7, 'gamma': 1.8000988998306209, 'lambda_sparse': 3.042269361989089e-05, 'lr': 0.0036696621299531257, 'weight_decay': 6.11753208252284e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:45:51,661] Trial 3 finished with value: 0.8773748149013891 and parameters: {'n_d': 13, 'n_a': 16, 'n_steps': 3, 'gamma': 1.184494522018282, 'lambda_sparse': 7.278052120739614e-05, 'lr': 0.0015042968522291228, 'weight_decay': 3.670952595968633e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:46:10,937] Trial 4 finished with value: 0.7316557905079684 and parameters: {'n_d': 58, 'n_a': 30, 'n_steps': 6, 'gamma': 1.1631472528640852, 'lambda_sparse': 0.00016741108375431123, 'lr': 0.00132683763208543, 'weight_decay': 0.0001055621246759072}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:46:29,135] Trial 5 finished with value: -2.6085275586458163 and parameters: {'n_d': 36, 'n_a': 39, 'n_steps': 8, 'gamma': 1.9514764303876548, 'lambda_sparse': 1.7951831885369155e-05, 'lr': 0.0005348805087601064, 'weight_decay': 2.39507605638888e-05}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:46:55,606] Trial 6 finished with value: 0.9120395131079854 and parameters: {'n_d': 54, 'n_a': 61, 'n_steps': 4, 'gamma': 1.4541426478340935, 'lambda_sparse': 0.00028869217690275694, 'lr': 0.03229092757546942, 'weight_decay': 0.0001353540396928402}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:47:31,999] Trial 7 finished with value: 0.31688535684938124 and parameters: {'n_d': 57, 'n_a': 34, 'n_steps': 8, 'gamma': 1.099379699384465, 'lambda_sparse': 0.00010612155895206958, 'lr': 0.0004064045327186482, 'weight_decay': 4.203111644174169e-05}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:47:55,716] Trial 8 finished with value: 0.9033330311782465 and parameters: {'n_d': 11, 'n_a': 31, 'n_steps': 5, 'gamma': 1.4782146365685525, 'lambda_sparse': 2.3809932039515488e-05, 'lr': 0.0019084567097620011, 'weight_decay': 7.532448425628997e-05}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:48:25,388] Trial 9 finished with value: 0.9223448506465448 and parameters: {'n_d': 39, 'n_a': 22, 'n_steps': 7, 'gamma': 1.2676012965575918, 'lambda_sparse': 0.003085510364685706, 'lr': 0.07206578379920976, 'weight_decay': 1.8413906578211554e-05}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:49:00,143] Trial 10 finished with value: 0.9142516587456886 and parameters: {'n_d': 30, 'n_a': 50, 'n_steps': 10, 'gamma': 1.629270056058973, 'lambda_sparse': 0.0012615864601703405, 'lr': 0.01084044243420582, 'weight_decay': 1.0690688782916358e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:49:26,458] Trial 11 finished with value: 0.850705258017426 and parameters: {'n_d': 21, 'n_a': 48, 'n_steps': 6, 'gamma': 1.6819155221078597, 'lambda_sparse': 1.2236021835893614e-05, 'lr': 0.008092706954774447, 'weight_decay': 5.005723347580318e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:50:05,252] Trial 12 finished with value: 0.9123791111388826 and parameters: {'n_d': 26, 'n_a': 44, 'n_steps': 10, 'gamma': 1.9788964301841405, 'lambda_sparse': 0.0006756353633120481, 'lr': 0.005345541127252063, 'weight_decay': 5.922383732886355e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:50:38,696] Trial 13 finished with value: -0.011711037227324805 and parameters: {'n_d': 43, 'n_a': 22, 'n_steps': 8, 'gamma': 1.3466593649327987, 'lambda_sparse': 4.213830781250375e-05, 'lr': 0.00013918088234098015, 'weight_decay': 1.1664918061178906e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:50:54,886] Trial 14 finished with value: 0.8870272243901401 and parameters: {'n_d': 46, 'n_a': 58, 'n_steps': 3, 'gamma': 1.651499958057598, 'lambda_sparse': 0.00021472312394314505, 'lr': 0.013423229906992143, 'weight_decay': 0.0005746869328691961}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:51:17,935] Trial 15 finished with value: 0.9047625136604472 and parameters: {'n_d': 30, 'n_a': 25, 'n_steps': 5, 'gamma': 1.8106510134488563, 'lambda_sparse': 3.331483879623966e-05, 'lr': 0.004323897816856968, 'weight_decay': 1.0381591715590426e-05}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:51:30,836] Trial 16 finished with value: -1.3321039727865287 and parameters: {'n_d': 25, 'n_a': 40, 'n_steps': 7, 'gamma': 1.5561052829810864, 'lambda_sparse': 0.007065773117473613, 'lr': 0.0006817258403580222, 'weight_decay': 2.448567901442103e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:52:09,384] Trial 17 finished with value: 0.9158149694491433 and parameters: {'n_d': 8, 'n_a': 9, 'n_steps': 9, 'gamma': 1.384244951343198, 'lambda_sparse': 1.1554769442805743e-05, 'lr': 0.02795514261967764, 'weight_decay': 1.128065103544139e-05}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:52:25,192] Trial 18 finished with value: 0.8070572930183956 and parameters: {'n_d': 22, 'n_a': 54, 'n_steps': 5, 'gamma': 1.8180603682668792, 'lambda_sparse': 0.000636380103810252, 'lr': 0.02100061113350553, 'weight_decay': 2.247716796377757e-06}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:52:39,540] Trial 19 finished with value: -2.0373408242116833 and parameters: {'n_d': 33, 'n_a': 16, 'n_steps': 4, 'gamma': 1.0064161229483288, 'lambda_sparse': 9.141573849239043e-05, 'lr': 0.0001940102021916384, 'weight_decay': 0.0002706427484118722}. Best is trial 0 with value: 0.9301479181470897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:53:07,022] A new study created in memory with name: no-name-cc4827bf-145b-4cb5-a057-40747bdaa5df
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:53:39,184] Trial 0 finished with value: 0.9244776062922537 and parameters: {'n_d': 31, 'n_a': 39, 'n_steps': 6, 'gamma': 1.9117109778641415, 'lambda_sparse': 0.0002925808215795133, 'lr': 0.022972819316530932, 'weight_decay': 3.992737659260518e-06}. Best is trial 0 with value: 0.9244776062922537.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:54:08,113] Trial 1 finished with value: 0.8942173975161047 and parameters: {'n_d': 63, 'n_a': 12, 'n_steps': 10, 'gamma': 1.3861177365411192, 'lambda_sparse': 0.009703706334410447, 'lr': 0.0489487571528804, 'weight_decay': 4.092316489140241e-05}. Best is trial 0 with value: 0.9244776062922537.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:54:48,358] Trial 2 finished with value: -8.178409811956776 and parameters: {'n_d': 50, 'n_a': 28, 'n_steps': 8, 'gamma': 1.8170461302770768, 'lambda_sparse': 6.009447037564426e-05, 'lr': 0.00014774787172398338, 'weight_decay': 0.00016637586961461322}. Best is trial 0 with value: 0.9244776062922537.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:55:08,592] Trial 3 finished with value: 0.9497446950571514 and parameters: {'n_d': 32, 'n_a': 61, 'n_steps': 4, 'gamma': 1.9059062268673181, 'lambda_sparse': 1.8127812214086167e-05, 'lr': 0.06318127683521893, 'weight_decay': 0.00024304896824789334}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:55:24,263] Trial 4 finished with value: 0.8482426873335832 and parameters: {'n_d': 13, 'n_a': 17, 'n_steps': 7, 'gamma': 1.2975223922491441, 'lambda_sparse': 0.0007812980000121664, 'lr': 0.06673934705393449, 'weight_decay': 0.0006369020635947489}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:56:00,290] Trial 5 finished with value: 0.8192809282743536 and parameters: {'n_d': 60, 'n_a': 59, 'n_steps': 9, 'gamma': 1.7256144742381676, 'lambda_sparse': 0.00020958826378228738, 'lr': 0.0005900879324271091, 'weight_decay': 3.9264912074201574e-05}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:56:35,611] Trial 6 finished with value: -0.3162431494143949 and parameters: {'n_d': 32, 'n_a': 11, 'n_steps': 7, 'gamma': 1.7827348257921396, 'lambda_sparse': 0.0008022686126355735, 'lr': 0.00014098489193570816, 'weight_decay': 0.0005291127210472026}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:56:49,118] Trial 7 finished with value: 0.7750763904857305 and parameters: {'n_d': 61, 'n_a': 32, 'n_steps': 3, 'gamma': 1.9329808020646126, 'lambda_sparse': 0.008554802366867316, 'lr': 0.0013703291006906015, 'weight_decay': 6.19796448648865e-06}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:57:03,030] Trial 8 finished with value: 0.9298003337108007 and parameters: {'n_d': 36, 'n_a': 25, 'n_steps': 3, 'gamma': 1.0468827996766414, 'lambda_sparse': 0.003499741956335145, 'lr': 0.03595218383254165, 'weight_decay': 4.587625390990022e-06}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:57:31,268] Trial 9 finished with value: 0.9114274940662261 and parameters: {'n_d': 24, 'n_a': 46, 'n_steps': 4, 'gamma': 1.6465086508791944, 'lambda_sparse': 0.0006050617535251293, 'lr': 0.006849088632074244, 'weight_decay': 2.103896376879707e-06}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:57:59,119] Trial 10 finished with value: 0.8941192622922509 and parameters: {'n_d': 46, 'n_a': 64, 'n_steps': 5, 'gamma': 1.5390315045731129, 'lambda_sparse': 1.1516929187126457e-05, 'lr': 0.009096047342827573, 'weight_decay': 0.0001348105649821049}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:58:15,552] Trial 11 finished with value: 0.911762651685831 and parameters: {'n_d': 42, 'n_a': 51, 'n_steps': 3, 'gamma': 1.095493983630868, 'lambda_sparse': 1.4172496911192511e-05, 'lr': 0.08719020233366462, 'weight_decay': 1.0747507085068053e-05}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:58:40,557] Trial 12 finished with value: 0.9056732189275528 and parameters: {'n_d': 23, 'n_a': 24, 'n_steps': 5, 'gamma': 1.020001426415365, 'lambda_sparse': 0.0019594953879730234, 'lr': 0.01772760524070683, 'weight_decay': 1.1327409023877688e-06}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:59:06,040] Trial 13 finished with value: 0.9263000066089954 and parameters: {'n_d': 38, 'n_a': 40, 'n_steps': 4, 'gamma': 1.2283499838897356, 'lambda_sparse': 6.876569892091627e-05, 'lr': 0.003222246780820904, 'weight_decay': 1.9837859439307024e-05}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:59:18,444] Trial 14 finished with value: 0.8737152451595578 and parameters: {'n_d': 8, 'n_a': 22, 'n_steps': 3, 'gamma': 1.4610741199457005, 'lambda_sparse': 0.0027948931697872018, 'lr': 0.033055844945688896, 'weight_decay': 0.00014827045246783814}. Best is trial 3 with value: 0.9497446950571514.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 13:59:42,014] Trial 15 finished with value: 0.9591154794468598 and parameters: {'n_d': 20, 'n_a': 50, 'n_steps': 5, 'gamma': 1.586264027778189, 'lambda_sparse': 4.390591317581279e-05, 'lr': 0.09949701762408966, 'weight_decay': 6.412855463668178e-05}. Best is trial 15 with value: 0.9591154794468598.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:00:08,588] Trial 16 finished with value: 0.932698030351819 and parameters: {'n_d': 21, 'n_a': 54, 'n_steps': 5, 'gamma': 1.6345411248610089, 'lambda_sparse': 3.50646412403404e-05, 'lr': 0.010345953386689678, 'weight_decay': 7.178246024984518e-05}. Best is trial 15 with value: 0.9591154794468598.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:00:39,938] Trial 17 finished with value: 0.9531633563292369 and parameters: {'n_d': 17, 'n_a': 49, 'n_steps': 6, 'gamma': 1.9965073029254028, 'lambda_sparse': 3.0346477753115756e-05, 'lr': 0.0824340512095076, 'weight_decay': 0.00026287599277444054}. Best is trial 15 with value: 0.9591154794468598.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:01:03,653] Trial 18 finished with value: 0.9145092052997633 and parameters: {'n_d': 16, 'n_a': 46, 'n_steps': 6, 'gamma': 1.9885687366725922, 'lambda_sparse': 0.0001310880197883064, 'lr': 0.09638842270254305, 'weight_decay': 0.00034273865706783285}. Best is trial 15 with value: 0.9591154794468598.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:01:41,172] Trial 19 finished with value: 0.9196088348471831 and parameters: {'n_d': 8, 'n_a': 53, 'n_steps': 8, 'gamma': 1.5559842598937552, 'lambda_sparse': 3.6561128154125154e-05, 'lr': 0.0035009259296184076, 'weight_decay': 7.717283890315715e-05}. Best is trial 15 with value: 0.9591154794468598.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:02:13,369] A new study created in memory with name: no-name-5c967402-83e1-486e-9a7f-1df832dfb8eb
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:02:47,298] Trial 0 finished with value: 0.8059479525505868 and parameters: {'n_d': 25, 'n_a': 51, 'n_steps': 8, 'gamma': 1.6879149095864594, 'lambda_sparse': 1.6778235808619804e-05, 'lr': 0.0009146952867939663, 'weight_decay': 2.8311403496251646e-06}. Best is trial 0 with value: 0.8059479525505868.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:03:20,064] Trial 1 finished with value: 0.8836710282404634 and parameters: {'n_d': 10, 'n_a': 24, 'n_steps': 8, 'gamma': 1.014704770905031, 'lambda_sparse': 2.0808364953296328e-05, 'lr': 0.004619527937805055, 'weight_decay': 0.0001197389737788498}. Best is trial 1 with value: 0.8836710282404634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:03:34,404] Trial 2 finished with value: 0.9069247828369679 and parameters: {'n_d': 14, 'n_a': 62, 'n_steps': 4, 'gamma': 1.7222502775721404, 'lambda_sparse': 1.539827274359527e-05, 'lr': 0.050242010754266216, 'weight_decay': 0.0008720142306141293}. Best is trial 2 with value: 0.9069247828369679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:04:13,782] Trial 3 finished with value: 0.9334967251503767 and parameters: {'n_d': 48, 'n_a': 15, 'n_steps': 9, 'gamma': 1.0257541867129136, 'lambda_sparse': 0.0001553621865060092, 'lr': 0.052060273854641015, 'weight_decay': 0.00027722564179984073}. Best is trial 3 with value: 0.9334967251503767.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:04:52,079] Trial 4 finished with value: 0.9357462535409318 and parameters: {'n_d': 32, 'n_a': 15, 'n_steps': 8, 'gamma': 1.4020177140227672, 'lambda_sparse': 0.000938252732581042, 'lr': 0.09936942845623088, 'weight_decay': 4.798613147837953e-06}. Best is trial 4 with value: 0.9357462535409318.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:05:19,270] Trial 5 finished with value: 0.897383466957275 and parameters: {'n_d': 41, 'n_a': 64, 'n_steps': 5, 'gamma': 1.7636852951349233, 'lambda_sparse': 0.0009681840763757226, 'lr': 0.0010414217909874982, 'weight_decay': 6.943528424781007e-06}. Best is trial 4 with value: 0.9357462535409318.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:05:47,225] Trial 6 finished with value: 0.8129588249623878 and parameters: {'n_d': 17, 'n_a': 30, 'n_steps': 4, 'gamma': 1.248700270400631, 'lambda_sparse': 0.0013268029073752663, 'lr': 0.00038739890490610996, 'weight_decay': 1.4661353771522079e-05}. Best is trial 4 with value: 0.9357462535409318.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:06:30,166] Trial 7 finished with value: 0.9191566402120024 and parameters: {'n_d': 63, 'n_a': 53, 'n_steps': 10, 'gamma': 1.673761854893742, 'lambda_sparse': 0.00016258727177190157, 'lr': 0.020927525318998805, 'weight_decay': 3.3897143912329974e-05}. Best is trial 4 with value: 0.9357462535409318.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:06:57,146] Trial 8 finished with value: 0.8953681428604886 and parameters: {'n_d': 18, 'n_a': 29, 'n_steps': 5, 'gamma': 1.923556500216005, 'lambda_sparse': 0.0059979780853374335, 'lr': 0.01850438394133027, 'weight_decay': 1.2490071400200074e-05}. Best is trial 4 with value: 0.9357462535409318.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:07:20,688] Trial 9 finished with value: 0.9254198058684208 and parameters: {'n_d': 53, 'n_a': 41, 'n_steps': 5, 'gamma': 1.3353703469469131, 'lambda_sparse': 0.00015496487802151184, 'lr': 0.010361306544574693, 'weight_decay': 4.747172915693038e-06}. Best is trial 4 with value: 0.9357462535409318.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:07:50,220] Trial 10 finished with value: 0.9359354850499508 and parameters: {'n_d': 29, 'n_a': 8, 'n_steps': 7, 'gamma': 1.4572132542118705, 'lambda_sparse': 0.006276303389312379, 'lr': 0.08709241326115083, 'weight_decay': 1.985114258571638e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:08:22,700] Trial 11 finished with value: 0.9053016007178537 and parameters: {'n_d': 29, 'n_a': 8, 'n_steps': 7, 'gamma': 1.4507487537860804, 'lambda_sparse': 0.009272464236027116, 'lr': 0.07686950509072603, 'weight_decay': 1.3608121361585401e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:08:50,045] Trial 12 finished with value: 0.9255605711746707 and parameters: {'n_d': 35, 'n_a': 15, 'n_steps': 7, 'gamma': 1.499866136349206, 'lambda_sparse': 0.002174292908037218, 'lr': 0.09012832924035945, 'weight_decay': 1.245340536734053e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:09:21,813] Trial 13 finished with value: 0.4293750345716584 and parameters: {'n_d': 29, 'n_a': 8, 'n_steps': 6, 'gamma': 1.280222854412022, 'lambda_sparse': 0.0006477935283115101, 'lr': 0.00011137396708694065, 'weight_decay': 2.6968383032346416e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:10:05,753] Trial 14 finished with value: 0.9244295387325254 and parameters: {'n_d': 37, 'n_a': 20, 'n_steps': 9, 'gamma': 1.393375878088405, 'lambda_sparse': 0.002149230039203107, 'lr': 0.006101878266845872, 'weight_decay': 5.0522871332012376e-05}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:10:40,895] Trial 15 finished with value: 0.8815383392568372 and parameters: {'n_d': 22, 'n_a': 36, 'n_steps': 8, 'gamma': 1.1680261543112973, 'lambda_sparse': 0.004147857394739158, 'lr': 0.025201970764765807, 'weight_decay': 1.5356404243855238e-05}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:11:10,876] Trial 16 finished with value: 0.879496745449152 and parameters: {'n_d': 44, 'n_a': 15, 'n_steps': 6, 'gamma': 1.5334406176634459, 'lambda_sparse': 0.0004205497218265913, 'lr': 0.0018008320566241679, 'weight_decay': 2.881041382619072e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:11:50,996] Trial 17 finished with value: 0.9349498745143187 and parameters: {'n_d': 33, 'n_a': 23, 'n_steps': 10, 'gamma': 1.5747234535704786, 'lambda_sparse': 5.694592469355194e-05, 'lr': 0.028543933539158423, 'weight_decay': 1.0974261367381685e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:12:24,994] Trial 18 finished with value: 0.9076852154447216 and parameters: {'n_d': 54, 'n_a': 8, 'n_steps': 7, 'gamma': 1.137671002582115, 'lambda_sparse': 0.0036746232722113374, 'lr': 0.011351803338252617, 'weight_decay': 5.995987027847303e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 14:12:45,297] Trial 19 finished with value: 0.9292486165975886 and parameters: {'n_d': 24, 'n_a': 17, 'n_steps': 3, 'gamma': 1.8626828710756898, 'lambda_sparse': 0.008985669865288473, 'lr': 0.09329072774068994, 'weight_decay': 9.37188954270735e-06}. Best is trial 10 with value: 0.9359354850499508.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-06 14:13:34 [INFO] TabNet →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/tabnet (mean R²=0.9379)
2025-08-06 14:13:34 [INFO] Ensemble weights: TabPFN=0.340, Tree=0.340, TabNet=0.320
2025-08-06 14:13:34 [INFO] Loading individual models into memory...
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-06 14:13:38 [INFO] Saved weighted ensemble to /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses_rona/final_model.pkl
