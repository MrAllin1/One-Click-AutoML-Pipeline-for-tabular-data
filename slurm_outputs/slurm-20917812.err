cpu-bind=MASK - dlcgpu02, task  0  0 [1775076]: mask 0xf0000000f set
/var/spool/slurm/job20917812/slurm_script: line 11: module: command not found
/var/spool/slurm/job20917812/slurm_script: line 14: cd: /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template: Permission denied
2025-08-04 20:00:06 [INFO] Using device: cuda
2025-08-04 20:00:06 [INFO] Training TabPFN model...
[I 2025-08-04 20:00:06,316] A new study created in memory with name: no-name-18298bce-0950-46ba-a8f0-c101bd561988
2025-08-04 20:00:06 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
2025-08-04 20:00:06 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-04 20:03:20,901] Trial 0 finished with value: 0.9260572256148073 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.9260572256148073.
2025-08-04 20:03:20 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
2025-08-04 20:03:20 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-04 20:06:58,062] Trial 1 finished with value: 0.9262889835026962 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 1 with value: 0.9262889835026962.
2025-08-04 20:06:58 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
2025-08-04 20:06:58 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-04 20:11:04,990] Trial 2 finished with value: 0.9240255091562499 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 1 with value: 0.9262889835026962.
2025-08-04 20:11:04 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
2025-08-04 20:11:05 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-04 20:13:18,658] Trial 3 finished with value: 0.9252326124326563 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 1 with value: 0.9262889835026962.
2025-08-04 20:13:18 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
2025-08-04 20:13:18 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-04 20:16:39,939] Trial 4 finished with value: 0.9259055239950397 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 1 with value: 0.9262889835026962.
2025-08-04 20:16:39 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
2025-08-04 20:16:39 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:17:49 [INFO] ⏸️ Pruned trial 5 at step 5 (R²=0.9252)
[I 2025-08-04 20:17:49,589] Trial 5 pruned. 
2025-08-04 20:17:49 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
2025-08-04 20:17:49 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:19:44 [INFO] ⏸️ Pruned trial 6 at step 5 (R²=0.9246)
[I 2025-08-04 20:19:44,587] Trial 6 pruned. 
2025-08-04 20:19:44 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
2025-08-04 20:19:44 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:21:37 [INFO] ⏸️ Pruned trial 7 at step 5 (R²=0.9246)
[I 2025-08-04 20:21:37,589] Trial 7 pruned. 
2025-08-04 20:21:37 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
2025-08-04 20:21:37 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:22:03 [INFO] ⏸️ Pruned trial 8 at step 1 (R²=0.9173)
[I 2025-08-04 20:22:03,748] Trial 8 pruned. 
2025-08-04 20:22:03 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
2025-08-04 20:22:03 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:24:02 [INFO] ⏸️ Pruned trial 9 at step 5 (R²=0.9251)
[I 2025-08-04 20:24:02,996] Trial 9 pruned. 
2025-08-04 20:24:03 [INFO] 🔍 Trial 10: n_bootstrap=20, sample_frac=0.74
2025-08-04 20:24:03 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:24:28 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.9174)
[I 2025-08-04 20:24:28,434] Trial 10 pruned. 
2025-08-04 20:24:28 [INFO] 🔍 Trial 11: n_bootstrap=17, sample_frac=0.81
2025-08-04 20:24:28 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:24:40 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.9165)
[I 2025-08-04 20:24:40,893] Trial 11 pruned. 
2025-08-04 20:24:40 [INFO] 🔍 Trial 12: n_bootstrap=18, sample_frac=0.83
2025-08-04 20:24:40 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:24:53 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.9173)
[I 2025-08-04 20:24:53,567] Trial 12 pruned. 
2025-08-04 20:24:53 [INFO] 🔍 Trial 13: n_bootstrap=15, sample_frac=0.74
2025-08-04 20:24:53 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:25:19 [INFO] ⏸️ Pruned trial 13 at step 1 (R²=0.9171)
[I 2025-08-04 20:25:19,243] Trial 13 pruned. 
2025-08-04 20:25:19 [INFO] 🔍 Trial 14: n_bootstrap=16, sample_frac=0.60
2025-08-04 20:25:19 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:25:39 [INFO] ⏸️ Pruned trial 14 at step 1 (R²=0.9171)
[I 2025-08-04 20:25:39,838] Trial 14 pruned. 
2025-08-04 20:25:39 [INFO] 🔍 Trial 15: n_bootstrap=14, sample_frac=0.88
2025-08-04 20:25:39 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:26:35 [INFO] ⏸️ Pruned trial 15 at step 4 (R²=0.9234)
[I 2025-08-04 20:26:35,448] Trial 15 pruned. 
2025-08-04 20:26:35 [INFO] 🔍 Trial 16: n_bootstrap=18, sample_frac=0.78
2025-08-04 20:26:35 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:26:47 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.9169)
[I 2025-08-04 20:26:47,443] Trial 16 pruned. 
2025-08-04 20:26:47 [INFO] 🔍 Trial 17: n_bootstrap=20, sample_frac=0.84
2025-08-04 20:26:47 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:27:39 [INFO] ⏸️ Pruned trial 17 at step 4 (R²=0.9230)
[I 2025-08-04 20:27:39,784] Trial 17 pruned. 
2025-08-04 20:27:39 [INFO] 🔍 Trial 18: n_bootstrap=16, sample_frac=0.78
2025-08-04 20:27:39 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:27:51 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.9174)
[I 2025-08-04 20:27:51,713] Trial 18 pruned. 
2025-08-04 20:27:51 [INFO] 🔍 Trial 19: n_bootstrap=13, sample_frac=0.72
2025-08-04 20:27:51 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:29:56 [INFO] ⏸️ Pruned trial 19 at step 5 (R²=0.9251)
[I 2025-08-04 20:29:56,046] Trial 19 pruned. 
2025-08-04 20:29:56 [INFO] 🔍 Trial 20: n_bootstrap=18, sample_frac=0.86
2025-08-04 20:29:56 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:30:49 [INFO] ⏸️ Pruned trial 20 at step 4 (R²=0.9229)
[I 2025-08-04 20:30:49,456] Trial 20 pruned. 
2025-08-04 20:30:49 [INFO] 🔍 Trial 21: n_bootstrap=16, sample_frac=0.81
2025-08-04 20:30:49 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:31:01 [INFO] ⏸️ Pruned trial 21 at step 1 (R²=0.9167)
[I 2025-08-04 20:31:01,911] Trial 21 pruned. 
2025-08-04 20:31:01 [INFO] 🔍 Trial 22: n_bootstrap=15, sample_frac=0.83
2025-08-04 20:31:01 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:31:14 [INFO] ⏸️ Pruned trial 22 at step 1 (R²=0.9175)
[I 2025-08-04 20:31:14,759] Trial 22 pruned. 
2025-08-04 20:31:14 [INFO] 🔍 Trial 23: n_bootstrap=17, sample_frac=0.79
2025-08-04 20:31:14 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:31:26 [INFO] ⏸️ Pruned trial 23 at step 1 (R²=0.9168)
[I 2025-08-04 20:31:26,832] Trial 23 pruned. 
2025-08-04 20:31:26 [INFO] 🔍 Trial 24: n_bootstrap=17, sample_frac=0.90
2025-08-04 20:31:26 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:32:23 [INFO] ⏸️ Pruned trial 24 at step 4 (R²=0.9235)
[I 2025-08-04 20:32:23,396] Trial 24 pruned. 
2025-08-04 20:32:23 [INFO] 🔍 Trial 25: n_bootstrap=14, sample_frac=0.86
2025-08-04 20:32:23 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:32:36 [INFO] ⏸️ Pruned trial 25 at step 1 (R²=0.9170)
[I 2025-08-04 20:32:36,771] Trial 25 pruned. 
2025-08-04 20:32:36 [INFO] 🔍 Trial 26: n_bootstrap=15, sample_frac=0.81
2025-08-04 20:32:36 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:32:49 [INFO] ⏸️ Pruned trial 26 at step 1 (R²=0.9166)
[I 2025-08-04 20:32:49,101] Trial 26 pruned. 
2025-08-04 20:32:49 [INFO] 🔍 Trial 27: n_bootstrap=19, sample_frac=0.72
2025-08-04 20:32:49 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:34:53 [INFO] ⏸️ Pruned trial 27 at step 5 (R²=0.9250)
[I 2025-08-04 20:34:53,159] Trial 27 pruned. 
2025-08-04 20:34:53 [INFO] 🔍 Trial 28: n_bootstrap=13, sample_frac=0.76
2025-08-04 20:34:53 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:35:19 [INFO] ⏸️ Pruned trial 28 at step 1 (R²=0.9170)
[I 2025-08-04 20:35:19,362] Trial 28 pruned. 
2025-08-04 20:35:19 [INFO] 🔍 Trial 29: n_bootstrap=12, sample_frac=0.72
2025-08-04 20:35:19 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:35:43 [INFO] ⏸️ Pruned trial 29 at step 1 (R²=0.9175)
[I 2025-08-04 20:35:43,930] Trial 29 pruned. 
2025-08-04 20:35:43 [INFO] 🏆 Best Params: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}, R²=0.92629
2025-08-04 20:35:43 [INFO] Bootstrap training → dataset=exam_dataset, device=cuda
2025-08-04 20:35:43 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-04 20:35:43 [INFO] [1/18] bootstrap sample size=9665
2025-08-04 20:35:56 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_1.pkl
2025-08-04 20:35:56 [INFO] [2/18] bootstrap sample size=9665
2025-08-04 20:36:08 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_2.pkl
2025-08-04 20:36:08 [INFO] [3/18] bootstrap sample size=9665
2025-08-04 20:36:20 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_3.pkl
2025-08-04 20:36:20 [INFO] [4/18] bootstrap sample size=9665
2025-08-04 20:36:32 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_4.pkl
2025-08-04 20:36:33 [INFO] [5/18] bootstrap sample size=9665
2025-08-04 20:36:45 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_5.pkl
2025-08-04 20:36:45 [INFO] [6/18] bootstrap sample size=9665
2025-08-04 20:36:57 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_6.pkl
2025-08-04 20:36:57 [INFO] [7/18] bootstrap sample size=9665
2025-08-04 20:37:09 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_7.pkl
2025-08-04 20:37:09 [INFO] [8/18] bootstrap sample size=9665
2025-08-04 20:37:21 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_8.pkl
2025-08-04 20:37:22 [INFO] [9/18] bootstrap sample size=9665
2025-08-04 20:37:34 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_9.pkl
2025-08-04 20:37:34 [INFO] [10/18] bootstrap sample size=9665
2025-08-04 20:37:46 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_10.pkl
2025-08-04 20:37:46 [INFO] [11/18] bootstrap sample size=9665
2025-08-04 20:37:58 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_11.pkl
2025-08-04 20:37:58 [INFO] [12/18] bootstrap sample size=9665
2025-08-04 20:38:11 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_12.pkl
2025-08-04 20:38:11 [INFO] [13/18] bootstrap sample size=9665
2025-08-04 20:38:23 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_13.pkl
2025-08-04 20:38:23 [INFO] [14/18] bootstrap sample size=9665
2025-08-04 20:38:35 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_14.pkl
2025-08-04 20:38:35 [INFO] [15/18] bootstrap sample size=9665
2025-08-04 20:38:47 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_15.pkl
2025-08-04 20:38:48 [INFO] [16/18] bootstrap sample size=9665
2025-08-04 20:39:00 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_16.pkl
2025-08-04 20:39:00 [INFO] [17/18] bootstrap sample size=9665
2025-08-04 20:39:12 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_17.pkl
2025-08-04 20:39:12 [INFO] [18/18] bootstrap sample size=9665
2025-08-04 20:39:24 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/bootstrap_18.pkl
2025-08-04 20:39:24 [INFO] 📊 Final OOB R² = 0.92629
2025-08-04 20:39:32 [INFO] Saved ensemble → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/ensemble.pkl
2025-08-04 20:39:32 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-04 20:39:32 [INFO] Total time: 228.6s
2025-08-04 20:39:32 [INFO] TabPFN →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/exam_dataset/ensemble.pkl (R²=0.9263)
2025-08-04 20:39:32 [INFO] Training tree-based model...
2025-08-04 20:39:32 [INFO] AutoML pipeline started
2025-08-04 20:39:32 [INFO] Output directory '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam' is ready and logging is configured.
2025-08-04 20:39:32 [INFO] Merged training data: 12398 rows
2025-08-04 20:39:32 [INFO] Split data into pool (11158 rows) and validation (1240 rows)
2025-08-04 20:39:32 [INFO] Feature engineering completed: 15 features
[I 2025-08-04 20:39:32,554] A new study created in memory with name: no-name-f420c47b-67ca-4aa0-bf01-48d8abe486d7
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-04 20:48:11,897] Trial 0 finished with value: -0.9164100287424646 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.9164100287424646.
[I 2025-08-04 20:48:23,399] Trial 1 finished with value: -0.9245196154026717 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 1 with value: -0.9245196154026717.
[I 2025-08-04 20:49:57,190] Trial 2 finished with value: -0.9274053522300518 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 2 with value: -0.9274053522300518.
[I 2025-08-04 20:50:05,120] Trial 3 finished with value: -0.9346163301487718 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 3 with value: -0.9346163301487718.
[I 2025-08-04 20:50:24,930] Trial 4 finished with value: -0.9314149100758451 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 3 with value: -0.9346163301487718.
[I 2025-08-04 20:50:34,657] Trial 5 finished with value: -0.9365145554317158 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 20:53:19,233] Trial 6 finished with value: -0.9208795579715405 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 20:53:27,690] Trial 7 finished with value: -0.9338207628826083 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:03:08,789] Trial 8 finished with value: -0.9069448262169507 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:03:17,664] Trial 9 finished with value: -0.9234276502104131 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:03:22,957] Trial 10 finished with value: -0.9258796217630637 and parameters: {'learning_rate': 0.25802800909330637, 'depth': 7, 'l2_leaf_reg': 4.3528391851812, 'border_count': 36}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:03:31,773] Trial 11 finished with value: -0.9346633034095774 and parameters: {'learning_rate': 0.1634682281229447, 'depth': 6, 'l2_leaf_reg': 3.2989911288867892, 'border_count': 95}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:03:42,011] Trial 12 finished with value: -0.935889340413145 and parameters: {'learning_rate': 0.1306466769020582, 'depth': 6, 'l2_leaf_reg': 3.579111995814171, 'border_count': 111}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:03:56,999] Trial 13 finished with value: -0.9359820141363432 and parameters: {'learning_rate': 0.11037742138434228, 'depth': 7, 'l2_leaf_reg': 4.082643943639809, 'border_count': 177}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:04:39,264] Trial 14 finished with value: -0.9315470450876612 and parameters: {'learning_rate': 0.09843718089120507, 'depth': 9, 'l2_leaf_reg': 5.845581037329155, 'border_count': 182}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:05:06,090] Trial 15 finished with value: -0.9351471980652359 and parameters: {'learning_rate': 0.060751287795671585, 'depth': 8, 'l2_leaf_reg': 4.749014046494259, 'border_count': 184}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:05:13,063] Trial 16 finished with value: -0.9321124804311587 and parameters: {'learning_rate': 0.27336146200089706, 'depth': 7, 'l2_leaf_reg': 2.2380336194640185, 'border_count': 143}. Best is trial 5 with value: -0.9365145554317158.
[I 2025-08-04 21:05:26,643] Trial 17 finished with value: -0.9374771027139299 and parameters: {'learning_rate': 0.0915438724927121, 'depth': 6, 'l2_leaf_reg': 3.832739990621571, 'border_count': 200}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:05:40,704] Trial 18 finished with value: -0.9355734703289957 and parameters: {'learning_rate': 0.047014244451715134, 'depth': 6, 'l2_leaf_reg': 5.63515072985838, 'border_count': 205}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:05:51,871] Trial 19 finished with value: -0.9359257860531285 and parameters: {'learning_rate': 0.16125116153170904, 'depth': 5, 'l2_leaf_reg': 8.6162576900609, 'border_count': 255}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:06:00,072] Trial 20 finished with value: -0.9353142594111364 and parameters: {'learning_rate': 0.07836573102205684, 'depth': 4, 'l2_leaf_reg': 1.9907971308601173, 'border_count': 122}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:06:14,113] Trial 21 finished with value: -0.9364482555656701 and parameters: {'learning_rate': 0.109967101149632, 'depth': 7, 'l2_leaf_reg': 4.054082405180091, 'border_count': 166}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:06:37,288] Trial 22 finished with value: -0.9332923626313315 and parameters: {'learning_rate': 0.09328779505866444, 'depth': 8, 'l2_leaf_reg': 3.542037553987999, 'border_count': 152}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:06:51,047] Trial 23 finished with value: -0.9358429232404554 and parameters: {'learning_rate': 0.06144679710343858, 'depth': 6, 'l2_leaf_reg': 4.885872381242277, 'border_count': 196}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:07:00,358] Trial 24 finished with value: -0.9358109896654732 and parameters: {'learning_rate': 0.21369384509507866, 'depth': 5, 'l2_leaf_reg': 3.9518678932161593, 'border_count': 230}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:07:14,622] Trial 25 finished with value: -0.9357095629812122 and parameters: {'learning_rate': 0.12677934973470115, 'depth': 7, 'l2_leaf_reg': 3.0261976859857613, 'border_count': 163}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:07:51,994] Trial 26 finished with value: -0.9308869262277625 and parameters: {'learning_rate': 0.03802826804245624, 'depth': 9, 'l2_leaf_reg': 6.037458362364329, 'border_count': 127}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:08:02,501] Trial 27 finished with value: -0.9372137312433283 and parameters: {'learning_rate': 0.12916904034041643, 'depth': 6, 'l2_leaf_reg': 5.118620137003777, 'border_count': 164}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:08:11,305] Trial 28 finished with value: -0.9358715808888223 and parameters: {'learning_rate': 0.19558986295656192, 'depth': 5, 'l2_leaf_reg': 5.198122627535891, 'border_count': 194}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:08:20,505] Trial 29 finished with value: -0.9364993115127944 and parameters: {'learning_rate': 0.1362255002105408, 'depth': 6, 'l2_leaf_reg': 6.875962023752984, 'border_count': 83}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:08:28,619] Trial 30 finished with value: -0.9285458901541928 and parameters: {'learning_rate': 0.08883073853701694, 'depth': 4, 'l2_leaf_reg': 8.014853820805108, 'border_count': 47}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:08:39,198] Trial 31 finished with value: -0.9363759909005838 and parameters: {'learning_rate': 0.13187299017899828, 'depth': 6, 'l2_leaf_reg': 6.894362458310247, 'border_count': 77}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:08:50,754] Trial 32 finished with value: -0.9367975349818589 and parameters: {'learning_rate': 0.06453158160268196, 'depth': 6, 'l2_leaf_reg': 6.3527257006836635, 'border_count': 95}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:09:00,725] Trial 33 finished with value: -0.9353450069993958 and parameters: {'learning_rate': 0.06621419026185009, 'depth': 5, 'l2_leaf_reg': 5.4746386793722674, 'border_count': 110}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:09:10,201] Trial 34 finished with value: -0.9294396996312164 and parameters: {'learning_rate': 0.048966646584564295, 'depth': 5, 'l2_leaf_reg': 6.095917066962305, 'border_count': 57}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:09:24,561] Trial 35 finished with value: -0.9329564383496152 and parameters: {'learning_rate': 0.03376615172791702, 'depth': 6, 'l2_leaf_reg': 4.554413040788706, 'border_count': 221}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:10:11,119] Trial 36 finished with value: -0.9297694368374476 and parameters: {'learning_rate': 0.08253868439719643, 'depth': 9, 'l2_leaf_reg': 1.1562256315519184, 'border_count': 239}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:10:21,037] Trial 37 finished with value: -0.9254705387441232 and parameters: {'learning_rate': 0.018987111356915002, 'depth': 5, 'l2_leaf_reg': 2.458616765262823, 'border_count': 96}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:10:37,049] Trial 38 finished with value: -0.935860691513209 and parameters: {'learning_rate': 0.06966252906631139, 'depth': 7, 'l2_leaf_reg': 5.250599681157814, 'border_count': 139}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:10:46,178] Trial 39 finished with value: -0.9316680478599363 and parameters: {'learning_rate': 0.05635289077502356, 'depth': 4, 'l2_leaf_reg': 7.72378839469825, 'border_count': 160}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:10:58,231] Trial 40 finished with value: -0.9339873026150188 and parameters: {'learning_rate': 0.040944463869511595, 'depth': 6, 'l2_leaf_reg': 6.499373893735429, 'border_count': 111}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:11:08,490] Trial 41 finished with value: -0.9361544325721063 and parameters: {'learning_rate': 0.1440567328992123, 'depth': 6, 'l2_leaf_reg': 7.45639208925827, 'border_count': 83}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:11:17,914] Trial 42 finished with value: -0.9371839523820839 and parameters: {'learning_rate': 0.09800023743214056, 'depth': 5, 'l2_leaf_reg': 6.417211444137877, 'border_count': 88}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:11:25,827] Trial 43 finished with value: -0.9358144541134503 and parameters: {'learning_rate': 0.10934611412776463, 'depth': 4, 'l2_leaf_reg': 6.315189966474568, 'border_count': 63}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:11:35,555] Trial 44 finished with value: -0.9355448957323608 and parameters: {'learning_rate': 0.07253843117392765, 'depth': 5, 'l2_leaf_reg': 3.1686430514089157, 'border_count': 102}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:11:44,702] Trial 45 finished with value: -0.9369659265889598 and parameters: {'learning_rate': 0.09667921669157944, 'depth': 5, 'l2_leaf_reg': 1.7459259593369594, 'border_count': 118}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:14:39,623] Trial 46 finished with value: -0.903206236228056 and parameters: {'learning_rate': 0.18967695742290386, 'depth': 12, 'l2_leaf_reg': 1.5190183876867593, 'border_count': 137}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:14:49,649] Trial 47 finished with value: -0.9370191003322359 and parameters: {'learning_rate': 0.10166221210016765, 'depth': 5, 'l2_leaf_reg': 1.9818858547123277, 'border_count': 122}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:15:00,274] Trial 48 finished with value: -0.9365649079764854 and parameters: {'learning_rate': 0.1012074321165179, 'depth': 5, 'l2_leaf_reg': 1.7849682280588377, 'border_count': 154}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:15:09,155] Trial 49 finished with value: -0.9361781405743634 and parameters: {'learning_rate': 0.11566778049698365, 'depth': 4, 'l2_leaf_reg': 2.7370659161779054, 'border_count': 120}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:15:17,759] Trial 50 finished with value: -0.9353272872544652 and parameters: {'learning_rate': 0.16158664119378693, 'depth': 5, 'l2_leaf_reg': 1.5452246354038786, 'border_count': 171}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:15:29,147] Trial 51 finished with value: -0.9368646184194931 and parameters: {'learning_rate': 0.09215863045276913, 'depth': 7, 'l2_leaf_reg': 2.1113095328685745, 'border_count': 90}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:15:41,122] Trial 52 finished with value: -0.935340996256756 and parameters: {'learning_rate': 0.08946506862168087, 'depth': 7, 'l2_leaf_reg': 2.2803809336388876, 'border_count': 85}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:15:50,936] Trial 53 finished with value: -0.9325949411664846 and parameters: {'learning_rate': 0.11852017421861728, 'depth': 7, 'l2_leaf_reg': 1.896465591407923, 'border_count': 104}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:15:57,978] Trial 54 finished with value: -0.935141247631839 and parameters: {'learning_rate': 0.2307913559266204, 'depth': 5, 'l2_leaf_reg': 1.0931359507218659, 'border_count': 129}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:16:08,499] Trial 55 finished with value: -0.9358504400623211 and parameters: {'learning_rate': 0.10134480078791538, 'depth': 6, 'l2_leaf_reg': 2.8867780032131156, 'border_count': 69}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:16:20,593] Trial 56 finished with value: -0.9322066645882717 and parameters: {'learning_rate': 0.14827206352539699, 'depth': 8, 'l2_leaf_reg': 1.4271902819118065, 'border_count': 92}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:18:15,705] Trial 57 finished with value: -0.919568985398654 and parameters: {'learning_rate': 0.07972397043946676, 'depth': 11, 'l2_leaf_reg': 2.247703716179584, 'border_count': 136}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:18:25,460] Trial 58 finished with value: -0.9354165186477525 and parameters: {'learning_rate': 0.1797187278796497, 'depth': 6, 'l2_leaf_reg': 3.7801007345119193, 'border_count': 120}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:18:42,927] Trial 59 finished with value: -0.9361491732579662 and parameters: {'learning_rate': 0.0847555321247918, 'depth': 7, 'l2_leaf_reg': 4.507191484098444, 'border_count': 197}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:19:06,839] Trial 60 finished with value: -0.9215955026445389 and parameters: {'learning_rate': 0.010827949621077951, 'depth': 8, 'l2_leaf_reg': 3.360327047085481, 'border_count': 151}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:19:18,379] Trial 61 finished with value: -0.9360711265539019 and parameters: {'learning_rate': 0.06215039240870436, 'depth': 6, 'l2_leaf_reg': 6.6224905933016505, 'border_count': 91}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:19:28,430] Trial 62 finished with value: -0.9344996717391695 and parameters: {'learning_rate': 0.0520796668444507, 'depth': 5, 'l2_leaf_reg': 5.863009580222566, 'border_count': 104}. Best is trial 17 with value: -0.9374771027139299.
[I 2025-08-04 21:19:39,400] Trial 63 finished with value: -0.9377070114056277 and parameters: {'learning_rate': 0.1009413537444838, 'depth': 6, 'l2_leaf_reg': 2.5030631045192715, 'border_count': 114}. Best is trial 63 with value: -0.9377070114056277.
[I 2025-08-04 21:19:51,795] Trial 64 finished with value: -0.9372427854642336 and parameters: {'learning_rate': 0.09587108983228439, 'depth': 7, 'l2_leaf_reg': 2.581920952450144, 'border_count': 117}. Best is trial 63 with value: -0.9377070114056277.
[I 2025-08-04 21:20:01,093] Trial 65 finished with value: -0.9361167108017601 and parameters: {'learning_rate': 0.10246272908455539, 'depth': 5, 'l2_leaf_reg': 2.730260568640568, 'border_count': 116}. Best is trial 63 with value: -0.9377070114056277.
[I 2025-08-04 21:20:11,812] Trial 66 finished with value: -0.9366209737219583 and parameters: {'learning_rate': 0.12254167347931458, 'depth': 6, 'l2_leaf_reg': 2.4686400725246402, 'border_count': 127}. Best is trial 63 with value: -0.9377070114056277.
[I 2025-08-04 21:20:20,256] Trial 67 finished with value: -0.9341801283652922 and parameters: {'learning_rate': 0.14972588342566656, 'depth': 4, 'l2_leaf_reg': 4.296056753916439, 'border_count': 146}. Best is trial 63 with value: -0.9377070114056277.
[I 2025-08-04 21:20:33,290] Trial 68 finished with value: -0.937947336864943 and parameters: {'learning_rate': 0.07611298109631905, 'depth': 6, 'l2_leaf_reg': 1.710189306040677, 'border_count': 185}. Best is trial 68 with value: -0.937947336864943.
[I 2025-08-04 21:20:52,442] Trial 69 finished with value: -0.9369921405870816 and parameters: {'learning_rate': 0.07141172643615191, 'depth': 7, 'l2_leaf_reg': 3.100650462660868, 'border_count': 211}. Best is trial 68 with value: -0.937947336864943.
[I 2025-08-04 21:21:06,215] Trial 70 finished with value: -0.9364003211100312 and parameters: {'learning_rate': 0.07770049740387357, 'depth': 6, 'l2_leaf_reg': 9.987768393033573, 'border_count': 189}. Best is trial 68 with value: -0.937947336864943.
[I 2025-08-04 21:21:24,097] Trial 71 finished with value: -0.9359335993516369 and parameters: {'learning_rate': 0.07217787316460034, 'depth': 7, 'l2_leaf_reg': 3.224736016026589, 'border_count': 210}. Best is trial 68 with value: -0.937947336864943.
[I 2025-08-04 21:21:39,741] Trial 72 finished with value: -0.9372231671546553 and parameters: {'learning_rate': 0.10673593954272746, 'depth': 7, 'l2_leaf_reg': 2.4951046072807306, 'border_count': 203}. Best is trial 68 with value: -0.937947336864943.
[I 2025-08-04 21:22:00,765] Trial 73 finished with value: -0.9340580423007268 and parameters: {'learning_rate': 0.1101179102721322, 'depth': 8, 'l2_leaf_reg': 2.5184877937347703, 'border_count': 175}. Best is trial 68 with value: -0.937947336864943.
[I 2025-08-04 21:22:12,677] Trial 74 finished with value: -0.9379526600008538 and parameters: {'learning_rate': 0.13267505990345801, 'depth': 6, 'l2_leaf_reg': 3.587085733385045, 'border_count': 182}. Best is trial 74 with value: -0.9379526600008538.
[I 2025-08-04 21:22:26,385] Trial 75 finished with value: -0.9383275872858118 and parameters: {'learning_rate': 0.13405024307488314, 'depth': 6, 'l2_leaf_reg': 3.501243568790243, 'border_count': 182}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:22:38,909] Trial 76 finished with value: -0.9360421863906925 and parameters: {'learning_rate': 0.12763298627571826, 'depth': 6, 'l2_leaf_reg': 3.4834754880237098, 'border_count': 201}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:22:52,679] Trial 77 finished with value: -0.9358169030733048 and parameters: {'learning_rate': 0.13890448585230983, 'depth': 7, 'l2_leaf_reg': 3.82931145593156, 'border_count': 184}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:23:04,943] Trial 78 finished with value: -0.9377535443715438 and parameters: {'learning_rate': 0.12081425545004018, 'depth': 6, 'l2_leaf_reg': 2.9596209894448946, 'border_count': 180}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:23:19,185] Trial 79 finished with value: -0.9340231013398086 and parameters: {'learning_rate': 0.17159313870721787, 'depth': 7, 'l2_leaf_reg': 2.90842402854053, 'border_count': 221}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:23:31,156] Trial 80 finished with value: -0.9356355259640299 and parameters: {'learning_rate': 0.08720868836352504, 'depth': 6, 'l2_leaf_reg': 4.0334316951307105, 'border_count': 190}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:23:42,734] Trial 81 finished with value: -0.9369651474393063 and parameters: {'learning_rate': 0.12194192565973552, 'depth': 6, 'l2_leaf_reg': 4.248840981065879, 'border_count': 181}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:23:52,351] Trial 82 finished with value: -0.9362470842228771 and parameters: {'learning_rate': 0.15488588099455589, 'depth': 6, 'l2_leaf_reg': 3.6619764793801166, 'border_count': 172}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:24:03,142] Trial 83 finished with value: -0.9356884679800673 and parameters: {'learning_rate': 0.13433857363364446, 'depth': 6, 'l2_leaf_reg': 3.4008261042226238, 'border_count': 167}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:24:16,339] Trial 84 finished with value: -0.9299877201379312 and parameters: {'learning_rate': 0.20360996213698632, 'depth': 8, 'l2_leaf_reg': 2.6862952488841056, 'border_count': 159}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:24:29,448] Trial 85 finished with value: -0.9360731778781188 and parameters: {'learning_rate': 0.11065043860702711, 'depth': 6, 'l2_leaf_reg': 5.0533684168208755, 'border_count': 205}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:24:46,244] Trial 86 finished with value: -0.9363144765015367 and parameters: {'learning_rate': 0.10998568386714708, 'depth': 7, 'l2_leaf_reg': 3.03659569714679, 'border_count': 190}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:24:58,152] Trial 87 finished with value: -0.9369585335371251 and parameters: {'learning_rate': 0.13898762891217878, 'depth': 6, 'l2_leaf_reg': 4.658798592393078, 'border_count': 179}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:25:17,025] Trial 88 finished with value: -0.9368364533520632 and parameters: {'learning_rate': 0.05791571796222382, 'depth': 7, 'l2_leaf_reg': 2.2216602690381437, 'border_count': 205}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:25:30,625] Trial 89 finished with value: -0.928558633364795 and parameters: {'learning_rate': 0.020437946530117313, 'depth': 6, 'l2_leaf_reg': 3.644724700500868, 'border_count': 187}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:25:46,527] Trial 90 finished with value: -0.9370870416940598 and parameters: {'learning_rate': 0.09365936437954728, 'depth': 7, 'l2_leaf_reg': 1.3977351618352645, 'border_count': 196}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:26:00,179] Trial 91 finished with value: -0.9358554247306096 and parameters: {'learning_rate': 0.08369344886381452, 'depth': 6, 'l2_leaf_reg': 5.575269820537514, 'border_count': 217}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:26:10,477] Trial 92 finished with value: -0.9367021231361005 and parameters: {'learning_rate': 0.12079909033643824, 'depth': 5, 'l2_leaf_reg': 2.911613508919771, 'border_count': 168}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:26:21,968] Trial 93 finished with value: -0.9366010754503016 and parameters: {'learning_rate': 0.10330731457968138, 'depth': 6, 'l2_leaf_reg': 2.4421393683404866, 'border_count': 174}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:26:33,611] Trial 94 finished with value: -0.9366685960999337 and parameters: {'learning_rate': 0.1290448792777616, 'depth': 6, 'l2_leaf_reg': 2.0548105890681008, 'border_count': 158}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:26:44,089] Trial 95 finished with value: -0.936792918615129 and parameters: {'learning_rate': 0.09127252391992034, 'depth': 5, 'l2_leaf_reg': 1.7825083215974706, 'border_count': 200}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:27:28,539] Trial 96 finished with value: -0.9308361409307431 and parameters: {'learning_rate': 0.09690622995692617, 'depth': 9, 'l2_leaf_reg': 3.2088254064283506, 'border_count': 230}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:27:39,682] Trial 97 finished with value: -0.9358877567235016 and parameters: {'learning_rate': 0.16895406688977924, 'depth': 6, 'l2_leaf_reg': 7.210187932303568, 'border_count': 181}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:27:57,329] Trial 98 finished with value: -0.9372688732326184 and parameters: {'learning_rate': 0.1139816422058178, 'depth': 7, 'l2_leaf_reg': 2.6253440750915544, 'border_count': 194}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:28:19,271] Trial 99 finished with value: -0.9345997515970643 and parameters: {'learning_rate': 0.11625262725295282, 'depth': 8, 'l2_leaf_reg': 2.5946348020362184, 'border_count': 193}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:28:31,502] Trial 100 finished with value: -0.9343289778206941 and parameters: {'learning_rate': 0.1526389011073617, 'depth': 7, 'l2_leaf_reg': 1.6331487098147286, 'border_count': 201}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:28:42,992] Trial 101 finished with value: -0.936749136068943 and parameters: {'learning_rate': 0.10523515373751614, 'depth': 6, 'l2_leaf_reg': 2.3815474949093107, 'border_count': 185}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:28:58,943] Trial 102 finished with value: -0.9370139319923568 and parameters: {'learning_rate': 0.11737177935493202, 'depth': 7, 'l2_leaf_reg': 3.9246213702603194, 'border_count': 176}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:29:10,180] Trial 103 finished with value: -0.9363690925796238 and parameters: {'learning_rate': 0.08301163839957308, 'depth': 5, 'l2_leaf_reg': 2.7519923083260434, 'border_count': 205}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:29:23,050] Trial 104 finished with value: -0.9347764478579036 and parameters: {'learning_rate': 0.1297370489451993, 'depth': 7, 'l2_leaf_reg': 3.440119213242295, 'border_count': 164}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:29:36,798] Trial 105 finished with value: -0.9368555187790836 and parameters: {'learning_rate': 0.06681877025486102, 'depth': 6, 'l2_leaf_reg': 4.21441552528716, 'border_count': 194}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:29:54,471] Trial 106 finished with value: -0.9360819097054633 and parameters: {'learning_rate': 0.07748129221100516, 'depth': 7, 'l2_leaf_reg': 8.870307244503364, 'border_count': 179}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:30:14,682] Trial 107 finished with value: -0.9340352161926472 and parameters: {'learning_rate': 0.1403719393396903, 'depth': 8, 'l2_leaf_reg': 2.994209864383732, 'border_count': 170}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:30:25,578] Trial 108 finished with value: -0.9334786301511706 and parameters: {'learning_rate': 0.0976851031822602, 'depth': 7, 'l2_leaf_reg': 1.2729334215384438, 'border_count': 75}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:30:37,054] Trial 109 finished with value: -0.9365883820275108 and parameters: {'learning_rate': 0.10750072785516634, 'depth': 6, 'l2_leaf_reg': 2.1383636108590256, 'border_count': 210}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:30:46,568] Trial 110 finished with value: -0.9311776296260437 and parameters: {'learning_rate': 0.09122424541732199, 'depth': 6, 'l2_leaf_reg': 5.364026124128767, 'border_count': 46}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:31:02,676] Trial 111 finished with value: -0.9374213030961231 and parameters: {'learning_rate': 0.09575438161689416, 'depth': 7, 'l2_leaf_reg': 1.4346442732684226, 'border_count': 197}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:31:18,181] Trial 112 finished with value: -0.9343836780717952 and parameters: {'learning_rate': 0.11151374155540773, 'depth': 7, 'l2_leaf_reg': 1.865498004788924, 'border_count': 216}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:31:32,002] Trial 113 finished with value: -0.9348404699202089 and parameters: {'learning_rate': 0.09648049773536826, 'depth': 7, 'l2_leaf_reg': 3.23301458423151, 'border_count': 133}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:31:55,538] Trial 114 finished with value: -0.9346901318768841 and parameters: {'learning_rate': 0.08743327917580895, 'depth': 8, 'l2_leaf_reg': 1.642782515714472, 'border_count': 186}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:32:09,352] Trial 115 finished with value: -0.9379246229776127 and parameters: {'learning_rate': 0.07590397517761129, 'depth': 6, 'l2_leaf_reg': 2.5582844167722945, 'border_count': 200}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:32:22,793] Trial 116 finished with value: -0.9382320621131657 and parameters: {'learning_rate': 0.07577012675359944, 'depth': 6, 'l2_leaf_reg': 2.6309502212297122, 'border_count': 191}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:32:35,286] Trial 117 finished with value: -0.9365235743255045 and parameters: {'learning_rate': 0.06748717834599374, 'depth': 6, 'l2_leaf_reg': 2.601918832581602, 'border_count': 193}. Best is trial 75 with value: -0.9383275872858118.
[I 2025-08-04 21:32:49,160] Trial 118 finished with value: -0.9389520305606593 and parameters: {'learning_rate': 0.07471778566689616, 'depth': 6, 'l2_leaf_reg': 1.0323598914456964, 'border_count': 199}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:33:01,618] Trial 119 finished with value: -0.9369758691522962 and parameters: {'learning_rate': 0.07451937480928078, 'depth': 6, 'l2_leaf_reg': 1.2699986903470744, 'border_count': 197}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:33:15,327] Trial 120 finished with value: -0.9368370695472968 and parameters: {'learning_rate': 0.06183348209131044, 'depth': 6, 'l2_leaf_reg': 1.009453153132857, 'border_count': 208}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:33:28,540] Trial 121 finished with value: -0.937525181066335 and parameters: {'learning_rate': 0.07917656328250365, 'depth': 6, 'l2_leaf_reg': 2.374420363074213, 'border_count': 214}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:33:41,963] Trial 122 finished with value: -0.9372689238701442 and parameters: {'learning_rate': 0.07451403939354209, 'depth': 6, 'l2_leaf_reg': 1.953678971376421, 'border_count': 225}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:33:56,561] Trial 123 finished with value: -0.9363271662031035 and parameters: {'learning_rate': 0.05092666921257513, 'depth': 6, 'l2_leaf_reg': 2.0471742902854793, 'border_count': 226}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:34:11,369] Trial 124 finished with value: -0.9354803562504423 and parameters: {'learning_rate': 0.04476144166341401, 'depth': 6, 'l2_leaf_reg': 2.2653414173885666, 'border_count': 237}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:34:25,571] Trial 125 finished with value: -0.9370216224129033 and parameters: {'learning_rate': 0.05770791040927377, 'depth': 6, 'l2_leaf_reg': 1.418181855103893, 'border_count': 216}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:34:39,192] Trial 126 finished with value: -0.9366027416035326 and parameters: {'learning_rate': 0.08046299546385632, 'depth': 6, 'l2_leaf_reg': 1.8700814101069607, 'border_count': 198}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:34:53,068] Trial 127 finished with value: -0.9367293240112684 and parameters: {'learning_rate': 0.07006001407866544, 'depth': 6, 'l2_leaf_reg': 2.30732859547739, 'border_count': 223}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:35:07,646] Trial 128 finished with value: -0.9382910760152369 and parameters: {'learning_rate': 0.07280634437004838, 'depth': 6, 'l2_leaf_reg': 2.8683579932719816, 'border_count': 238}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:35:19,203] Trial 129 finished with value: -0.9361135661912042 and parameters: {'learning_rate': 0.07675666189340062, 'depth': 5, 'l2_leaf_reg': 1.221709672262423, 'border_count': 234}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:35:33,250] Trial 130 finished with value: -0.9374212892443087 and parameters: {'learning_rate': 0.07204591584114797, 'depth': 6, 'l2_leaf_reg': 2.8441207286733503, 'border_count': 214}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:35:48,039] Trial 131 finished with value: -0.9366519875536852 and parameters: {'learning_rate': 0.06531480108542544, 'depth': 6, 'l2_leaf_reg': 3.0722641227584377, 'border_count': 253}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:36:02,609] Trial 132 finished with value: -0.9380487217507962 and parameters: {'learning_rate': 0.07403157149539247, 'depth': 6, 'l2_leaf_reg': 2.7751685800962904, 'border_count': 247}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:36:17,334] Trial 133 finished with value: -0.9376322723098584 and parameters: {'learning_rate': 0.08191987738094077, 'depth': 6, 'l2_leaf_reg': 2.880900178674254, 'border_count': 240}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:36:32,114] Trial 134 finished with value: -0.9384120090015153 and parameters: {'learning_rate': 0.08353188754412064, 'depth': 6, 'l2_leaf_reg': 3.3222878098155646, 'border_count': 246}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:36:46,124] Trial 135 finished with value: -0.9376119116840013 and parameters: {'learning_rate': 0.08287500822110554, 'depth': 6, 'l2_leaf_reg': 3.6466491369484473, 'border_count': 243}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:37:01,030] Trial 136 finished with value: -0.9372794680173179 and parameters: {'learning_rate': 0.08143642497081158, 'depth': 6, 'l2_leaf_reg': 3.557295866655739, 'border_count': 246}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:37:12,627] Trial 137 finished with value: -0.9355204730660882 and parameters: {'learning_rate': 0.06119426117156498, 'depth': 5, 'l2_leaf_reg': 3.308611226911633, 'border_count': 244}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:37:27,371] Trial 138 finished with value: -0.9369562442468645 and parameters: {'learning_rate': 0.053860365512279414, 'depth': 6, 'l2_leaf_reg': 2.8360406903842543, 'border_count': 243}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:37:42,017] Trial 139 finished with value: -0.9373143864011914 and parameters: {'learning_rate': 0.08604940305896239, 'depth': 6, 'l2_leaf_reg': 3.6772203559730667, 'border_count': 239}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:37:56,937] Trial 140 finished with value: -0.936540764332818 and parameters: {'learning_rate': 0.06951070564999894, 'depth': 6, 'l2_leaf_reg': 3.1140682116720155, 'border_count': 250}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:38:11,304] Trial 141 finished with value: -0.9371720520831985 and parameters: {'learning_rate': 0.07695763877239999, 'depth': 6, 'l2_leaf_reg': 3.813170838247813, 'border_count': 230}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:38:26,133] Trial 142 finished with value: -0.936521490629031 and parameters: {'learning_rate': 0.08443377651623618, 'depth': 6, 'l2_leaf_reg': 3.3222971569561337, 'border_count': 254}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:38:40,815] Trial 143 finished with value: -0.937586671857906 and parameters: {'learning_rate': 0.06422555293174272, 'depth': 6, 'l2_leaf_reg': 2.97876331810118, 'border_count': 244}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:38:55,658] Trial 144 finished with value: -0.9365321167496351 and parameters: {'learning_rate': 0.06451894741991905, 'depth': 6, 'l2_leaf_reg': 3.015736430170588, 'border_count': 242}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:40:33,102] Trial 145 finished with value: -0.9277724908097105 and parameters: {'learning_rate': 0.07335082691555045, 'depth': 10, 'l2_leaf_reg': 2.7609464850045544, 'border_count': 249}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:40:47,872] Trial 146 finished with value: -0.936605627722732 and parameters: {'learning_rate': 0.05841185415560823, 'depth': 6, 'l2_leaf_reg': 2.512250484303494, 'border_count': 236}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:40:59,509] Trial 147 finished with value: -0.936877969346925 and parameters: {'learning_rate': 0.07958698293835531, 'depth': 5, 'l2_leaf_reg': 3.4824869364123705, 'border_count': 247}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:41:13,929] Trial 148 finished with value: -0.9359593253259074 and parameters: {'learning_rate': 0.06744038320565815, 'depth': 6, 'l2_leaf_reg': 2.878368730029561, 'border_count': 230}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:41:27,325] Trial 149 finished with value: -0.9371328507240773 and parameters: {'learning_rate': 0.08815165752334868, 'depth': 6, 'l2_leaf_reg': 2.337953303596827, 'border_count': 234}. Best is trial 118 with value: -0.9389520305606593.
[I 2025-08-04 21:41:28,720] A new study created in memory with name: no-name-98dc4695-e6bb-4a09-a899-a0c854f49c91
[I 2025-08-04 21:41:36,861] Trial 0 finished with value: -0.9277739549794971 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.9277739549794971.
[I 2025-08-04 21:41:39,299] Trial 1 finished with value: -0.9175795815320305 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.9277739549794971.
[I 2025-08-04 21:41:46,691] Trial 2 finished with value: -0.9285494192225825 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:41:50,630] Trial 3 finished with value: -0.9265832791162982 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:42:01,595] Trial 4 finished with value: -0.9166947187441241 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:42:03,878] Trial 5 finished with value: -0.8965007616771669 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:42:11,786] Trial 6 finished with value: -0.9256627116179155 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:42:14,175] Trial 7 finished with value: -0.9013750280532744 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:42:17,006] Trial 8 finished with value: -0.9162777317234351 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:42:27,295] Trial 9 finished with value: -0.9145025923059924 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 2 with value: -0.9285494192225825.
[I 2025-08-04 21:42:29,877] Trial 10 finished with value: -0.9322341394414309 and parameters: {'learning_rate': 0.13388899274129873, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.7846562513261506, 'bagging_fraction': 0.721539898400351, 'reg_alpha': 4.344469108550396, 'reg_lambda': 0.010039786460205695}. Best is trial 10 with value: -0.9322341394414309.
[I 2025-08-04 21:42:32,296] Trial 11 finished with value: -0.9326232293316193 and parameters: {'learning_rate': 0.17061837680423544, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.7930679183446125, 'bagging_fraction': 0.7171781358782056, 'reg_alpha': 4.188416507348498, 'reg_lambda': 0.008427137829973095}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:42:34,093] Trial 12 finished with value: -0.9286742451411243 and parameters: {'learning_rate': 0.18413559883361694, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.7447014489005493, 'bagging_fraction': 0.7372735823178598, 'reg_alpha': 8.964592852736423, 'reg_lambda': 0.014790975660203105}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:42:36,178] Trial 13 finished with value: -0.9302958854268804 and parameters: {'learning_rate': 0.19416552625841807, 'num_leaves': 16, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.8255079015857972, 'bagging_fraction': 0.7184628468385728, 'reg_alpha': 9.86874546485378, 'reg_lambda': 0.018313125916897974}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:42:41,015] Trial 14 finished with value: -0.9277523244858455 and parameters: {'learning_rate': 0.10632746242224578, 'num_leaves': 68, 'max_depth': 10, 'min_child_samples': 24, 'feature_fraction': 0.7226065972922637, 'bagging_fraction': 0.8152199006501988, 'reg_alpha': 0.48655210851246783, 'reg_lambda': 0.009410050130685054}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:42:45,572] Trial 15 finished with value: -0.9275163933749921 and parameters: {'learning_rate': 0.10468345169209065, 'num_leaves': 80, 'max_depth': 9, 'min_child_samples': 25, 'feature_fraction': 0.8705765955899738, 'bagging_fraction': 0.6924745509172271, 'reg_alpha': 0.8613950980416505, 'reg_lambda': 0.14184312049385903}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:42:48,999] Trial 16 finished with value: -0.9291017588821108 and parameters: {'learning_rate': 0.10696355595474458, 'num_leaves': 100, 'max_depth': 6, 'min_child_samples': 24, 'feature_fraction': 0.9972051753265123, 'bagging_fraction': 0.8100308334813918, 'reg_alpha': 0.0003127872267463454, 'reg_lambda': 0.0011311754430479313}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:42:53,699] Trial 17 finished with value: -0.9310291439731555 and parameters: {'learning_rate': 0.0775638293899637, 'num_leaves': 32, 'max_depth': 10, 'min_child_samples': 38, 'feature_fraction': 0.7864602527183489, 'bagging_fraction': 0.6707750474677461, 'reg_alpha': 0.04278686026057723, 'reg_lambda': 0.059625168763162296}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:42:57,710] Trial 18 finished with value: -0.9266226465991885 and parameters: {'learning_rate': 0.14584365323126963, 'num_leaves': 38, 'max_depth': 8, 'min_child_samples': 19, 'feature_fraction': 0.6811852168264261, 'bagging_fraction': 0.8814486898577985, 'reg_alpha': 1.471635936015753, 'reg_lambda': 8.844421481756813}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:01,060] Trial 19 finished with value: -0.9288331817767126 and parameters: {'learning_rate': 0.13940127601485913, 'num_leaves': 101, 'max_depth': 6, 'min_child_samples': 47, 'feature_fraction': 0.8556796651546272, 'bagging_fraction': 0.7507285077111834, 'reg_alpha': 9.320234976399455e-05, 'reg_lambda': 0.001399205508112251}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:03,904] Trial 20 finished with value: -0.9300538069367257 and parameters: {'learning_rate': 0.06944011694508737, 'num_leaves': 8, 'max_depth': 10, 'min_child_samples': 17, 'feature_fraction': 0.9292066062055611, 'bagging_fraction': 0.7758600196137365, 'reg_alpha': 0.005648917487926644, 'reg_lambda': 0.0049393924646631455}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:08,678] Trial 21 finished with value: -0.9290929846912788 and parameters: {'learning_rate': 0.08380477803932176, 'num_leaves': 34, 'max_depth': 11, 'min_child_samples': 34, 'feature_fraction': 0.7666948077315919, 'bagging_fraction': 0.663476297802019, 'reg_alpha': 0.06488076794060954, 'reg_lambda': 0.0990642034530435}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:11,865] Trial 22 finished with value: -0.9285683693062236 and parameters: {'learning_rate': 0.1353614774481775, 'num_leaves': 32, 'max_depth': 8, 'min_child_samples': 31, 'feature_fraction': 0.7640114903106479, 'bagging_fraction': 0.6719619733911685, 'reg_alpha': 2.369086467322926, 'reg_lambda': 0.08608658423775213}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:16,738] Trial 23 finished with value: -0.9291725881030442 and parameters: {'learning_rate': 0.08611953811044991, 'num_leaves': 40, 'max_depth': 9, 'min_child_samples': 45, 'feature_fraction': 0.8293948872008855, 'bagging_fraction': 0.6282221555974891, 'reg_alpha': 0.046038928759881435, 'reg_lambda': 0.5066647232247354}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:21,132] Trial 24 finished with value: -0.9266181308857331 and parameters: {'learning_rate': 0.1502089207538033, 'num_leaves': 88, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.7165450002607957, 'bagging_fraction': 0.6857451940424342, 'reg_alpha': 0.14877709671190803, 'reg_lambda': 0.00015237282916574538}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:25,523] Trial 25 finished with value: -0.9311804948959402 and parameters: {'learning_rate': 0.07889506653661935, 'num_leaves': 23, 'max_depth': 7, 'min_child_samples': 65, 'feature_fraction': 0.7872531104702358, 'bagging_fraction': 0.7705362811579022, 'reg_alpha': 2.2568909856733703, 'reg_lambda': 0.026718635088575797}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:29,778] Trial 26 finished with value: -0.9295876166858108 and parameters: {'learning_rate': 0.11870002064662485, 'num_leaves': 55, 'max_depth': 7, 'min_child_samples': 66, 'feature_fraction': 0.8460236691844591, 'bagging_fraction': 0.8726160779551502, 'reg_alpha': 3.1702108544588574, 'reg_lambda': 1.8203071015057385e-05}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:32,256] Trial 27 finished with value: -0.9297887867177594 and parameters: {'learning_rate': 0.17923841769606658, 'num_leaves': 20, 'max_depth': 5, 'min_child_samples': 59, 'feature_fraction': 0.7390135402481219, 'bagging_fraction': 0.7253718634982701, 'reg_alpha': 0.8530709993085848, 'reg_lambda': 0.0030641454227052687}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:37,131] Trial 28 finished with value: -0.92837410317762 and parameters: {'learning_rate': 0.05449420304014894, 'num_leaves': 115, 'max_depth': 7, 'min_child_samples': 71, 'feature_fraction': 0.8968771588167361, 'bagging_fraction': 0.7787588257864038, 'reg_alpha': 8.427473817598928, 'reg_lambda': 0.027656598087602693}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:40,986] Trial 29 finished with value: -0.9291050169968542 and parameters: {'learning_rate': 0.04336916626266124, 'num_leaves': 68, 'max_depth': 5, 'min_child_samples': 50, 'feature_fraction': 0.5898374005315236, 'bagging_fraction': 0.864012693783303, 'reg_alpha': 3.043938196474693e-07, 'reg_lambda': 0.5585966658289305}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:45,787] Trial 30 finished with value: -0.9310780609802796 and parameters: {'learning_rate': 0.09011100227963116, 'num_leaves': 159, 'max_depth': 7, 'min_child_samples': 66, 'feature_fraction': 0.6720316394318787, 'bagging_fraction': 0.7643080707754748, 'reg_alpha': 2.4249713988677598e-08, 'reg_lambda': 2.0293261529724993}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:50,413] Trial 31 finished with value: -0.9315912829003873 and parameters: {'learning_rate': 0.09584985731696036, 'num_leaves': 183, 'max_depth': 7, 'min_child_samples': 63, 'feature_fraction': 0.6620115466051189, 'bagging_fraction': 0.775523345103255, 'reg_alpha': 3.023531518734761e-08, 'reg_lambda': 4.255402825005155}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:43:55,909] Trial 32 finished with value: -0.9300612923157903 and parameters: {'learning_rate': 0.06967890649270342, 'num_leaves': 174, 'max_depth': 9, 'min_child_samples': 72, 'feature_fraction': 0.5917037946427761, 'bagging_fraction': 0.706558656720526, 'reg_alpha': 2.864197319471123, 'reg_lambda': 8.55614824543317}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:00,304] Trial 33 finished with value: -0.9294364841004477 and parameters: {'learning_rate': 0.12131069962597554, 'num_leaves': 252, 'max_depth': 8, 'min_child_samples': 57, 'feature_fraction': 0.6305221789473104, 'bagging_fraction': 0.7919210436332718, 'reg_alpha': 8.518237757762891e-07, 'reg_lambda': 0.1997565063916904}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:04,160] Trial 34 finished with value: -0.9297723441697681 and parameters: {'learning_rate': 0.09684409668416581, 'num_leaves': 228, 'max_depth': 6, 'min_child_samples': 60, 'feature_fraction': 0.8107371168752, 'bagging_fraction': 0.84385147666225, 'reg_alpha': 1.2613593911945544e-07, 'reg_lambda': 1.551165792966824}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:06,894] Trial 35 finished with value: -0.927447101014913 and parameters: {'learning_rate': 0.16308733916834112, 'num_leaves': 184, 'max_depth': 5, 'min_child_samples': 53, 'feature_fraction': 0.7841748023685646, 'bagging_fraction': 0.5932474184974728, 'reg_alpha': 0.01681067790194756, 'reg_lambda': 0.0017580216317886637}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:12,001] Trial 36 finished with value: -0.928155766073506 and parameters: {'learning_rate': 0.0359334721003579, 'num_leaves': 25, 'max_depth': 8, 'min_child_samples': 63, 'feature_fraction': 0.70820419615924, 'bagging_fraction': 0.8998618587941228, 'reg_alpha': 0.2752111098977866, 'reg_lambda': 0.0002495346832039776}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:14,665] Trial 37 finished with value: -0.9256848305268907 and parameters: {'learning_rate': 0.06142750073851609, 'num_leaves': 202, 'max_depth': 4, 'min_child_samples': 92, 'feature_fraction': 0.548411554685583, 'bagging_fraction': 0.7454291696298938, 'reg_alpha': 0.00013154044909501937, 'reg_lambda': 4.723513603961402e-06}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:18,090] Trial 38 finished with value: -0.9284603491511044 and parameters: {'learning_rate': 0.12386732708514225, 'num_leaves': 161, 'max_depth': 7, 'min_child_samples': 29, 'feature_fraction': 0.6499419807275955, 'bagging_fraction': 0.5013339806386407, 'reg_alpha': 0.0010438560409938528, 'reg_lambda': 0.027327997116568494}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:21,427] Trial 39 finished with value: -0.9217841929611434 and parameters: {'learning_rate': 0.02695393258989714, 'num_leaves': 48, 'max_depth': 4, 'min_child_samples': 44, 'feature_fraction': 0.804657285729722, 'bagging_fraction': 0.6248778971701563, 'reg_alpha': 6.006928541035471e-08, 'reg_lambda': 0.3353284394882826}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:24,506] Trial 40 finished with value: -0.9271364352286492 and parameters: {'learning_rate': 0.16195769109257846, 'num_leaves': 131, 'max_depth': 6, 'min_child_samples': 89, 'feature_fraction': 0.7581011923903223, 'bagging_fraction': 0.8052775710596803, 'reg_alpha': 7.703681668328621e-06, 'reg_lambda': 6.11200763140353e-05}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:28,962] Trial 41 finished with value: -0.9298345148955187 and parameters: {'learning_rate': 0.09043086039230255, 'num_leaves': 153, 'max_depth': 7, 'min_child_samples': 67, 'feature_fraction': 0.6800505032647716, 'bagging_fraction': 0.7615499005724335, 'reg_alpha': 2.5322617904473502e-08, 'reg_lambda': 2.204422202371421}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:33,403] Trial 42 finished with value: -0.9301901321175375 and parameters: {'learning_rate': 0.07481487680958111, 'num_leaves': 169, 'max_depth': 8, 'min_child_samples': 71, 'feature_fraction': 0.5025524239120907, 'bagging_fraction': 0.769827539127413, 'reg_alpha': 1.5412897352327233e-08, 'reg_lambda': 2.039440014951944}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:38,029] Trial 43 finished with value: -0.929734490790206 and parameters: {'learning_rate': 0.05976494364925911, 'num_leaves': 192, 'max_depth': 7, 'min_child_samples': 77, 'feature_fraction': 0.6236026370162361, 'bagging_fraction': 0.8380417085915601, 'reg_alpha': 1.018356193294236e-06, 'reg_lambda': 0.0004920961506900474}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:42,737] Trial 44 finished with value: -0.9225309558897508 and parameters: {'learning_rate': 0.01869296065815932, 'num_leaves': 117, 'max_depth': 6, 'min_child_samples': 63, 'feature_fraction': 0.6732800815168527, 'bagging_fraction': 0.7121831930698759, 'reg_alpha': 6.108700964841709e-08, 'reg_lambda': 4.072908126446562}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:45,270] Trial 45 finished with value: -0.9279296560759862 and parameters: {'learning_rate': 0.19874869046307966, 'num_leaves': 218, 'max_depth': 5, 'min_child_samples': 100, 'feature_fraction': 0.7389270595325426, 'bagging_fraction': 0.7378700370812161, 'reg_alpha': 1.7579173903488288e-07, 'reg_lambda': 0.006664776629837565}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:49,666] Trial 46 finished with value: -0.9289923377569693 and parameters: {'learning_rate': 0.09722023735017092, 'num_leaves': 153, 'max_depth': 8, 'min_child_samples': 52, 'feature_fraction': 0.655117919646726, 'bagging_fraction': 0.8006000998455877, 'reg_alpha': 1.3317516216079845e-08, 'reg_lambda': 0.8869289158190443}. Best is trial 11 with value: -0.9326232293316193.
[I 2025-08-04 21:44:52,671] Trial 47 finished with value: -0.9335925141942159 and parameters: {'learning_rate': 0.11708818014643872, 'num_leaves': 18, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.7041778120298744, 'bagging_fraction': 0.697448806582189, 'reg_alpha': 4.5021313189421654, 'reg_lambda': 0.04151145750160436}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:44:55,704] Trial 48 finished with value: -0.9313838933545995 and parameters: {'learning_rate': 0.11501438069926845, 'num_leaves': 17, 'max_depth': 9, 'min_child_samples': 11, 'feature_fraction': 0.7769510662250949, 'bagging_fraction': 0.6478091901498046, 'reg_alpha': 4.1261212774530245, 'reg_lambda': 0.02334433922232406}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:44:58,185] Trial 49 finished with value: -0.929938746548461 and parameters: {'learning_rate': 0.11449175317707151, 'num_leaves': 9, 'max_depth': 11, 'min_child_samples': 12, 'feature_fraction': 0.7054884773723784, 'bagging_fraction': 0.5817147621039089, 'reg_alpha': 0.40305082755305394, 'reg_lambda': 0.04699883783335638}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:01,153] Trial 50 finished with value: -0.9247343075778858 and parameters: {'learning_rate': 0.16593061151089497, 'num_leaves': 47, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.7331553426925765, 'bagging_fraction': 0.6433355077265688, 'reg_alpha': 6.619664039426575, 'reg_lambda': 0.010134523859985117}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:04,241] Trial 51 finished with value: -0.9289341443357673 and parameters: {'learning_rate': 0.12676333263331888, 'num_leaves': 22, 'max_depth': 6, 'min_child_samples': 20, 'feature_fraction': 0.7787413097535243, 'bagging_fraction': 0.6958730724010137, 'reg_alpha': 0.8795527270886163, 'reg_lambda': 0.003581125508325938}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:07,241] Trial 52 finished with value: -0.9301744732164654 and parameters: {'learning_rate': 0.14132489604917817, 'num_leaves': 19, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.8278571114963875, 'bagging_fraction': 0.6457943909283859, 'reg_alpha': 4.148589418882324, 'reg_lambda': 0.19400116461088868}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:10,925] Trial 53 finished with value: -0.9298007692191266 and parameters: {'learning_rate': 0.10174275487905038, 'num_leaves': 27, 'max_depth': 8, 'min_child_samples': 21, 'feature_fraction': 0.8024115892230136, 'bagging_fraction': 0.6097600746474022, 'reg_alpha': 1.6686927402472385, 'reg_lambda': 0.0008548828657257396}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:15,114] Trial 54 finished with value: -0.927563159083215 and parameters: {'learning_rate': 0.10928544414455421, 'num_leaves': 63, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.752777859351113, 'bagging_fraction': 0.724545386598475, 'reg_alpha': 0.12089038279414326, 'reg_lambda': 0.028514372070809403}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:17,681] Trial 55 finished with value: -0.9303728289290554 and parameters: {'learning_rate': 0.13039705721604652, 'num_leaves': 8, 'max_depth': 10, 'min_child_samples': 24, 'feature_fraction': 0.8526632933364486, 'bagging_fraction': 0.5571047430979031, 'reg_alpha': 1.0695261221491232, 'reg_lambda': 0.00934268444005161}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:22,245] Trial 56 finished with value: -0.9307026967971102 and parameters: {'learning_rate': 0.07712107322149576, 'num_leaves': 43, 'max_depth': 7, 'min_child_samples': 17, 'feature_fraction': 0.7740750700807855, 'bagging_fraction': 0.6566789726233456, 'reg_alpha': 4.733719453543678, 'reg_lambda': 0.06031182454364148}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:24,972] Trial 57 finished with value: -0.9299391017296662 and parameters: {'learning_rate': 0.15148696241234183, 'num_leaves': 17, 'max_depth': 9, 'min_child_samples': 27, 'feature_fraction': 0.6922543371720171, 'bagging_fraction': 0.680167433781008, 'reg_alpha': 0.2284227776043902, 'reg_lambda': 0.0022501356628224513}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:27,409] Trial 58 finished with value: -0.9264282418480867 and parameters: {'learning_rate': 0.17688658722862965, 'num_leaves': 78, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.8245284814105734, 'bagging_fraction': 0.7030754467704599, 'reg_alpha': 0.5025082329817327, 'reg_lambda': 3.4799247778076824e-08}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:32,164] Trial 59 finished with value: -0.9291558961796648 and parameters: {'learning_rate': 0.08473820356621595, 'num_leaves': 33, 'max_depth': 11, 'min_child_samples': 21, 'feature_fraction': 0.7278812565968453, 'bagging_fraction': 0.7293556786856445, 'reg_alpha': 2.786141402383698e-05, 'reg_lambda': 0.016015772825401974}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:38,054] Trial 60 finished with value: -0.931498043419342 and parameters: {'learning_rate': 0.10954777175921075, 'num_leaves': 27, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8666924690855702, 'bagging_fraction': 0.7866076683480797, 'reg_alpha': 1.9989547980791798, 'reg_lambda': 0.1274190596290912}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:41,419] Trial 61 finished with value: -0.9331963955741038 and parameters: {'learning_rate': 0.11501830401101515, 'num_leaves': 15, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.9306115265134505, 'bagging_fraction': 0.7531157392316215, 'reg_alpha': 3.2726129476863783, 'reg_lambda': 0.3244667238616087}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:44,906] Trial 62 finished with value: -0.9323608363766633 and parameters: {'learning_rate': 0.11321054664864469, 'num_leaves': 14, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.9423576082411145, 'bagging_fraction': 0.7456204300648367, 'reg_alpha': 5.326610136306561, 'reg_lambda': 0.3110556696726189}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:48,143] Trial 63 finished with value: -0.9289089116979483 and parameters: {'learning_rate': 0.14735458598012896, 'num_leaves': 29, 'max_depth': 8, 'min_child_samples': 16, 'feature_fraction': 0.9369918841495862, 'bagging_fraction': 0.7883815046899839, 'reg_alpha': 1.5382264908247507, 'reg_lambda': 0.12838682890061076}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:50,748] Trial 64 finished with value: -0.9318192794206597 and parameters: {'learning_rate': 0.13406367129079688, 'num_leaves': 8, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.9576949297138274, 'bagging_fraction': 0.8201199906929513, 'reg_alpha': 8.551879965296692, 'reg_lambda': 0.27770706226548947}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:53,188] Trial 65 finished with value: -0.9290069747492489 and parameters: {'learning_rate': 0.13102871917948875, 'num_leaves': 8, 'max_depth': 8, 'min_child_samples': 17, 'feature_fraction': 0.9735727280617753, 'bagging_fraction': 0.8303320379264449, 'reg_alpha': 6.957311563645314, 'reg_lambda': 0.9017103176109458}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:55,671] Trial 66 finished with value: -0.9285482518913959 and parameters: {'learning_rate': 0.17850671929281645, 'num_leaves': 15, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.9472131453556978, 'bagging_fraction': 0.7519221936960301, 'reg_alpha': 9.986220707212702, 'reg_lambda': 0.3702316105097294}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:45:58,679] Trial 67 finished with value: -0.9271154172535978 and parameters: {'learning_rate': 0.16166834198409227, 'num_leaves': 37, 'max_depth': 7, 'min_child_samples': 22, 'feature_fraction': 0.9963800395481486, 'bagging_fraction': 0.7516215654704528, 'reg_alpha': 0.588293357740989, 'reg_lambda': 4.88860562763201}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:01,565] Trial 68 finished with value: -0.9296379615186169 and parameters: {'learning_rate': 0.13724253089677954, 'num_leaves': 53, 'max_depth': 5, 'min_child_samples': 18, 'feature_fraction': 0.9064741621162569, 'bagging_fraction': 0.8202785749670009, 'reg_alpha': 3.0889326411958473, 'reg_lambda': 0.2815108677006235}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:05,945] Trial 69 finished with value: -0.9288470293983903 and parameters: {'learning_rate': 0.09378399382098716, 'num_leaves': 39, 'max_depth': 7, 'min_child_samples': 33, 'feature_fraction': 0.9593014077876234, 'bagging_fraction': 0.7168191416697859, 'reg_alpha': 0.002283776460079378, 'reg_lambda': 0.8638379840735255}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:09,230] Trial 70 finished with value: -0.9307067634133407 and parameters: {'learning_rate': 0.10320117824627881, 'num_leaves': 13, 'max_depth': 8, 'min_child_samples': 15, 'feature_fraction': 0.8882041218474472, 'bagging_fraction': 0.8570450463343546, 'reg_alpha': 0.01839395847074128, 'reg_lambda': 0.0817481579037151}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:12,850] Trial 71 finished with value: -0.9315908604913435 and parameters: {'learning_rate': 0.11900704850635443, 'num_leaves': 27, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.865954123414865, 'bagging_fraction': 0.7837110916125064, 'reg_alpha': 1.7998587980903928, 'reg_lambda': 0.155475637656986}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:15,556] Trial 72 finished with value: -0.9296384686544542 and parameters: {'learning_rate': 0.12106204123681276, 'num_leaves': 21, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.9171195112392827, 'bagging_fraction': 0.7337989926810097, 'reg_alpha': 1.316807253344019, 'reg_lambda': 0.5417430411425413}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:18,613] Trial 73 finished with value: -0.9287064149928584 and parameters: {'learning_rate': 0.147135221201674, 'num_leaves': 30, 'max_depth': 7, 'min_child_samples': 14, 'feature_fraction': 0.919271533852599, 'bagging_fraction': 0.6900136966425756, 'reg_alpha': 5.051335549353959, 'reg_lambda': 0.23357412695883878}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:21,506] Trial 74 finished with value: -0.9301518971935587 and parameters: {'learning_rate': 0.13102315325460792, 'num_leaves': 13, 'max_depth': 8, 'min_child_samples': 19, 'feature_fraction': 0.9791822943558435, 'bagging_fraction': 0.8185250170980464, 'reg_alpha': 9.856872174529078, 'reg_lambda': 0.05096029445146006}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:25,987] Trial 75 finished with value: -0.929430100882889 and parameters: {'learning_rate': 0.11487270285904769, 'num_leaves': 46, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.9477960490452074, 'bagging_fraction': 0.9155429188929195, 'reg_alpha': 0.7555694091086441, 'reg_lambda': 3.9481259368281405}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:28,504] Trial 76 finished with value: -0.9282492587019979 and parameters: {'learning_rate': 0.19097077905870374, 'num_leaves': 237, 'max_depth': 6, 'min_child_samples': 23, 'feature_fraction': 0.8666824412151088, 'bagging_fraction': 0.7582722532206645, 'reg_alpha': 0.20807183626281894, 'reg_lambda': 1.4581748003965969}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:31,278] Trial 77 finished with value: -0.928110681025311 and parameters: {'learning_rate': 0.1549250681644655, 'num_leaves': 23, 'max_depth': 8, 'min_child_samples': 16, 'feature_fraction': 0.936170668144496, 'bagging_fraction': 0.7801261917730086, 'reg_alpha': 2.290260378444363, 'reg_lambda': 0.05166543830804311}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:33,966] Trial 78 finished with value: -0.9287115617454326 and parameters: {'learning_rate': 0.1748989842029231, 'num_leaves': 33, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8806476516969757, 'bagging_fraction': 0.9887698355368885, 'reg_alpha': 3.5271629390813204, 'reg_lambda': 0.005567718328042488}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:37,782] Trial 79 finished with value: -0.9313872850737106 and parameters: {'learning_rate': 0.0684970051119825, 'num_leaves': 15, 'max_depth': 7, 'min_child_samples': 19, 'feature_fraction': 0.8978788895185832, 'bagging_fraction': 0.8008872788481445, 'reg_alpha': 0.06422055362710619, 'reg_lambda': 0.15016309686132384}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:42,711] Trial 80 finished with value: -0.9279642216624058 and parameters: {'learning_rate': 0.09907870174196502, 'num_leaves': 62, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.9881056930724993, 'bagging_fraction': 0.6717702585395179, 'reg_alpha': 0.3551477527259214, 'reg_lambda': 9.882675599092101}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:46,632] Trial 81 finished with value: -0.9322253981795073 and parameters: {'learning_rate': 0.11106030463863235, 'num_leaves': 27, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8471168478198772, 'bagging_fraction': 0.7892470581335724, 'reg_alpha': 2.1967762947951477, 'reg_lambda': 0.11392485018380068}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:50,747] Trial 82 finished with value: -0.9272490076510032 and parameters: {'learning_rate': 0.13752426708402213, 'num_leaves': 139, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8429331068429633, 'bagging_fraction': 0.7374862511054959, 'reg_alpha': 5.909845753304321, 'reg_lambda': 0.380367363920059}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:53,181] Trial 83 finished with value: -0.9286829400536372 and parameters: {'learning_rate': 0.12239646861526292, 'num_leaves': 8, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.9058899234329245, 'bagging_fraction': 0.7720248842390873, 'reg_alpha': 1.462473240565974, 'reg_lambda': 0.09237077235391432}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:56,457] Trial 84 finished with value: -0.9320197442626439 and parameters: {'learning_rate': 0.10729630909246536, 'num_leaves': 39, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.9598485660908723, 'bagging_fraction': 0.7074871957905918, 'reg_alpha': 2.9201533495352887, 'reg_lambda': 0.03947136230763612}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:46:59,940] Trial 85 finished with value: -0.9283908542442652 and parameters: {'learning_rate': 0.10836125521482733, 'num_leaves': 36, 'max_depth': 5, 'min_child_samples': 27, 'feature_fraction': 0.9591240133460468, 'bagging_fraction': 0.7044687907635966, 'reg_alpha': 2.4925057492130515e-06, 'reg_lambda': 0.013184412476561082}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:03,668] Trial 86 finished with value: -0.9314985803037761 and parameters: {'learning_rate': 0.08635899158858057, 'num_leaves': 23, 'max_depth': 6, 'min_child_samples': 18, 'feature_fraction': 0.9506140409796088, 'bagging_fraction': 0.741999783859552, 'reg_alpha': 3.0198884545850606, 'reg_lambda': 1.2626528393345318e-06}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:07,289] Trial 87 finished with value: -0.9310542500456267 and parameters: {'learning_rate': 0.09494539040561079, 'num_leaves': 15, 'max_depth': 6, 'min_child_samples': 15, 'feature_fraction': 0.9293431522939762, 'bagging_fraction': 0.7189030486518848, 'reg_alpha': 0.8638092124267505, 'reg_lambda': 0.029207322861191667}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:12,293] Trial 88 finished with value: -0.9309254904585689 and parameters: {'learning_rate': 0.0367063577048648, 'num_leaves': 19, 'max_depth': 8, 'min_child_samples': 13, 'feature_fraction': 0.965253737135232, 'bagging_fraction': 0.7615210569983083, 'reg_alpha': 5.57986892026944, 'reg_lambda': 0.9450843099785537}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:15,966] Trial 89 finished with value: -0.9299032948014497 and parameters: {'learning_rate': 0.10500579185760546, 'num_leaves': 123, 'max_depth': 5, 'min_child_samples': 26, 'feature_fraction': 0.8147407729558737, 'bagging_fraction': 0.6813238866779256, 'reg_alpha': 0.0009198931625390137, 'reg_lambda': 0.04702329589109057}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:20,813] Trial 90 finished with value: -0.9288456023109317 and parameters: {'learning_rate': 0.05070739507230711, 'num_leaves': 50, 'max_depth': 7, 'min_child_samples': 61, 'feature_fraction': 0.702541427325036, 'bagging_fraction': 0.7020590423401668, 'reg_alpha': 2.794340569329785, 'reg_lambda': 0.007434449342441043}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:24,741] Trial 91 finished with value: -0.9287041233277373 and parameters: {'learning_rate': 0.11554856722848271, 'num_leaves': 42, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.6581187430045187, 'bagging_fraction': 0.7927197762450651, 'reg_alpha': 1.707230419945309, 'reg_lambda': 0.21818981294883752}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:27,637] Trial 92 finished with value: -0.9291772965858204 and parameters: {'learning_rate': 0.1288161650726821, 'num_leaves': 26, 'max_depth': 6, 'min_child_samples': 41, 'feature_fraction': 0.6339648458577817, 'bagging_fraction': 0.8133551752559858, 'reg_alpha': 0.6023828168397007, 'reg_lambda': 0.07811456464915988}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:32,148] Trial 93 finished with value: -0.9297675285449187 and parameters: {'learning_rate': 0.09040029233809642, 'num_leaves': 30, 'max_depth': 8, 'min_child_samples': 68, 'feature_fraction': 0.8421605296337805, 'bagging_fraction': 0.7769776763714452, 'reg_alpha': 7.054762043390045, 'reg_lambda': 0.03604369203160173}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:34,717] Trial 94 finished with value: -0.9310893644626688 and parameters: {'learning_rate': 0.14355862588559856, 'num_leaves': 11, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.7977669148814016, 'bagging_fraction': 0.7264465465115658, 'reg_alpha': 1.1940386611686, 'reg_lambda': 0.01416828652036975}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:37,052] Trial 95 finished with value: -0.929307773151303 and parameters: {'learning_rate': 0.1606007986552731, 'num_leaves': 21, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.7936946216749714, 'bagging_fraction': 0.7631972645621767, 'reg_alpha': 4.472980116309301, 'reg_lambda': 0.4744158377818043}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:40,622] Trial 96 finished with value: -0.9305963745480588 and parameters: {'learning_rate': 0.11149477577714231, 'num_leaves': 38, 'max_depth': 6, 'min_child_samples': 16, 'feature_fraction': 0.8807168360479105, 'bagging_fraction': 0.7463105804593879, 'reg_alpha': 2.7154286850362164, 'reg_lambda': 0.003967601682423393}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:45,444] Trial 97 finished with value: -0.9243223835514748 and parameters: {'learning_rate': 0.016269458536358902, 'num_leaves': 14, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.7172091731220495, 'bagging_fraction': 0.8295630921745443, 'reg_alpha': 3.221272679858322e-05, 'reg_lambda': 0.11539889117145455}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:48,687] Trial 98 finished with value: -0.9313372052453055 and parameters: {'learning_rate': 0.12360574536698543, 'num_leaves': 26, 'max_depth': 7, 'min_child_samples': 20, 'feature_fraction': 0.7472705299680854, 'bagging_fraction': 0.8501878537607567, 'reg_alpha': 8.824432672805846, 'reg_lambda': 0.021692696076154035}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:54,712] Trial 99 finished with value: -0.9258619367181893 and parameters: {'learning_rate': 0.08141260415072209, 'num_leaves': 204, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.9828347771300242, 'bagging_fraction': 0.7953181306202777, 'reg_alpha': 0.1412324418445226, 'reg_lambda': 0.16898009564421293}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:47:58,595] Trial 100 finished with value: -0.9297331003495246 and parameters: {'learning_rate': 0.10173976967818292, 'num_leaves': 57, 'max_depth': 6, 'min_child_samples': 17, 'feature_fraction': 0.760918622608756, 'bagging_fraction': 0.7164839997710968, 'reg_alpha': 2.115378060977715, 'reg_lambda': 2.5789512757556157}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:02,786] Trial 101 finished with value: -0.9293009226530984 and parameters: {'learning_rate': 0.08681774653714261, 'num_leaves': 100, 'max_depth': 6, 'min_child_samples': 18, 'feature_fraction': 0.953642638954028, 'bagging_fraction': 0.744075880736297, 'reg_alpha': 3.6434957534420036, 'reg_lambda': 1.1380958327791145e-06}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:05,425] Trial 102 finished with value: -0.9282832885286668 and parameters: {'learning_rate': 0.1335459270465905, 'num_leaves': 23, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.9432740559905325, 'bagging_fraction': 0.6611123132913544, 'reg_alpha': 0.9577531828837389, 'reg_lambda': 0.29092911250580433}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:09,186] Trial 103 finished with value: -0.9301468374072925 and parameters: {'learning_rate': 0.11686578874743389, 'num_leaves': 18, 'max_depth': 7, 'min_child_samples': 56, 'feature_fraction': 0.9672714720796443, 'bagging_fraction': 0.7553912024670405, 'reg_alpha': 6.135777942532418, 'reg_lambda': 5.319511199657163e-06}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:14,779] Trial 104 finished with value: -0.9226676476362776 and parameters: {'learning_rate': 0.011118203949804705, 'num_leaves': 32, 'max_depth': 5, 'min_child_samples': 10, 'feature_fraction': 0.9291049277642037, 'bagging_fraction': 0.739189535859, 'reg_alpha': 2.1918956872168787, 'reg_lambda': 9.749311265805631e-05}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:18,012] Trial 105 finished with value: -0.9303199282334681 and parameters: {'learning_rate': 0.07303975999370235, 'num_leaves': 11, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.9198324475449908, 'bagging_fraction': 0.7087900219179437, 'reg_alpha': 0.45007949030313354, 'reg_lambda': 3.3427210669033186e-05}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:21,855] Trial 106 finished with value: -0.93070256656798 and parameters: {'learning_rate': 0.09616483187193142, 'num_leaves': 26, 'max_depth': 7, 'min_child_samples': 18, 'feature_fraction': 0.6081141264785268, 'bagging_fraction': 0.7839924984661079, 'reg_alpha': 3.9228656869300926, 'reg_lambda': 0.001004657121014039}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:24,691] Trial 107 finished with value: -0.9268654070138999 and parameters: {'learning_rate': 0.1699127997506999, 'num_leaves': 44, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.9057093536175562, 'bagging_fraction': 0.7689803172897844, 'reg_alpha': 1.2701074775667776, 'reg_lambda': 0.0023402323551967837}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:30,002] Trial 108 finished with value: -0.9294173326714903 and parameters: {'learning_rate': 0.08776852553254974, 'num_leaves': 182, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.6885265502244438, 'bagging_fraction': 0.6958847732869788, 'reg_alpha': 3.3282631627288595, 'reg_lambda': 0.7486890498952169}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:32,758] Trial 109 finished with value: -0.9275108957105289 and parameters: {'learning_rate': 0.15291353346959338, 'num_leaves': 19, 'max_depth': 7, 'min_child_samples': 22, 'feature_fraction': 0.9988220130490056, 'bagging_fraction': 0.7273515802822238, 'reg_alpha': 9.92802154071222, 'reg_lambda': 1.2226102316754615e-08}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:35,926] Trial 110 finished with value: -0.9313613643700714 and parameters: {'learning_rate': 0.13959763594471966, 'num_leaves': 85, 'max_depth': 6, 'min_child_samples': 11, 'feature_fraction': 0.9724094857308215, 'bagging_fraction': 0.8078050807077453, 'reg_alpha': 5.648655462436173, 'reg_lambda': 1.4434081859455554}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:39,798] Trial 111 finished with value: -0.9317038181628327 and parameters: {'learning_rate': 0.10538805496053773, 'num_leaves': 30, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8657632186546311, 'bagging_fraction': 0.7889001575694897, 'reg_alpha': 1.7394144222549495, 'reg_lambda': 0.12414414556762994}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:44,341] Trial 112 finished with value: -0.9322519649129852 and parameters: {'learning_rate': 0.10816561784885793, 'num_leaves': 33, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.858697596230926, 'bagging_fraction': 0.8239463306309434, 'reg_alpha': 1.8689527835376318, 'reg_lambda': 1.3431570469165077e-07}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:47,795] Trial 113 finished with value: -0.9313881568836647 and parameters: {'learning_rate': 0.12279798056273634, 'num_leaves': 33, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.855444209525309, 'bagging_fraction': 0.830924590857922, 'reg_alpha': 0.6406792131796256, 'reg_lambda': 0.09184771326205254}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:51,787] Trial 114 finished with value: -0.9300929622943281 and parameters: {'learning_rate': 0.110399325226685, 'num_leaves': 38, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.8345188113867756, 'bagging_fraction': 0.8002616899426641, 'reg_alpha': 1.7590817509592147, 'reg_lambda': 1.481610035758484e-07}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:54,785] Trial 115 finished with value: -0.9304040282287793 and parameters: {'learning_rate': 0.10389254585669927, 'num_leaves': 14, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8180047699834928, 'bagging_fraction': 0.7822475468391794, 'reg_alpha': 1.0153122502208431, 'reg_lambda': 0.03917516135212321}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:48:58,805] Trial 116 finished with value: -0.9293277539476031 and parameters: {'learning_rate': 0.1175084384576577, 'num_leaves': 29, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.8724838306442046, 'bagging_fraction': 0.8212792693487267, 'reg_alpha': 0.3012092897241138, 'reg_lambda': 0.06639708380359484}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:02,017] Trial 117 finished with value: -0.9298419245667793 and parameters: {'learning_rate': 0.1278721289541258, 'num_leaves': 11, 'max_depth': 7, 'min_child_samples': 86, 'feature_fraction': 0.8657616644385624, 'bagging_fraction': 0.8088974296828956, 'reg_alpha': 0.0001950590563335355, 'reg_lambda': 0.17097747992433698}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:07,002] Trial 118 finished with value: -0.9326557124264376 and parameters: {'learning_rate': 0.030555422481770966, 'num_leaves': 19, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.8866928173784201, 'bagging_fraction': 0.7713943514353409, 'reg_alpha': 0.006112701552660187, 'reg_lambda': 0.000471327098755175}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:12,048] Trial 119 finished with value: -0.9309896554479309 and parameters: {'learning_rate': 0.032772400641311525, 'num_leaves': 19, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.8928779578860766, 'bagging_fraction': 0.876630173708171, 'reg_alpha': 0.0064556911427700635, 'reg_lambda': 0.0005076424777233899}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:15,140] Trial 120 finished with value: -0.9266432347930879 and parameters: {'learning_rate': 0.0415332466159165, 'num_leaves': 9, 'max_depth': 8, 'min_child_samples': 20, 'feature_fraction': 0.8330258291392578, 'bagging_fraction': 0.8389972886567709, 'reg_alpha': 0.03378234736838146, 'reg_lambda': 0.018525545687256714}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:20,897] Trial 121 finished with value: -0.9309569477165681 and parameters: {'learning_rate': 0.022457969301225462, 'num_leaves': 23, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.8501316194041657, 'bagging_fraction': 0.7553737621000733, 'reg_alpha': 0.00045788083278891495, 'reg_lambda': 0.01057579053759264}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:28,200] Trial 122 finished with value: -0.9317363228013642 and parameters: {'learning_rate': 0.0208274972855635, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.8839630227327128, 'bagging_fraction': 0.7722599398778462, 'reg_alpha': 2.0592017534267266, 'reg_lambda': 0.4334551636887732}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:36,503] Trial 123 finished with value: -0.9297641000379142 and parameters: {'learning_rate': 0.022615057809344224, 'num_leaves': 42, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8729856198383039, 'bagging_fraction': 0.7747263099751227, 'reg_alpha': 4.414041170184156, 'reg_lambda': 6.1452824213400685}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:43,233] Trial 124 finished with value: -0.9309088885353338 and parameters: {'learning_rate': 0.029194485262953308, 'num_leaves': 36, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.8854862845476539, 'bagging_fraction': 0.73361135911499, 'reg_alpha': 2.527734121968921, 'reg_lambda': 0.46868397697733544}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:46,380] Trial 125 finished with value: -0.9168408528192942 and parameters: {'learning_rate': 0.017793321213543975, 'num_leaves': 8, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.9054375391449175, 'bagging_fraction': 0.7649905903221501, 'reg_alpha': 6.850972018625532, 'reg_lambda': 1.0854001449168618e-05}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:49:57,611] Trial 126 finished with value: -0.9281634594056397 and parameters: {'learning_rate': 0.024544034182905607, 'num_leaves': 256, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.9269479948393532, 'bagging_fraction': 0.7985475869248447, 'reg_alpha': 1.4652877036181635, 'reg_lambda': 0.3171318514074972}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:02,337] Trial 127 finished with value: -0.9296725567170714 and parameters: {'learning_rate': 0.020981618286257837, 'num_leaves': 16, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.9418789481907781, 'bagging_fraction': 0.6880659523937335, 'reg_alpha': 0.6698827559114822, 'reg_lambda': 0.0003190365073170942}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:12,613] Trial 128 finished with value: -0.9206326141146034 and parameters: {'learning_rate': 0.015021081368705402, 'num_leaves': 72, 'max_depth': 15, 'min_child_samples': 76, 'feature_fraction': 0.78815540720166, 'bagging_fraction': 0.7907831656795877, 'reg_alpha': 0.007492626855592249, 'reg_lambda': 0.61483118958676}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:18,763] Trial 129 finished with value: -0.9287808126046795 and parameters: {'learning_rate': 0.09256561044365584, 'num_leaves': 94, 'max_depth': 7, 'min_child_samples': 13, 'feature_fraction': 0.8568079936592051, 'bagging_fraction': 0.7216112598156988, 'reg_alpha': 8.926337079907002e-06, 'reg_lambda': 2.9023912583177034}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:27,610] Trial 130 finished with value: -0.9311035556048939 and parameters: {'learning_rate': 0.03222217452145805, 'num_leaves': 49, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.6637757653617176, 'bagging_fraction': 0.7464655576432583, 'reg_alpha': 6.240008247378574e-07, 'reg_lambda': 1.0746389794199647}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:31,810] Trial 131 finished with value: -0.9310340394717066 and parameters: {'learning_rate': 0.10785522619551158, 'num_leaves': 27, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8603106635325516, 'bagging_fraction': 0.773758360976164, 'reg_alpha': 5.159589945718969, 'reg_lambda': 0.2479767337010547}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:38,472] Trial 132 finished with value: -0.9323135688092451 and parameters: {'learning_rate': 0.027911431617373268, 'num_leaves': 31, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.8441179644973799, 'bagging_fraction': 0.8252920858069093, 'reg_alpha': 2.4408491051765737, 'reg_lambda': 0.12262974252334746}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:45,275] Trial 133 finished with value: -0.9323388183639487 and parameters: {'learning_rate': 0.027659486473172647, 'num_leaves': 31, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8404157529360712, 'bagging_fraction': 0.7122041893278721, 'reg_alpha': 2.7391504904234165, 'reg_lambda': 0.07129676465396506}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:52,497] Trial 134 finished with value: -0.9310086486867606 and parameters: {'learning_rate': 0.01902974744639056, 'num_leaves': 33, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8218679383647145, 'bagging_fraction': 0.8512581865794983, 'reg_alpha': 2.5181217254048303, 'reg_lambda': 0.11377276181315917}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:50:57,680] Trial 135 finished with value: -0.9305941594183444 and parameters: {'learning_rate': 0.027322323486530378, 'num_leaves': 20, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.8427832573590899, 'bagging_fraction': 0.8647437675288968, 'reg_alpha': 3.8901604295250474, 'reg_lambda': 0.02770452405789421}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:06,900] Trial 136 finished with value: -0.9301184684215787 and parameters: {'learning_rate': 0.026709936881564308, 'num_leaves': 57, 'max_depth': 9, 'min_child_samples': 17, 'feature_fraction': 0.8064217983097772, 'bagging_fraction': 0.6770114094113384, 'reg_alpha': 1.8355057905231593, 'reg_lambda': 0.06916767742440677}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:13,505] Trial 137 finished with value: -0.9324072167545486 and parameters: {'learning_rate': 0.029960597731951637, 'num_leaves': 30, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8764285704799476, 'bagging_fraction': 0.7137546074545713, 'reg_alpha': 1.1654391406736686, 'reg_lambda': 0.041179645466203486}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:21,125] Trial 138 finished with value: -0.9313496849287646 and parameters: {'learning_rate': 0.035955876006685566, 'num_leaves': 43, 'max_depth': 8, 'min_child_samples': 15, 'feature_fraction': 0.7721837834162765, 'bagging_fraction': 0.7107246786540845, 'reg_alpha': 0.8654774351047633, 'reg_lambda': 0.03416734540244106}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:25,434] Trial 139 finished with value: -0.9303919385167061 and parameters: {'learning_rate': 0.02969392864717183, 'num_leaves': 15, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8352024412751217, 'bagging_fraction': 0.729834459962339, 'reg_alpha': 7.792314399310904, 'reg_lambda': 0.005110224768949741}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:31,167] Trial 140 finished with value: -0.9296781765678551 and parameters: {'learning_rate': 0.024559486694988083, 'num_leaves': 23, 'max_depth': 9, 'min_child_samples': 19, 'feature_fraction': 0.8810694240763124, 'bagging_fraction': 0.7010406919958344, 'reg_alpha': 3.2878361307804487, 'reg_lambda': 0.05873362080076683}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:37,851] Trial 141 finished with value: -0.9330387104973186 and parameters: {'learning_rate': 0.03393229737396841, 'num_leaves': 32, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.894299640089489, 'bagging_fraction': 0.6950812300078502, 'reg_alpha': 1.117756503069952, 'reg_lambda': 0.11729398146168855}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:44,970] Trial 142 finished with value: -0.9323640698338156 and parameters: {'learning_rate': 0.03075534142320165, 'num_leaves': 35, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.8957975621469318, 'bagging_fraction': 0.7092544209536423, 'reg_alpha': 1.0912725338690172, 'reg_lambda': 0.19170543001191043}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:51:52,769] Trial 143 finished with value: -0.93228945520622 and parameters: {'learning_rate': 0.033351649858618077, 'num_leaves': 39, 'max_depth': 8, 'min_child_samples': 13, 'feature_fraction': 0.9144265484309638, 'bagging_fraction': 0.6945337974001659, 'reg_alpha': 1.3072612531334906, 'reg_lambda': 0.1959849233078355}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:52:01,207] Trial 144 finished with value: -0.9311744360181804 and parameters: {'learning_rate': 0.033536228739973487, 'num_leaves': 51, 'max_depth': 8, 'min_child_samples': 13, 'feature_fraction': 0.8964835870871073, 'bagging_fraction': 0.6939850370929211, 'reg_alpha': 0.4260554364771047, 'reg_lambda': 0.20515157465310488}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:52:08,488] Trial 145 finished with value: -0.9320575927830432 and parameters: {'learning_rate': 0.03803640294169992, 'num_leaves': 39, 'max_depth': 8, 'min_child_samples': 15, 'feature_fraction': 0.9086252044155925, 'bagging_fraction': 0.6640716741740385, 'reg_alpha': 1.1603278925815221, 'reg_lambda': 0.08812905772848695}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:52:16,352] Trial 146 finished with value: -0.9314660032410499 and parameters: {'learning_rate': 0.03737395553096273, 'num_leaves': 45, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.9026780140397903, 'bagging_fraction': 0.6673415680278627, 'reg_alpha': 1.1226743304892148, 'reg_lambda': 0.07993263096012374}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:52:22,555] Trial 147 finished with value: -0.9323693098460405 and parameters: {'learning_rate': 0.045647433306498474, 'num_leaves': 30, 'max_depth': 8, 'min_child_samples': 17, 'feature_fraction': 0.9124618209133789, 'bagging_fraction': 0.6562212323805172, 'reg_alpha': 0.48341746021903076, 'reg_lambda': 0.12114806562539922}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:52:29,237] Trial 148 finished with value: -0.931623566891791 and parameters: {'learning_rate': 0.030806800925002504, 'num_leaves': 30, 'max_depth': 9, 'min_child_samples': 17, 'feature_fraction': 0.9136501850774947, 'bagging_fraction': 0.6155430334849871, 'reg_alpha': 0.19447010775749218, 'reg_lambda': 0.15426429132620934}. Best is trial 47 with value: -0.9335925141942159.
[I 2025-08-04 21:52:34,975] Trial 149 finished with value: -0.9329203360684089 and parameters: {'learning_rate': 0.04788846120424475, 'num_leaves': 25, 'max_depth': 9, 'min_child_samples': 12, 'feature_fraction': 0.9202726516452251, 'bagging_fraction': 0.6859668072598535, 'reg_alpha': 0.4994352780869922, 'reg_lambda': 0.05079039460398434}. Best is trial 47 with value: -0.9335925141942159.
2025-08-04 21:52:36 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.9174347881230897, 'val_lightgbm': 0.9094858848971265, 'val_ensemble': 0.9168376621272787}
2025-08-04 21:52:36 [INFO] Selected best model 'catboost' with validation R²=0.9174
2025-08-04 21:52:36 [INFO] Retraining best model 'catboost' on full dataset
2025-08-04 21:52:37 [INFO] Retraining completed in 1.48s
2025-08-04 21:52:37 [INFO] Saved final model to '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/final_catboost.pkl'
2025-08-04 21:52:37 [INFO] Tree-based → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/final_catboost.pkl (R²=0.9174)
2025-08-04 21:52:37 [INFO] Training TabNet model...
[I 2025-08-04 21:52:40,875] A new study created in memory with name: no-name-7e3a5830-90c6-4c6c-ab55-0822c05338da
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 21:54:30,948] Trial 0 finished with value: 0.8256311914014975 and parameters: {'n_d': 53, 'n_a': 58, 'n_steps': 8, 'gamma': 1.2213660461590372, 'lambda_sparse': 7.732664212538494e-05, 'lr': 0.0014141525491467909, 'weight_decay': 5.7131086718714545e-05}. Best is trial 0 with value: 0.8256311914014975.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 21:56:32,910] Trial 1 finished with value: 0.7321256156848357 and parameters: {'n_d': 15, 'n_a': 51, 'n_steps': 9, 'gamma': 1.4265979596267115, 'lambda_sparse': 0.001522487163436047, 'lr': 0.00041452689067054456, 'weight_decay': 1.4223077442209994e-05}. Best is trial 0 with value: 0.8256311914014975.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 21:58:45,299] Trial 2 finished with value: 0.7830351144240245 and parameters: {'n_d': 38, 'n_a': 15, 'n_steps': 10, 'gamma': 1.4518794981471563, 'lambda_sparse': 0.004636310600523158, 'lr': 0.0021469267561868787, 'weight_decay': 4.275497307469431e-05}. Best is trial 0 with value: 0.8256311914014975.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:00:14,749] Trial 3 finished with value: 0.47277175050220466 and parameters: {'n_d': 11, 'n_a': 14, 'n_steps': 6, 'gamma': 1.9811977850113207, 'lambda_sparse': 1.2715208266146244e-05, 'lr': 0.0002534067257346498, 'weight_decay': 0.000175633709615003}. Best is trial 0 with value: 0.8256311914014975.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:01:22,462] Trial 4 finished with value: 0.8856025095289205 and parameters: {'n_d': 39, 'n_a': 12, 'n_steps': 3, 'gamma': 1.6240915968442948, 'lambda_sparse': 0.006267466958808385, 'lr': 0.01764284645753476, 'weight_decay': 0.0002160957717603248}. Best is trial 4 with value: 0.8856025095289205.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:03:01,517] Trial 5 finished with value: 0.8097133757112249 and parameters: {'n_d': 30, 'n_a': 45, 'n_steps': 7, 'gamma': 1.7961653152467532, 'lambda_sparse': 0.000948032073025328, 'lr': 0.0013815391942702691, 'weight_decay': 2.421850479911104e-05}. Best is trial 4 with value: 0.8856025095289205.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:04:22,434] Trial 6 finished with value: 0.8788087049471154 and parameters: {'n_d': 40, 'n_a': 30, 'n_steps': 4, 'gamma': 1.6955033219488642, 'lambda_sparse': 2.344102421375335e-05, 'lr': 0.0019053718463678307, 'weight_decay': 1.4123616388177262e-06}. Best is trial 4 with value: 0.8856025095289205.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:06:34,118] Trial 7 finished with value: 0.7332997208184381 and parameters: {'n_d': 36, 'n_a': 32, 'n_steps': 10, 'gamma': 1.9292684903302049, 'lambda_sparse': 6.532590570913245e-05, 'lr': 0.001978101869433676, 'weight_decay': 1.4956474970823214e-06}. Best is trial 4 with value: 0.8856025095289205.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:07:08,360] Trial 8 finished with value: -73.16642108038619 and parameters: {'n_d': 44, 'n_a': 37, 'n_steps': 8, 'gamma': 1.5258815534965449, 'lambda_sparse': 3.5981549448065835e-05, 'lr': 0.0006749320857879367, 'weight_decay': 1.6397488362947303e-05}. Best is trial 4 with value: 0.8856025095289205.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:08:16,902] Trial 9 finished with value: 0.9002163527808135 and parameters: {'n_d': 63, 'n_a': 8, 'n_steps': 3, 'gamma': 1.181799218664192, 'lambda_sparse': 0.00024092541185004776, 'lr': 0.05403698723806885, 'weight_decay': 1.1309586887304667e-06}. Best is trial 9 with value: 0.9002163527808135.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:09:39,526] Trial 10 finished with value: 0.8580360307436076 and parameters: {'n_d': 63, 'n_a': 24, 'n_steps': 5, 'gamma': 1.0102932271921525, 'lambda_sparse': 0.00027047608873814955, 'lr': 0.08863122870685035, 'weight_decay': 0.0009773592440684026}. Best is trial 9 with value: 0.9002163527808135.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:10:50,472] Trial 11 finished with value: 0.8931452020004639 and parameters: {'n_d': 64, 'n_a': 9, 'n_steps': 3, 'gamma': 1.2255149422723022, 'lambda_sparse': 0.008009845616793368, 'lr': 0.026482374666234237, 'weight_decay': 0.0003377293040432661}. Best is trial 9 with value: 0.9002163527808135.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:11:58,066] Trial 12 finished with value: 0.9142941274298396 and parameters: {'n_d': 64, 'n_a': 9, 'n_steps': 3, 'gamma': 1.2193122183238618, 'lambda_sparse': 0.0002549511155838312, 'lr': 0.015038954051043553, 'weight_decay': 4.187110698822661e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:13:17,280] Trial 13 finished with value: 0.8973747133275051 and parameters: {'n_d': 53, 'n_a': 21, 'n_steps': 5, 'gamma': 1.2019346982437715, 'lambda_sparse': 0.00022752043926716872, 'lr': 0.00990923626015814, 'weight_decay': 3.3815333252694685e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:14:40,627] Trial 14 finished with value: 0.8872203459844579 and parameters: {'n_d': 55, 'n_a': 21, 'n_steps': 4, 'gamma': 1.0020636306066906, 'lambda_sparse': 0.0007174975191161939, 'lr': 0.09644619251816927, 'weight_decay': 5.107173650890609e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:15:49,958] Trial 15 finished with value: 0.8867038861936637 and parameters: {'n_d': 24, 'n_a': 8, 'n_steps': 3, 'gamma': 1.3310746671218365, 'lambda_sparse': 0.00011610975739612639, 'lr': 0.006837064919923165, 'weight_decay': 5.476274465852341e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:17:09,161] Trial 16 finished with value: 0.9040387242512089 and parameters: {'n_d': 58, 'n_a': 41, 'n_steps': 5, 'gamma': 1.1525196810145808, 'lambda_sparse': 0.00039125575692993536, 'lr': 0.03564305864609138, 'weight_decay': 1.0175529533684597e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:18:28,472] Trial 17 finished with value: 0.9044833364992817 and parameters: {'n_d': 47, 'n_a': 42, 'n_steps': 5, 'gamma': 1.0979818206050294, 'lambda_sparse': 0.0005033031190539058, 'lr': 0.029471456523321487, 'weight_decay': 3.953399895413992e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:19:57,286] Trial 18 finished with value: 0.8835350793244011 and parameters: {'n_d': 49, 'n_a': 51, 'n_steps': 6, 'gamma': 1.3278778742237187, 'lambda_sparse': 0.002355661162371131, 'lr': 0.005691550216175324, 'weight_decay': 7.208387713245731e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:21:19,630] Trial 19 finished with value: 0.8985756319260328 and parameters: {'n_d': 47, 'n_a': 64, 'n_steps': 4, 'gamma': 1.0969604905143864, 'lambda_sparse': 0.0005568796712121277, 'lr': 0.01304457140953098, 'weight_decay': 2.7425959272403697e-06}. Best is trial 12 with value: 0.9142941274298396.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:23:03,146] A new study created in memory with name: no-name-3b0cded2-724b-4c36-bcf4-ad9e2be77035
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:24:54,017] Trial 0 finished with value: 0.5339702690471912 and parameters: {'n_d': 48, 'n_a': 39, 'n_steps': 8, 'gamma': 1.9906822376409408, 'lambda_sparse': 0.0003704846382858252, 'lr': 0.0001768751788882151, 'weight_decay': 1.571501683394306e-06}. Best is trial 0 with value: 0.5339702690471912.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:26:23,045] Trial 1 finished with value: 0.9055705794702087 and parameters: {'n_d': 27, 'n_a': 14, 'n_steps': 6, 'gamma': 1.7160219064419941, 'lambda_sparse': 1.6303768234522925e-05, 'lr': 0.009447073572126199, 'weight_decay': 5.152985095525713e-05}. Best is trial 1 with value: 0.9055705794702087.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:27:30,698] Trial 2 finished with value: 0.8017703374319389 and parameters: {'n_d': 61, 'n_a': 10, 'n_steps': 3, 'gamma': 1.5407434030406733, 'lambda_sparse': 0.001979493700971025, 'lr': 0.00017668661667038848, 'weight_decay': 8.000432461538844e-06}. Best is trial 1 with value: 0.9055705794702087.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:28:38,466] Trial 3 finished with value: 0.9108271013784321 and parameters: {'n_d': 48, 'n_a': 48, 'n_steps': 3, 'gamma': 1.4481143867843849, 'lambda_sparse': 0.0005352915994627024, 'lr': 0.015871167780314045, 'weight_decay': 0.0009406574439483447}. Best is trial 3 with value: 0.9108271013784321.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:30:19,443] Trial 4 finished with value: 0.48638603242545375 and parameters: {'n_d': 53, 'n_a': 13, 'n_steps': 7, 'gamma': 1.8509110714342747, 'lambda_sparse': 0.004387387298051618, 'lr': 0.00020639343807069495, 'weight_decay': 7.515339362683552e-05}. Best is trial 3 with value: 0.9108271013784321.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:31:44,909] Trial 5 finished with value: 0.7184675422285369 and parameters: {'n_d': 54, 'n_a': 18, 'n_steps': 6, 'gamma': 1.8500702297961766, 'lambda_sparse': 7.693327648800533e-05, 'lr': 0.00041651062278055194, 'weight_decay': 2.3759886765234323e-06}. Best is trial 3 with value: 0.9108271013784321.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:32:11,775] Trial 6 finished with value: 0.5049699954768928 and parameters: {'n_d': 36, 'n_a': 52, 'n_steps': 4, 'gamma': 1.4989465503070516, 'lambda_sparse': 0.007610544599402601, 'lr': 0.08739351075898902, 'weight_decay': 0.00011870793707993704}. Best is trial 3 with value: 0.9108271013784321.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:33:51,793] Trial 7 finished with value: 0.46961276087791126 and parameters: {'n_d': 33, 'n_a': 23, 'n_steps': 7, 'gamma': 1.3580640827453243, 'lambda_sparse': 0.0030375280559025073, 'lr': 0.00010000903308906485, 'weight_decay': 1.439101062270686e-05}. Best is trial 3 with value: 0.9108271013784321.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:35:14,211] Trial 8 finished with value: 0.915432104785973 and parameters: {'n_d': 61, 'n_a': 10, 'n_steps': 4, 'gamma': 1.7886336376204282, 'lambda_sparse': 0.004411585962660649, 'lr': 0.020686886902608982, 'weight_decay': 9.362067005571352e-06}. Best is trial 8 with value: 0.915432104785973.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:37:13,787] Trial 9 finished with value: 0.9148415516464247 and parameters: {'n_d': 37, 'n_a': 46, 'n_steps': 9, 'gamma': 1.0987397771378995, 'lambda_sparse': 2.3079790771319726e-05, 'lr': 0.0018940898234844812, 'weight_decay': 0.0005130489883728426}. Best is trial 8 with value: 0.915432104785973.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:38:34,415] Trial 10 finished with value: 0.9188651195162565 and parameters: {'n_d': 10, 'n_a': 64, 'n_steps': 5, 'gamma': 1.0066498481690507, 'lambda_sparse': 0.000986674396059145, 'lr': 0.09815259957724315, 'weight_decay': 6.121985603989058e-06}. Best is trial 10 with value: 0.9188651195162565.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:39:53,588] Trial 11 finished with value: 0.9219846752576917 and parameters: {'n_d': 9, 'n_a': 60, 'n_steps': 5, 'gamma': 1.0006183580327757, 'lambda_sparse': 0.0013628160387175632, 'lr': 0.07266649951658928, 'weight_decay': 5.863070614706903e-06}. Best is trial 11 with value: 0.9219846752576917.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:41:13,082] Trial 12 finished with value: 0.9151608376576597 and parameters: {'n_d': 8, 'n_a': 64, 'n_steps': 5, 'gamma': 1.0147909888310855, 'lambda_sparse': 0.0009462318485575072, 'lr': 0.06894077252280027, 'weight_decay': 4.303907047140935e-06}. Best is trial 11 with value: 0.9219846752576917.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:41:35,777] Trial 13 finished with value: 0.0018250724549506714 and parameters: {'n_d': 9, 'n_a': 64, 'n_steps': 5, 'gamma': 1.1934019900797899, 'lambda_sparse': 0.00014164660224533554, 'lr': 0.0379102860879587, 'weight_decay': 2.1848682599852596e-05}. Best is trial 11 with value: 0.9219846752576917.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:43:46,285] Trial 14 finished with value: 0.8581854382804877 and parameters: {'n_d': 18, 'n_a': 57, 'n_steps': 10, 'gamma': 1.2326180052404445, 'lambda_sparse': 0.0010551634505575186, 'lr': 0.0035552126789873888, 'weight_decay': 4.021075337866577e-06}. Best is trial 11 with value: 0.9219846752576917.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:45:07,263] Trial 15 finished with value: 0.9112678152646798 and parameters: {'n_d': 21, 'n_a': 29, 'n_steps': 5, 'gamma': 1.000909211796781, 'lambda_sparse': 0.00016010961306736166, 'lr': 0.09806171392420263, 'weight_decay': 2.927927280304274e-05}. Best is trial 11 with value: 0.9219846752576917.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:46:32,434] Trial 16 finished with value: 0.9196443037242569 and parameters: {'n_d': 17, 'n_a': 57, 'n_steps': 4, 'gamma': 1.2313732295697766, 'lambda_sparse': 0.0012683047769838898, 'lr': 0.004757946455408374, 'weight_decay': 1.024752120055683e-06}. Best is trial 11 with value: 0.9219846752576917.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:47:54,834] Trial 17 finished with value: 0.8908251401108132 and parameters: {'n_d': 18, 'n_a': 39, 'n_steps': 4, 'gamma': 1.2671363058265073, 'lambda_sparse': 0.0017973161349385872, 'lr': 0.0012073209354036727, 'weight_decay': 1.0222855037555243e-06}. Best is trial 11 with value: 0.9219846752576917.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:49:02,469] Trial 18 finished with value: 0.9237499423128608 and parameters: {'n_d': 25, 'n_a': 56, 'n_steps': 3, 'gamma': 1.1252484279673873, 'lambda_sparse': 0.00024277670098128443, 'lr': 0.005832946453480581, 'weight_decay': 2.487378178582759e-06}. Best is trial 18 with value: 0.9237499423128608.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:49:36,107] Trial 19 finished with value: 0.5641857616888968 and parameters: {'n_d': 27, 'n_a': 56, 'n_steps': 3, 'gamma': 1.1411030165766576, 'lambda_sparse': 5.436120230341308e-05, 'lr': 0.00846817490687747, 'weight_decay': 2.1295577296226863e-06}. Best is trial 18 with value: 0.9237499423128608.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:51:20,958] A new study created in memory with name: no-name-d9df496d-eea9-4a18-8561-eaff2f69b08a
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:53:11,404] Trial 0 finished with value: 0.8904367108141225 and parameters: {'n_d': 43, 'n_a': 24, 'n_steps': 8, 'gamma': 1.4830664901146675, 'lambda_sparse': 4.6376056488468e-05, 'lr': 0.010387755229519098, 'weight_decay': 0.00024641901916496074}. Best is trial 0 with value: 0.8904367108141225.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:54:50,508] Trial 1 finished with value: 0.843724274471347 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 7, 'gamma': 1.5954789232552065, 'lambda_sparse': 3.250931736297948e-05, 'lr': 0.0009685023905502693, 'weight_decay': 1.830063723629289e-05}. Best is trial 0 with value: 0.8904367108141225.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:56:11,800] Trial 2 finished with value: 0.9137214301344443 and parameters: {'n_d': 53, 'n_a': 26, 'n_steps': 4, 'gamma': 1.8722202083279356, 'lambda_sparse': 0.00023263663416322748, 'lr': 0.005381794626372136, 'weight_decay': 1.2161881970252556e-05}. Best is trial 2 with value: 0.9137214301344443.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:57:49,710] Trial 3 finished with value: 0.9062291085852235 and parameters: {'n_d': 8, 'n_a': 45, 'n_steps': 7, 'gamma': 1.5775041401189855, 'lambda_sparse': 0.0022949930538530786, 'lr': 0.005631326081774082, 'weight_decay': 1.2133185860276223e-06}. Best is trial 2 with value: 0.9137214301344443.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 22:58:58,267] Trial 4 finished with value: 0.8031922553005373 and parameters: {'n_d': 22, 'n_a': 48, 'n_steps': 3, 'gamma': 1.9219301693135526, 'lambda_sparse': 0.0001390263681952063, 'lr': 0.00011191530279631131, 'weight_decay': 1.1809278166190402e-06}. Best is trial 2 with value: 0.9137214301344443.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:00:38,439] Trial 5 finished with value: 0.889288072704193 and parameters: {'n_d': 11, 'n_a': 37, 'n_steps': 7, 'gamma': 1.7138513127814619, 'lambda_sparse': 5.284972314753698e-05, 'lr': 0.004189794420498008, 'weight_decay': 0.000601736933789273}. Best is trial 2 with value: 0.9137214301344443.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:02:53,594] Trial 6 finished with value: 0.6460072974110762 and parameters: {'n_d': 53, 'n_a': 33, 'n_steps': 10, 'gamma': 1.8852713748964218, 'lambda_sparse': 0.009413247644752052, 'lr': 0.0005605632308372729, 'weight_decay': 0.00021368244416759477}. Best is trial 2 with value: 0.9137214301344443.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:04:34,374] Trial 7 finished with value: 0.6015165781841507 and parameters: {'n_d': 45, 'n_a': 24, 'n_steps': 7, 'gamma': 1.5599583945968303, 'lambda_sparse': 9.548780130057697e-05, 'lr': 0.00022099566714567703, 'weight_decay': 2.6253461392391278e-05}. Best is trial 2 with value: 0.9137214301344443.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:06:25,303] Trial 8 finished with value: 0.9185113594959006 and parameters: {'n_d': 57, 'n_a': 22, 'n_steps': 8, 'gamma': 1.1475737302633406, 'lambda_sparse': 0.0005233626210654004, 'lr': 0.05228205704147349, 'weight_decay': 2.057684386794411e-06}. Best is trial 8 with value: 0.9185113594959006.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:06:46,219] Trial 9 finished with value: 0.5782682003862735 and parameters: {'n_d': 36, 'n_a': 11, 'n_steps': 3, 'gamma': 1.6522950128202867, 'lambda_sparse': 0.0003678047941832561, 'lr': 0.09871159277689578, 'weight_decay': 0.0004539891409320893}. Best is trial 8 with value: 0.9185113594959006.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:08:48,220] Trial 10 finished with value: 0.9115076691003797 and parameters: {'n_d': 61, 'n_a': 10, 'n_steps': 10, 'gamma': 1.063508288927672, 'lambda_sparse': 0.0008680466736148467, 'lr': 0.09459421165814573, 'weight_decay': 6.189706143329498e-06}. Best is trial 8 with value: 0.9185113594959006.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:10:10,228] Trial 11 finished with value: 0.9263640288074161 and parameters: {'n_d': 64, 'n_a': 21, 'n_steps': 5, 'gamma': 1.1967358839583717, 'lambda_sparse': 0.00039536195651915067, 'lr': 0.019278376865308818, 'weight_decay': 6.942404142006172e-06}. Best is trial 11 with value: 0.9263640288074161.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:11:30,402] Trial 12 finished with value: 0.9183335852894232 and parameters: {'n_d': 63, 'n_a': 57, 'n_steps': 5, 'gamma': 1.0784657309368963, 'lambda_sparse': 1.043482996233385e-05, 'lr': 0.026403928012022106, 'weight_decay': 4.05077983018802e-06}. Best is trial 11 with value: 0.9263640288074161.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:12:50,288] Trial 13 finished with value: 0.931205537029994 and parameters: {'n_d': 54, 'n_a': 17, 'n_steps': 5, 'gamma': 1.2823330642914574, 'lambda_sparse': 0.0007973095571447046, 'lr': 0.02623957023268384, 'weight_decay': 3.630533655350239e-06}. Best is trial 13 with value: 0.931205537029994.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:14:03,700] Trial 14 finished with value: 0.9250551987609158 and parameters: {'n_d': 46, 'n_a': 16, 'n_steps': 5, 'gamma': 1.3035455678546053, 'lambda_sparse': 0.0016336507770743146, 'lr': 0.01774227560811355, 'weight_decay': 7.006716535826185e-05}. Best is trial 13 with value: 0.931205537029994.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:15:23,330] Trial 15 finished with value: 0.9305182465722 and parameters: {'n_d': 63, 'n_a': 18, 'n_steps': 5, 'gamma': 1.2947278128016686, 'lambda_sparse': 0.004570081210804034, 'lr': 0.027538320169510064, 'weight_decay': 6.186953228800909e-06}. Best is trial 13 with value: 0.931205537029994.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:16:45,908] Trial 16 finished with value: 0.8940245652642549 and parameters: {'n_d': 52, 'n_a': 8, 'n_steps': 4, 'gamma': 1.3836345481281078, 'lambda_sparse': 0.00674497923463018, 'lr': 0.0015603495930881204, 'weight_decay': 5.6903335267441516e-05}. Best is trial 13 with value: 0.931205537029994.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:18:14,416] Trial 17 finished with value: 0.9175225010881676 and parameters: {'n_d': 30, 'n_a': 16, 'n_steps': 6, 'gamma': 1.3047939568650182, 'lambda_sparse': 0.0035516578173545393, 'lr': 0.03756889747173061, 'weight_decay': 3.3021091296904408e-06}. Best is trial 13 with value: 0.931205537029994.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:19:43,793] Trial 18 finished with value: 0.9184708159905819 and parameters: {'n_d': 39, 'n_a': 63, 'n_steps': 6, 'gamma': 1.425226901088072, 'lambda_sparse': 0.0009487689874218764, 'lr': 0.009409590364286444, 'weight_decay': 8.59773131121747e-06}. Best is trial 13 with value: 0.931205537029994.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:21:05,905] Trial 19 finished with value: 0.905369082190071 and parameters: {'n_d': 50, 'n_a': 39, 'n_steps': 4, 'gamma': 1.2562960920566444, 'lambda_sparse': 0.004301856396717118, 'lr': 0.002131419996370927, 'weight_decay': 2.6413915626062125e-06}. Best is trial 13 with value: 0.931205537029994.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:22:47,078] A new study created in memory with name: no-name-d4bb9ae6-935d-4ec5-b8b9-f648023efbbc
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:24:27,424] Trial 0 finished with value: 0.4224450751143116 and parameters: {'n_d': 29, 'n_a': 34, 'n_steps': 7, 'gamma': 1.7191797119024583, 'lambda_sparse': 0.009188289299601849, 'lr': 0.00020995969346253022, 'weight_decay': 4.053323219206863e-05}. Best is trial 0 with value: 0.4224450751143116.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:26:28,821] Trial 1 finished with value: 0.8579611290114308 and parameters: {'n_d': 11, 'n_a': 35, 'n_steps': 9, 'gamma': 1.9314333107069142, 'lambda_sparse': 0.00059879091488464, 'lr': 0.0068736680100303605, 'weight_decay': 5.409559494988841e-05}. Best is trial 1 with value: 0.8579611290114308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:28:14,911] Trial 2 finished with value: 0.8420840632396369 and parameters: {'n_d': 32, 'n_a': 19, 'n_steps': 8, 'gamma': 1.1651188207719687, 'lambda_sparse': 0.0001380292890140107, 'lr': 0.0013495943575889012, 'weight_decay': 2.4164858365208733e-05}. Best is trial 1 with value: 0.8579611290114308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:29:23,262] Trial 3 finished with value: 0.9245636587070227 and parameters: {'n_d': 50, 'n_a': 21, 'n_steps': 3, 'gamma': 1.2521557733732405, 'lambda_sparse': 1.231873890444073e-05, 'lr': 0.004654884411050589, 'weight_decay': 1.1200188722050353e-05}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:31:15,089] Trial 4 finished with value: 0.8240042987839004 and parameters: {'n_d': 28, 'n_a': 38, 'n_steps': 8, 'gamma': 1.3881219613807891, 'lambda_sparse': 3.300072671311487e-05, 'lr': 0.0014940880590974162, 'weight_decay': 0.0002243329508765931}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:31:47,145] Trial 5 finished with value: 0.5206470251258267 and parameters: {'n_d': 43, 'n_a': 61, 'n_steps': 3, 'gamma': 1.052344365023723, 'lambda_sparse': 0.00018483264421973415, 'lr': 0.04705813663844404, 'weight_decay': 0.0003569491019810348}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:34:01,298] Trial 6 finished with value: 0.8308759298420468 and parameters: {'n_d': 62, 'n_a': 19, 'n_steps': 10, 'gamma': 1.5374276859933498, 'lambda_sparse': 0.007607933114283824, 'lr': 0.007687246388414901, 'weight_decay': 3.233344992517392e-06}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:35:10,655] Trial 7 finished with value: 0.8810068487239201 and parameters: {'n_d': 15, 'n_a': 50, 'n_steps': 3, 'gamma': 1.734329438768913, 'lambda_sparse': 0.002683615198734617, 'lr': 0.0005485661905501999, 'weight_decay': 0.0007064992838192374}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:36:32,126] Trial 8 finished with value: 0.7542065329284822 and parameters: {'n_d': 15, 'n_a': 37, 'n_steps': 4, 'gamma': 1.4746401665109516, 'lambda_sparse': 0.001072251886899959, 'lr': 0.00016012259301837023, 'weight_decay': 0.00010130315706681282}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:36:49,392] Trial 9 finished with value: -5316.609850688235 and parameters: {'n_d': 42, 'n_a': 12, 'n_steps': 5, 'gamma': 1.878780705051612, 'lambda_sparse': 0.00022398109637667113, 'lr': 0.00011408354083533324, 'weight_decay': 1.2093748870791519e-05}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:37:30,066] Trial 10 finished with value: 0.5938116220056724 and parameters: {'n_d': 62, 'n_a': 25, 'n_steps': 5, 'gamma': 1.2620007267522007, 'lambda_sparse': 1.424152155698376e-05, 'lr': 0.07985976048736122, 'weight_decay': 1.224606944439478e-06}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:38:37,041] Trial 11 finished with value: 0.8873138982114775 and parameters: {'n_d': 52, 'n_a': 52, 'n_steps': 3, 'gamma': 1.6596202522748307, 'lambda_sparse': 0.002183555876114026, 'lr': 0.0005547558782764803, 'weight_decay': 0.0007806571333611033}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:40:00,581] Trial 12 finished with value: 0.9136983510522614 and parameters: {'n_d': 51, 'n_a': 52, 'n_steps': 4, 'gamma': 1.6433561353692592, 'lambda_sparse': 4.479895205149025e-05, 'lr': 0.014151224649690193, 'weight_decay': 6.646684670886883e-06}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:40:34,958] Trial 13 finished with value: 0.3450328480150985 and parameters: {'n_d': 52, 'n_a': 48, 'n_steps': 5, 'gamma': 1.3667584864361193, 'lambda_sparse': 4.83790025357258e-05, 'lr': 0.017853760936593473, 'weight_decay': 3.7428685038282927e-06}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:42:05,146] Trial 14 finished with value: 0.9180891554377308 and parameters: {'n_d': 52, 'n_a': 63, 'n_steps': 6, 'gamma': 1.22489531062965, 'lambda_sparse': 1.4188459667448428e-05, 'lr': 0.018504781015411427, 'weight_decay': 6.697395413252819e-06}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:43:35,061] Trial 15 finished with value: 0.9216378548449419 and parameters: {'n_d': 43, 'n_a': 8, 'n_steps': 6, 'gamma': 1.0215636355992272, 'lambda_sparse': 1.0499551622580476e-05, 'lr': 0.0031559256666590933, 'weight_decay': 1.4062054526244287e-05}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:45:14,159] Trial 16 finished with value: 0.9073166224964974 and parameters: {'n_d': 41, 'n_a': 8, 'n_steps': 7, 'gamma': 1.000850879019756, 'lambda_sparse': 1.1257146045593463e-05, 'lr': 0.002932471427214061, 'weight_decay': 1.8744017268428023e-05}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:46:46,287] Trial 17 finished with value: 0.9086763172938034 and parameters: {'n_d': 45, 'n_a': 26, 'n_steps': 6, 'gamma': 1.1231372479675403, 'lambda_sparse': 7.701986054537746e-05, 'lr': 0.0035743647710322598, 'weight_decay': 6.988739460596194e-05}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:48:08,947] Trial 18 finished with value: 0.891876536561567 and parameters: {'n_d': 36, 'n_a': 15, 'n_steps': 4, 'gamma': 1.306462158507811, 'lambda_sparse': 2.8270539744812442e-05, 'lr': 0.0016870537055074949, 'weight_decay': 1.1398355377055375e-06}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:50:20,558] Trial 19 finished with value: 0.7383313383847162 and parameters: {'n_d': 22, 'n_a': 8, 'n_steps': 10, 'gamma': 1.1003237492916957, 'lambda_sparse': 7.268157465107227e-05, 'lr': 0.0005396989516125126, 'weight_decay': 1.2696039344347259e-05}. Best is trial 3 with value: 0.9245636587070227.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:51:40,677] A new study created in memory with name: no-name-950f2c76-4ed1-4b45-89b4-6444f3e1992a
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:53:00,994] Trial 0 finished with value: 0.8802490069192308 and parameters: {'n_d': 23, 'n_a': 19, 'n_steps': 4, 'gamma': 1.9645171611783367, 'lambda_sparse': 5.066027064087969e-05, 'lr': 0.00873408623337733, 'weight_decay': 5.377966620136309e-06}. Best is trial 0 with value: 0.8802490069192308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:55:11,311] Trial 1 finished with value: 0.5748830428943368 and parameters: {'n_d': 27, 'n_a': 51, 'n_steps': 10, 'gamma': 1.1978213527112596, 'lambda_sparse': 0.0006277140530177894, 'lr': 0.0002440519702425115, 'weight_decay': 3.4419090058890318e-06}. Best is trial 0 with value: 0.8802490069192308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:55:40,555] Trial 2 finished with value: 0.7243262055067404 and parameters: {'n_d': 29, 'n_a': 57, 'n_steps': 7, 'gamma': 1.2810118488475735, 'lambda_sparse': 9.22180575635214e-05, 'lr': 0.06710402881553333, 'weight_decay': 0.0003082361727549179}. Best is trial 0 with value: 0.8802490069192308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:56:36,104] Trial 3 finished with value: 0.5313956672509987 and parameters: {'n_d': 17, 'n_a': 29, 'n_steps': 9, 'gamma': 1.9043237060594924, 'lambda_sparse': 0.0024867050017839685, 'lr': 0.0297394118451028, 'weight_decay': 2.025117650324989e-05}. Best is trial 0 with value: 0.8802490069192308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 23:58:48,804] Trial 4 finished with value: 0.47776292331438774 and parameters: {'n_d': 45, 'n_a': 59, 'n_steps': 10, 'gamma': 1.8720891803097983, 'lambda_sparse': 5.009871567846323e-05, 'lr': 0.00034758342880108616, 'weight_decay': 4.67869018291959e-05}. Best is trial 0 with value: 0.8802490069192308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:00:29,659] Trial 5 finished with value: 0.8471132531436716 and parameters: {'n_d': 50, 'n_a': 58, 'n_steps': 7, 'gamma': 1.620816662963069, 'lambda_sparse': 0.0024103425824184245, 'lr': 0.0016169944620759874, 'weight_decay': 6.016808608564665e-06}. Best is trial 0 with value: 0.8802490069192308.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:01:50,748] Trial 6 finished with value: 0.8882495331886883 and parameters: {'n_d': 46, 'n_a': 59, 'n_steps': 5, 'gamma': 1.8167528132408308, 'lambda_sparse': 2.4148805064721996e-05, 'lr': 0.0009130897330427558, 'weight_decay': 2.17171733332748e-06}. Best is trial 6 with value: 0.8882495331886883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:02:23,939] Trial 7 finished with value: 0.5777036353973306 and parameters: {'n_d': 31, 'n_a': 41, 'n_steps': 4, 'gamma': 1.7953975700369127, 'lambda_sparse': 0.008815210762562208, 'lr': 0.06819947169521674, 'weight_decay': 0.0004602388790293918}. Best is trial 6 with value: 0.8882495331886883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:03:37,054] Trial 8 finished with value: 0.86789413176812 and parameters: {'n_d': 23, 'n_a': 56, 'n_steps': 4, 'gamma': 1.7373570440160262, 'lambda_sparse': 0.0019146684480854735, 'lr': 0.000957521271315048, 'weight_decay': 0.00020480973022095531}. Best is trial 6 with value: 0.8882495331886883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:04:57,418] Trial 9 finished with value: 0.9044249108004229 and parameters: {'n_d': 23, 'n_a': 13, 'n_steps': 4, 'gamma': 1.1343480972640174, 'lambda_sparse': 0.009714141258659157, 'lr': 0.08248115830282399, 'weight_decay': 9.756274741922354e-06}. Best is trial 9 with value: 0.9044249108004229.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:06:05,210] Trial 10 finished with value: 0.9180529413175436 and parameters: {'n_d': 9, 'n_a': 8, 'n_steps': 3, 'gamma': 1.0218733299021645, 'lambda_sparse': 0.009699649766212497, 'lr': 0.012651972303965097, 'weight_decay': 4.4748677292883025e-05}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:07:15,721] Trial 11 finished with value: 0.8996597845918709 and parameters: {'n_d': 10, 'n_a': 8, 'n_steps': 3, 'gamma': 1.0063664218689183, 'lambda_sparse': 0.009866471896156125, 'lr': 0.008684994221941198, 'weight_decay': 3.928372775704573e-05}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:08:23,891] Trial 12 finished with value: 0.906694903887246 and parameters: {'n_d': 10, 'n_a': 10, 'n_steps': 3, 'gamma': 1.044842099229068, 'lambda_sparse': 0.0005338880031264965, 'lr': 0.013802016881928086, 'weight_decay': 1.4969528997828596e-05}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:09:54,609] Trial 13 finished with value: 0.9078794055721539 and parameters: {'n_d': 8, 'n_a': 23, 'n_steps': 6, 'gamma': 1.4106465207493897, 'lambda_sparse': 0.0002536322438738021, 'lr': 0.008855778995115455, 'weight_decay': 9.242112238450614e-05}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:11:23,808] Trial 14 finished with value: 0.8906357802050678 and parameters: {'n_d': 61, 'n_a': 24, 'n_steps': 6, 'gamma': 1.3994154934062237, 'lambda_sparse': 0.00016696146962935128, 'lr': 0.002994167251519415, 'weight_decay': 0.00011475100982782193}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:13:07,959] Trial 15 finished with value: 0.898962292703228 and parameters: {'n_d': 8, 'n_a': 35, 'n_steps': 8, 'gamma': 1.4797660006737279, 'lambda_sparse': 0.0002916396067047587, 'lr': 0.018693268775189165, 'weight_decay': 0.0008713316226952765}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:14:36,997] Trial 16 finished with value: 0.9003753482889388 and parameters: {'n_d': 15, 'n_a': 18, 'n_steps': 6, 'gamma': 1.3376870101301526, 'lambda_sparse': 1.0757365461341857e-05, 'lr': 0.002886186909962281, 'weight_decay': 9.07353274077756e-05}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:15:56,206] Trial 17 finished with value: 0.9033346474877837 and parameters: {'n_d': 16, 'n_a': 28, 'n_steps': 5, 'gamma': 1.5430484339604427, 'lambda_sparse': 0.0009484592683502292, 'lr': 0.007274131799763563, 'weight_decay': 8.590940538630034e-05}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:17:49,051] Trial 18 finished with value: 0.24938149805219145 and parameters: {'n_d': 36, 'n_a': 17, 'n_steps': 8, 'gamma': 1.6427011590238159, 'lambda_sparse': 0.00019990394888239776, 'lr': 0.00011603578043755448, 'weight_decay': 3.145372243187399e-05}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:19:09,497] Trial 19 finished with value: 0.9050850383204107 and parameters: {'n_d': 17, 'n_a': 37, 'n_steps': 5, 'gamma': 1.1852787375745744, 'lambda_sparse': 0.0011451298420782365, 'lr': 0.03553233242976734, 'weight_decay': 0.00016913220041112973}. Best is trial 10 with value: 0.9180529413175436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:20:48,539] A new study created in memory with name: no-name-e8b64bde-8e16-4110-851f-2bdde5b8371c
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:22:29,404] Trial 0 finished with value: 0.8381107293517036 and parameters: {'n_d': 28, 'n_a': 26, 'n_steps': 7, 'gamma': 1.1356396791269712, 'lambda_sparse': 0.0023524444000421673, 'lr': 0.0007230012877466125, 'weight_decay': 4.271473877940035e-05}. Best is trial 0 with value: 0.8381107293517036.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:23:52,731] Trial 1 finished with value: 0.8226517167462936 and parameters: {'n_d': 63, 'n_a': 64, 'n_steps': 4, 'gamma': 1.8862429285580764, 'lambda_sparse': 1.8123667647268386e-05, 'lr': 0.00018168763469203538, 'weight_decay': 2.2902010845731524e-05}. Best is trial 0 with value: 0.8381107293517036.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:25:37,569] Trial 2 finished with value: 0.0864949646339005 and parameters: {'n_d': 62, 'n_a': 13, 'n_steps': 8, 'gamma': 1.6153048992255368, 'lambda_sparse': 0.0014232883277938803, 'lr': 0.00010957930822892042, 'weight_decay': 3.896852585890841e-06}. Best is trial 0 with value: 0.8381107293517036.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:27:18,993] Trial 3 finished with value: 0.8836217122555269 and parameters: {'n_d': 62, 'n_a': 9, 'n_steps': 7, 'gamma': 1.4248050811329105, 'lambda_sparse': 8.034145600456272e-05, 'lr': 0.004240414295120681, 'weight_decay': 2.2412801229127114e-05}. Best is trial 3 with value: 0.8836217122555269.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:28:49,200] Trial 4 finished with value: 0.9148599844871284 and parameters: {'n_d': 32, 'n_a': 22, 'n_steps': 6, 'gamma': 1.3140101250310352, 'lambda_sparse': 0.004107174576869687, 'lr': 0.01617814487137666, 'weight_decay': 9.910179780618152e-06}. Best is trial 4 with value: 0.9148599844871284.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:30:08,787] Trial 5 finished with value: 0.9042646594399146 and parameters: {'n_d': 41, 'n_a': 47, 'n_steps': 5, 'gamma': 1.3667737263170299, 'lambda_sparse': 0.0007395455247531145, 'lr': 0.005107227737314833, 'weight_decay': 7.407905794449021e-05}. Best is trial 4 with value: 0.9148599844871284.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:31:31,112] Trial 6 finished with value: 0.9012623410897892 and parameters: {'n_d': 34, 'n_a': 38, 'n_steps': 5, 'gamma': 1.6991062908210015, 'lambda_sparse': 0.0002155610549964832, 'lr': 0.08862548860809383, 'weight_decay': 1.5355825890020027e-05}. Best is trial 4 with value: 0.9148599844871284.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:33:44,757] Trial 7 finished with value: -0.6167334145476668 and parameters: {'n_d': 39, 'n_a': 40, 'n_steps': 10, 'gamma': 1.692338176669018, 'lambda_sparse': 0.00035242353129706427, 'lr': 0.00016356224948136508, 'weight_decay': 8.195600410124017e-06}. Best is trial 4 with value: 0.9148599844871284.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:34:52,096] Trial 8 finished with value: 0.9165500045986309 and parameters: {'n_d': 22, 'n_a': 19, 'n_steps': 3, 'gamma': 1.0275333925307533, 'lambda_sparse': 0.003099897413196077, 'lr': 0.003455287516924111, 'weight_decay': 5.231234764858812e-06}. Best is trial 8 with value: 0.9165500045986309.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:36:14,818] Trial 9 finished with value: 0.9179213898457795 and parameters: {'n_d': 51, 'n_a': 23, 'n_steps': 5, 'gamma': 1.764579078899526, 'lambda_sparse': 0.00013334240280732916, 'lr': 0.02896061081449044, 'weight_decay': 1.6886223169847527e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:38:15,676] Trial 10 finished with value: 0.8884820388078281 and parameters: {'n_d': 8, 'n_a': 30, 'n_steps': 9, 'gamma': 1.9609059192067606, 'lambda_sparse': 3.09937969869723e-05, 'lr': 0.0732525270682723, 'weight_decay': 0.0002558522127455914}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:39:23,690] Trial 11 finished with value: 0.9018844970496075 and parameters: {'n_d': 19, 'n_a': 18, 'n_steps': 3, 'gamma': 1.0145097078583154, 'lambda_sparse': 0.00815562184698792, 'lr': 0.01891539886712917, 'weight_decay': 1.0569708854718642e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:40:31,615] Trial 12 finished with value: 0.888931542355101 and parameters: {'n_d': 49, 'n_a': 29, 'n_steps': 3, 'gamma': 1.7882008587159903, 'lambda_sparse': 0.00010244091072829146, 'lr': 0.0011624840882369647, 'weight_decay': 1.26278228511252e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:41:01,267] Trial 13 finished with value: -0.047239221796400166 and parameters: {'n_d': 50, 'n_a': 14, 'n_steps': 4, 'gamma': 1.256841689599829, 'lambda_sparse': 0.0006630448807889381, 'lr': 0.01802030127557356, 'weight_decay': 2.9413185249960544e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:42:22,588] Trial 14 finished with value: 0.8703681904164837 and parameters: {'n_d': 22, 'n_a': 21, 'n_steps': 5, 'gamma': 1.5006019514238866, 'lambda_sparse': 7.283513706955002e-05, 'lr': 0.0013234179422868108, 'weight_decay': 3.453622834425518e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:43:30,601] Trial 15 finished with value: 0.9130732616100099 and parameters: {'n_d': 8, 'n_a': 51, 'n_steps': 3, 'gamma': 1.5440370158901973, 'lambda_sparse': 0.00030324411593507473, 'lr': 0.0076888178937313464, 'weight_decay': 0.0007232202850154674}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:44:45,483] Trial 16 finished with value: 0.9145218496744489 and parameters: {'n_d': 48, 'n_a': 33, 'n_steps': 4, 'gamma': 1.191680870373606, 'lambda_sparse': 0.009097902146922892, 'lr': 0.032864454824799424, 'weight_decay': 2.3029528582930807e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:46:16,506] Trial 17 finished with value: 0.9090106087054197 and parameters: {'n_d': 17, 'n_a': 8, 'n_steps': 6, 'gamma': 1.0253756812041475, 'lambda_sparse': 0.0013492842757266848, 'lr': 0.0023144451743074826, 'weight_decay': 5.845148961313097e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:47:38,853] Trial 18 finished with value: 0.8704713952102126 and parameters: {'n_d': 54, 'n_a': 24, 'n_steps': 4, 'gamma': 1.834255766754706, 'lambda_sparse': 0.00015223308308815083, 'lr': 0.0005508773212811211, 'weight_decay': 8.505647912323397e-05}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:49:00,933] Trial 19 finished with value: 0.8999825783029074 and parameters: {'n_d': 28, 'n_a': 17, 'n_steps': 5, 'gamma': 1.7070007299450283, 'lambda_sparse': 3.849822830165186e-05, 'lr': 0.0093455070345828, 'weight_decay': 1.7460113332392707e-06}. Best is trial 9 with value: 0.9179213898457795.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:51:06,621] A new study created in memory with name: no-name-e90f31d3-0420-4a8f-9380-b20a706b949a
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:52:38,278] Trial 0 finished with value: 0.913367044209143 and parameters: {'n_d': 25, 'n_a': 64, 'n_steps': 6, 'gamma': 1.0098720274534476, 'lambda_sparse': 0.00027191556628206075, 'lr': 0.0011192145257727932, 'weight_decay': 6.439373738967939e-05}. Best is trial 0 with value: 0.913367044209143.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:54:42,777] Trial 1 finished with value: 0.9125855941361883 and parameters: {'n_d': 49, 'n_a': 48, 'n_steps': 9, 'gamma': 1.2358101657896097, 'lambda_sparse': 0.002501114966386143, 'lr': 0.013467605691336103, 'weight_decay': 6.542788835189359e-05}. Best is trial 0 with value: 0.913367044209143.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:55:51,361] Trial 2 finished with value: 0.9235871167252959 and parameters: {'n_d': 27, 'n_a': 63, 'n_steps': 3, 'gamma': 1.30887138111916, 'lambda_sparse': 0.00015251177136914356, 'lr': 0.021204966964219352, 'weight_decay': 2.767389693845941e-06}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:57:53,985] Trial 3 finished with value: 0.9215404195497792 and parameters: {'n_d': 26, 'n_a': 32, 'n_steps': 9, 'gamma': 1.0078301644975496, 'lambda_sparse': 2.1816000655489473e-05, 'lr': 0.06305307508912304, 'weight_decay': 6.554443207633976e-05}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 00:59:57,797] Trial 4 finished with value: 0.6705299056839771 and parameters: {'n_d': 43, 'n_a': 44, 'n_steps': 9, 'gamma': 1.6613017228592577, 'lambda_sparse': 1.217731959306437e-05, 'lr': 0.000402490393712576, 'weight_decay': 8.01973286126491e-06}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:00:41,036] Trial 5 finished with value: 0.3783747058570106 and parameters: {'n_d': 48, 'n_a': 13, 'n_steps': 4, 'gamma': 1.9376226578412172, 'lambda_sparse': 0.008401341019525678, 'lr': 0.06687770795489294, 'weight_decay': 8.817131110246051e-06}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:02:02,204] Trial 6 finished with value: 0.9085068184592473 and parameters: {'n_d': 44, 'n_a': 31, 'n_steps': 4, 'gamma': 1.756437387107478, 'lambda_sparse': 0.0006539638723964382, 'lr': 0.09622894132363752, 'weight_decay': 0.0006460370708412807}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:04:04,774] Trial 7 finished with value: 0.9136505718611285 and parameters: {'n_d': 11, 'n_a': 22, 'n_steps': 9, 'gamma': 1.8164977281991537, 'lambda_sparse': 8.869035074591082e-05, 'lr': 0.06915177891038028, 'weight_decay': 1.0037223308971131e-05}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:06:06,833] Trial 8 finished with value: -0.06755364190823321 and parameters: {'n_d': 35, 'n_a': 61, 'n_steps': 9, 'gamma': 1.406677510871424, 'lambda_sparse': 0.0039892169578113245, 'lr': 0.0001230831714102954, 'weight_decay': 2.7867337444481516e-05}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:07:28,473] Trial 9 finished with value: 0.7068824544939065 and parameters: {'n_d': 15, 'n_a': 31, 'n_steps': 5, 'gamma': 1.4509657165199434, 'lambda_sparse': 2.1495855396072815e-05, 'lr': 0.00013110178649377124, 'weight_decay': 7.699183248997945e-05}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:08:36,835] Trial 10 finished with value: 0.9205243132448464 and parameters: {'n_d': 61, 'n_a': 50, 'n_steps': 3, 'gamma': 1.2719279378668995, 'lambda_sparse': 0.00011181223062514819, 'lr': 0.007047472988512997, 'weight_decay': 1.1451296556560261e-06}. Best is trial 2 with value: 0.9235871167252959.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:10:17,260] Trial 11 finished with value: 0.9303102187289346 and parameters: {'n_d': 27, 'n_a': 39, 'n_steps': 7, 'gamma': 1.036189598280014, 'lambda_sparse': 3.601146675426796e-05, 'lr': 0.019307440157338793, 'weight_decay': 1.0972485319404283e-06}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:11:59,538] Trial 12 finished with value: 0.9204819322602635 and parameters: {'n_d': 26, 'n_a': 55, 'n_steps': 7, 'gamma': 1.2054977889061655, 'lambda_sparse': 6.09153594232006e-05, 'lr': 0.015109348004793128, 'weight_decay': 1.7037277080334106e-06}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:13:41,911] Trial 13 finished with value: 0.9134297817625581 and parameters: {'n_d': 33, 'n_a': 39, 'n_steps': 7, 'gamma': 1.1306598205538252, 'lambda_sparse': 0.0003897605032530321, 'lr': 0.003025827771194542, 'weight_decay': 3.0985162602780807e-06}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:15:12,073] Trial 14 finished with value: 0.9259755443814688 and parameters: {'n_d': 20, 'n_a': 16, 'n_steps': 6, 'gamma': 1.3661385971175264, 'lambda_sparse': 4.761067713919301e-05, 'lr': 0.022185690559405346, 'weight_decay': 3.2848730408469187e-06}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:16:42,855] Trial 15 finished with value: 0.8996860242619776 and parameters: {'n_d': 17, 'n_a': 8, 'n_steps': 6, 'gamma': 1.5697882933284588, 'lambda_sparse': 4.02387428055364e-05, 'lr': 0.004953171715871577, 'weight_decay': 4.406682331349498e-06}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:18:18,617] Trial 16 finished with value: 0.9015773712411161 and parameters: {'n_d': 8, 'n_a': 23, 'n_steps': 7, 'gamma': 1.3873172020435596, 'lambda_sparse': 3.2843548708892705e-05, 'lr': 0.028055362289528922, 'weight_decay': 1.2156695420493635e-06}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:19:36,264] Trial 17 finished with value: 0.9010423467007718 and parameters: {'n_d': 21, 'n_a': 21, 'n_steps': 5, 'gamma': 1.1172844565512694, 'lambda_sparse': 1.1435474500557847e-05, 'lr': 0.0025126803699804514, 'weight_decay': 2.1369330512866165e-05}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:21:26,771] Trial 18 finished with value: 0.892302299755979 and parameters: {'n_d': 32, 'n_a': 39, 'n_steps': 8, 'gamma': 1.5260229665069651, 'lambda_sparse': 0.0006970943438704189, 'lr': 0.008860484131069046, 'weight_decay': 0.0003384474938640664}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:23:15,026] Trial 19 finished with value: 0.9206026429621663 and parameters: {'n_d': 19, 'n_a': 14, 'n_steps': 8, 'gamma': 1.1424219564413418, 'lambda_sparse': 0.0001927098409414978, 'lr': 0.0339705563504061, 'weight_decay': 5.10554558900444e-06}. Best is trial 11 with value: 0.9303102187289346.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:25:48,264] A new study created in memory with name: no-name-098a70bd-c9e9-47e3-849a-7db99c5b0b59
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:27:29,294] Trial 0 finished with value: 0.9176723613722028 and parameters: {'n_d': 52, 'n_a': 52, 'n_steps': 7, 'gamma': 1.1318924272862965, 'lambda_sparse': 5.911457821414611e-05, 'lr': 0.07198301391243468, 'weight_decay': 3.3923286363029835e-06}. Best is trial 0 with value: 0.9176723613722028.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:28:37,359] Trial 1 finished with value: 0.8957803201470338 and parameters: {'n_d': 39, 'n_a': 25, 'n_steps': 3, 'gamma': 1.4279635399648698, 'lambda_sparse': 4.947101077794035e-05, 'lr': 0.0007693435593815522, 'weight_decay': 2.286216218334639e-06}. Best is trial 0 with value: 0.9176723613722028.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:30:40,232] Trial 2 finished with value: 0.4502455064268519 and parameters: {'n_d': 24, 'n_a': 16, 'n_steps': 9, 'gamma': 1.8411991573455064, 'lambda_sparse': 9.315485443054174e-05, 'lr': 0.00040063007339595296, 'weight_decay': 0.00017151300004590372}. Best is trial 0 with value: 0.9176723613722028.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:32:00,851] Trial 3 finished with value: 0.9204013988081426 and parameters: {'n_d': 59, 'n_a': 11, 'n_steps': 5, 'gamma': 1.8122371963189847, 'lambda_sparse': 5.090040874362857e-05, 'lr': 0.0313100531725142, 'weight_decay': 0.00028155935067572996}. Best is trial 3 with value: 0.9204013988081426.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:33:31,399] Trial 4 finished with value: 0.8594378220150177 and parameters: {'n_d': 50, 'n_a': 30, 'n_steps': 6, 'gamma': 1.2831731898923906, 'lambda_sparse': 4.557334742357625e-05, 'lr': 0.0005101808575020564, 'weight_decay': 9.929789199507564e-05}. Best is trial 3 with value: 0.9204013988081426.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:35:11,549] Trial 5 finished with value: 0.8896505751102397 and parameters: {'n_d': 46, 'n_a': 15, 'n_steps': 7, 'gamma': 1.7860037905378938, 'lambda_sparse': 2.784911115177834e-05, 'lr': 0.04886765408503192, 'weight_decay': 6.082151826531856e-06}. Best is trial 3 with value: 0.9204013988081426.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:37:15,717] Trial 6 finished with value: 0.9036946606392221 and parameters: {'n_d': 17, 'n_a': 57, 'n_steps': 9, 'gamma': 1.7977571633734828, 'lambda_sparse': 0.0001020083252355957, 'lr': 0.013871506032395314, 'weight_decay': 0.00015869901941304636}. Best is trial 3 with value: 0.9204013988081426.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:38:45,525] Trial 7 finished with value: 0.9213329219882904 and parameters: {'n_d': 8, 'n_a': 48, 'n_steps': 6, 'gamma': 1.2698422745512934, 'lambda_sparse': 0.00033081065064522396, 'lr': 0.007349343419987441, 'weight_decay': 0.0003005530661625933}. Best is trial 7 with value: 0.9213329219882904.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:40:36,156] Trial 8 finished with value: 0.8972442393353683 and parameters: {'n_d': 39, 'n_a': 55, 'n_steps': 8, 'gamma': 1.5868166294864894, 'lambda_sparse': 1.391860996914809e-05, 'lr': 0.0027527958049797397, 'weight_decay': 0.0007074712054890064}. Best is trial 7 with value: 0.9213329219882904.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:41:56,346] Trial 9 finished with value: 0.8992677346055873 and parameters: {'n_d': 17, 'n_a': 10, 'n_steps': 5, 'gamma': 1.2665539180946275, 'lambda_sparse': 0.00033401807003799504, 'lr': 0.0020572949173788637, 'weight_decay': 2.845568806078142e-06}. Best is trial 7 with value: 0.9213329219882904.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:43:07,075] Trial 10 finished with value: 0.9283016261872349 and parameters: {'n_d': 10, 'n_a': 42, 'n_steps': 3, 'gamma': 1.0299988854302922, 'lambda_sparse': 0.003099297034562831, 'lr': 0.012830326818818596, 'weight_decay': 1.8818570689253983e-05}. Best is trial 10 with value: 0.9283016261872349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:44:15,833] Trial 11 finished with value: 0.9330672520703711 and parameters: {'n_d': 8, 'n_a': 42, 'n_steps': 3, 'gamma': 1.1017866444531008, 'lambda_sparse': 0.00331634730484517, 'lr': 0.009309000402330674, 'weight_decay': 2.255735925680766e-05}. Best is trial 11 with value: 0.9330672520703711.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:45:23,457] Trial 12 finished with value: 0.7879899247328335 and parameters: {'n_d': 9, 'n_a': 41, 'n_steps': 3, 'gamma': 1.0150749212518664, 'lambda_sparse': 0.004504293201766045, 'lr': 0.00011391522432399227, 'weight_decay': 1.9395925754736033e-05}. Best is trial 11 with value: 0.9330672520703711.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:46:45,035] Trial 13 finished with value: 0.9205546368303842 and parameters: {'n_d': 25, 'n_a': 40, 'n_steps': 4, 'gamma': 1.010396147857058, 'lambda_sparse': 0.0053961133725682646, 'lr': 0.008450095399670766, 'weight_decay': 2.02846428901405e-05}. Best is trial 11 with value: 0.9330672520703711.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:47:03,328] Trial 14 finished with value: -39.795552646502074 and parameters: {'n_d': 28, 'n_a': 64, 'n_steps': 4, 'gamma': 1.1409024964576113, 'lambda_sparse': 0.0016319761505741671, 'lr': 0.017965876807943055, 'weight_decay': 4.057711896434899e-05}. Best is trial 11 with value: 0.9330672520703711.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:48:10,898] Trial 15 finished with value: 0.9271476568240747 and parameters: {'n_d': 16, 'n_a': 34, 'n_steps': 3, 'gamma': 1.572130152320163, 'lambda_sparse': 0.002195335834847585, 'lr': 0.005594217704100148, 'weight_decay': 1.0930597219971582e-05}. Best is trial 11 with value: 0.9330672520703711.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:49:32,945] Trial 16 finished with value: 0.9335020556543777 and parameters: {'n_d': 32, 'n_a': 45, 'n_steps': 4, 'gamma': 1.4310497520745145, 'lambda_sparse': 0.0011501259610298311, 'lr': 0.023786647668141172, 'weight_decay': 4.891713221929396e-05}. Best is trial 16 with value: 0.9335020556543777.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:50:56,067] Trial 17 finished with value: 0.9271722380417661 and parameters: {'n_d': 31, 'n_a': 46, 'n_steps': 4, 'gamma': 1.4247240167176065, 'lambda_sparse': 0.000901859805270901, 'lr': 0.0304213546251201, 'weight_decay': 5.850154317240757e-05}. Best is trial 16 with value: 0.9335020556543777.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:52:18,003] Trial 18 finished with value: 0.8765673672445553 and parameters: {'n_d': 35, 'n_a': 26, 'n_steps': 5, 'gamma': 1.9919311906096713, 'lambda_sparse': 0.00796693408606253, 'lr': 0.0016925752277955034, 'weight_decay': 6.327091604425354e-05}. Best is trial 16 with value: 0.9335020556543777.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:54:31,959] Trial 19 finished with value: 0.908480626806855 and parameters: {'n_d': 64, 'n_a': 35, 'n_steps': 10, 'gamma': 1.6398745217865733, 'lambda_sparse': 0.000816191078641177, 'lr': 0.09385545960745909, 'weight_decay': 1.2951843297767331e-06}. Best is trial 16 with value: 0.9335020556543777.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:56:13,646] A new study created in memory with name: no-name-ed9852be-d4e1-40db-8e1e-56fbb45cfdfb
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:57:28,824] Trial 0 finished with value: 0.9009315587359471 and parameters: {'n_d': 50, 'n_a': 59, 'n_steps': 4, 'gamma': 1.2772624543140298, 'lambda_sparse': 0.0016761110629575859, 'lr': 0.0008831168516032432, 'weight_decay': 0.0007594976133143829}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 01:59:11,584] Trial 1 finished with value: -0.4584185405077075 and parameters: {'n_d': 56, 'n_a': 58, 'n_steps': 7, 'gamma': 1.9250466365820846, 'lambda_sparse': 0.00017760086149302292, 'lr': 0.00010004485365809103, 'weight_decay': 0.0003022360213984187}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:01:03,484] Trial 2 finished with value: 0.8449752501446434 and parameters: {'n_d': 10, 'n_a': 22, 'n_steps': 8, 'gamma': 1.711491266016199, 'lambda_sparse': 0.0052279419453797275, 'lr': 0.005309089426600555, 'weight_decay': 0.0008170170324216364}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:03:18,804] Trial 3 finished with value: 0.891924003714069 and parameters: {'n_d': 49, 'n_a': 27, 'n_steps': 10, 'gamma': 1.4010005435459085, 'lambda_sparse': 3.427645852279527e-05, 'lr': 0.01310744918122293, 'weight_decay': 0.0008484688949783091}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:04:38,945] Trial 4 finished with value: 0.862191701273297 and parameters: {'n_d': 54, 'n_a': 22, 'n_steps': 5, 'gamma': 1.8927682932719905, 'lambda_sparse': 0.00141159943319534, 'lr': 0.0028528342207995386, 'weight_decay': 1.2254037255021972e-06}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:06:19,296] Trial 5 finished with value: 0.8955963640311331 and parameters: {'n_d': 58, 'n_a': 17, 'n_steps': 7, 'gamma': 1.7634930558850614, 'lambda_sparse': 0.0006112059230441674, 'lr': 0.02719307241780128, 'weight_decay': 6.975876453330569e-06}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:08:24,496] Trial 6 finished with value: 0.8110484385636301 and parameters: {'n_d': 15, 'n_a': 35, 'n_steps': 9, 'gamma': 1.7354956040027565, 'lambda_sparse': 3.187607657952901e-05, 'lr': 0.002956327243516036, 'weight_decay': 0.00019290220359720797}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:10:07,151] Trial 7 finished with value: 0.8857858517087094 and parameters: {'n_d': 53, 'n_a': 16, 'n_steps': 7, 'gamma': 1.1598978869019656, 'lambda_sparse': 0.0024212618595774206, 'lr': 0.0016913845909925348, 'weight_decay': 3.919390248804861e-05}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:11:06,504] Trial 8 finished with value: 0.5720800348106428 and parameters: {'n_d': 11, 'n_a': 46, 'n_steps': 9, 'gamma': 1.8630900658694338, 'lambda_sparse': 1.6577976736758257e-05, 'lr': 0.07126498585232914, 'weight_decay': 5.414647523437967e-06}. Best is trial 0 with value: 0.9009315587359471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:12:22,575] Trial 9 finished with value: 0.9063083868022436 and parameters: {'n_d': 35, 'n_a': 24, 'n_steps': 5, 'gamma': 1.1445365114080273, 'lambda_sparse': 0.0015679744482905592, 'lr': 0.043160480241932954, 'weight_decay': 3.9315458807486976e-05}. Best is trial 9 with value: 0.9063083868022436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:13:00,666] Trial 10 finished with value: 0.8251477900028215 and parameters: {'n_d': 31, 'n_a': 9, 'n_steps': 3, 'gamma': 1.034083202180653, 'lambda_sparse': 0.00014751428725540117, 'lr': 0.08861030295772356, 'weight_decay': 3.111511455831476e-05}. Best is trial 9 with value: 0.9063083868022436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:14:23,417] Trial 11 finished with value: 0.8720017360047887 and parameters: {'n_d': 38, 'n_a': 64, 'n_steps': 4, 'gamma': 1.2992969173361608, 'lambda_sparse': 0.006854081351849445, 'lr': 0.0004787927986023832, 'weight_decay': 5.9999411370133615e-05}. Best is trial 9 with value: 0.9063083868022436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:15:45,976] Trial 12 finished with value: 0.8679429763518018 and parameters: {'n_d': 40, 'n_a': 48, 'n_steps': 5, 'gamma': 1.2433689041220033, 'lambda_sparse': 0.0007015402965891829, 'lr': 0.0005828505001984476, 'weight_decay': 0.00013477060937538632}. Best is trial 9 with value: 0.9063083868022436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:16:58,652] Trial 13 finished with value: 0.8242126211091352 and parameters: {'n_d': 27, 'n_a': 33, 'n_steps': 5, 'gamma': 1.4868377426289163, 'lambda_sparse': 0.0021839244731523847, 'lr': 0.0006892403408588432, 'weight_decay': 1.7876020287602605e-05}. Best is trial 9 with value: 0.9063083868022436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:18:04,052] Trial 14 finished with value: 0.8330245919156739 and parameters: {'n_d': 45, 'n_a': 45, 'n_steps': 3, 'gamma': 1.0073634687575481, 'lambda_sparse': 0.00045389079742337904, 'lr': 0.0001661547265318781, 'weight_decay': 1.1161853464485495e-06}. Best is trial 9 with value: 0.9063083868022436.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:19:16,021] Trial 15 finished with value: 0.9216011454698375 and parameters: {'n_d': 64, 'n_a': 53, 'n_steps': 4, 'gamma': 1.1768676362517745, 'lambda_sparse': 0.0014956610400808752, 'lr': 0.008143430803596762, 'weight_decay': 0.0003624451876599859}. Best is trial 15 with value: 0.9216011454698375.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:20:46,877] Trial 16 finished with value: 0.9145421711089435 and parameters: {'n_d': 64, 'n_a': 52, 'n_steps': 6, 'gamma': 1.1446535900286101, 'lambda_sparse': 0.00019102460741352953, 'lr': 0.016243948420488385, 'weight_decay': 9.514654297530601e-05}. Best is trial 15 with value: 0.9216011454698375.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:22:19,520] Trial 17 finished with value: 0.8990874012284304 and parameters: {'n_d': 64, 'n_a': 52, 'n_steps': 6, 'gamma': 1.4139194585183348, 'lambda_sparse': 0.00013673084605378535, 'lr': 0.011337125880256978, 'weight_decay': 9.945855273758995e-05}. Best is trial 15 with value: 0.9216011454698375.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:23:51,620] Trial 18 finished with value: 0.8936199016552689 and parameters: {'n_d': 64, 'n_a': 40, 'n_steps': 6, 'gamma': 1.5709247130239397, 'lambda_sparse': 7.57181169785045e-05, 'lr': 0.011161130313073626, 'weight_decay': 0.00033922609293012804}. Best is trial 15 with value: 0.9216011454698375.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:25:10,519] Trial 19 finished with value: 0.8971864230477717 and parameters: {'n_d': 24, 'n_a': 54, 'n_steps': 4, 'gamma': 1.1353898986000384, 'lambda_sparse': 0.00036786974946868763, 'lr': 0.005243974897150587, 'weight_decay': 0.000309923747380651}. Best is trial 15 with value: 0.9216011454698375.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:27:10,132] A new study created in memory with name: no-name-b3d2ab42-a577-4c69-ac9f-e5b37484e962
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:29:24,922] Trial 0 finished with value: 0.8818674962544792 and parameters: {'n_d': 13, 'n_a': 18, 'n_steps': 10, 'gamma': 1.1534492364142697, 'lambda_sparse': 0.008888006830670021, 'lr': 0.010217185580323869, 'weight_decay': 4.2207503563315786e-05}. Best is trial 0 with value: 0.8818674962544792.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:31:38,081] Trial 1 finished with value: 0.8991949493285349 and parameters: {'n_d': 43, 'n_a': 8, 'n_steps': 10, 'gamma': 1.098489148847102, 'lambda_sparse': 0.0003670232093137692, 'lr': 0.032425316013632556, 'weight_decay': 3.988802233413503e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:33:40,714] Trial 2 finished with value: 0.8734629066705426 and parameters: {'n_d': 16, 'n_a': 56, 'n_steps': 9, 'gamma': 1.5245528719862826, 'lambda_sparse': 0.00018042673478623711, 'lr': 0.0576475123138658, 'weight_decay': 0.00013409452503952628}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:35:57,633] Trial 3 finished with value: 0.5625103754745282 and parameters: {'n_d': 60, 'n_a': 41, 'n_steps': 10, 'gamma': 1.865235002960574, 'lambda_sparse': 0.000401488885882412, 'lr': 0.0004296551706028169, 'weight_decay': 0.00014188582335374037}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:37:07,122] Trial 4 finished with value: 0.8159765621155635 and parameters: {'n_d': 37, 'n_a': 43, 'n_steps': 3, 'gamma': 1.2089511930562098, 'lambda_sparse': 1.917311925301849e-05, 'lr': 0.00010276475477364813, 'weight_decay': 6.392994413941096e-05}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:38:15,429] Trial 5 finished with value: 0.8952884769919616 and parameters: {'n_d': 36, 'n_a': 60, 'n_steps': 3, 'gamma': 1.8114520371326979, 'lambda_sparse': 0.0010383322257208909, 'lr': 0.021326357116330377, 'weight_decay': 4.097220804255724e-05}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:38:47,019] Trial 6 finished with value: 0.6972855746278843 and parameters: {'n_d': 57, 'n_a': 54, 'n_steps': 6, 'gamma': 1.2570511004346585, 'lambda_sparse': 4.246421555141815e-05, 'lr': 0.07352464099153581, 'weight_decay': 0.0005941126283006975}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:40:56,627] Trial 7 finished with value: 0.8723845087612628 and parameters: {'n_d': 23, 'n_a': 48, 'n_steps': 10, 'gamma': 1.0636261601625998, 'lambda_sparse': 0.0005549723990900398, 'lr': 0.001627938453013895, 'weight_decay': 0.0001476559348939222}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:43:12,018] Trial 8 finished with value: 0.8878501522199806 and parameters: {'n_d': 58, 'n_a': 11, 'n_steps': 10, 'gamma': 1.1533919941305257, 'lambda_sparse': 0.0014899100523398077, 'lr': 0.006170431420429672, 'weight_decay': 0.0002503850869898364}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:45:26,863] Trial 9 finished with value: 0.8620235048521042 and parameters: {'n_d': 38, 'n_a': 31, 'n_steps': 10, 'gamma': 1.169496874629246, 'lambda_sparse': 1.0887333958096705e-05, 'lr': 0.0009709709362373079, 'weight_decay': 0.00018695347968540523}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:47:06,566] Trial 10 finished with value: 0.8910755189952542 and parameters: {'n_d': 46, 'n_a': 27, 'n_steps': 7, 'gamma': 1.4520966396372175, 'lambda_sparse': 7.961204537532925e-05, 'lr': 0.02400981006563444, 'weight_decay': 2.815055790341115e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:47:31,330] Trial 11 finished with value: 0.2113756291979797 and parameters: {'n_d': 25, 'n_a': 61, 'n_steps': 3, 'gamma': 1.973617240799256, 'lambda_sparse': 0.0018247101042939212, 'lr': 0.017847346894069804, 'weight_decay': 6.671104629751861e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:48:07,972] Trial 12 finished with value: 0.43548087855151074 and parameters: {'n_d': 46, 'n_a': 9, 'n_steps': 6, 'gamma': 1.7057621295932908, 'lambda_sparse': 0.001352508642370709, 'lr': 0.036833843819816484, 'weight_decay': 1.2064623649428322e-05}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:49:23,468] Trial 13 finished with value: 0.877277750282724 and parameters: {'n_d': 47, 'n_a': 22, 'n_steps': 4, 'gamma': 1.4204202020455856, 'lambda_sparse': 0.0073503822951736155, 'lr': 0.004092155454420122, 'weight_decay': 1.303369750117752e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:51:15,885] Trial 14 finished with value: 0.8801709366455641 and parameters: {'n_d': 31, 'n_a': 34, 'n_steps': 8, 'gamma': 1.6803437969658164, 'lambda_sparse': 0.00017153157750773718, 'lr': 0.012089827759449208, 'weight_decay': 1.5239844134859898e-05}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:51:48,632] Trial 15 finished with value: 0.312805703394606 and parameters: {'n_d': 41, 'n_a': 49, 'n_steps': 5, 'gamma': 1.7023085605145163, 'lambda_sparse': 0.0007844673100548965, 'lr': 0.07413701586369978, 'weight_decay': 5.344599921443481e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:53:39,343] Trial 16 finished with value: 0.8366361641456969 and parameters: {'n_d': 30, 'n_a': 17, 'n_steps': 8, 'gamma': 1.3403551655402466, 'lambda_sparse': 0.003297099739605483, 'lr': 0.002237410891510904, 'weight_decay': 2.235559208952414e-05}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:54:58,715] Trial 17 finished with value: 0.8966497035329679 and parameters: {'n_d': 51, 'n_a': 64, 'n_steps': 5, 'gamma': 1.5760100831921529, 'lambda_sparse': 0.000198607743265604, 'lr': 0.029129072598891106, 'weight_decay': 1.1384401486111043e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:56:18,340] Trial 18 finished with value: 0.8825241671169651 and parameters: {'n_d': 53, 'n_a': 40, 'n_steps': 5, 'gamma': 1.594387819314965, 'lambda_sparse': 0.00021034186451309884, 'lr': 0.007834205760356925, 'weight_decay': 1.013137106585908e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:58:02,006] Trial 19 finished with value: 0.8951619872568524 and parameters: {'n_d': 64, 'n_a': 26, 'n_steps': 7, 'gamma': 1.0167357517945068, 'lambda_sparse': 8.221719866124758e-05, 'lr': 0.038943065219292486, 'weight_decay': 2.141838289140395e-06}. Best is trial 1 with value: 0.8991949493285349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-05 03:00:47 [INFO] TabNet →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/tabnet (mean R²=0.9239)
2025-08-05 03:00:47 [INFO] Ensemble weights: TabPFN=0.335, Tree=0.331, TabNet=0.334
2025-08-05 03:00:47 [INFO] Loading individual models into memory...
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-05 03:01:09 [INFO] Saved weighted ensemble to /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-exam/final_model.pkl
