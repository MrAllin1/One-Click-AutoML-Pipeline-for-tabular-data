cpu-bind=MASK - dlcgpu13, task  0  0 [2979551]: mask 0xf0000000f set
/var/spool/slurm/job20924028/slurm_script: line 11: module: command not found
2025-08-05 12:20:11 [INFO] Using device: cuda
2025-08-05 12:20:11 [INFO] Training TabPFN model...
[I 2025-08-05 12:20:11,767] A new study created in memory with name: no-name-ab48a7bd-eff0-4025-b6ec-e2a22f268713
2025-08-05 12:20:11 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
[I 2025-08-05 12:20:52,791] Trial 0 finished with value: 0.9947661253436134 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.9947661253436134.
2025-08-05 12:20:52 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
[I 2025-08-05 12:21:36,629] Trial 1 finished with value: 0.9946630211389406 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 0 with value: 0.9947661253436134.
2025-08-05 12:21:36 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
[I 2025-08-05 12:22:00,306] Trial 2 finished with value: 0.9945498334389935 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 0 with value: 0.9947661253436134.
2025-08-05 12:22:00 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
[I 2025-08-05 12:22:27,509] Trial 3 finished with value: 0.9946654872672674 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 0 with value: 0.9947661253436134.
2025-08-05 12:22:27 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
[I 2025-08-05 12:23:07,852] Trial 4 finished with value: 0.9948113973201834 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:23:07 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
2025-08-05 12:23:10 [INFO] ⏸️ Pruned trial 5 at step 1 (R²=0.9994)
[I 2025-08-05 12:23:10,510] Trial 5 pruned. 
2025-08-05 12:23:10 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
[I 2025-08-05 12:23:51,829] Trial 6 finished with value: 0.9946090669017689 and parameters: {'n_bootstrap': 19, 'sample_frac': 0.6637017332034828}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:23:51 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
[I 2025-08-05 12:24:18,050] Trial 7 finished with value: 0.9946226267964412 and parameters: {'n_bootstrap': 12, 'sample_frac': 0.6550213529560301}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:24:18 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
[I 2025-08-05 12:24:49,460] Trial 8 finished with value: 0.9947054510229377 and parameters: {'n_bootstrap': 13, 'sample_frac': 0.7574269294896714}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:24:49 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
[I 2025-08-05 12:25:20,675] Trial 9 finished with value: 0.9947570850691764 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.6873687420594126}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:25:20 [INFO] 🔍 Trial 10: n_bootstrap=17, sample_frac=0.82
2025-08-05 12:25:23 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.9995)
[I 2025-08-05 12:25:23,142] Trial 10 pruned. 
2025-08-05 12:25:23 [INFO] 🔍 Trial 11: n_bootstrap=15, sample_frac=0.83
2025-08-05 12:25:25 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.9995)
[I 2025-08-05 12:25:25,643] Trial 11 pruned. 
2025-08-05 12:25:25 [INFO] 🔍 Trial 12: n_bootstrap=16, sample_frac=0.87
2025-08-05 12:25:28 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.9994)
[I 2025-08-05 12:25:28,309] Trial 12 pruned. 
2025-08-05 12:25:28 [INFO] 🔍 Trial 13: n_bootstrap=20, sample_frac=0.72
[I 2025-08-05 12:26:15,061] Trial 13 finished with value: 0.9946675070334579 and parameters: {'n_bootstrap': 20, 'sample_frac': 0.7177358676307897}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:26:15 [INFO] 🔍 Trial 14: n_bootstrap=15, sample_frac=0.60
[I 2025-08-05 12:26:45,917] Trial 14 finished with value: 0.9946951933808392 and parameters: {'n_bootstrap': 15, 'sample_frac': 0.6039530197390021}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:26:45 [INFO] 🔍 Trial 15: n_bootstrap=17, sample_frac=0.81
2025-08-05 12:26:48 [INFO] ⏸️ Pruned trial 15 at step 1 (R²=0.9995)
[I 2025-08-05 12:26:48,416] Trial 15 pruned. 
2025-08-05 12:26:48 [INFO] 🔍 Trial 16: n_bootstrap=13, sample_frac=0.85
2025-08-05 12:26:50 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.9994)
[I 2025-08-05 12:26:50,972] Trial 16 pruned. 
2025-08-05 12:26:50 [INFO] 🔍 Trial 17: n_bootstrap=16, sample_frac=0.79
2025-08-05 12:26:53 [INFO] ⏸️ Pruned trial 17 at step 1 (R²=0.9995)
[I 2025-08-05 12:26:53,395] Trial 17 pruned. 
2025-08-05 12:26:53 [INFO] 🔍 Trial 18: n_bootstrap=14, sample_frac=0.90
2025-08-05 12:26:56 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.9995)
[I 2025-08-05 12:26:56,091] Trial 18 pruned. 
2025-08-05 12:26:56 [INFO] 🔍 Trial 19: n_bootstrap=17, sample_frac=0.74
[I 2025-08-05 12:27:36,104] Trial 19 finished with value: 0.9946799546784977 and parameters: {'n_bootstrap': 17, 'sample_frac': 0.7365866415929077}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:27:36 [INFO] 🔍 Trial 20: n_bootstrap=14, sample_frac=0.84
2025-08-05 12:27:38 [INFO] ⏸️ Pruned trial 20 at step 1 (R²=0.9994)
[I 2025-08-05 12:27:38,694] Trial 20 pruned. 
2025-08-05 12:27:38 [INFO] 🔍 Trial 21: n_bootstrap=14, sample_frac=0.71
2025-08-05 12:27:40 [INFO] ⏸️ Pruned trial 21 at step 1 (R²=0.9995)
[I 2025-08-05 12:27:40,920] Trial 21 pruned. 
2025-08-05 12:27:40 [INFO] 🔍 Trial 22: n_bootstrap=13, sample_frac=0.78
2025-08-05 12:27:43 [INFO] ⏸️ Pruned trial 22 at step 1 (R²=0.9995)
[I 2025-08-05 12:27:43,340] Trial 22 pruned. 
2025-08-05 12:27:43 [INFO] 🔍 Trial 23: n_bootstrap=15, sample_frac=0.69
[I 2025-08-05 12:28:16,994] Trial 23 finished with value: 0.9947556410146937 and parameters: {'n_bootstrap': 15, 'sample_frac': 0.6883526733161716}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:28:17 [INFO] 🔍 Trial 24: n_bootstrap=12, sample_frac=0.75
2025-08-05 12:28:19 [INFO] ⏸️ Pruned trial 24 at step 1 (R²=0.9995)
[I 2025-08-05 12:28:19,341] Trial 24 pruned. 
2025-08-05 12:28:19 [INFO] 🔍 Trial 25: n_bootstrap=16, sample_frac=0.62
[I 2025-08-05 12:28:52,666] Trial 25 finished with value: 0.9947190355102992 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.6188127426802384}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:28:52 [INFO] 🔍 Trial 26: n_bootstrap=15, sample_frac=0.87
2025-08-05 12:28:55 [INFO] ⏸️ Pruned trial 26 at step 1 (R²=0.9994)
[I 2025-08-05 12:28:55,300] Trial 26 pruned. 
2025-08-05 12:28:55 [INFO] 🔍 Trial 27: n_bootstrap=12, sample_frac=0.80
2025-08-05 12:28:57 [INFO] ⏸️ Pruned trial 27 at step 1 (R²=0.9995)
[I 2025-08-05 12:28:57,753] Trial 27 pruned. 
2025-08-05 12:28:57 [INFO] 🔍 Trial 28: n_bootstrap=18, sample_frac=0.69
[I 2025-08-05 12:29:38,124] Trial 28 finished with value: 0.9945716551586714 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.6910338902665674}. Best is trial 4 with value: 0.9948113973201834.
2025-08-05 12:29:38 [INFO] 🔍 Trial 29: n_bootstrap=18, sample_frac=0.73
2025-08-05 12:29:40 [INFO] ⏸️ Pruned trial 29 at step 1 (R²=0.9995)
[I 2025-08-05 12:29:40,426] Trial 29 pruned. 
2025-08-05 12:29:40 [INFO] 🏆 Best Params: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}, R²=0.99481
2025-08-05 12:29:40 [INFO] Bootstrap training → dataset=brazilian_houses, device=cuda
2025-08-05 12:29:40 [INFO] [1/16] bootstrap sample size=3421
2025-08-05 12:29:43 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_1.pkl
2025-08-05 12:29:43 [INFO] [2/16] bootstrap sample size=3421
2025-08-05 12:29:48 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_2.pkl
2025-08-05 12:29:48 [INFO] [3/16] bootstrap sample size=3421
2025-08-05 12:29:51 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_3.pkl
2025-08-05 12:29:51 [INFO] [4/16] bootstrap sample size=3421
2025-08-05 12:29:53 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_4.pkl
2025-08-05 12:29:54 [INFO] [5/16] bootstrap sample size=3421
2025-08-05 12:29:56 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_5.pkl
2025-08-05 12:29:56 [INFO] [6/16] bootstrap sample size=3421
2025-08-05 12:29:59 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_6.pkl
2025-08-05 12:29:59 [INFO] [7/16] bootstrap sample size=3421
2025-08-05 12:30:02 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_7.pkl
2025-08-05 12:30:02 [INFO] [8/16] bootstrap sample size=3421
2025-08-05 12:30:04 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_8.pkl
2025-08-05 12:30:04 [INFO] [9/16] bootstrap sample size=3421
2025-08-05 12:30:07 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_9.pkl
2025-08-05 12:30:07 [INFO] [10/16] bootstrap sample size=3421
2025-08-05 12:30:11 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_10.pkl
2025-08-05 12:30:11 [INFO] [11/16] bootstrap sample size=3421
2025-08-05 12:30:15 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_11.pkl
2025-08-05 12:30:15 [INFO] [12/16] bootstrap sample size=3421
2025-08-05 12:30:18 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_12.pkl
2025-08-05 12:30:18 [INFO] [13/16] bootstrap sample size=3421
2025-08-05 12:30:20 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_13.pkl
2025-08-05 12:30:21 [INFO] [14/16] bootstrap sample size=3421
2025-08-05 12:30:23 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_14.pkl
2025-08-05 12:30:23 [INFO] [15/16] bootstrap sample size=3421
2025-08-05 12:30:26 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_15.pkl
2025-08-05 12:30:26 [INFO] [16/16] bootstrap sample size=3421
2025-08-05 12:30:29 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/bootstrap_16.pkl
2025-08-05 12:30:29 [INFO] 📊 Final OOB R² = 0.99481
2025-08-05 12:30:35 [INFO] Saved ensemble → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/ensemble.pkl
2025-08-05 12:30:35 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-05 12:30:35 [INFO] Total time: 54.8s
2025-08-05 12:30:35 [INFO] TabPFN →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/brazilian_houses/ensemble.pkl (R²=0.9948)
2025-08-05 12:30:35 [INFO] Training tree-based model...
2025-08-05 12:30:35 [INFO] AutoML pipeline started
2025-08-05 12:30:35 [INFO] Output directory '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses' is ready and logging is configured.
2025-08-05 12:30:35 [INFO] Merged training data: 4212 rows
2025-08-05 12:30:35 [INFO] Split data into pool (3790 rows) and validation (422 rows)
2025-08-05 12:30:35 [INFO] Feature engineering completed: 11 features
[I 2025-08-05 12:30:35,302] A new study created in memory with name: no-name-a09a79d2-7dd4-4805-a09c-4711d1c19f91
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-05 12:33:31,586] Trial 0 finished with value: -0.9830612446660296 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.9830612446660296.
[I 2025-08-05 12:33:37,514] Trial 1 finished with value: -0.9888740677795781 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-05 12:34:48,068] Trial 2 finished with value: -0.9844131707527499 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-05 12:34:52,137] Trial 3 finished with value: -0.9875646494125891 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-05 12:35:01,784] Trial 4 finished with value: -0.9857845286914062 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-05 12:35:07,088] Trial 5 finished with value: -0.9882095727768767 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-05 12:36:29,989] Trial 6 finished with value: -0.983355054504821 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 1 with value: -0.9888740677795781.
[I 2025-08-05 12:36:34,004] Trial 7 finished with value: -0.9891723970988948 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-05 12:38:58,651] Trial 8 finished with value: -0.9787649489967307 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-05 12:39:02,902] Trial 9 finished with value: -0.9890264646974869 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-05 12:39:06,134] Trial 10 finished with value: -0.9846699366865703 and parameters: {'learning_rate': 0.2552948136610821, 'depth': 7, 'l2_leaf_reg': 6.215107140682327, 'border_count': 36}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-05 12:39:09,461] Trial 11 finished with value: -0.9856480668107046 and parameters: {'learning_rate': 0.11386552028513468, 'depth': 4, 'l2_leaf_reg': 7.6878249427006295, 'border_count': 34}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-05 12:39:17,710] Trial 12 finished with value: -0.987193965492055 and parameters: {'learning_rate': 0.02131175919937471, 'depth': 7, 'l2_leaf_reg': 6.714957031037731, 'border_count': 170}. Best is trial 7 with value: -0.9891723970988948.
[I 2025-08-05 12:39:22,060] Trial 13 finished with value: -0.9892486566616215 and parameters: {'learning_rate': 0.05491899012584811, 'depth': 4, 'l2_leaf_reg': 9.338493890692899, 'border_count': 78}. Best is trial 13 with value: -0.9892486566616215.
[I 2025-08-05 12:39:27,847] Trial 14 finished with value: -0.9881261698662263 and parameters: {'learning_rate': 0.06271124466425858, 'depth': 6, 'l2_leaf_reg': 9.554836484635672, 'border_count': 79}. Best is trial 13 with value: -0.9892486566616215.
[I 2025-08-05 12:39:38,141] Trial 15 finished with value: -0.9845506545608348 and parameters: {'learning_rate': 0.11519240087159174, 'depth': 9, 'l2_leaf_reg': 8.787983927901438, 'border_count': 62}. Best is trial 13 with value: -0.9892486566616215.
[I 2025-08-05 12:39:42,624] Trial 16 finished with value: -0.9899199320720229 and parameters: {'learning_rate': 0.04704643856781044, 'depth': 4, 'l2_leaf_reg': 5.043875815493685, 'border_count': 108}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:39:48,797] Trial 17 finished with value: -0.9886157762422559 and parameters: {'learning_rate': 0.04299159344815616, 'depth': 6, 'l2_leaf_reg': 4.9431715074202085, 'border_count': 110}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:39:55,318] Trial 18 finished with value: -0.9895998320933137 and parameters: {'learning_rate': 0.11561513904055767, 'depth': 6, 'l2_leaf_reg': 3.9276183289831463, 'border_count': 135}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:01,925] Trial 19 finished with value: -0.9872271720693492 and parameters: {'learning_rate': 0.26369018334394767, 'depth': 6, 'l2_leaf_reg': 3.913972053768391, 'border_count': 178}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:13,410] Trial 20 finished with value: -0.9868889974875408 and parameters: {'learning_rate': 0.13118618358879097, 'depth': 8, 'l2_leaf_reg': 5.4245808762372265, 'border_count': 141}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:17,884] Trial 21 finished with value: -0.9888440983540973 and parameters: {'learning_rate': 0.056667833645229634, 'depth': 4, 'l2_leaf_reg': 4.136091875403359, 'border_count': 95}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:23,204] Trial 22 finished with value: -0.9888092922887941 and parameters: {'learning_rate': 0.03495597071590568, 'depth': 5, 'l2_leaf_reg': 2.988016042438531, 'border_count': 123}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:30,565] Trial 23 finished with value: -0.9875103168648508 and parameters: {'learning_rate': 0.16624339820308198, 'depth': 7, 'l2_leaf_reg': 8.403430812183041, 'border_count': 93}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:35,557] Trial 24 finished with value: -0.988966025956415 and parameters: {'learning_rate': 0.08902635280281779, 'depth': 5, 'l2_leaf_reg': 5.334907331464369, 'border_count': 147}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:40,836] Trial 25 finished with value: -0.9869027635764869 and parameters: {'learning_rate': 0.04920332711565596, 'depth': 6, 'l2_leaf_reg': 5.922666336816717, 'border_count': 53}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:45,138] Trial 26 finished with value: -0.989551346486736 and parameters: {'learning_rate': 0.17665845012530415, 'depth': 4, 'l2_leaf_reg': 4.527544405036116, 'border_count': 107}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:50,727] Trial 27 finished with value: -0.9886665477586934 and parameters: {'learning_rate': 0.17874908286272934, 'depth': 5, 'l2_leaf_reg': 4.291562172687347, 'border_count': 182}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:40:57,397] Trial 28 finished with value: -0.9890307332974073 and parameters: {'learning_rate': 0.22042554420520363, 'depth': 6, 'l2_leaf_reg': 2.2196208754278413, 'border_count': 197}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:41:02,091] Trial 29 finished with value: -0.9893403714778121 and parameters: {'learning_rate': 0.12644890036298762, 'depth': 4, 'l2_leaf_reg': 3.3677981070036513, 'border_count': 151}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:41:10,211] Trial 30 finished with value: -0.9886994175452533 and parameters: {'learning_rate': 0.1998424663219883, 'depth': 7, 'l2_leaf_reg': 4.606184156177052, 'border_count': 129}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:41:14,927] Trial 31 finished with value: -0.9898760818361817 and parameters: {'learning_rate': 0.13360557464541079, 'depth': 4, 'l2_leaf_reg': 3.5269241579943778, 'border_count': 159}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:41:20,069] Trial 32 finished with value: -0.9884711925014498 and parameters: {'learning_rate': 0.09525674311720078, 'depth': 5, 'l2_leaf_reg': 1.7684683207332768, 'border_count': 107}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:41:24,338] Trial 33 finished with value: -0.9898492228691321 and parameters: {'learning_rate': 0.29617315369159336, 'depth': 4, 'l2_leaf_reg': 3.151894961641595, 'border_count': 160}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:41:29,818] Trial 34 finished with value: -0.9894046871757738 and parameters: {'learning_rate': 0.14910999270278194, 'depth': 5, 'l2_leaf_reg': 3.363970091218451, 'border_count': 158}. Best is trial 16 with value: -0.9899199320720229.
[I 2025-08-05 12:41:34,655] Trial 35 finished with value: -0.9912749589890518 and parameters: {'learning_rate': 0.10262523980364108, 'depth': 4, 'l2_leaf_reg': 2.618080916894446, 'border_count': 196}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:41:39,601] Trial 36 finished with value: -0.9894313680821238 and parameters: {'learning_rate': 0.06637088038450864, 'depth': 4, 'l2_leaf_reg': 1.1562256315519184, 'border_count': 228}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:42:03,095] Trial 37 finished with value: -0.9851497433824834 and parameters: {'learning_rate': 0.03783235435214252, 'depth': 9, 'l2_leaf_reg': 2.1606625031814826, 'border_count': 192}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:42:09,017] Trial 38 finished with value: -0.988781595211775 and parameters: {'learning_rate': 0.28029656436703526, 'depth': 5, 'l2_leaf_reg': 2.3603387125583275, 'border_count': 255}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:42:13,910] Trial 39 finished with value: -0.9905835584560612 and parameters: {'learning_rate': 0.09967369743653258, 'depth': 4, 'l2_leaf_reg': 1.6824399155666263, 'border_count': 210}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:21,308] Trial 40 finished with value: -0.9828918759739119 and parameters: {'learning_rate': 0.09765723519629871, 'depth': 11, 'l2_leaf_reg': 1.6137794177875469, 'border_count': 233}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:26,041] Trial 41 finished with value: -0.9902188802049592 and parameters: {'learning_rate': 0.14632978137200253, 'depth': 4, 'l2_leaf_reg': 2.9782990472695077, 'border_count': 162}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:30,938] Trial 42 finished with value: -0.9903284782591808 and parameters: {'learning_rate': 0.07713582695477122, 'depth': 4, 'l2_leaf_reg': 2.533345117695543, 'border_count': 210}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:36,820] Trial 43 finished with value: -0.9898155063521452 and parameters: {'learning_rate': 0.0748334310474749, 'depth': 5, 'l2_leaf_reg': 2.7580485985712784, 'border_count': 214}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:41,696] Trial 44 finished with value: -0.9904400657537634 and parameters: {'learning_rate': 0.08613907326243302, 'depth': 4, 'l2_leaf_reg': 1.7821883308729478, 'border_count': 208}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:46,578] Trial 45 finished with value: -0.9900035573115487 and parameters: {'learning_rate': 0.08352081515252029, 'depth': 4, 'l2_leaf_reg': 1.812731097726318, 'border_count': 208}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:52,506] Trial 46 finished with value: -0.9884387292722783 and parameters: {'learning_rate': 0.09872370683183171, 'depth': 5, 'l2_leaf_reg': 1.0567185223553839, 'border_count': 239}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:44:57,343] Trial 47 finished with value: -0.9910155436484696 and parameters: {'learning_rate': 0.07718283286866867, 'depth': 4, 'l2_leaf_reg': 2.5333108108441276, 'border_count': 200}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:03,256] Trial 48 finished with value: -0.9892412260653641 and parameters: {'learning_rate': 0.06963778588914839, 'depth': 5, 'l2_leaf_reg': 2.4087432503165256, 'border_count': 219}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:08,105] Trial 49 finished with value: -0.9903883592626059 and parameters: {'learning_rate': 0.060924473428840144, 'depth': 4, 'l2_leaf_reg': 1.8705795459258323, 'border_count': 204}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:32,384] Trial 50 finished with value: -0.9850701257185775 and parameters: {'learning_rate': 0.10645501074520745, 'depth': 9, 'l2_leaf_reg': 1.3457301493587808, 'border_count': 199}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:37,273] Trial 51 finished with value: -0.9901291743995616 and parameters: {'learning_rate': 0.06041869597748931, 'depth': 4, 'l2_leaf_reg': 2.0165423024795235, 'border_count': 203}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:42,251] Trial 52 finished with value: -0.9902296642705952 and parameters: {'learning_rate': 0.07257543392730571, 'depth': 4, 'l2_leaf_reg': 2.561870640508954, 'border_count': 242}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:47,844] Trial 53 finished with value: -0.9887578893046556 and parameters: {'learning_rate': 0.0830551642184434, 'depth': 5, 'l2_leaf_reg': 1.5408111770251711, 'border_count': 186}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:52,734] Trial 54 finished with value: -0.9906509282511087 and parameters: {'learning_rate': 0.053873047784201974, 'depth': 4, 'l2_leaf_reg': 1.9450121852618725, 'border_count': 221}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:45:57,226] Trial 55 finished with value: -0.9894396901121814 and parameters: {'learning_rate': 0.05142512487606263, 'depth': 4, 'l2_leaf_reg': 1.8645019047354299, 'border_count': 176}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:46:03,184] Trial 56 finished with value: -0.9891697354237283 and parameters: {'learning_rate': 0.04047131582012417, 'depth': 5, 'l2_leaf_reg': 1.3341049623833388, 'border_count': 223}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:46:07,925] Trial 57 finished with value: -0.9884949709261331 and parameters: {'learning_rate': 0.011609930160367014, 'depth': 4, 'l2_leaf_reg': 2.177588313105877, 'border_count': 188}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:46:13,828] Trial 58 finished with value: -0.9894423758755269 and parameters: {'learning_rate': 0.029126146979250485, 'depth': 5, 'l2_leaf_reg': 1.546806937436294, 'border_count': 219}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:49:25,723] Trial 59 finished with value: -0.9817527346970207 and parameters: {'learning_rate': 0.06103520728119887, 'depth': 12, 'l2_leaf_reg': 2.917557519145487, 'border_count': 172}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:49:30,713] Trial 60 finished with value: -0.9887987432619582 and parameters: {'learning_rate': 0.04469964582841724, 'depth': 4, 'l2_leaf_reg': 1.022917573570061, 'border_count': 234}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:49:35,596] Trial 61 finished with value: -0.9902163012657897 and parameters: {'learning_rate': 0.07873102149786142, 'depth': 4, 'l2_leaf_reg': 2.3932796534129412, 'border_count': 208}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:49:40,510] Trial 62 finished with value: -0.9907817476122951 and parameters: {'learning_rate': 0.08638158175645762, 'depth': 4, 'l2_leaf_reg': 2.651332398103982, 'border_count': 211}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:49:45,155] Trial 63 finished with value: -0.99007251295722 and parameters: {'learning_rate': 0.10824296663951714, 'depth': 4, 'l2_leaf_reg': 2.0128337904720897, 'border_count': 196}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:49:51,121] Trial 64 finished with value: -0.9899970346861812 and parameters: {'learning_rate': 0.08906364469061084, 'depth': 5, 'l2_leaf_reg': 3.814657302619673, 'border_count': 226}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:49:55,985] Trial 65 finished with value: -0.9905604196207577 and parameters: {'learning_rate': 0.0595415354706779, 'depth': 4, 'l2_leaf_reg': 2.730260568640568, 'border_count': 203}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:03,418] Trial 66 finished with value: -0.9895716704567585 and parameters: {'learning_rate': 0.0540847194678496, 'depth': 6, 'l2_leaf_reg': 2.5933301166925893, 'border_count': 215}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:08,430] Trial 67 finished with value: -0.9905390544280804 and parameters: {'learning_rate': 0.11859158872377654, 'depth': 4, 'l2_leaf_reg': 2.7906983735983637, 'border_count': 242}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:14,512] Trial 68 finished with value: -0.9896224717231952 and parameters: {'learning_rate': 0.11449055856467757, 'depth': 5, 'l2_leaf_reg': 3.3209450002082512, 'border_count': 245}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:22,200] Trial 69 finished with value: -0.9876989365294216 and parameters: {'learning_rate': 0.014888463560777308, 'depth': 6, 'l2_leaf_reg': 3.661721529788761, 'border_count': 255}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:27,165] Trial 70 finished with value: -0.9903639042998357 and parameters: {'learning_rate': 0.06722930320465444, 'depth': 4, 'l2_leaf_reg': 2.900930983197482, 'border_count': 231}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:31,447] Trial 71 finished with value: -0.9904722263893266 and parameters: {'learning_rate': 0.12357650909738935, 'depth': 4, 'l2_leaf_reg': 2.7052642540682883, 'border_count': 221}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:36,380] Trial 72 finished with value: -0.9912418879437265 and parameters: {'learning_rate': 0.1314005112680107, 'depth': 4, 'l2_leaf_reg': 3.169590735976461, 'border_count': 222}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:41,271] Trial 73 finished with value: -0.9905188706983907 and parameters: {'learning_rate': 0.14632998622110432, 'depth': 4, 'l2_leaf_reg': 3.1794315395389976, 'border_count': 249}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:50:47,016] Trial 74 finished with value: -0.9896378594856566 and parameters: {'learning_rate': 0.09523524242132046, 'depth': 5, 'l2_leaf_reg': 3.1692293121125683, 'border_count': 190}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:51:53,259] Trial 75 finished with value: -0.9841848841930814 and parameters: {'learning_rate': 0.13471663940552486, 'depth': 10, 'l2_leaf_reg': 4.070703871987812, 'border_count': 236}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:51:58,257] Trial 76 finished with value: -0.9912141690090707 and parameters: {'learning_rate': 0.16321769011026604, 'depth': 4, 'l2_leaf_reg': 3.5415407476409344, 'border_count': 226}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:03,014] Trial 77 finished with value: -0.9911406998278297 and parameters: {'learning_rate': 0.2063717003569693, 'depth': 4, 'l2_leaf_reg': 3.5619766944767877, 'border_count': 199}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:08,575] Trial 78 finished with value: -0.9894428215951299 and parameters: {'learning_rate': 0.19239476410409145, 'depth': 5, 'l2_leaf_reg': 4.379075511061603, 'border_count': 181}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:13,226] Trial 79 finished with value: -0.9901155238150879 and parameters: {'learning_rate': 0.23110974822492386, 'depth': 4, 'l2_leaf_reg': 3.6140876963404014, 'border_count': 227}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:18,915] Trial 80 finished with value: -0.9899860041701805 and parameters: {'learning_rate': 0.15807335682179727, 'depth': 5, 'l2_leaf_reg': 7.240204839770766, 'border_count': 195}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:23,623] Trial 81 finished with value: -0.9907814406134487 and parameters: {'learning_rate': 0.2018288804355402, 'depth': 4, 'l2_leaf_reg': 2.2111254966048373, 'border_count': 202}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:28,045] Trial 82 finished with value: -0.9897019707135826 and parameters: {'learning_rate': 0.20371892590117957, 'depth': 4, 'l2_leaf_reg': 2.4185975127366675, 'border_count': 214}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:32,695] Trial 83 finished with value: -0.9902347888915418 and parameters: {'learning_rate': 0.25172629463237217, 'depth': 4, 'l2_leaf_reg': 2.162266078667419, 'border_count': 200}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:37,463] Trial 84 finished with value: -0.9907346139514406 and parameters: {'learning_rate': 0.16299139993529788, 'depth': 4, 'l2_leaf_reg': 3.4419542004956143, 'border_count': 216}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:42,380] Trial 85 finished with value: -0.9903768550782065 and parameters: {'learning_rate': 0.18235464592777523, 'depth': 4, 'l2_leaf_reg': 3.491966327899771, 'border_count': 217}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:47,334] Trial 86 finished with value: -0.9905793926190147 and parameters: {'learning_rate': 0.16592023751672846, 'depth': 4, 'l2_leaf_reg': 4.764402912829105, 'border_count': 224}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:53,206] Trial 87 finished with value: -0.9901731441239277 and parameters: {'learning_rate': 0.20811979774119307, 'depth': 5, 'l2_leaf_reg': 3.7840020821123943, 'border_count': 205}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:52:57,932] Trial 88 finished with value: -0.990603982497178 and parameters: {'learning_rate': 0.22507804108026577, 'depth': 4, 'l2_leaf_reg': 5.822341971277818, 'border_count': 183}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:11,904] Trial 89 finished with value: -0.9860190828910523 and parameters: {'learning_rate': 0.1359208053871254, 'depth': 8, 'l2_leaf_reg': 3.0442868691664633, 'border_count': 230}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:17,685] Trial 90 finished with value: -0.9895960762814017 and parameters: {'learning_rate': 0.1574276302243018, 'depth': 5, 'l2_leaf_reg': 4.02550779553221, 'border_count': 192}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:22,336] Trial 91 finished with value: -0.9907056581721886 and parameters: {'learning_rate': 0.24306760125650667, 'depth': 4, 'l2_leaf_reg': 3.228575046533984, 'border_count': 211}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:26,931] Trial 92 finished with value: -0.990775999861601 and parameters: {'learning_rate': 0.24426441214152317, 'depth': 4, 'l2_leaf_reg': 3.2897055257161005, 'border_count': 212}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:31,776] Trial 93 finished with value: -0.990441308831523 and parameters: {'learning_rate': 0.24427549943950425, 'depth': 4, 'l2_leaf_reg': 3.2783838400358603, 'border_count': 209}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:36,470] Trial 94 finished with value: -0.9901963278715276 and parameters: {'learning_rate': 0.28677572853637595, 'depth': 4, 'l2_leaf_reg': 3.4183800946591214, 'border_count': 212}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:41,235] Trial 95 finished with value: -0.9911339245526849 and parameters: {'learning_rate': 0.19073066265821512, 'depth': 4, 'l2_leaf_reg': 4.24410743345012, 'border_count': 199}. Best is trial 35 with value: -0.9912749589890518.
[I 2025-08-05 12:53:46,077] Trial 96 finished with value: -0.9915853113835247 and parameters: {'learning_rate': 0.18457985778167543, 'depth': 4, 'l2_leaf_reg': 3.7995310639985314, 'border_count': 200}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:53:51,533] Trial 97 finished with value: -0.9891529095667126 and parameters: {'learning_rate': 0.19398840970186768, 'depth': 5, 'l2_leaf_reg': 4.262009072031541, 'border_count': 166}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:53:56,328] Trial 98 finished with value: -0.9911424510728752 and parameters: {'learning_rate': 0.17919760192331344, 'depth': 4, 'l2_leaf_reg': 5.25842324125762, 'border_count': 197}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:01,115] Trial 99 finished with value: -0.9910098672531781 and parameters: {'learning_rate': 0.1824048136411049, 'depth': 4, 'l2_leaf_reg': 3.775106815754635, 'border_count': 198}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:06,815] Trial 100 finished with value: -0.9891632345456612 and parameters: {'learning_rate': 0.17482816962670344, 'depth': 5, 'l2_leaf_reg': 5.186138156623258, 'border_count': 175}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:11,630] Trial 101 finished with value: -0.9900835663444777 and parameters: {'learning_rate': 0.18566035453745927, 'depth': 4, 'l2_leaf_reg': 4.506755853893747, 'border_count': 186}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:16,211] Trial 102 finished with value: -0.9906774411329506 and parameters: {'learning_rate': 0.21373102361692814, 'depth': 4, 'l2_leaf_reg': 4.726112336751238, 'border_count': 199}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:20,854] Trial 103 finished with value: -0.9909303663399198 and parameters: {'learning_rate': 0.15001661995864954, 'depth': 4, 'l2_leaf_reg': 4.214816334568546, 'border_count': 195}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:25,687] Trial 104 finished with value: -0.9900202010476452 and parameters: {'learning_rate': 0.14190547334987139, 'depth': 4, 'l2_leaf_reg': 4.1652341991807855, 'border_count': 194}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:30,348] Trial 105 finished with value: -0.9901812925297765 and parameters: {'learning_rate': 0.10592999784148338, 'depth': 4, 'l2_leaf_reg': 3.8102262927912895, 'border_count': 191}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:35,106] Trial 106 finished with value: -0.9902078976862159 and parameters: {'learning_rate': 0.1742388860862839, 'depth': 4, 'l2_leaf_reg': 5.737601716070634, 'border_count': 182}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:44,582] Trial 107 finished with value: -0.9879364541722279 and parameters: {'learning_rate': 0.1460645659892246, 'depth': 7, 'l2_leaf_reg': 3.674163874060443, 'border_count': 205}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:48,896] Trial 108 finished with value: -0.9902275487982871 and parameters: {'learning_rate': 0.12028210740808096, 'depth': 4, 'l2_leaf_reg': 6.164802961512898, 'border_count': 196}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:54,551] Trial 109 finished with value: -0.9899795950475181 and parameters: {'learning_rate': 0.15535036084347517, 'depth': 5, 'l2_leaf_reg': 5.034389230862326, 'border_count': 188}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:54:59,390] Trial 110 finished with value: -0.9915691875452491 and parameters: {'learning_rate': 0.12761763897649395, 'depth': 4, 'l2_leaf_reg': 4.374256114675471, 'border_count': 201}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:04,242] Trial 111 finished with value: -0.9911666856807182 and parameters: {'learning_rate': 0.13092131586397324, 'depth': 4, 'l2_leaf_reg': 3.978029213080267, 'border_count': 199}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:09,024] Trial 112 finished with value: -0.9903851388584444 and parameters: {'learning_rate': 0.1305805158557615, 'depth': 4, 'l2_leaf_reg': 3.958992252052686, 'border_count': 179}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:13,668] Trial 113 finished with value: -0.9904582975863108 and parameters: {'learning_rate': 0.2670497710820697, 'depth': 4, 'l2_leaf_reg': 4.433736236354906, 'border_count': 200}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:18,158] Trial 114 finished with value: -0.9893738008383808 and parameters: {'learning_rate': 0.16913548414303625, 'depth': 4, 'l2_leaf_reg': 4.243402071215975, 'border_count': 171}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:22,966] Trial 115 finished with value: -0.9903075697641522 and parameters: {'learning_rate': 0.12782917882814074, 'depth': 4, 'l2_leaf_reg': 4.680131310391002, 'border_count': 187}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:27,749] Trial 116 finished with value: -0.9906372975050644 and parameters: {'learning_rate': 0.14950121130021293, 'depth': 4, 'l2_leaf_reg': 4.932651471816018, 'border_count': 205}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:33,529] Trial 117 finished with value: -0.9899310950422564 and parameters: {'learning_rate': 0.13888362947789493, 'depth': 5, 'l2_leaf_reg': 3.853693773949847, 'border_count': 196}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:38,164] Trial 118 finished with value: -0.9899735007205963 and parameters: {'learning_rate': 0.19049864945271433, 'depth': 4, 'l2_leaf_reg': 5.594827529957806, 'border_count': 193}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:42,972] Trial 119 finished with value: -0.9907395885249077 and parameters: {'learning_rate': 0.11164560232424234, 'depth': 4, 'l2_leaf_reg': 3.6351601678898224, 'border_count': 200}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:48,554] Trial 120 finished with value: -0.9903550127214299 and parameters: {'learning_rate': 0.15394479941773132, 'depth': 5, 'l2_leaf_reg': 5.266067660918778, 'border_count': 205}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:53,475] Trial 121 finished with value: -0.9910009566851787 and parameters: {'learning_rate': 0.09327427994074522, 'depth': 4, 'l2_leaf_reg': 3.035464421561083, 'border_count': 220}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:55:58,402] Trial 122 finished with value: -0.9913818104092407 and parameters: {'learning_rate': 0.10535653013936488, 'depth': 4, 'l2_leaf_reg': 3.9370937982574583, 'border_count': 224}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:03,317] Trial 123 finished with value: -0.990792131200837 and parameters: {'learning_rate': 0.09544561174493321, 'depth': 4, 'l2_leaf_reg': 3.078808596264404, 'border_count': 218}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:08,282] Trial 124 finished with value: -0.9907239467275539 and parameters: {'learning_rate': 0.10422982352378066, 'depth': 4, 'l2_leaf_reg': 3.9569521653762436, 'border_count': 237}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:13,238] Trial 125 finished with value: -0.9902183913601055 and parameters: {'learning_rate': 0.12115856877466238, 'depth': 4, 'l2_leaf_reg': 2.8888103078635154, 'border_count': 227}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:18,146] Trial 126 finished with value: -0.9900469757053523 and parameters: {'learning_rate': 0.08974613495232578, 'depth': 4, 'l2_leaf_reg': 3.503392624426021, 'border_count': 217}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:23,016] Trial 127 finished with value: -0.9907768119232893 and parameters: {'learning_rate': 0.1027987554624808, 'depth': 4, 'l2_leaf_reg': 3.729303112567547, 'border_count': 222}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:27,985] Trial 128 finished with value: -0.9908192269303978 and parameters: {'learning_rate': 0.1787432435223434, 'depth': 4, 'l2_leaf_reg': 4.049626078297425, 'border_count': 231}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:32,485] Trial 129 finished with value: -0.9874516828808592 and parameters: {'learning_rate': 0.11209306473388103, 'depth': 5, 'l2_leaf_reg': 4.588542601189678, 'border_count': 49}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:37,046] Trial 130 finished with value: -0.9912420371809793 and parameters: {'learning_rate': 0.21350817389225069, 'depth': 4, 'l2_leaf_reg': 3.506915794126192, 'border_count': 223}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:41,393] Trial 131 finished with value: -0.9896198262594218 and parameters: {'learning_rate': 0.22186406401851347, 'depth': 4, 'l2_leaf_reg': 9.968809662341299, 'border_count': 224}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:46,174] Trial 132 finished with value: -0.9905594835617177 and parameters: {'learning_rate': 0.19828159796751144, 'depth': 4, 'l2_leaf_reg': 3.556746598027792, 'border_count': 247}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:51,027] Trial 133 finished with value: -0.9907856835601041 and parameters: {'learning_rate': 0.12930009339711337, 'depth': 4, 'l2_leaf_reg': 3.0477990504064723, 'border_count': 207}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:56:55,884] Trial 134 finished with value: -0.9914197605899879 and parameters: {'learning_rate': 0.1694978129159271, 'depth': 4, 'l2_leaf_reg': 4.318161114703478, 'border_count': 214}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:57:00,796] Trial 135 finished with value: -0.9909326431247936 and parameters: {'learning_rate': 0.16580264733487687, 'depth': 4, 'l2_leaf_reg': 4.300267666748139, 'border_count': 213}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:57:54,863] Trial 136 finished with value: -0.9852002145022318 and parameters: {'learning_rate': 0.18250227551450093, 'depth': 10, 'l2_leaf_reg': 4.014152673339721, 'border_count': 199}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:57:59,519] Trial 137 finished with value: -0.9900550287208851 and parameters: {'learning_rate': 0.22005497594453366, 'depth': 4, 'l2_leaf_reg': 4.450973464363474, 'border_count': 241}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:03,678] Trial 138 finished with value: -0.9897910026222696 and parameters: {'learning_rate': 0.2095763863048089, 'depth': 4, 'l2_leaf_reg': 4.823661268130083, 'border_count': 118}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:17,487] Trial 139 finished with value: -0.9884109867228685 and parameters: {'learning_rate': 0.16531957529312666, 'depth': 8, 'l2_leaf_reg': 8.112575781570754, 'border_count': 208}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:23,263] Trial 140 finished with value: -0.988945743749054 and parameters: {'learning_rate': 0.23432831327536596, 'depth': 5, 'l2_leaf_reg': 3.479775140432754, 'border_count': 203}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:28,100] Trial 141 finished with value: -0.9900417593356299 and parameters: {'learning_rate': 0.02224958974429549, 'depth': 4, 'l2_leaf_reg': 3.8396985094320364, 'border_count': 220}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:32,636] Trial 142 finished with value: -0.9898516110356039 and parameters: {'learning_rate': 0.1878635077025203, 'depth': 4, 'l2_leaf_reg': 3.3012027543483033, 'border_count': 227}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:37,552] Trial 143 finished with value: -0.9909431033475882 and parameters: {'learning_rate': 0.13871790247166313, 'depth': 4, 'l2_leaf_reg': 3.6502745375799317, 'border_count': 216}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:42,363] Trial 144 finished with value: -0.9912024236928744 and parameters: {'learning_rate': 0.11881195965301379, 'depth': 4, 'l2_leaf_reg': 3.140638007805917, 'border_count': 210}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:47,028] Trial 145 finished with value: -0.9903424643574119 and parameters: {'learning_rate': 0.12037979694825224, 'depth': 4, 'l2_leaf_reg': 4.119703133019705, 'border_count': 190}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:51,923] Trial 146 finished with value: -0.9906436559529892 and parameters: {'learning_rate': 0.17489616599290786, 'depth': 4, 'l2_leaf_reg': 2.8301700936614713, 'border_count': 210}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:58:56,883] Trial 147 finished with value: -0.9902950100598717 and parameters: {'learning_rate': 0.16044701867724714, 'depth': 4, 'l2_leaf_reg': 3.8555038746206645, 'border_count': 233}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:59:01,754] Trial 148 finished with value: -0.9911192538619119 and parameters: {'learning_rate': 0.13789206680925087, 'depth': 4, 'l2_leaf_reg': 3.387250076215124, 'border_count': 202}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:59:06,637] Trial 149 finished with value: -0.991272629489116 and parameters: {'learning_rate': 0.12628352981764476, 'depth': 4, 'l2_leaf_reg': 2.5493662799731456, 'border_count': 202}. Best is trial 96 with value: -0.9915853113835247.
[I 2025-08-05 12:59:07,133] A new study created in memory with name: no-name-de8b86c8-cf0f-4d81-9cc0-2eb126cf1cde
[I 2025-08-05 12:59:13,072] Trial 0 finished with value: -0.9850958115930564 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-05 12:59:14,099] Trial 1 finished with value: -0.983554004732287 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-05 12:59:17,640] Trial 2 finished with value: -0.9848042409738558 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-05 12:59:19,399] Trial 3 finished with value: -0.9843401704056666 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-05 12:59:24,561] Trial 4 finished with value: -0.9840948084419894 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-05 12:59:26,164] Trial 5 finished with value: -0.9833209189317458 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-05 12:59:30,094] Trial 6 finished with value: -0.9841295500163006 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 0 with value: -0.9850958115930564.
[I 2025-08-05 12:59:31,648] Trial 7 finished with value: -0.9852105685685585 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-05 12:59:33,838] Trial 8 finished with value: -0.9839736933490055 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-05 12:59:39,461] Trial 9 finished with value: -0.9835814150871492 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-05 12:59:39,912] Trial 10 finished with value: -0.9821927149365139 and parameters: {'learning_rate': 0.1696879465047447, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.7102020040921988, 'bagging_fraction': 0.6901464801259053, 'reg_alpha': 5.475583883351959, 'reg_lambda': 0.012278672550406735}. Best is trial 7 with value: -0.9852105685685585.
[I 2025-08-05 12:59:45,993] Trial 11 finished with value: -0.9854330315284197 and parameters: {'learning_rate': 0.023612213425042897, 'num_leaves': 84, 'max_depth': 11, 'min_child_samples': 50, 'feature_fraction': 0.5106977741957487, 'bagging_fraction': 0.6769474312859594, 'reg_alpha': 4.077391468444027e-08, 'reg_lambda': 2.8339857425759094}. Best is trial 11 with value: -0.9854330315284197.
[I 2025-08-05 12:59:47,941] Trial 12 finished with value: -0.9834680834592187 and parameters: {'learning_rate': 0.017375334315313847, 'num_leaves': 70, 'max_depth': 11, 'min_child_samples': 38, 'feature_fraction': 0.7066877922057526, 'bagging_fraction': 0.6929964536410342, 'reg_alpha': 5.011953391371097, 'reg_lambda': 0.015293497883219966}. Best is trial 11 with value: -0.9854330315284197.
[I 2025-08-05 12:59:51,236] Trial 13 finished with value: -0.9859322713126835 and parameters: {'learning_rate': 0.08170216566351561, 'num_leaves': 74, 'max_depth': 10, 'min_child_samples': 37, 'feature_fraction': 0.5313382495460985, 'bagging_fraction': 0.7574852070104715, 'reg_alpha': 1.0741482674311923e-08, 'reg_lambda': 0.012925569907645785}. Best is trial 13 with value: -0.9859322713126835.
[I 2025-08-05 12:59:53,655] Trial 14 finished with value: -0.9867867518897562 and parameters: {'learning_rate': 0.09706314692140564, 'num_leaves': 95, 'max_depth': 10, 'min_child_samples': 20, 'feature_fraction': 0.5065701578589041, 'bagging_fraction': 0.805551721718827, 'reg_alpha': 1.3277235692639058e-08, 'reg_lambda': 9.207736961357908}. Best is trial 14 with value: -0.9867867518897562.
[I 2025-08-05 12:59:55,378] Trial 15 finished with value: -0.9858215334541173 and parameters: {'learning_rate': 0.0952567704737395, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 18, 'feature_fraction': 0.5951601664395402, 'bagging_fraction': 0.8295143024044869, 'reg_alpha': 1.2555970917650801e-08, 'reg_lambda': 0.09652712124824227}. Best is trial 14 with value: -0.9867867518897562.
[I 2025-08-05 12:59:56,830] Trial 16 finished with value: -0.9862188459377738 and parameters: {'learning_rate': 0.08721996044676585, 'num_leaves': 16, 'max_depth': 6, 'min_child_samples': 25, 'feature_fraction': 0.5026527562028454, 'bagging_fraction': 0.7912554411220166, 'reg_alpha': 3.2148894967806533e-07, 'reg_lambda': 0.002132721853912506}. Best is trial 14 with value: -0.9867867518897562.
[I 2025-08-05 12:59:58,120] Trial 17 finished with value: -0.9872797837594737 and parameters: {'learning_rate': 0.16640556451022465, 'num_leaves': 8, 'max_depth': 6, 'min_child_samples': 25, 'feature_fraction': 0.5002348369942121, 'bagging_fraction': 0.8465376210505953, 'reg_alpha': 5.565463586618742e-07, 'reg_lambda': 0.000662062419286776}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-05 12:59:59,784] Trial 18 finished with value: -0.9867884210248381 and parameters: {'learning_rate': 0.18930075101573227, 'num_leaves': 109, 'max_depth': 7, 'min_child_samples': 26, 'feature_fraction': 0.5964137372667864, 'bagging_fraction': 0.9069968527889158, 'reg_alpha': 6.124765019459823e-05, 'reg_lambda': 9.502723948810397}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-05 13:00:01,422] Trial 19 finished with value: -0.9856926554095423 and parameters: {'learning_rate': 0.1994505198099203, 'num_leaves': 34, 'max_depth': 6, 'min_child_samples': 25, 'feature_fraction': 0.5850170424663035, 'bagging_fraction': 0.9134336554829188, 'reg_alpha': 0.00010490127974903605, 'reg_lambda': 0.21956774205104937}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-05 13:00:03,211] Trial 20 finished with value: -0.9863042574079518 and parameters: {'learning_rate': 0.1394393349665469, 'num_leaves': 108, 'max_depth': 7, 'min_child_samples': 48, 'feature_fraction': 0.6505152466626335, 'bagging_fraction': 0.8854014330392775, 'reg_alpha': 0.00012702142020136917, 'reg_lambda': 4.968024444828976e-06}. Best is trial 17 with value: -0.9872797837594737.
[I 2025-08-05 13:00:05,985] Trial 21 finished with value: -0.9873843170652185 and parameters: {'learning_rate': 0.11980668545099626, 'num_leaves': 169, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.5575244364272848, 'bagging_fraction': 0.8621383194962051, 'reg_alpha': 6.120507414183693e-07, 'reg_lambda': 3.910490313439891}. Best is trial 21 with value: -0.9873843170652185.
[I 2025-08-05 13:00:08,271] Trial 22 finished with value: -0.9873962169890118 and parameters: {'learning_rate': 0.13390499764355238, 'num_leaves': 167, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.5747304286519771, 'bagging_fraction': 0.8768909561654321, 'reg_alpha': 4.4337140247952704e-07, 'reg_lambda': 8.876628301054751}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-05 13:00:12,119] Trial 23 finished with value: -0.986445106352277 and parameters: {'learning_rate': 0.12784342713816071, 'num_leaves': 165, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.5635435705366558, 'bagging_fraction': 0.863041576426429, 'reg_alpha': 8.770825153388619e-07, 'reg_lambda': 0.09015550012932438}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-05 13:00:13,978] Trial 24 finished with value: -0.9859535223582798 and parameters: {'learning_rate': 0.11634939113748385, 'num_leaves': 169, 'max_depth': 9, 'min_child_samples': 16, 'feature_fraction': 0.6258720382546296, 'bagging_fraction': 0.9762067146120206, 'reg_alpha': 1.51029692338442e-07, 'reg_lambda': 0.5844619370737302}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-05 13:00:15,776] Trial 25 finished with value: -0.9859002517285523 and parameters: {'learning_rate': 0.06625869567185537, 'num_leaves': 214, 'max_depth': 5, 'min_child_samples': 28, 'feature_fraction': 0.545367506305898, 'bagging_fraction': 0.7559790938635295, 'reg_alpha': 1.7154441705014054e-06, 'reg_lambda': 1.1574612736518413e-08}. Best is trial 22 with value: -0.9873962169890118.
[I 2025-08-05 13:00:17,392] Trial 26 finished with value: -0.9875292389089779 and parameters: {'learning_rate': 0.1396583434103578, 'num_leaves': 154, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.7798274948837373, 'bagging_fraction': 0.8543954637858238, 'reg_alpha': 1.646406340941009e-05, 'reg_lambda': 0.00027256522613180686}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-05 13:00:18,682] Trial 27 finished with value: -0.9861419840446768 and parameters: {'learning_rate': 0.14237310201538045, 'num_leaves': 158, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.8235453728708663, 'bagging_fraction': 0.9329396417213827, 'reg_alpha': 1.9907775481841456e-05, 'reg_lambda': 0.004320430752821306}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-05 13:00:21,391] Trial 28 finished with value: -0.985656058925683 and parameters: {'learning_rate': 0.11022955088098459, 'num_leaves': 187, 'max_depth': 13, 'min_child_samples': 31, 'feature_fraction': 0.7750701530559109, 'bagging_fraction': 0.8757914141339567, 'reg_alpha': 0.0005968994109134424, 'reg_lambda': 7.87701300552545e-05}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-05 13:00:23,895] Trial 29 finished with value: -0.9846375588583071 and parameters: {'learning_rate': 0.07104275119013423, 'num_leaves': 250, 'max_depth': 8, 'min_child_samples': 65, 'feature_fraction': 0.741724658826805, 'bagging_fraction': 0.9532962576261433, 'reg_alpha': 1.486136376273211e-07, 'reg_lambda': 1.4135188249861919}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-05 13:00:26,496] Trial 30 finished with value: -0.9858112098028785 and parameters: {'learning_rate': 0.03842745754146896, 'num_leaves': 125, 'max_depth': 10, 'min_child_samples': 19, 'feature_fraction': 0.849546226415591, 'bagging_fraction': 0.7964679771167982, 'reg_alpha': 2.635739731538385e-06, 'reg_lambda': 0.30910203656894697}. Best is trial 26 with value: -0.9875292389089779.
[I 2025-08-05 13:00:28,920] Trial 31 finished with value: -0.9879990328860193 and parameters: {'learning_rate': 0.15618089007816505, 'num_leaves': 153, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.5684344567882854, 'bagging_fraction': 0.8474479025082922, 'reg_alpha': 6.143281937219954e-08, 'reg_lambda': 0.0010686824862189725}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:30,623] Trial 32 finished with value: -0.9874897487995069 and parameters: {'learning_rate': 0.15874745936136636, 'num_leaves': 187, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.7444967265387155, 'bagging_fraction': 0.8959659863362562, 'reg_alpha': 4.7922735794173125e-08, 'reg_lambda': 0.00014207003101464417}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:32,003] Trial 33 finished with value: -0.9859417978951456 and parameters: {'learning_rate': 0.15351070471870026, 'num_leaves': 192, 'max_depth': 8, 'min_child_samples': 20, 'feature_fraction': 0.7568451644319717, 'bagging_fraction': 0.8991713143814992, 'reg_alpha': 8.413937049327848e-08, 'reg_lambda': 8.752610537412802e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:32,941] Trial 34 finished with value: -0.9869141341839761 and parameters: {'learning_rate': 0.10544549966140175, 'num_leaves': 152, 'max_depth': 5, 'min_child_samples': 15, 'feature_fraction': 0.6784614859528049, 'bagging_fraction': 0.7755273932830261, 'reg_alpha': 7.969180414392415e-08, 'reg_lambda': 3.7788032716352305e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:34,249] Trial 35 finished with value: -0.9872697682878464 and parameters: {'learning_rate': 0.16308733916834112, 'num_leaves': 223, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8611472869134348, 'bagging_fraction': 0.8224499888525351, 'reg_alpha': 5.153304095570123e-06, 'reg_lambda': 0.00022102295400946057}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:37,015] Trial 36 finished with value: -0.9855402238219059 and parameters: {'learning_rate': 0.07694241512968658, 'num_leaves': 181, 'max_depth': 8, 'min_child_samples': 31, 'feature_fraction': 0.9267635526278051, 'bagging_fraction': 0.7266367682142773, 'reg_alpha': 3.8885478350505913e-08, 'reg_lambda': 0.001494841711599115}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:39,162] Trial 37 finished with value: -0.9850545985943013 and parameters: {'learning_rate': 0.05797253248356863, 'num_leaves': 231, 'max_depth': 6, 'min_child_samples': 43, 'feature_fraction': 0.7374821279913889, 'bagging_fraction': 0.927676545065034, 'reg_alpha': 1.985346685505641e-07, 'reg_lambda': 1.7005350852014366e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:40,224] Trial 38 finished with value: -0.9846497122909987 and parameters: {'learning_rate': 0.1293301361489344, 'num_leaves': 123, 'max_depth': 4, 'min_child_samples': 67, 'feature_fraction': 0.8130472788619331, 'bagging_fraction': 0.5013339806386407, 'reg_alpha': 1.9585985092618524e-05, 'reg_lambda': 0.0002480235864678539}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:41,350] Trial 39 finished with value: -0.9857606091594502 and parameters: {'learning_rate': 0.1956018137717553, 'num_leaves': 145, 'max_depth': 7, 'min_child_samples': 22, 'feature_fraction': 0.9899226356996809, 'bagging_fraction': 0.9630947936090172, 'reg_alpha': 8.878948278543989e-07, 'reg_lambda': 3.586764912589282e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:42,717] Trial 40 finished with value: -0.9861483532402211 and parameters: {'learning_rate': 0.04823714040678821, 'num_leaves': 200, 'max_depth': 4, 'min_child_samples': 32, 'feature_fraction': 0.6164032825930349, 'bagging_fraction': 0.8455193484576664, 'reg_alpha': 0.0006121496593029671, 'reg_lambda': 4.3052016214873256e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:44,863] Trial 41 finished with value: -0.9865794002314029 and parameters: {'learning_rate': 0.12736882276726205, 'num_leaves': 180, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.5543932613164914, 'bagging_fraction': 0.8619141949295612, 'reg_alpha': 1.3835144728584246e-06, 'reg_lambda': 4.308564258342925}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:46,640] Trial 42 finished with value: -0.9864899707571642 and parameters: {'learning_rate': 0.11640543831565052, 'num_leaves': 169, 'max_depth': 8, 'min_child_samples': 11, 'feature_fraction': 0.64851332992864, 'bagging_fraction': 0.887105135671054, 'reg_alpha': 4.151554040019469e-07, 'reg_lambda': 0.05702044679692784}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:47,828] Trial 43 finished with value: -0.9862233792450693 and parameters: {'learning_rate': 0.15319460975861438, 'num_leaves': 138, 'max_depth': 9, 'min_child_samples': 15, 'feature_fraction': 0.785517566476569, 'bagging_fraction': 0.8574320686468996, 'reg_alpha': 8.940710679335368e-06, 'reg_lambda': 0.9883732589095742}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:52,092] Trial 44 finished with value: -0.9868981763819231 and parameters: {'learning_rate': 0.09696556666025834, 'num_leaves': 159, 'max_depth': 11, 'min_child_samples': 10, 'feature_fraction': 0.6714746757944438, 'bagging_fraction': 0.8150557744500045, 'reg_alpha': 3.3011828431753455e-08, 'reg_lambda': 0.000476608710759108}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:55,031] Trial 45 finished with value: -0.9860571625314061 and parameters: {'learning_rate': 0.17593167061879617, 'num_leaves': 176, 'max_depth': 10, 'min_child_samples': 60, 'feature_fraction': 0.5752124059107432, 'bagging_fraction': 0.9279885353236574, 'reg_alpha': 7.339348514738463e-08, 'reg_lambda': 0.031355207515892373}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:56,154] Trial 46 finished with value: -0.9840973573572528 and parameters: {'learning_rate': 0.13876286943444374, 'num_leaves': 197, 'max_depth': 5, 'min_child_samples': 92, 'feature_fraction': 0.6083811284380387, 'bagging_fraction': 0.8759438685792194, 'reg_alpha': 2.8647682482129344e-06, 'reg_lambda': 0.0037985902638350256}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:00:58,555] Trial 47 finished with value: -0.9856961992260367 and parameters: {'learning_rate': 0.039003521725171166, 'num_leaves': 149, 'max_depth': 8, 'min_child_samples': 22, 'feature_fraction': 0.9153163866399331, 'bagging_fraction': 0.6088435881640017, 'reg_alpha': 2.340559173163026e-08, 'reg_lambda': 0.0010420611415106447}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:01,407] Trial 48 finished with value: -0.9859231856306682 and parameters: {'learning_rate': 0.028707747283418756, 'num_leaves': 133, 'max_depth': 7, 'min_child_samples': 17, 'feature_fraction': 0.638569301262528, 'bagging_fraction': 0.7309306946570661, 'reg_alpha': 3.981335059637075e-07, 'reg_lambda': 3.4199189046230976e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:04,237] Trial 49 finished with value: -0.9850878184182384 and parameters: {'learning_rate': 0.08644262967346897, 'num_leaves': 209, 'max_depth': 9, 'min_child_samples': 71, 'feature_fraction': 0.5322849656343382, 'bagging_fraction': 0.9967411011074679, 'reg_alpha': 0.006820610536238465, 'reg_lambda': 8.49747687871126e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:05,273] Trial 50 finished with value: -0.9868086545759398 and parameters: {'learning_rate': 0.17611677471844353, 'num_leaves': 116, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.7010928088414482, 'bagging_fraction': 0.8311428059899459, 'reg_alpha': 7.633786478083986e-06, 'reg_lambda': 1.4187206847345547e-06}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:06,397] Trial 51 finished with value: -0.9859528247099071 and parameters: {'learning_rate': 0.15794745050281928, 'num_leaves': 159, 'max_depth': 6, 'min_child_samples': 23, 'feature_fraction': 0.5290889479515248, 'bagging_fraction': 0.8452467592363159, 'reg_alpha': 7.964377944743309e-07, 'reg_lambda': 0.0006874711021097879}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:07,911] Trial 52 finished with value: -0.9860303203515295 and parameters: {'learning_rate': 0.12091008150921699, 'num_leaves': 171, 'max_depth': 7, 'min_child_samples': 18, 'feature_fraction': 0.5728600724279137, 'bagging_fraction': 0.9043299205858639, 'reg_alpha': 3.0737742058414563e-07, 'reg_lambda': 0.0001756704386077031}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:09,667] Trial 53 finished with value: -0.9869744370261804 and parameters: {'learning_rate': 0.10450368357430939, 'num_leaves': 144, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.5282116926663796, 'bagging_fraction': 0.7805890581570856, 'reg_alpha': 3.6763545437465525e-05, 'reg_lambda': 0.0065828901954720735}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:11,953] Trial 54 finished with value: -0.9861739657720145 and parameters: {'learning_rate': 0.17346430749328517, 'num_leaves': 51, 'max_depth': 14, 'min_child_samples': 27, 'feature_fraction': 0.5586372355187991, 'bagging_fraction': 0.8437207969732806, 'reg_alpha': 6.651653534495644e-08, 'reg_lambda': 4.211720601546369}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:15,099] Trial 55 finished with value: -0.9867922566082991 and parameters: {'learning_rate': 0.14695326196203293, 'num_leaves': 151, 'max_depth': 10, 'min_child_samples': 10, 'feature_fraction': 0.5137239743203557, 'bagging_fraction': 0.8912459499674709, 'reg_alpha': 6.279820835382187e-07, 'reg_lambda': 0.0018549568812067433}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:16,071] Trial 56 finished with value: -0.9866797631801487 and parameters: {'learning_rate': 0.13303901645539085, 'num_leaves': 189, 'max_depth': 5, 'min_child_samples': 20, 'feature_fraction': 0.5922201819706935, 'bagging_fraction': 0.9164243485538224, 'reg_alpha': 2.542834341437061e-07, 'reg_lambda': 2.0516877237188335e-07}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:17,389] Trial 57 finished with value: -0.9870198212294377 and parameters: {'learning_rate': 0.18261644280272346, 'num_leaves': 162, 'max_depth': 4, 'min_child_samples': 17, 'feature_fraction': 0.5036768786693336, 'bagging_fraction': 0.8062873092440409, 'reg_alpha': 2.2527525222606647e-08, 'reg_lambda': 3.7150222972156575e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:19,776] Trial 58 finished with value: -0.9860048656918409 and parameters: {'learning_rate': 0.0944728525336205, 'num_leaves': 26, 'max_depth': 11, 'min_child_samples': 35, 'feature_fraction': 0.7610439157522915, 'bagging_fraction': 0.8658528332085295, 'reg_alpha': 2.076340832487175e-06, 'reg_lambda': 0.0005207068844824646}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:20,543] Trial 59 finished with value: -0.9865971119045289 and parameters: {'learning_rate': 0.16143840835512058, 'num_leaves': 102, 'max_depth': 3, 'min_child_samples': 13, 'feature_fraction': 0.7168195167847097, 'bagging_fraction': 0.8478687831381345, 'reg_alpha': 0.8980992068116294, 'reg_lambda': 0.2676367874653128}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:26,260] Trial 60 finished with value: -0.9856623108711224 and parameters: {'learning_rate': 0.01789528035385612, 'num_leaves': 130, 'max_depth': 9, 'min_child_samples': 24, 'feature_fraction': 0.6057841410755372, 'bagging_fraction': 0.7701032823057072, 'reg_alpha': 1.5471825695098408e-07, 'reg_lambda': 0.00015132472931856096}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:27,525] Trial 61 finished with value: -0.987249451222706 and parameters: {'learning_rate': 0.16415773876964443, 'num_leaves': 228, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.8406984342342535, 'bagging_fraction': 0.8168930520458646, 'reg_alpha': 5.983644109070899e-06, 'reg_lambda': 0.00033998519690463236}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:28,585] Trial 62 finished with value: -0.9865416072114511 and parameters: {'learning_rate': 0.14246319567203172, 'num_leaves': 227, 'max_depth': 7, 'min_child_samples': 13, 'feature_fraction': 0.8778707736338811, 'bagging_fraction': 0.8296414708519048, 'reg_alpha': 3.752611972213392e-06, 'reg_lambda': 9.557392762464854e-05}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:30,651] Trial 63 finished with value: -0.9874602794736784 and parameters: {'learning_rate': 0.11459526526004513, 'num_leaves': 177, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.899379129967788, 'bagging_fraction': 0.8731130182292134, 'reg_alpha': 1.3777214736498081e-06, 'reg_lambda': 0.001025087767541426}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:32,071] Trial 64 finished with value: -0.9859176475700137 and parameters: {'learning_rate': 0.11446406057269488, 'num_leaves': 181, 'max_depth': 8, 'min_child_samples': 17, 'feature_fraction': 0.9494792080665542, 'bagging_fraction': 0.9427867879597246, 'reg_alpha': 8.368323337946462e-07, 'reg_lambda': 0.022639786869083935}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:33,762] Trial 65 finished with value: -0.9856585946906307 and parameters: {'learning_rate': 0.19949171709945593, 'num_leaves': 173, 'max_depth': 8, 'min_child_samples': 29, 'feature_fraction': 0.904103923644936, 'bagging_fraction': 0.8816719309217209, 'reg_alpha': 1.2198078484296486e-07, 'reg_lambda': 0.008641979786038092}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:35,730] Trial 66 finished with value: -0.9860189781020375 and parameters: {'learning_rate': 0.10389105384747896, 'num_leaves': 205, 'max_depth': 9, 'min_child_samples': 21, 'feature_fraction': 0.6687902451328799, 'bagging_fraction': 0.8689175929385188, 'reg_alpha': 1.0684253104097143e-08, 'reg_lambda': 0.0008642450619887948}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:38,108] Trial 67 finished with value: -0.9861847685604086 and parameters: {'learning_rate': 0.12171848546992174, 'num_leaves': 193, 'max_depth': 6, 'min_child_samples': 50, 'feature_fraction': 0.5438477398750303, 'bagging_fraction': 0.9131552692974101, 'reg_alpha': 1.4654780335936827e-05, 'reg_lambda': 0.0034467067500832936}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:40,984] Trial 68 finished with value: -0.9853973892607086 and parameters: {'learning_rate': 0.07480295181373106, 'num_leaves': 139, 'max_depth': 8, 'min_child_samples': 41, 'feature_fraction': 0.7251951364720742, 'bagging_fraction': 0.9010767403359924, 'reg_alpha': 1.697523636802676e-06, 'reg_lambda': 1.5659781171024014e-08}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:42,670] Trial 69 finished with value: -0.9867531723113971 and parameters: {'learning_rate': 0.14822118386328037, 'num_leaves': 165, 'max_depth': 10, 'min_child_samples': 13, 'feature_fraction': 0.8281519289712604, 'bagging_fraction': 0.796585054492928, 'reg_alpha': 0.00013888114874143444, 'reg_lambda': 0.5679888110580483}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:44,393] Trial 70 finished with value: -0.9864671799655558 and parameters: {'learning_rate': 0.1313812129415191, 'num_leaves': 156, 'max_depth': 8, 'min_child_samples': 19, 'feature_fraction': 0.569625359318856, 'bagging_fraction': 0.9536606871826898, 'reg_alpha': 6.235727706877531e-08, 'reg_lambda': 2.5222853747444245}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:45,625] Trial 71 finished with value: -0.98763484664321 and parameters: {'learning_rate': 0.16615763927474433, 'num_leaves': 215, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8904522637914591, 'bagging_fraction': 0.8213260229096735, 'reg_alpha': 3.905895197493586e-06, 'reg_lambda': 0.00026270614529808436}. Best is trial 31 with value: -0.9879990328860193.
[I 2025-08-05 13:01:47,713] Trial 72 finished with value: -0.9883720183415127 and parameters: {'learning_rate': 0.18056080344222483, 'num_leaves': 219, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.9521349495066572, 'bagging_fraction': 0.8514734970258908, 'reg_alpha': 1.0536122334861126e-06, 'reg_lambda': 8.751163903031449}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:49,089] Trial 73 finished with value: -0.9882622567663993 and parameters: {'learning_rate': 0.18947338820982654, 'num_leaves': 184, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.9514951125821989, 'bagging_fraction': 0.8510858430078347, 'reg_alpha': 1.325861121917445e-06, 'reg_lambda': 3.7338263475247464}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:49,964] Trial 74 finished with value: -0.9864516976157051 and parameters: {'learning_rate': 0.18279017669887043, 'num_leaves': 247, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.9510566336291827, 'bagging_fraction': 0.8381791698312648, 'reg_alpha': 1.310691897260012e-05, 'reg_lambda': 7.043898119289713}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:51,192] Trial 75 finished with value: -0.9870540187218367 and parameters: {'learning_rate': 0.18703605351195268, 'num_leaves': 237, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.9983139247218186, 'bagging_fraction': 0.8918860917327313, 'reg_alpha': 1.1723806622667706e-06, 'reg_lambda': 1.5374411649423436}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:52,344] Trial 76 finished with value: -0.9865323826029837 and parameters: {'learning_rate': 0.15266555836306253, 'num_leaves': 214, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.9711370693829077, 'bagging_fraction': 0.8568036302327512, 'reg_alpha': 3.6870060183813194e-06, 'reg_lambda': 9.809340707206351}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:53,883] Trial 77 finished with value: -0.9882840864322608 and parameters: {'learning_rate': 0.167989453276013, 'num_leaves': 219, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.9390785208970333, 'bagging_fraction': 0.8748692354636461, 'reg_alpha': 6.79197189722548e-05, 'reg_lambda': 6.176871920301797}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:55,073] Trial 78 finished with value: -0.9871286829583414 and parameters: {'learning_rate': 0.19956551678515083, 'num_leaves': 214, 'max_depth': 5, 'min_child_samples': 10, 'feature_fraction': 0.9422722954431024, 'bagging_fraction': 0.8082334276932376, 'reg_alpha': 4.907350346881099e-05, 'reg_lambda': 0.8358838734471404}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:55,976] Trial 79 finished with value: -0.9859171759735805 and parameters: {'learning_rate': 0.16880366538215555, 'num_leaves': 237, 'max_depth': 6, 'min_child_samples': 18, 'feature_fraction': 0.8815792648366843, 'bagging_fraction': 0.8229112254685218, 'reg_alpha': 0.00042237334918299825, 'reg_lambda': 0.15291416422679163}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:56,804] Trial 80 finished with value: -0.9860310239541258 and parameters: {'learning_rate': 0.14240377193769863, 'num_leaves': 221, 'max_depth': 5, 'min_child_samples': 15, 'feature_fraction': 0.9030975144765824, 'bagging_fraction': 0.7846633980001139, 'reg_alpha': 2.6487959770736792e-05, 'reg_lambda': 0.0013543553804423213}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:58,056] Trial 81 finished with value: -0.987027257449423 and parameters: {'learning_rate': 0.15688606738383584, 'num_leaves': 203, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.9734569619826393, 'bagging_fraction': 0.8770316127038411, 'reg_alpha': 0.0002294452437106921, 'reg_lambda': 5.441769114380621}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:01:59,113] Trial 82 finished with value: -0.9876129141957783 and parameters: {'learning_rate': 0.17355902085004823, 'num_leaves': 197, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.9296398247956568, 'bagging_fraction': 0.8552453664424593, 'reg_alpha': 7.51698379964411e-06, 'reg_lambda': 1.9147608687847522}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:00,141] Trial 83 finished with value: -0.9873435715156083 and parameters: {'learning_rate': 0.17857255775523181, 'num_leaves': 187, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.9292056559705985, 'bagging_fraction': 0.858352400720043, 'reg_alpha': 3.328594287281763e-05, 'reg_lambda': 1.2976012895129139}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:01,012] Trial 84 finished with value: -0.9860509978946667 and parameters: {'learning_rate': 0.16757129710382335, 'num_leaves': 194, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.8974825262665204, 'bagging_fraction': 0.8372744626077447, 'reg_alpha': 8.979587488315609e-05, 'reg_lambda': 6.422778759791608e-05}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:02,129] Trial 85 finished with value: -0.9877487904680982 and parameters: {'learning_rate': 0.18823068170686336, 'num_leaves': 219, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.8651742987767396, 'bagging_fraction': 0.9200313349924366, 'reg_alpha': 9.520889463047119e-06, 'reg_lambda': 2.4587418914523433}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:03,112] Trial 86 finished with value: -0.9858245347285071 and parameters: {'learning_rate': 0.18773561604706263, 'num_leaves': 221, 'max_depth': 6, 'min_child_samples': 21, 'feature_fraction': 0.86452808750862, 'bagging_fraction': 0.9162718186552167, 'reg_alpha': 0.0013596737832744714, 'reg_lambda': 2.5320593089472863}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:03,786] Trial 87 finished with value: -0.9857860535467683 and parameters: {'learning_rate': 0.1527729932512767, 'num_leaves': 208, 'max_depth': 5, 'min_child_samples': 14, 'feature_fraction': 0.9300367873538115, 'bagging_fraction': 0.8948389189246599, 'reg_alpha': 1.0916662503326015e-05, 'reg_lambda': 0.6287606671262345}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:04,692] Trial 88 finished with value: -0.9870330253803836 and parameters: {'learning_rate': 0.17004357154521146, 'num_leaves': 254, 'max_depth': 6, 'min_child_samples': 13, 'feature_fraction': 0.963503554161085, 'bagging_fraction': 0.9221968761904931, 'reg_alpha': 4.579623874356345e-06, 'reg_lambda': 3.5778883824665404}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:05,725] Trial 89 finished with value: -0.9859024215739247 and parameters: {'learning_rate': 0.18973735449369364, 'num_leaves': 239, 'max_depth': 7, 'min_child_samples': 18, 'feature_fraction': 0.919346750005544, 'bagging_fraction': 0.9415955285115627, 'reg_alpha': 8.815066075388036e-06, 'reg_lambda': 0.37715871583687205}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:07,036] Trial 90 finished with value: -0.985960636240884 and parameters: {'learning_rate': 0.12539133153062804, 'num_leaves': 215, 'max_depth': 6, 'min_child_samples': 23, 'feature_fraction': 0.8025408728226828, 'bagging_fraction': 0.9708549146617322, 'reg_alpha': 2.0732125854209135e-05, 'reg_lambda': 2.131087274257325}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:08,588] Trial 91 finished with value: -0.9876174505285494 and parameters: {'learning_rate': 0.14004998569338126, 'num_leaves': 201, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.867022960046228, 'bagging_fraction': 0.8490517343323919, 'reg_alpha': 5.39999332705708e-05, 'reg_lambda': 0.00031407930332873234}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:10,001] Trial 92 finished with value: -0.9873837599382128 and parameters: {'learning_rate': 0.1376834719836902, 'num_leaves': 201, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8682244664874781, 'bagging_fraction': 0.8528765614206484, 'reg_alpha': 5.374580325087787e-05, 'reg_lambda': 0.0001207187206281133}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:10,884] Trial 93 finished with value: -0.9858674332111063 and parameters: {'learning_rate': 0.16373168802738516, 'num_leaves': 220, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.9371913824555923, 'bagging_fraction': 0.8863823648627102, 'reg_alpha': 7.10109171697503e-05, 'reg_lambda': 0.0003475488697519553}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:11,911] Trial 94 finished with value: -0.9870543495820682 and parameters: {'learning_rate': 0.17933530232950273, 'num_leaves': 198, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.852877911236438, 'bagging_fraction': 0.8257967098944745, 'reg_alpha': 0.00024602664289478905, 'reg_lambda': 2.518124379799025e-05}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:13,044] Trial 95 finished with value: -0.9858931859971379 and parameters: {'learning_rate': 0.14795587895837034, 'num_leaves': 232, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.9836207789487175, 'bagging_fraction': 0.8671174387976363, 'reg_alpha': 0.0001507341628641645, 'reg_lambda': 5.8928167970700434e-05}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:14,722] Trial 96 finished with value: -0.9838578548169528 and parameters: {'learning_rate': 0.13674233157982535, 'num_leaves': 204, 'max_depth': 5, 'min_child_samples': 100, 'feature_fraction': 0.9590336391267404, 'bagging_fraction': 0.9058119674998661, 'reg_alpha': 2.8991502167587784e-06, 'reg_lambda': 6.434805708119112}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:15,792] Trial 97 finished with value: -0.9871678764261981 and parameters: {'learning_rate': 0.17404231927055225, 'num_leaves': 189, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.9114909129225703, 'bagging_fraction': 0.8362971887180022, 'reg_alpha': 3.685966776566466e-05, 'reg_lambda': 9.219678855776368e-06}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:17,057] Trial 98 finished with value: -0.9857896750399465 and parameters: {'learning_rate': 0.15849338055121334, 'num_leaves': 184, 'max_depth': 7, 'min_child_samples': 20, 'feature_fraction': 0.8911840817576969, 'bagging_fraction': 0.851414672767248, 'reg_alpha': 6.246031222380552e-06, 'reg_lambda': 0.0002413093394746176}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:18,887] Trial 99 finished with value: -0.9860214125257825 and parameters: {'learning_rate': 0.010911699880692119, 'num_leaves': 210, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8750267111639118, 'bagging_fraction': 0.7431710301685029, 'reg_alpha': 1.7311544376987395e-08, 'reg_lambda': 3.3215173227581625}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:19,749] Trial 100 finished with value: -0.9858194883588756 and parameters: {'learning_rate': 0.19117358198975445, 'num_leaves': 217, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.8360354839324343, 'bagging_fraction': 0.8111350291850622, 'reg_alpha': 0.07217022334431497, 'reg_lambda': 1.3731838290708787}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:21,697] Trial 101 finished with value: -0.9840555756134324 and parameters: {'learning_rate': 0.14401524892916054, 'num_leaves': 181, 'max_depth': 8, 'min_child_samples': 87, 'feature_fraction': 0.9186098260965798, 'bagging_fraction': 0.8735342950848686, 'reg_alpha': 2.3807084394942185e-06, 'reg_lambda': 0.0009790719992020256}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:25,199] Trial 102 finished with value: -0.9872734725699008 and parameters: {'learning_rate': 0.042351464472852686, 'num_leaves': 196, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.7807899444601023, 'bagging_fraction': 0.8686441322488634, 'reg_alpha': 1.3546628212702861e-06, 'reg_lambda': 0.0004602459630211886}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:26,938] Trial 103 finished with value: -0.9866327709361149 and parameters: {'learning_rate': 0.11414596323375277, 'num_leaves': 190, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.8192837895549286, 'bagging_fraction': 0.888237946956316, 'reg_alpha': 1.9221342519544934e-05, 'reg_lambda': 0.00013082089737038994}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:28,473] Trial 104 finished with value: -0.9862678414420014 and parameters: {'learning_rate': 0.058209145808434136, 'num_leaves': 224, 'max_depth': 7, 'min_child_samples': 17, 'feature_fraction': 0.8887734856175724, 'bagging_fraction': 0.9353855123489151, 'reg_alpha': 5.032325134147054e-07, 'reg_lambda': 4.818744413020787}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:31,878] Trial 105 finished with value: -0.987405196727356 and parameters: {'learning_rate': 0.03533844536780055, 'num_leaves': 175, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8530793392469461, 'bagging_fraction': 0.8801863388263699, 'reg_alpha': 1.154414337534388e-05, 'reg_lambda': 0.002714382979894179}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:32,997] Trial 106 finished with value: -0.9861536872877016 and parameters: {'learning_rate': 0.1302858019198548, 'num_leaves': 210, 'max_depth': 6, 'min_child_samples': 19, 'feature_fraction': 0.9431093057488996, 'bagging_fraction': 0.8430804352587453, 'reg_alpha': 5.31519080046963e-06, 'reg_lambda': 0.00020124844504448207}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:34,073] Trial 107 finished with value: -0.9857740251647188 and parameters: {'learning_rate': 0.16013321254442803, 'num_leaves': 232, 'max_depth': 8, 'min_child_samples': 14, 'feature_fraction': 0.905919648958518, 'bagging_fraction': 0.568330849459986, 'reg_alpha': 2.783778474475233e-07, 'reg_lambda': 0.0003054625797331225}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:35,719] Trial 108 finished with value: -0.9862417043981877 and parameters: {'learning_rate': 0.19863944369846537, 'num_leaves': 175, 'max_depth': 9, 'min_child_samples': 12, 'feature_fraction': 0.6871359479674568, 'bagging_fraction': 0.7010548938708235, 'reg_alpha': 4.6760035486985113e-08, 'reg_lambda': 0.0005825727705708118}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:36,977] Trial 109 finished with value: -0.9866691356024407 and parameters: {'learning_rate': 0.10811765760906121, 'num_leaves': 207, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.793123636899939, 'bagging_fraction': 0.901234460339287, 'reg_alpha': 1.260677076913496e-06, 'reg_lambda': 6.67029054262157}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:37,646] Trial 110 finished with value: -0.9858402577827278 and parameters: {'learning_rate': 0.1736985038846044, 'num_leaves': 197, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.9592583730020339, 'bagging_fraction': 0.8591137908386869, 'reg_alpha': 1.0611283860000166e-07, 'reg_lambda': 1.9059643143644949}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:40,611] Trial 111 finished with value: -0.9873408039557189 and parameters: {'learning_rate': 0.034350007754329594, 'num_leaves': 178, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8559188363635856, 'bagging_fraction': 0.8760964433983144, 'reg_alpha': 1.1528185237877021e-05, 'reg_lambda': 0.002215497996025671}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:44,742] Trial 112 finished with value: -0.9871901701997062 and parameters: {'learning_rate': 0.02924132953701179, 'num_leaves': 184, 'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.8433598915415192, 'bagging_fraction': 0.8798717087445956, 'reg_alpha': 2.701196684221842e-05, 'reg_lambda': 0.0003212895424181401}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:48,018] Trial 113 finished with value: -0.9864071917475288 and parameters: {'learning_rate': 0.02052812207917615, 'num_leaves': 167, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.892557715928591, 'bagging_fraction': 0.7962272925776894, 'reg_alpha': 8.605354804120228e-06, 'reg_lambda': 0.001269904668857182}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:49,914] Trial 114 finished with value: -0.983612605034548 and parameters: {'learning_rate': 0.03616590180532698, 'num_leaves': 154, 'max_depth': 5, 'min_child_samples': 77, 'feature_fraction': 0.8738043551547168, 'bagging_fraction': 0.8225342691653069, 'reg_alpha': 2.9675549055990344e-06, 'reg_lambda': 0.0024983913243621504}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:54,088] Trial 115 finished with value: -0.9865773509950427 and parameters: {'learning_rate': 0.025295239230530772, 'num_leaves': 164, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.7688440974584132, 'bagging_fraction': 0.8532740128702133, 'reg_alpha': 1.974657541397223e-06, 'reg_lambda': 0.0006480603312875129}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:55,402] Trial 116 finished with value: -0.985544268339704 and parameters: {'learning_rate': 0.0446141689262171, 'num_leaves': 148, 'max_depth': 6, 'min_child_samples': 18, 'feature_fraction': 0.9251893845060142, 'bagging_fraction': 0.8344827278361224, 'reg_alpha': 1.5895076116055237e-05, 'reg_lambda': 0.008183840802134721}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:02:57,458] Trial 117 finished with value: -0.9855375077388429 and parameters: {'learning_rate': 0.03361111988499305, 'num_leaves': 172, 'max_depth': 7, 'min_child_samples': 15, 'feature_fraction': 0.979468897543487, 'bagging_fraction': 0.6557598047692232, 'reg_alpha': 8.41812100355881e-05, 'reg_lambda': 0.005485440734960973}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:00,081] Trial 118 finished with value: -0.9851708445210358 and parameters: {'learning_rate': 0.15082447844100622, 'num_leaves': 201, 'max_depth': 9, 'min_child_samples': 60, 'feature_fraction': 0.9360682394647946, 'bagging_fraction': 0.8639907193209992, 'reg_alpha': 4.729374453027869e-05, 'reg_lambda': 0.0032522465842771946}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:01,430] Trial 119 finished with value: -0.9872563379965241 and parameters: {'learning_rate': 0.1798900908655116, 'num_leaves': 192, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8319081896834432, 'bagging_fraction': 0.9104880017097084, 'reg_alpha': 4.7872513467296835e-06, 'reg_lambda': 0.0746977388840696}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:02,145] Trial 120 finished with value: -0.9858503757620749 and parameters: {'learning_rate': 0.16474246563687905, 'num_leaves': 161, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.953900530089215, 'bagging_fraction': 0.9237073755497494, 'reg_alpha': 2.832952298578779e-08, 'reg_lambda': 0.8684143603881638}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:05,571] Trial 121 finished with value: -0.985543242520982 and parameters: {'learning_rate': 0.051891276873630786, 'num_leaves': 175, 'max_depth': 8, 'min_child_samples': 46, 'feature_fraction': 0.7378478436075724, 'bagging_fraction': 0.8860323875025592, 'reg_alpha': 1.9655993740899745e-07, 'reg_lambda': 8.718082799769919}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:07,140] Trial 122 finished with value: -0.9873540787494728 and parameters: {'learning_rate': 0.13560220776174295, 'num_leaves': 185, 'max_depth': 8, 'min_child_samples': 11, 'feature_fraction': 0.8827419100919413, 'bagging_fraction': 0.8954039443627659, 'reg_alpha': 6.37930007059764e-07, 'reg_lambda': 2.6365591724411908}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:08,671] Trial 123 finished with value: -0.9874662900718963 and parameters: {'learning_rate': 0.14424388392969326, 'num_leaves': 170, 'max_depth': 9, 'min_child_samples': 13, 'feature_fraction': 0.908998170061243, 'bagging_fraction': 0.8494905389164883, 'reg_alpha': 1.1312128585505417e-06, 'reg_lambda': 5.4027683848136885}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:10,313] Trial 124 finished with value: -0.9874810669730489 and parameters: {'learning_rate': 0.12215469465346798, 'num_leaves': 179, 'max_depth': 9, 'min_child_samples': 13, 'feature_fraction': 0.8608679356498566, 'bagging_fraction': 0.8425021702704366, 'reg_alpha': 8.977608448472212e-07, 'reg_lambda': 4.227194631965389}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:11,665] Trial 125 finished with value: -0.986738917353982 and parameters: {'learning_rate': 0.12146986881304495, 'num_leaves': 216, 'max_depth': 9, 'min_child_samples': 16, 'feature_fraction': 0.9106233993717794, 'bagging_fraction': 0.8469297393515793, 'reg_alpha': 9.450014494559664e-07, 'reg_lambda': 4.114599250296689}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:12,884] Trial 126 finished with value: -0.9873156924791846 and parameters: {'learning_rate': 0.14364839926900574, 'num_leaves': 180, 'max_depth': 9, 'min_child_samples': 12, 'feature_fraction': 0.8953670763922372, 'bagging_fraction': 0.8186163981416041, 'reg_alpha': 2.0460705828202426e-06, 'reg_lambda': 5.530006663664815}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:14,464] Trial 127 finished with value: -0.9871360762238179 and parameters: {'learning_rate': 0.12614385604460113, 'num_leaves': 225, 'max_depth': 10, 'min_child_samples': 13, 'feature_fraction': 0.9258085462596127, 'bagging_fraction': 0.8380783870203995, 'reg_alpha': 3.6217031856721414e-07, 'reg_lambda': 1.9859966559378204}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:15,726] Trial 128 finished with value: -0.9858051078194501 and parameters: {'learning_rate': 0.1507810365244716, 'num_leaves': 137, 'max_depth': 9, 'min_child_samples': 17, 'feature_fraction': 0.9412485484973263, 'bagging_fraction': 0.8034167968716979, 'reg_alpha': 3.936585252578998e-06, 'reg_lambda': 1.2149909906017755}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:17,361] Trial 129 finished with value: -0.9866947507361719 and parameters: {'learning_rate': 0.09951726387766904, 'num_leaves': 170, 'max_depth': 10, 'min_child_samples': 14, 'feature_fraction': 0.8672638067099725, 'bagging_fraction': 0.830182777745884, 'reg_alpha': 6.279058462730546e-07, 'reg_lambda': 9.563277133413873}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:19,832] Trial 130 finished with value: -0.9862641191819964 and parameters: {'learning_rate': 0.1865019170214644, 'num_leaves': 157, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.966865538096542, 'bagging_fraction': 0.8668870902961702, 'reg_alpha': 1.085518457383021e-06, 'reg_lambda': 4.112549061968329}. Best is trial 72 with value: -0.9883720183415127.
[I 2025-08-05 13:03:21,738] Trial 131 finished with value: -0.9887257100865543 and parameters: {'learning_rate': 0.15996571729914286, 'num_leaves': 187, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.8451145350830436, 'bagging_fraction': 0.8534027490356716, 'reg_alpha': 1.1152289964280488e-05, 'reg_lambda': 2.933063018415669}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:23,226] Trial 132 finished with value: -0.9884637300745709 and parameters: {'learning_rate': 0.15727092408443485, 'num_leaves': 193, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.845715281773433, 'bagging_fraction': 0.8573666901472738, 'reg_alpha': 6.899864936389022e-06, 'reg_lambda': 3.005388714025817}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:24,250] Trial 133 finished with value: -0.9875617234541313 and parameters: {'learning_rate': 0.15783984133163872, 'num_leaves': 193, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.8124982071179696, 'bagging_fraction': 0.8527539600503208, 'reg_alpha': 8.889312622017128e-06, 'reg_lambda': 3.091638148501508}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:25,492] Trial 134 finished with value: -0.987878891281041 and parameters: {'learning_rate': 0.16863234852745335, 'num_leaves': 205, 'max_depth': 6, 'min_child_samples': 11, 'feature_fraction': 0.8094303249405582, 'bagging_fraction': 0.8570487874786616, 'reg_alpha': 6.018838081225705e-06, 'reg_lambda': 2.915180506646019}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:26,512] Trial 135 finished with value: -0.9879082754256796 and parameters: {'learning_rate': 0.1696842962136095, 'num_leaves': 204, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.8168904734017227, 'bagging_fraction': 0.85868582001333, 'reg_alpha': 8.632831419918828e-06, 'reg_lambda': 0.4179247241394508}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:27,659] Trial 136 finished with value: -0.9873501975223217 and parameters: {'learning_rate': 0.16254690536317845, 'num_leaves': 204, 'max_depth': 5, 'min_child_samples': 11, 'feature_fraction': 0.8071800384166216, 'bagging_fraction': 0.8573718600108947, 'reg_alpha': 7.706910091538227e-06, 'reg_lambda': 0.4571994983076578}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:28,630] Trial 137 finished with value: -0.9867183011297239 and parameters: {'learning_rate': 0.1764699671157065, 'num_leaves': 211, 'max_depth': 6, 'min_child_samples': 15, 'feature_fraction': 0.7972683565590029, 'bagging_fraction': 0.8276142394408348, 'reg_alpha': 2.489330528808308e-05, 'reg_lambda': 0.15765135066692273}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:30,043] Trial 138 finished with value: -0.9886559012004108 and parameters: {'learning_rate': 0.16672146290288006, 'num_leaves': 199, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.8083809319192852, 'bagging_fraction': 0.8617619101070222, 'reg_alpha': 1.5764809593565324e-05, 'reg_lambda': 2.6170230584599885}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:31,916] Trial 139 finished with value: -0.9856183170300996 and parameters: {'learning_rate': 0.16986582529295227, 'num_leaves': 196, 'max_depth': 6, 'min_child_samples': 55, 'feature_fraction': 0.8099369970729468, 'bagging_fraction': 0.8612799371439551, 'reg_alpha': 5.947500264087335e-06, 'reg_lambda': 0.8436378092701915}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:33,251] Trial 140 finished with value: -0.9881307682876264 and parameters: {'learning_rate': 0.18985603741680018, 'num_leaves': 219, 'max_depth': 5, 'min_child_samples': 10, 'feature_fraction': 0.8205162078599963, 'bagging_fraction': 0.8462471181325845, 'reg_alpha': 1.5081835763504502e-05, 'reg_lambda': 2.859603639863942}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:34,208] Trial 141 finished with value: -0.9880867157962079 and parameters: {'learning_rate': 0.18731746597956328, 'num_leaves': 201, 'max_depth': 5, 'min_child_samples': 10, 'feature_fraction': 0.8279990300264535, 'bagging_fraction': 0.8491059128018922, 'reg_alpha': 1.248641241170372e-05, 'reg_lambda': 2.7624102274008715}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:35,174] Trial 142 finished with value: -0.9882186834991152 and parameters: {'learning_rate': 0.19941737850776578, 'num_leaves': 219, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8253427050740976, 'bagging_fraction': 0.8391409191339402, 'reg_alpha': 1.4153344279228911e-05, 'reg_lambda': 1.718107125138791}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:36,167] Trial 143 finished with value: -0.988338173416281 and parameters: {'learning_rate': 0.1871087329303521, 'num_leaves': 219, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8243212311130194, 'bagging_fraction': 0.8359829144511499, 'reg_alpha': 1.5838707933746045e-05, 'reg_lambda': 1.4963524984869228}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:37,054] Trial 144 finished with value: -0.9871553604133135 and parameters: {'learning_rate': 0.1994687894843345, 'num_leaves': 219, 'max_depth': 4, 'min_child_samples': 12, 'feature_fraction': 0.8208404128021505, 'bagging_fraction': 0.8151595385108533, 'reg_alpha': 1.342402305199359e-05, 'reg_lambda': 1.6345646111897778}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:37,896] Trial 145 finished with value: -0.986896794486156 and parameters: {'learning_rate': 0.18709322269597117, 'num_leaves': 228, 'max_depth': 3, 'min_child_samples': 15, 'feature_fraction': 0.8390463102886908, 'bagging_fraction': 0.839147584650339, 'reg_alpha': 2.0149050776934845e-05, 'reg_lambda': 1.0833385051814302}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:38,932] Trial 146 finished with value: -0.988036451266959 and parameters: {'learning_rate': 0.18855922798017352, 'num_leaves': 213, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.8289022409345873, 'bagging_fraction': 0.8304083959327659, 'reg_alpha': 3.227456270659735e-05, 'reg_lambda': 0.6358750048846704}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:39,883] Trial 147 finished with value: -0.9874339244374071 and parameters: {'learning_rate': 0.1889579909844495, 'num_leaves': 241, 'max_depth': 4, 'min_child_samples': 12, 'feature_fraction': 0.8288290630002791, 'bagging_fraction': 0.8308119256193388, 'reg_alpha': 1.617099529548929e-05, 'reg_lambda': 0.7837856372061922}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:40,590] Trial 148 finished with value: -0.9859307502306853 and parameters: {'learning_rate': 0.18852095305794078, 'num_leaves': 207, 'max_depth': 4, 'min_child_samples': 14, 'feature_fraction': 0.7880032420618206, 'bagging_fraction': 0.8677161659688943, 'reg_alpha': 2.905350539660205e-05, 'reg_lambda': 0.4575342777990121}. Best is trial 131 with value: -0.9887257100865543.
[I 2025-08-05 13:03:41,639] Trial 149 finished with value: -0.9863422291127042 and parameters: {'learning_rate': 0.19842011651053057, 'num_leaves': 233, 'max_depth': 5, 'min_child_samples': 17, 'feature_fraction': 0.843413973279858, 'bagging_fraction': 0.8408176539547692, 'reg_alpha': 3.715086010488598e-05, 'reg_lambda': 2.5823796717805303}. Best is trial 131 with value: -0.9887257100865543.
2025-08-05 13:03:42 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.9947816916685762, 'val_lightgbm': 0.993543410756154, 'val_ensemble': 0.9952995853659523}
2025-08-05 13:03:42 [INFO] Selected best model 'ensemble' with validation R²=0.9953
2025-08-05 13:03:42 [INFO] Retraining best model 'ensemble' on full dataset
2025-08-05 13:03:43 [INFO] Retraining completed in 0.98s
2025-08-05 13:03:43 [INFO] Saved final model to '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/final_ensemble.pkl'
2025-08-05 13:03:43 [INFO] Tree-based → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/final_ensemble.pkl (R²=0.9953)
2025-08-05 13:03:43 [INFO] Training TabNet model...
[I 2025-08-05 13:03:44,116] A new study created in memory with name: no-name-4fddd54b-4a1f-46ef-aebc-545f5cd9094c
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:04:19,997] Trial 0 finished with value: 0.9059235497117588 and parameters: {'n_d': 22, 'n_a': 57, 'n_steps': 7, 'gamma': 1.975861563736558, 'lambda_sparse': 2.9971925985757793e-05, 'lr': 0.01600041789446452, 'weight_decay': 6.016855211994473e-06}. Best is trial 0 with value: 0.9059235497117588.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:04:39,747] Trial 1 finished with value: 0.889549202147329 and parameters: {'n_d': 15, 'n_a': 54, 'n_steps': 4, 'gamma': 1.9363906044833685, 'lambda_sparse': 0.0015204966233404273, 'lr': 0.0012162477869959425, 'weight_decay': 2.10315345427832e-05}. Best is trial 0 with value: 0.9059235497117588.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:05:09,210] Trial 2 finished with value: 0.8075785413017338 and parameters: {'n_d': 40, 'n_a': 36, 'n_steps': 7, 'gamma': 1.3743360612876132, 'lambda_sparse': 0.0008069569722492603, 'lr': 0.0007868571177417605, 'weight_decay': 0.0009494837416022258}. Best is trial 0 with value: 0.9059235497117588.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:05:32,415] Trial 3 finished with value: 0.5211524000389025 and parameters: {'n_d': 62, 'n_a': 46, 'n_steps': 5, 'gamma': 1.5249833265582384, 'lambda_sparse': 1.1914247259946011e-05, 'lr': 0.0001965984712280154, 'weight_decay': 0.0008194890009678333}. Best is trial 0 with value: 0.9059235497117588.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:06:08,717] Trial 4 finished with value: 0.22746935941122304 and parameters: {'n_d': 40, 'n_a': 23, 'n_steps': 8, 'gamma': 1.987693760150933, 'lambda_sparse': 1.1159331618886693e-05, 'lr': 0.0004454964255661838, 'weight_decay': 0.00042830129892032487}. Best is trial 0 with value: 0.9059235497117588.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:06:32,096] Trial 5 finished with value: 0.8993414915168543 and parameters: {'n_d': 41, 'n_a': 13, 'n_steps': 3, 'gamma': 1.7338779491120395, 'lambda_sparse': 3.0643785772785046e-05, 'lr': 0.0010950880635467598, 'weight_decay': 6.702705762783929e-05}. Best is trial 0 with value: 0.9059235497117588.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:07:02,433] Trial 6 finished with value: 0.7116742270562997 and parameters: {'n_d': 48, 'n_a': 17, 'n_steps': 6, 'gamma': 1.8968213943498875, 'lambda_sparse': 3.932203368815488e-05, 'lr': 0.0006490608345859321, 'weight_decay': 8.470494795887522e-05}. Best is trial 0 with value: 0.9059235497117588.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:07:30,482] Trial 7 finished with value: 0.9114674054695742 and parameters: {'n_d': 21, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5163118239915203, 'lambda_sparse': 0.004147009681843804, 'lr': 0.028588805604370444, 'weight_decay': 4.778034606884726e-05}. Best is trial 7 with value: 0.9114674054695742.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:08:02,154] Trial 8 finished with value: 0.846512665020061 and parameters: {'n_d': 21, 'n_a': 17, 'n_steps': 6, 'gamma': 1.6552928402302323, 'lambda_sparse': 0.004910451327885939, 'lr': 0.0014030079463908537, 'weight_decay': 1.0459990797031809e-05}. Best is trial 7 with value: 0.9114674054695742.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:08:26,608] Trial 9 finished with value: 0.9051885621697434 and parameters: {'n_d': 23, 'n_a': 37, 'n_steps': 6, 'gamma': 1.0358359469472687, 'lambda_sparse': 0.0007441025335228455, 'lr': 0.055121982053367394, 'weight_decay': 8.301087821330218e-05}. Best is trial 7 with value: 0.9114674054695742.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:09:14,932] Trial 10 finished with value: 0.9228584291211682 and parameters: {'n_d': 10, 'n_a': 28, 'n_steps': 10, 'gamma': 1.2598542559983932, 'lambda_sparse': 0.008281178508714127, 'lr': 0.013403106545147201, 'weight_decay': 1.4508393551066074e-06}. Best is trial 10 with value: 0.9228584291211682.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:09:57,218] Trial 11 finished with value: 0.902813547991744 and parameters: {'n_d': 9, 'n_a': 32, 'n_steps': 10, 'gamma': 1.255284758746844, 'lambda_sparse': 0.008178420168985847, 'lr': 0.00878516244497839, 'weight_decay': 1.6813649681446566e-06}. Best is trial 10 with value: 0.9228584291211682.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:10:45,757] Trial 12 finished with value: 0.9246504418901265 and parameters: {'n_d': 8, 'n_a': 27, 'n_steps': 10, 'gamma': 1.2205136639282723, 'lambda_sparse': 0.003126217979325936, 'lr': 0.08260213844334276, 'weight_decay': 1.9468746702582482e-06}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:11:32,380] Trial 13 finished with value: 0.9076955819665188 and parameters: {'n_d': 10, 'n_a': 25, 'n_steps': 10, 'gamma': 1.143973318456235, 'lambda_sparse': 0.00021837801727637705, 'lr': 0.0750095123600846, 'weight_decay': 1.0137926144146347e-06}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:12:09,048] Trial 14 finished with value: 0.865265259173851 and parameters: {'n_d': 30, 'n_a': 8, 'n_steps': 9, 'gamma': 1.3029173336487818, 'lambda_sparse': 0.0021726023132760926, 'lr': 0.005376120473237004, 'weight_decay': 3.474352224318689e-06}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:12:53,307] Trial 15 finished with value: 0.9198644808914962 and parameters: {'n_d': 8, 'n_a': 44, 'n_steps': 9, 'gamma': 1.0029714679883348, 'lambda_sparse': 0.00981190670942404, 'lr': 0.027025875402323724, 'weight_decay': 3.118272408043834e-06}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:13:36,928] Trial 16 finished with value: 0.9138649979730867 and parameters: {'n_d': 30, 'n_a': 25, 'n_steps': 9, 'gamma': 1.2224058225662289, 'lambda_sparse': 0.00021626296640421734, 'lr': 0.08242034193160827, 'weight_decay': 1.3311727205153345e-05}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:14:24,008] Trial 17 finished with value: 0.8634150005949532 and parameters: {'n_d': 15, 'n_a': 47, 'n_steps': 10, 'gamma': 1.3783382456336217, 'lambda_sparse': 0.0026075014903125, 'lr': 0.0029876859997331213, 'weight_decay': 1.036451174479791e-06}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:15:02,915] Trial 18 finished with value: 0.9064117268737616 and parameters: {'n_d': 56, 'n_a': 29, 'n_steps': 8, 'gamma': 1.1299963416054726, 'lambda_sparse': 0.0006235148334595124, 'lr': 0.01269759064966043, 'weight_decay': 2.987869883707373e-06}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:15:39,849] Trial 19 finished with value: 0.8791272710975861 and parameters: {'n_d': 15, 'n_a': 41, 'n_steps': 8, 'gamma': 1.3826711712131246, 'lambda_sparse': 9.584449872724307e-05, 'lr': 0.03596831385816209, 'weight_decay': 6.580199805352394e-06}. Best is trial 12 with value: 0.9246504418901265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:16:35,042] A new study created in memory with name: no-name-875fb960-2433-4716-bea8-0461e63f3898
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:17:13,323] Trial 0 finished with value: 0.9464972167863552 and parameters: {'n_d': 35, 'n_a': 14, 'n_steps': 9, 'gamma': 1.5661905408191479, 'lambda_sparse': 0.003058916887241655, 'lr': 0.08192428416023802, 'weight_decay': 4.404185419262773e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:17:40,937] Trial 1 finished with value: 0.9042590135128126 and parameters: {'n_d': 46, 'n_a': 21, 'n_steps': 6, 'gamma': 1.7598903014205647, 'lambda_sparse': 0.00015210279974074736, 'lr': 0.014725580487360258, 'weight_decay': 2.541999404054431e-05}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:18:13,544] Trial 2 finished with value: 0.0567355641558297 and parameters: {'n_d': 21, 'n_a': 60, 'n_steps': 6, 'gamma': 1.1390976036400529, 'lambda_sparse': 0.004597852553754865, 'lr': 0.00021326975943111652, 'weight_decay': 0.0005907122053527812}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:18:38,338] Trial 3 finished with value: 0.9381699181986592 and parameters: {'n_d': 14, 'n_a': 22, 'n_steps': 6, 'gamma': 1.610702395501664, 'lambda_sparse': 0.004172643347987913, 'lr': 0.08276124641721022, 'weight_decay': 2.491650747960309e-05}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:19:05,520] Trial 4 finished with value: 0.9232679203100328 and parameters: {'n_d': 38, 'n_a': 48, 'n_steps': 6, 'gamma': 1.9512832101610895, 'lambda_sparse': 4.143713589416372e-05, 'lr': 0.06831469557695227, 'weight_decay': 6.889479516026605e-05}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:19:40,217] Trial 5 finished with value: 0.9454015407658992 and parameters: {'n_d': 45, 'n_a': 50, 'n_steps': 9, 'gamma': 1.582438103301251, 'lambda_sparse': 5.15819083982534e-05, 'lr': 0.08997314382128316, 'weight_decay': 1.1566290925374805e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:20:12,234] Trial 6 finished with value: 0.9177249362482669 and parameters: {'n_d': 12, 'n_a': 47, 'n_steps': 6, 'gamma': 1.3943267581481908, 'lambda_sparse': 0.00263446573338058, 'lr': 0.005194923757847484, 'weight_decay': 2.7748324054983743e-05}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:20:57,194] Trial 7 finished with value: 0.89295839300091 and parameters: {'n_d': 24, 'n_a': 28, 'n_steps': 9, 'gamma': 1.4803316412776737, 'lambda_sparse': 0.0048954847145230036, 'lr': 0.002106868838698337, 'weight_decay': 0.0001859416883322872}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:21:33,315] Trial 8 finished with value: 0.8844740425649196 and parameters: {'n_d': 46, 'n_a': 27, 'n_steps': 7, 'gamma': 1.0295406781967356, 'lambda_sparse': 0.0001478225902915273, 'lr': 0.0011159267869906987, 'weight_decay': 6.3851639733055256e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:21:57,485] Trial 9 finished with value: 0.9140587263693148 and parameters: {'n_d': 29, 'n_a': 20, 'n_steps': 5, 'gamma': 1.2000587089359196, 'lambda_sparse': 0.00018077156254327152, 'lr': 0.0809751010937311, 'weight_decay': 5.927981276647116e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:22:13,325] Trial 10 finished with value: 0.8866384072984961 and parameters: {'n_d': 64, 'n_a': 8, 'n_steps': 3, 'gamma': 1.8162258108209837, 'lambda_sparse': 0.0007836626946939743, 'lr': 0.014473175783072034, 'weight_decay': 2.359115615379609e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:23:00,778] Trial 11 finished with value: 0.9041556170086305 and parameters: {'n_d': 54, 'n_a': 43, 'n_steps': 10, 'gamma': 1.6130377384410532, 'lambda_sparse': 1.0029611294981794e-05, 'lr': 0.02313097502750821, 'weight_decay': 1.397288100589852e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:23:23,623] Trial 12 finished with value: 0.8317225688341152 and parameters: {'n_d': 36, 'n_a': 64, 'n_steps': 8, 'gamma': 1.2934448884314043, 'lambda_sparse': 0.0006287315352730181, 'lr': 0.027012946756372357, 'weight_decay': 4.379001832118309e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:24:11,784] Trial 13 finished with value: 0.9323373845214475 and parameters: {'n_d': 39, 'n_a': 54, 'n_steps': 10, 'gamma': 1.6210975756964208, 'lambda_sparse': 3.4068336778556194e-05, 'lr': 0.00596990160197981, 'weight_decay': 1.2099110084182415e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:24:50,525] Trial 14 finished with value: 0.7379215324076052 and parameters: {'n_d': 53, 'n_a': 38, 'n_steps': 8, 'gamma': 1.4345086014703818, 'lambda_sparse': 0.0012542285311467087, 'lr': 0.0003532169286220908, 'weight_decay': 1.002351186428949e-05}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:25:35,502] Trial 15 finished with value: 0.9392809812481977 and parameters: {'n_d': 31, 'n_a': 8, 'n_steps': 9, 'gamma': 1.7532429667299154, 'lambda_sparse': 3.761497712052707e-05, 'lr': 0.03808711614579898, 'weight_decay': 2.7818820143870544e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:26:07,283] Trial 16 finished with value: 0.88253476521954 and parameters: {'n_d': 46, 'n_a': 34, 'n_steps': 8, 'gamma': 1.5849037587358956, 'lambda_sparse': 7.290630555041217e-05, 'lr': 0.008460361601765458, 'weight_decay': 1.0093995419441488e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:26:48,168] Trial 17 finished with value: 0.818828959434548 and parameters: {'n_d': 57, 'n_a': 54, 'n_steps': 9, 'gamma': 1.9857165464762696, 'lambda_sparse': 1.0786501074636352e-05, 'lr': 0.0012196475092997917, 'weight_decay': 1.4766446856253652e-05}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:27:02,765] Trial 18 finished with value: 0.8580384312529777 and parameters: {'n_d': 43, 'n_a': 14, 'n_steps': 4, 'gamma': 1.303365589311937, 'lambda_sparse': 0.009008641357355828, 'lr': 0.046147690739832416, 'weight_decay': 2.9976891379197613e-06}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:27:51,864] Trial 19 finished with value: 0.9350497932047072 and parameters: {'n_d': 30, 'n_a': 38, 'n_steps': 10, 'gamma': 1.5277116060896503, 'lambda_sparse': 0.0003225560793402662, 'lr': 0.012216477381200373, 'weight_decay': 5.519003668098489e-05}. Best is trial 0 with value: 0.9464972167863552.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:28:52,569] A new study created in memory with name: no-name-2f3f7080-ea0b-4b02-bbc2-28e3ec25b6f8
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:29:10,768] Trial 0 finished with value: 0.8783818187116028 and parameters: {'n_d': 38, 'n_a': 45, 'n_steps': 3, 'gamma': 1.2046944449902703, 'lambda_sparse': 0.0009624986997578015, 'lr': 0.045734546552492886, 'weight_decay': 7.445890278625507e-05}. Best is trial 0 with value: 0.8783818187116028.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:29:59,722] Trial 1 finished with value: 0.3874249802258146 and parameters: {'n_d': 42, 'n_a': 41, 'n_steps': 10, 'gamma': 1.2793958281951046, 'lambda_sparse': 0.00034178547697914514, 'lr': 0.0005032119541048687, 'weight_decay': 0.00010573184390647249}. Best is trial 0 with value: 0.8783818187116028.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:30:40,281] Trial 2 finished with value: 0.9467572193616931 and parameters: {'n_d': 44, 'n_a': 51, 'n_steps': 8, 'gamma': 1.0525479904890707, 'lambda_sparse': 0.009113294800144047, 'lr': 0.06306860753678682, 'weight_decay': 1.9866269515061206e-06}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:31:07,672] Trial 3 finished with value: 0.9464027831873404 and parameters: {'n_d': 34, 'n_a': 39, 'n_steps': 5, 'gamma': 1.8919195198965608, 'lambda_sparse': 0.002697367086599964, 'lr': 0.051430254859816144, 'weight_decay': 4.3921245427521264e-06}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:31:51,922] Trial 4 finished with value: 0.9359607517446398 and parameters: {'n_d': 45, 'n_a': 64, 'n_steps': 9, 'gamma': 1.5473095668092958, 'lambda_sparse': 0.0004826551338244289, 'lr': 0.009816833212851992, 'weight_decay': 2.25232370824346e-06}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:32:41,258] Trial 5 finished with value: 0.730074638644263 and parameters: {'n_d': 11, 'n_a': 57, 'n_steps': 10, 'gamma': 1.123521847285568, 'lambda_sparse': 0.0013210453668442213, 'lr': 0.0006408799393426083, 'weight_decay': 0.00045664189017806264}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:33:17,979] Trial 6 finished with value: 0.8981766575299711 and parameters: {'n_d': 49, 'n_a': 25, 'n_steps': 7, 'gamma': 1.843232020593192, 'lambda_sparse': 5.0095211171562164e-05, 'lr': 0.0035471370531770536, 'weight_decay': 0.0004551287700643419}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:34:02,947] Trial 7 finished with value: 0.586674818756096 and parameters: {'n_d': 15, 'n_a': 9, 'n_steps': 9, 'gamma': 1.6906214856766, 'lambda_sparse': 0.00012373966665075588, 'lr': 0.0006090778646459249, 'weight_decay': 1.3457139568421071e-06}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:34:39,155] Trial 8 finished with value: 0.850981774755776 and parameters: {'n_d': 22, 'n_a': 54, 'n_steps': 7, 'gamma': 1.3307171009152907, 'lambda_sparse': 0.0004449926755115052, 'lr': 0.0007906653810488821, 'weight_decay': 2.632109272653147e-05}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:35:07,354] Trial 9 finished with value: 0.9182002876546025 and parameters: {'n_d': 31, 'n_a': 34, 'n_steps': 5, 'gamma': 1.2279000847714867, 'lambda_sparse': 0.004306591476615721, 'lr': 0.0017886189610514074, 'weight_decay': 3.727384675041336e-05}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:35:47,712] Trial 10 finished with value: 0.8897487624065614 and parameters: {'n_d': 63, 'n_a': 23, 'n_steps': 8, 'gamma': 1.0356868945816724, 'lambda_sparse': 0.009906908782193283, 'lr': 0.013821153111665947, 'weight_decay': 9.633892531003045e-06}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:36:04,410] Trial 11 finished with value: 0.9324659745503898 and parameters: {'n_d': 28, 'n_a': 51, 'n_steps': 5, 'gamma': 1.938793996569926, 'lambda_sparse': 1.0204781826151012e-05, 'lr': 0.0936628220513497, 'weight_decay': 4.340534030448745e-06}. Best is trial 2 with value: 0.9467572193616931.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:36:32,668] Trial 12 finished with value: 0.9476479073826932 and parameters: {'n_d': 55, 'n_a': 34, 'n_steps': 5, 'gamma': 1.487836388438471, 'lambda_sparse': 0.0033485692169443484, 'lr': 0.025213792384440933, 'weight_decay': 6.78594193018285e-06}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:36:56,379] Trial 13 finished with value: 0.5930230024981001 and parameters: {'n_d': 55, 'n_a': 31, 'n_steps': 3, 'gamma': 1.4635460581641082, 'lambda_sparse': 0.009809776856600396, 'lr': 0.00010403708896438852, 'weight_decay': 1.1285220799321973e-05}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:37:28,152] Trial 14 finished with value: 0.9132370260063338 and parameters: {'n_d': 55, 'n_a': 47, 'n_steps': 6, 'gamma': 1.4376319907737172, 'lambda_sparse': 0.003215834753565422, 'lr': 0.016207360234560885, 'weight_decay': 1.2850353847991438e-06}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:37:59,961] Trial 15 finished with value: 0.9011265548063392 and parameters: {'n_d': 62, 'n_a': 17, 'n_steps': 6, 'gamma': 1.674367223239245, 'lambda_sparse': 0.001804621881370757, 'lr': 0.02956054296100239, 'weight_decay': 5.915256362027237e-06}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:38:24,220] Trial 16 finished with value: 0.9279479083550853 and parameters: {'n_d': 50, 'n_a': 63, 'n_steps': 4, 'gamma': 1.0451180288915136, 'lambda_sparse': 0.004328552601782457, 'lr': 0.005263390552409931, 'weight_decay': 1.564142662024205e-05}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:38:58,890] Trial 17 finished with value: 0.937663751614062 and parameters: {'n_d': 55, 'n_a': 29, 'n_steps': 8, 'gamma': 1.58937182617365, 'lambda_sparse': 0.0001183729796750994, 'lr': 0.08602280360672797, 'weight_decay': 2.576787377811956e-06}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:39:30,904] Trial 18 finished with value: 0.8847486505938682 and parameters: {'n_d': 41, 'n_a': 44, 'n_steps': 8, 'gamma': 1.3717183847002024, 'lambda_sparse': 0.0008263022115722023, 'lr': 0.024934193053517625, 'weight_decay': 1.1151204401622572e-06}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:39:58,102] Trial 19 finished with value: 0.9267725568009363 and parameters: {'n_d': 49, 'n_a': 58, 'n_steps': 4, 'gamma': 1.8159903392878425, 'lambda_sparse': 0.006446716245069822, 'lr': 0.00605853748414745, 'weight_decay': 2.5625555756561483e-06}. Best is trial 12 with value: 0.9476479073826932.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:40:30,027] A new study created in memory with name: no-name-aa488380-a25d-4e23-b35c-1c623234fc3f
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:41:09,025] Trial 0 finished with value: 0.9206014574441592 and parameters: {'n_d': 13, 'n_a': 36, 'n_steps': 9, 'gamma': 1.4888469461623373, 'lambda_sparse': 0.0021655437088757574, 'lr': 0.010792516457948998, 'weight_decay': 1.353513707404145e-05}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:41:32,703] Trial 1 finished with value: 0.8859074286834943 and parameters: {'n_d': 47, 'n_a': 23, 'n_steps': 3, 'gamma': 1.2683553456141676, 'lambda_sparse': 0.0006014285590682755, 'lr': 0.023966614413297067, 'weight_decay': 3.2614422671737446e-06}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:42:01,170] Trial 2 finished with value: 0.8915433501556977 and parameters: {'n_d': 33, 'n_a': 54, 'n_steps': 4, 'gamma': 1.7975464755978283, 'lambda_sparse': 0.003871091175871142, 'lr': 0.0006902840493332607, 'weight_decay': 2.6273034011320623e-05}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:42:29,296] Trial 3 finished with value: 0.8577843842506192 and parameters: {'n_d': 10, 'n_a': 33, 'n_steps': 5, 'gamma': 1.4068308640767815, 'lambda_sparse': 0.00933930314478063, 'lr': 0.004327841530123255, 'weight_decay': 0.00011313561990021714}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:42:53,085] Trial 4 finished with value: 0.9063299780397701 and parameters: {'n_d': 16, 'n_a': 17, 'n_steps': 3, 'gamma': 1.4461378667251865, 'lambda_sparse': 1.980839970696294e-05, 'lr': 0.002287281276378025, 'weight_decay': 4.185395243730842e-06}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:43:25,205] Trial 5 finished with value: -0.24128595626041727 and parameters: {'n_d': 49, 'n_a': 16, 'n_steps': 6, 'gamma': 1.7579673362784702, 'lambda_sparse': 0.0012052770804656752, 'lr': 0.00010534054722007155, 'weight_decay': 1.5804605977713699e-06}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:43:53,261] Trial 6 finished with value: 0.8856117561402519 and parameters: {'n_d': 38, 'n_a': 12, 'n_steps': 5, 'gamma': 1.9813576815288068, 'lambda_sparse': 0.00020342161269680013, 'lr': 0.0038944712536395144, 'weight_decay': 0.0007631760276341505}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:44:19,829] Trial 7 finished with value: 0.8826775555868349 and parameters: {'n_d': 31, 'n_a': 30, 'n_steps': 5, 'gamma': 1.4172811912755034, 'lambda_sparse': 0.0019536780080468036, 'lr': 0.0011959911776112373, 'weight_decay': 1.0787084559930966e-06}. Best is trial 0 with value: 0.9206014574441592.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:44:46,509] Trial 8 finished with value: 0.9500843116445726 and parameters: {'n_d': 37, 'n_a': 17, 'n_steps': 5, 'gamma': 1.6881856026276847, 'lambda_sparse': 0.003851260973331954, 'lr': 0.03060593947567735, 'weight_decay': 0.00013672996780664788}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:45:22,998] Trial 9 finished with value: 0.6312465148450804 and parameters: {'n_d': 34, 'n_a': 43, 'n_steps': 7, 'gamma': 1.6892326501969173, 'lambda_sparse': 0.00404441548441848, 'lr': 0.00042675875866087794, 'weight_decay': 0.00032929541776581165}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:45:55,911] Trial 10 finished with value: 0.9389568521191917 and parameters: {'n_d': 63, 'n_a': 56, 'n_steps': 8, 'gamma': 1.0482665893920915, 'lambda_sparse': 0.00012651765218144506, 'lr': 0.08760065665326175, 'weight_decay': 0.00010140076325293087}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:46:22,943] Trial 11 finished with value: 0.8901202022091944 and parameters: {'n_d': 63, 'n_a': 62, 'n_steps': 8, 'gamma': 1.105122400798299, 'lambda_sparse': 0.00011895168459444615, 'lr': 0.05691745017886118, 'weight_decay': 0.00014693193466169338}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:47:02,280] Trial 12 finished with value: 0.934378431111194 and parameters: {'n_d': 63, 'n_a': 47, 'n_steps': 10, 'gamma': 1.0286203374452472, 'lambda_sparse': 6.420077514847529e-05, 'lr': 0.08826421031032704, 'weight_decay': 7.194360441375545e-05}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:47:37,596] Trial 13 finished with value: 0.9375088557125009 and parameters: {'n_d': 53, 'n_a': 61, 'n_steps': 7, 'gamma': 1.600751426558075, 'lambda_sparse': 4.1847263311627386e-05, 'lr': 0.025773274908244645, 'weight_decay': 4.466501000345907e-05}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:48:07,449] Trial 14 finished with value: 0.8427407385999323 and parameters: {'n_d': 22, 'n_a': 8, 'n_steps': 8, 'gamma': 1.2018127338766735, 'lambda_sparse': 0.00034839302739310673, 'lr': 0.02782711727406612, 'weight_decay': 0.00027660838642646517}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:48:38,781] Trial 15 finished with value: 0.9266070641316464 and parameters: {'n_d': 42, 'n_a': 25, 'n_steps': 6, 'gamma': 1.95217943470338, 'lambda_sparse': 1.2385681042708003e-05, 'lr': 0.011061598099536208, 'weight_decay': 1.4779004204329161e-05}. Best is trial 8 with value: 0.9500843116445726.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:49:15,078] Trial 16 finished with value: 0.9560237680227183 and parameters: {'n_d': 25, 'n_a': 45, 'n_steps': 10, 'gamma': 1.2869264415217447, 'lambda_sparse': 0.0006834236512833361, 'lr': 0.09481398627312605, 'weight_decay': 0.0008260014298155594}. Best is trial 16 with value: 0.9560237680227183.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:49:47,543] Trial 17 finished with value: 0.9173334288936225 and parameters: {'n_d': 23, 'n_a': 43, 'n_steps': 10, 'gamma': 1.3173980834313264, 'lambda_sparse': 0.000767450972056568, 'lr': 0.04212525990735168, 'weight_decay': 0.0008508569674083208}. Best is trial 16 with value: 0.9560237680227183.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:50:12,042] Trial 18 finished with value: 0.9268753489380407 and parameters: {'n_d': 27, 'n_a': 46, 'n_steps': 4, 'gamma': 1.5890473939243894, 'lambda_sparse': 0.00979064783252679, 'lr': 0.010493205012622785, 'weight_decay': 0.00034591004182656814}. Best is trial 16 with value: 0.9560237680227183.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:50:30,565] Trial 19 finished with value: 0.6929285139730765 and parameters: {'n_d': 19, 'n_a': 24, 'n_steps': 9, 'gamma': 1.8571886101690354, 'lambda_sparse': 0.0004874437697795666, 'lr': 0.09739857251249923, 'weight_decay': 0.0005404044019963112}. Best is trial 16 with value: 0.9560237680227183.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:51:11,593] A new study created in memory with name: no-name-cc2ab722-a2e5-4714-9098-d598d6d28b14
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:51:26,247] Trial 0 finished with value: -8.34292846835994 and parameters: {'n_d': 14, 'n_a': 37, 'n_steps': 5, 'gamma': 1.6286061123485425, 'lambda_sparse': 0.0013275699566364667, 'lr': 0.02720196407715817, 'weight_decay': 5.3712401426696574e-05}. Best is trial 0 with value: -8.34292846835994.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:52:05,779] Trial 1 finished with value: 0.5075933039842071 and parameters: {'n_d': 62, 'n_a': 15, 'n_steps': 10, 'gamma': 1.5621819640149028, 'lambda_sparse': 0.0013939700030616174, 'lr': 0.0013313517433416815, 'weight_decay': 0.00010112672279336777}. Best is trial 1 with value: 0.5075933039842071.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:52:16,343] Trial 2 finished with value: -4.734564539233854 and parameters: {'n_d': 22, 'n_a': 51, 'n_steps': 8, 'gamma': 1.04320564886816, 'lambda_sparse': 0.0005347207033395944, 'lr': 0.011680935050381957, 'weight_decay': 0.0003149922031263771}. Best is trial 1 with value: 0.5075933039842071.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:52:31,286] Trial 3 finished with value: -1.5434370941036306 and parameters: {'n_d': 64, 'n_a': 32, 'n_steps': 10, 'gamma': 1.0571473734669885, 'lambda_sparse': 0.00023184732091194793, 'lr': 0.04603695582685329, 'weight_decay': 0.0005624136025164049}. Best is trial 1 with value: 0.5075933039842071.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:52:52,791] Trial 4 finished with value: 0.7109538541158824 and parameters: {'n_d': 30, 'n_a': 39, 'n_steps': 7, 'gamma': 1.4503402749236671, 'lambda_sparse': 0.0077169111981903035, 'lr': 0.003738843118127226, 'weight_decay': 8.727964662516223e-06}. Best is trial 4 with value: 0.7109538541158824.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:53:11,248] Trial 5 finished with value: -2.8673014117395264 and parameters: {'n_d': 58, 'n_a': 63, 'n_steps': 9, 'gamma': 1.3835541677511105, 'lambda_sparse': 8.272038960079135e-05, 'lr': 0.0003593537057997717, 'weight_decay': 2.5264771421477024e-06}. Best is trial 4 with value: 0.7109538541158824.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:53:35,187] Trial 6 finished with value: 0.8277231550223413 and parameters: {'n_d': 18, 'n_a': 48, 'n_steps': 3, 'gamma': 1.031081624634195, 'lambda_sparse': 0.00012660938378891893, 'lr': 0.0006696256799723331, 'weight_decay': 6.208125810539184e-05}. Best is trial 6 with value: 0.8277231550223413.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:53:54,879] Trial 7 finished with value: 0.5346526525470887 and parameters: {'n_d': 28, 'n_a': 64, 'n_steps': 8, 'gamma': 1.713812847128922, 'lambda_sparse': 2.0461273118124338e-05, 'lr': 0.07245921136285148, 'weight_decay': 0.0005460007241511459}. Best is trial 6 with value: 0.8277231550223413.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:54:34,128] Trial 8 finished with value: 0.943810257575765 and parameters: {'n_d': 26, 'n_a': 15, 'n_steps': 9, 'gamma': 1.8411011915246833, 'lambda_sparse': 0.00014063835447420065, 'lr': 0.041124194913742224, 'weight_decay': 0.0003453166610702628}. Best is trial 8 with value: 0.943810257575765.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:54:58,469] Trial 9 finished with value: -3.219420062773308 and parameters: {'n_d': 40, 'n_a': 56, 'n_steps': 10, 'gamma': 1.2162297245140399, 'lambda_sparse': 0.004322811946705737, 'lr': 0.0009123190120697177, 'weight_decay': 0.00011172359555128612}. Best is trial 8 with value: 0.943810257575765.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:55:05,907] Trial 10 finished with value: -4.568025888034078 and parameters: {'n_d': 43, 'n_a': 8, 'n_steps': 5, 'gamma': 1.9462267458059206, 'lambda_sparse': 3.272078848993391e-05, 'lr': 0.007927420667567152, 'weight_decay': 1.3569571874515845e-05}. Best is trial 8 with value: 0.943810257575765.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:55:15,598] Trial 11 finished with value: -3.3518070492406666 and parameters: {'n_d': 13, 'n_a': 24, 'n_steps': 3, 'gamma': 1.9764753266910446, 'lambda_sparse': 0.00011659602015833081, 'lr': 0.00014600750542574658, 'weight_decay': 0.00017018981025484776}. Best is trial 8 with value: 0.943810257575765.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:55:35,168] Trial 12 finished with value: 0.8976814751988778 and parameters: {'n_d': 21, 'n_a': 46, 'n_steps': 3, 'gamma': 1.795409486565727, 'lambda_sparse': 6.812647586447654e-05, 'lr': 0.0015898510298836216, 'weight_decay': 2.6152327223166233e-05}. Best is trial 8 with value: 0.943810257575765.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:56:03,418] Trial 13 finished with value: 0.9519078813461515 and parameters: {'n_d': 30, 'n_a': 25, 'n_steps': 5, 'gamma': 1.7982562405494287, 'lambda_sparse': 1.0563482557440064e-05, 'lr': 0.0026740409755150432, 'weight_decay': 2.046749248552546e-05}. Best is trial 13 with value: 0.9519078813461515.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:56:10,827] Trial 14 finished with value: -4.248516805818266 and parameters: {'n_d': 48, 'n_a': 22, 'n_steps': 5, 'gamma': 1.827556321719556, 'lambda_sparse': 1.1566263571925787e-05, 'lr': 0.005641093395689065, 'weight_decay': 3.0104078480487375e-06}. Best is trial 13 with value: 0.9519078813461515.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:56:33,050] Trial 15 finished with value: 0.8403565087849629 and parameters: {'n_d': 32, 'n_a': 25, 'n_steps': 6, 'gamma': 1.826465237500272, 'lambda_sparse': 3.365763727791857e-05, 'lr': 0.016937965459041637, 'weight_decay': 8.137040242429992e-06}. Best is trial 13 with value: 0.9519078813461515.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:56:54,068] Trial 16 finished with value: 0.6608554514251204 and parameters: {'n_d': 37, 'n_a': 13, 'n_steps': 7, 'gamma': 1.7002309714950494, 'lambda_sparse': 0.00038623752144276136, 'lr': 0.0030081935018851373, 'weight_decay': 1.2523439128865707e-06}. Best is trial 13 with value: 0.9519078813461515.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:57:15,468] Trial 17 finished with value: 0.8744802328302829 and parameters: {'n_d': 50, 'n_a': 30, 'n_steps': 6, 'gamma': 1.918530969930534, 'lambda_sparse': 1.3392956328404023e-05, 'lr': 0.08443374845876774, 'weight_decay': 2.122854180661125e-05}. Best is trial 13 with value: 0.9519078813461515.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:57:27,776] Trial 18 finished with value: 0.6469012760449102 and parameters: {'n_d': 26, 'n_a': 18, 'n_steps': 4, 'gamma': 1.3592895108748277, 'lambda_sparse': 0.0010522537807465678, 'lr': 0.02546655092634864, 'weight_decay': 0.00020480309039125713}. Best is trial 13 with value: 0.9519078813461515.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:57:59,842] Trial 19 finished with value: 0.8825626320222438 and parameters: {'n_d': 35, 'n_a': 8, 'n_steps': 8, 'gamma': 1.5726644006002244, 'lambda_sparse': 4.453032334684988e-05, 'lr': 0.002678128394696535, 'weight_decay': 0.0007881244160386048}. Best is trial 13 with value: 0.9519078813461515.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:58:33,901] A new study created in memory with name: no-name-588f86df-d36e-455e-9a6a-81d35b07b726
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:59:02,230] Trial 0 finished with value: 0.8912618449467345 and parameters: {'n_d': 38, 'n_a': 53, 'n_steps': 5, 'gamma': 1.8341776677748767, 'lambda_sparse': 0.00019350504901401183, 'lr': 0.0011435488841945358, 'weight_decay': 0.00023690714473799127}. Best is trial 0 with value: 0.8912618449467345.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 13:59:34,263] Trial 1 finished with value: 0.8867535578100139 and parameters: {'n_d': 56, 'n_a': 43, 'n_steps': 6, 'gamma': 1.0152286200201646, 'lambda_sparse': 0.0005927173242906595, 'lr': 0.0008582631525559231, 'weight_decay': 1.3024656032548756e-05}. Best is trial 0 with value: 0.8912618449467345.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:00:14,834] Trial 2 finished with value: 0.9321603310780897 and parameters: {'n_d': 21, 'n_a': 64, 'n_steps': 8, 'gamma': 1.5739298886534623, 'lambda_sparse': 0.003959028447607841, 'lr': 0.007718839133983847, 'weight_decay': 2.0505282793802046e-06}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:00:51,151] Trial 3 finished with value: 0.9211756349912885 and parameters: {'n_d': 53, 'n_a': 48, 'n_steps': 7, 'gamma': 1.4277546096380787, 'lambda_sparse': 0.00046623978944120996, 'lr': 0.005088968651778768, 'weight_decay': 6.526189743763526e-05}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:01:31,639] Trial 4 finished with value: 0.8931330879887982 and parameters: {'n_d': 62, 'n_a': 64, 'n_steps': 8, 'gamma': 1.0759209365498934, 'lambda_sparse': 0.00019632804304117466, 'lr': 0.016459842376229685, 'weight_decay': 0.00025282875570868386}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:02:20,088] Trial 5 finished with value: 0.9282998854996986 and parameters: {'n_d': 51, 'n_a': 55, 'n_steps': 10, 'gamma': 1.4368717848842933, 'lambda_sparse': 2.5208633775991533e-05, 'lr': 0.085350016861572, 'weight_decay': 2.4716193299920018e-05}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:02:45,583] Trial 6 finished with value: 0.8285280070202329 and parameters: {'n_d': 30, 'n_a': 58, 'n_steps': 4, 'gamma': 1.3853414117242888, 'lambda_sparse': 1.9124661423750915e-05, 'lr': 0.00038680294745984365, 'weight_decay': 1.725962547628459e-05}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:03:11,922] Trial 7 finished with value: 0.903942190348052 and parameters: {'n_d': 52, 'n_a': 38, 'n_steps': 4, 'gamma': 1.007832958506158, 'lambda_sparse': 3.9243875859335156e-05, 'lr': 0.002654328235628838, 'weight_decay': 0.0005696568569739856}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:03:38,668] Trial 8 finished with value: 0.8725356337178698 and parameters: {'n_d': 25, 'n_a': 37, 'n_steps': 5, 'gamma': 1.8877478592397208, 'lambda_sparse': 1.7832300338472874e-05, 'lr': 0.0009316637695539951, 'weight_decay': 1.2514901882003635e-05}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:04:02,283] Trial 9 finished with value: 0.8573349256830982 and parameters: {'n_d': 9, 'n_a': 43, 'n_steps': 3, 'gamma': 1.1629048627064664, 'lambda_sparse': 1.3588599482931676e-05, 'lr': 0.0004134392209147983, 'weight_decay': 1.8128739374037288e-06}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:04:51,913] Trial 10 finished with value: -20.04347982310558 and parameters: {'n_d': 11, 'n_a': 14, 'n_steps': 10, 'gamma': 1.6815741873433279, 'lambda_sparse': 0.008010417899604796, 'lr': 0.00010369967868397406, 'weight_decay': 1.060450087037737e-06}. Best is trial 2 with value: 0.9321603310780897.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:05:41,214] Trial 11 finished with value: 0.9388147636893436 and parameters: {'n_d': 41, 'n_a': 64, 'n_steps': 10, 'gamma': 1.5888521635484016, 'lambda_sparse': 0.009981352080060214, 'lr': 0.09387789082813092, 'weight_decay': 3.760190344950997e-06}. Best is trial 11 with value: 0.9388147636893436.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:06:22,822] Trial 12 finished with value: 0.9386575978391332 and parameters: {'n_d': 38, 'n_a': 23, 'n_steps': 9, 'gamma': 1.618022292720073, 'lambda_sparse': 0.009492228074840361, 'lr': 0.05585255105888836, 'weight_decay': 3.210215488660045e-06}. Best is trial 11 with value: 0.9388147636893436.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:07:06,503] Trial 13 finished with value: 0.9392532101537989 and parameters: {'n_d': 41, 'n_a': 24, 'n_steps': 9, 'gamma': 1.6921934705428607, 'lambda_sparse': 0.001748941981999692, 'lr': 0.08499075859128832, 'weight_decay': 4.914044310878099e-06}. Best is trial 13 with value: 0.9392532101537989.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:07:42,342] Trial 14 finished with value: 0.9293107938056744 and parameters: {'n_d': 44, 'n_a': 26, 'n_steps': 9, 'gamma': 1.753668905421389, 'lambda_sparse': 0.0017036676031170926, 'lr': 0.026955888786904147, 'weight_decay': 5.182043244151419e-06}. Best is trial 13 with value: 0.9392532101537989.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:08:27,466] Trial 15 finished with value: 0.9298764702455955 and parameters: {'n_d': 44, 'n_a': 27, 'n_steps': 9, 'gamma': 1.2939389511120027, 'lambda_sparse': 0.0018423749296024965, 'lr': 0.02694399915491776, 'weight_decay': 6.2435646607515325e-06}. Best is trial 13 with value: 0.9392532101537989.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:08:59,511] Trial 16 finished with value: 0.9466083662859819 and parameters: {'n_d': 31, 'n_a': 13, 'n_steps': 10, 'gamma': 1.9369349227425032, 'lambda_sparse': 0.0017549477154779319, 'lr': 0.08584899839116776, 'weight_decay': 4.756797529570425e-05}. Best is trial 16 with value: 0.9466083662859819.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:09:28,920] Trial 17 finished with value: 0.9079900843472171 and parameters: {'n_d': 31, 'n_a': 8, 'n_steps': 8, 'gamma': 1.994040813625104, 'lambda_sparse': 0.0011228430172643365, 'lr': 0.01223815152064178, 'weight_decay': 5.902253234876696e-05}. Best is trial 16 with value: 0.9466083662859819.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:10:01,947] Trial 18 finished with value: 0.8930015251447182 and parameters: {'n_d': 18, 'n_a': 17, 'n_steps': 7, 'gamma': 1.9958926375320043, 'lambda_sparse': 0.003128842200131388, 'lr': 0.035068850831332904, 'weight_decay': 5.957309867974868e-05}. Best is trial 16 with value: 0.9466083662859819.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:10:28,642] Trial 19 finished with value: 0.8807981447972221 and parameters: {'n_d': 32, 'n_a': 30, 'n_steps': 9, 'gamma': 1.8276108403415376, 'lambda_sparse': 0.0011016137688031778, 'lr': 0.041181338429041627, 'weight_decay': 0.000176842267730118}. Best is trial 16 with value: 0.9466083662859819.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:11:04,766] A new study created in memory with name: no-name-6f27222d-ad19-4709-b7fd-3602514a6e4b
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:11:27,721] Trial 0 finished with value: 0.7303867083037351 and parameters: {'n_d': 37, 'n_a': 37, 'n_steps': 7, 'gamma': 1.1314014303600266, 'lambda_sparse': 1.8479283093269137e-05, 'lr': 0.00104697074738142, 'weight_decay': 1.2341414518439058e-06}. Best is trial 0 with value: 0.7303867083037351.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:12:11,981] Trial 1 finished with value: 0.9212703011510052 and parameters: {'n_d': 62, 'n_a': 30, 'n_steps': 9, 'gamma': 1.5561097397293722, 'lambda_sparse': 2.8098963616753317e-05, 'lr': 0.020385500893435823, 'weight_decay': 1.1735365419787432e-05}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:12:52,863] Trial 2 finished with value: 0.8830975221754187 and parameters: {'n_d': 51, 'n_a': 20, 'n_steps': 8, 'gamma': 1.9238915587144905, 'lambda_sparse': 0.00019388813261121844, 'lr': 0.0035937042612629853, 'weight_decay': 6.061341857298923e-05}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:13:09,550] Trial 3 finished with value: 0.863217441557887 and parameters: {'n_d': 60, 'n_a': 16, 'n_steps': 3, 'gamma': 1.3201811913360928, 'lambda_sparse': 1.8783536481090197e-05, 'lr': 0.03969925334823383, 'weight_decay': 0.00011883732941083628}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:13:50,012] Trial 4 finished with value: 0.8334173930955286 and parameters: {'n_d': 61, 'n_a': 12, 'n_steps': 8, 'gamma': 1.586796256211711, 'lambda_sparse': 0.00044984224577405507, 'lr': 0.0014842410861021723, 'weight_decay': 1.0734752702673615e-05}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:14:14,647] Trial 5 finished with value: 0.9039576203199002 and parameters: {'n_d': 27, 'n_a': 33, 'n_steps': 4, 'gamma': 1.7624070402775147, 'lambda_sparse': 1.2811025368161976e-05, 'lr': 0.0026691202943090447, 'weight_decay': 4.883895970277845e-06}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:14:49,586] Trial 6 finished with value: 0.3938567438926903 and parameters: {'n_d': 45, 'n_a': 19, 'n_steps': 7, 'gamma': 1.2380164926988455, 'lambda_sparse': 6.486779222891994e-05, 'lr': 0.00016363202725530888, 'weight_decay': 1.041493142959026e-05}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:15:14,093] Trial 7 finished with value: 0.8310534213909463 and parameters: {'n_d': 41, 'n_a': 36, 'n_steps': 4, 'gamma': 1.4632598824021998, 'lambda_sparse': 0.0009252092750513706, 'lr': 0.0003750656146826942, 'weight_decay': 1.3056673416001125e-06}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:15:42,390] Trial 8 finished with value: 0.845932946467727 and parameters: {'n_d': 17, 'n_a': 8, 'n_steps': 5, 'gamma': 1.6695296260685462, 'lambda_sparse': 4.266452110920225e-05, 'lr': 0.0011183117836294125, 'weight_decay': 4.213218536230045e-06}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:16:31,343] Trial 9 finished with value: 0.8880693878150167 and parameters: {'n_d': 41, 'n_a': 32, 'n_steps': 10, 'gamma': 1.7589223290237945, 'lambda_sparse': 2.06210836386775e-05, 'lr': 0.0026079274990975063, 'weight_decay': 4.805456872705785e-05}. Best is trial 1 with value: 0.9212703011510052.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:17:09,380] Trial 10 finished with value: 0.9395902817026226 and parameters: {'n_d': 10, 'n_a': 59, 'n_steps': 10, 'gamma': 1.4162345337063051, 'lambda_sparse': 0.006102359608227491, 'lr': 0.08323153990997614, 'weight_decay': 0.0009782731343986621}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:17:32,090] Trial 11 finished with value: 0.8361069411572374 and parameters: {'n_d': 11, 'n_a': 63, 'n_steps': 10, 'gamma': 1.4330085520775289, 'lambda_sparse': 0.00840865598609659, 'lr': 0.0992958201484576, 'weight_decay': 0.0007608685837437994}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:18:13,703] Trial 12 finished with value: 0.9005157529970383 and parameters: {'n_d': 24, 'n_a': 64, 'n_steps': 9, 'gamma': 1.346005390376399, 'lambda_sparse': 0.008985775430379322, 'lr': 0.014937581107205895, 'weight_decay': 0.0007764598727018878}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:18:58,430] Trial 13 finished with value: 0.9262302959846176 and parameters: {'n_d': 29, 'n_a': 50, 'n_steps': 9, 'gamma': 1.531321443964044, 'lambda_sparse': 0.0015477922203700244, 'lr': 0.013420436142072868, 'weight_decay': 0.0002466322286021495}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:19:43,653] Trial 14 finished with value: 0.8722785109909144 and parameters: {'n_d': 28, 'n_a': 52, 'n_steps': 10, 'gamma': 1.007266134034571, 'lambda_sparse': 0.0025705170259452473, 'lr': 0.007909769025429891, 'weight_decay': 0.00028536260757352637}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:20:09,101] Trial 15 finished with value: 0.8465323430191976 and parameters: {'n_d': 13, 'n_a': 51, 'n_steps': 9, 'gamma': 1.1961028035399903, 'lambda_sparse': 0.0025183404188897007, 'lr': 0.07304382475398641, 'weight_decay': 0.00028256063193174245}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:20:30,039] Trial 16 finished with value: 0.8459460675088563 and parameters: {'n_d': 20, 'n_a': 52, 'n_steps': 6, 'gamma': 1.9311706510852318, 'lambda_sparse': 0.002673469254391691, 'lr': 0.025503709370205442, 'weight_decay': 0.00024509202370025885}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:20:50,717] Trial 17 finished with value: 0.7740569263566441 and parameters: {'n_d': 9, 'n_a': 45, 'n_steps': 8, 'gamma': 1.3663732073747323, 'lambda_sparse': 0.0009238934638373209, 'lr': 0.047952707893731246, 'weight_decay': 0.0009208505235810066}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:21:35,762] Trial 18 finished with value: 0.8897940125027702 and parameters: {'n_d': 33, 'n_a': 57, 'n_steps': 9, 'gamma': 1.648638427596797, 'lambda_sparse': 0.004669502642541024, 'lr': 0.009944524286627524, 'weight_decay': 0.00013826045711844593}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:22:08,117] Trial 19 finished with value: 0.8763496637145267 and parameters: {'n_d': 19, 'n_a': 46, 'n_steps': 6, 'gamma': 1.4821704692236803, 'lambda_sparse': 0.00092176976292323, 'lr': 0.005671321958320408, 'weight_decay': 0.0004342553145913767}. Best is trial 10 with value: 0.9395902817026226.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:22:52,293] A new study created in memory with name: no-name-54e228be-ffa7-4c9c-85b9-72ad1df18f0f
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:23:18,754] Trial 0 finished with value: 0.9190434395845128 and parameters: {'n_d': 56, 'n_a': 52, 'n_steps': 5, 'gamma': 1.5776472983285703, 'lambda_sparse': 0.0011152175185579392, 'lr': 0.08815750624303133, 'weight_decay': 4.51776451687369e-06}. Best is trial 0 with value: 0.9190434395845128.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:23:43,843] Trial 1 finished with value: 0.8795345493282232 and parameters: {'n_d': 32, 'n_a': 61, 'n_steps': 4, 'gamma': 1.948498993757862, 'lambda_sparse': 3.821424501985156e-05, 'lr': 0.0010730031670688242, 'weight_decay': 4.699709799986832e-05}. Best is trial 0 with value: 0.9190434395845128.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:24:08,848] Trial 2 finished with value: 0.9108851937997715 and parameters: {'n_d': 53, 'n_a': 14, 'n_steps': 4, 'gamma': 1.8245369207993107, 'lambda_sparse': 1.33948480255563e-05, 'lr': 0.01563869185186086, 'weight_decay': 0.0001353177841771865}. Best is trial 0 with value: 0.9190434395845128.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:24:18,641] Trial 3 finished with value: 0.13770606414217368 and parameters: {'n_d': 22, 'n_a': 14, 'n_steps': 3, 'gamma': 1.2346864884526165, 'lambda_sparse': 0.0033253345312167547, 'lr': 0.0022297878983929425, 'weight_decay': 3.33987173886929e-06}. Best is trial 0 with value: 0.9190434395845128.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:24:45,835] Trial 4 finished with value: 0.9469759237903461 and parameters: {'n_d': 18, 'n_a': 46, 'n_steps': 5, 'gamma': 1.6638282254935883, 'lambda_sparse': 3.040154238803206e-05, 'lr': 0.07741316524293139, 'weight_decay': 0.000990091958292702}. Best is trial 4 with value: 0.9469759237903461.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:25:13,671] Trial 5 finished with value: -5.615089076176478 and parameters: {'n_d': 31, 'n_a': 31, 'n_steps': 10, 'gamma': 1.0253455108926222, 'lambda_sparse': 0.0018152441078062157, 'lr': 0.00017520324491147527, 'weight_decay': 2.4122197200174336e-06}. Best is trial 4 with value: 0.9469759237903461.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:25:42,153] Trial 6 finished with value: 0.8663164390830426 and parameters: {'n_d': 41, 'n_a': 56, 'n_steps': 5, 'gamma': 1.5717782791913502, 'lambda_sparse': 0.0011622354398564928, 'lr': 0.009245864576786753, 'weight_decay': 0.00037731255676604585}. Best is trial 4 with value: 0.9469759237903461.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:26:21,504] Trial 7 finished with value: 0.08224971881721788 and parameters: {'n_d': 59, 'n_a': 61, 'n_steps': 8, 'gamma': 1.3474221325798696, 'lambda_sparse': 0.0003182716128427214, 'lr': 0.0001510740804794198, 'weight_decay': 3.8801871338069815e-05}. Best is trial 4 with value: 0.9469759237903461.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:26:54,106] Trial 8 finished with value: 0.9563485690016634 and parameters: {'n_d': 8, 'n_a': 12, 'n_steps': 8, 'gamma': 1.3632698061571915, 'lambda_sparse': 0.0035847895033271552, 'lr': 0.018765233355504903, 'weight_decay': 0.0009161158546060824}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:27:17,640] Trial 9 finished with value: 0.909382891186381 and parameters: {'n_d': 63, 'n_a': 8, 'n_steps': 3, 'gamma': 1.9130395530043982, 'lambda_sparse': 0.000872813898483556, 'lr': 0.003819608742018391, 'weight_decay': 0.0003768475656465577}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:27:47,431] Trial 10 finished with value: 0.8833259553349823 and parameters: {'n_d': 8, 'n_a': 29, 'n_steps': 8, 'gamma': 1.351483420222558, 'lambda_sparse': 0.009920455596237027, 'lr': 0.024485986296065236, 'weight_decay': 1.1523315870023537e-05}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:28:04,186] Trial 11 finished with value: 0.8976531278539194 and parameters: {'n_d': 10, 'n_a': 43, 'n_steps': 7, 'gamma': 1.7141372446401058, 'lambda_sparse': 9.544330483849094e-05, 'lr': 0.07827659252187215, 'weight_decay': 0.0008583995124695465}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:28:37,294] Trial 12 finished with value: 0.937136084636043 and parameters: {'n_d': 19, 'n_a': 42, 'n_steps': 9, 'gamma': 1.4256136430666553, 'lambda_sparse': 0.00011994542317525487, 'lr': 0.03381715622952899, 'weight_decay': 0.0008225063369607721}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:29:09,220] Trial 13 finished with value: 0.9150203612520736 and parameters: {'n_d': 18, 'n_a': 24, 'n_steps': 6, 'gamma': 1.1517928409521265, 'lambda_sparse': 1.2482615527830027e-05, 'lr': 0.006738472750105397, 'weight_decay': 0.00015958331972537476}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:29:40,371] Trial 14 finished with value: 0.9447893141246296 and parameters: {'n_d': 14, 'n_a': 40, 'n_steps': 7, 'gamma': 1.6972335274044301, 'lambda_sparse': 0.009764550577114024, 'lr': 0.045543703611491806, 'weight_decay': 0.00012002238721955037}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:30:12,510] Trial 15 finished with value: 0.9185517444282904 and parameters: {'n_d': 26, 'n_a': 49, 'n_steps': 6, 'gamma': 1.5663030942249563, 'lambda_sparse': 0.0002551175762749366, 'lr': 0.0164932832274464, 'weight_decay': 0.00040452809387020564}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:30:55,495] Trial 16 finished with value: 0.9359237287018696 and parameters: {'n_d': 43, 'n_a': 24, 'n_steps': 10, 'gamma': 1.7328455937565521, 'lambda_sparse': 3.609388587184014e-05, 'lr': 0.048381684169421596, 'weight_decay': 1.2463906479244844e-05}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:31:23,033] Trial 17 finished with value: -6.549045511885069 and parameters: {'n_d': 15, 'n_a': 36, 'n_steps': 8, 'gamma': 1.4674477562368096, 'lambda_sparse': 0.00041647458199289914, 'lr': 0.0006515738842141665, 'weight_decay': 0.0008873662294779042}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:31:50,937] Trial 18 finished with value: 0.8984369691125347 and parameters: {'n_d': 27, 'n_a': 48, 'n_steps': 5, 'gamma': 1.222537879044676, 'lambda_sparse': 0.003950843992252881, 'lr': 0.00891813636668867, 'weight_decay': 7.895992623395507e-05}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:32:21,966] Trial 19 finished with value: 0.9009416214235568 and parameters: {'n_d': 12, 'n_a': 18, 'n_steps': 9, 'gamma': 1.6545995559669728, 'lambda_sparse': 3.8265756930102426e-05, 'lr': 0.0856328958885346, 'weight_decay': 1.1017659092376727e-06}. Best is trial 8 with value: 0.9563485690016634.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:32:58,990] A new study created in memory with name: no-name-1db763ce-7136-47cb-92b4-043cc29b5521
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:33:35,538] Trial 0 finished with value: 0.9077091000620218 and parameters: {'n_d': 55, 'n_a': 22, 'n_steps': 7, 'gamma': 1.3267444515635773, 'lambda_sparse': 0.007110726601414527, 'lr': 0.019729578654067513, 'weight_decay': 1.700274002635541e-05}. Best is trial 0 with value: 0.9077091000620218.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:34:16,488] Trial 1 finished with value: 0.24622101108909733 and parameters: {'n_d': 28, 'n_a': 45, 'n_steps': 8, 'gamma': 1.017381807090094, 'lambda_sparse': 0.002310028044272628, 'lr': 0.00010511550693003328, 'weight_decay': 2.549243726952494e-06}. Best is trial 0 with value: 0.9077091000620218.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:34:40,989] Trial 2 finished with value: 0.9409156985807885 and parameters: {'n_d': 38, 'n_a': 33, 'n_steps': 4, 'gamma': 1.7717061891788353, 'lambda_sparse': 0.001059290007379507, 'lr': 0.054030597871908156, 'weight_decay': 0.00017891727434591828}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:35:06,462] Trial 3 finished with value: 0.9358493240152792 and parameters: {'n_d': 61, 'n_a': 12, 'n_steps': 4, 'gamma': 1.0013331331498017, 'lambda_sparse': 8.840762835492382e-05, 'lr': 0.013528492825135996, 'weight_decay': 8.496752052993617e-05}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:35:40,276] Trial 4 finished with value: 0.8856567825294707 and parameters: {'n_d': 28, 'n_a': 20, 'n_steps': 8, 'gamma': 1.235729129831692, 'lambda_sparse': 2.490975984089172e-05, 'lr': 0.009614847733355358, 'weight_decay': 0.00021126612636359436}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:36:08,696] Trial 5 finished with value: 0.8802161361578106 and parameters: {'n_d': 50, 'n_a': 17, 'n_steps': 5, 'gamma': 1.362612387268363, 'lambda_sparse': 0.00022613274820433688, 'lr': 0.0005334153771238814, 'weight_decay': 4.5056238404501236e-05}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:36:49,028] Trial 6 finished with value: 0.9055305358057164 and parameters: {'n_d': 50, 'n_a': 38, 'n_steps': 8, 'gamma': 1.3765318964431346, 'lambda_sparse': 0.00017224398767310632, 'lr': 0.0015684230662111583, 'weight_decay': 0.0002211283553303886}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:37:37,262] Trial 7 finished with value: 0.866700982410163 and parameters: {'n_d': 34, 'n_a': 56, 'n_steps': 10, 'gamma': 1.023071656320111, 'lambda_sparse': 0.001442785297451486, 'lr': 0.0013646733791940005, 'weight_decay': 0.0003207621264344836}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:38:18,294] Trial 8 finished with value: 0.9300350477069614 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 8, 'gamma': 1.6201727388902585, 'lambda_sparse': 2.405490012555852e-05, 'lr': 0.003358168581832813, 'weight_decay': 1.555370841148446e-06}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:38:53,601] Trial 9 finished with value: 0.88501083896942 and parameters: {'n_d': 59, 'n_a': 43, 'n_steps': 10, 'gamma': 1.1598194281776506, 'lambda_sparse': 0.00017829712121364142, 'lr': 0.0376324410029829, 'weight_decay': 1.1044181922736596e-05}. Best is trial 2 with value: 0.9409156985807885.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:39:11,964] Trial 10 finished with value: 0.9586110332735119 and parameters: {'n_d': 9, 'n_a': 31, 'n_steps': 3, 'gamma': 1.9172570512048974, 'lambda_sparse': 0.0008986214436216658, 'lr': 0.09963175887388223, 'weight_decay': 0.0005896301716181567}. Best is trial 10 with value: 0.9586110332735119.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:39:32,250] Trial 11 finished with value: 0.9623548549119486 and parameters: {'n_d': 9, 'n_a': 29, 'n_steps': 3, 'gamma': 1.9582992826808392, 'lambda_sparse': 0.0009983782471282704, 'lr': 0.07432683243957092, 'weight_decay': 0.0009152380101632095}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:39:51,355] Trial 12 finished with value: 0.9342126809960812 and parameters: {'n_d': 12, 'n_a': 30, 'n_steps': 3, 'gamma': 1.9995624061722577, 'lambda_sparse': 0.0006944957796688047, 'lr': 0.07634548903385015, 'weight_decay': 0.0009888989589908854}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:40:09,865] Trial 13 finished with value: 0.9321437576973899 and parameters: {'n_d': 11, 'n_a': 27, 'n_steps': 3, 'gamma': 1.9963704229253731, 'lambda_sparse': 0.00448480197777187, 'lr': 0.08875202711204949, 'weight_decay': 0.000771475164857201}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:40:38,098] Trial 14 finished with value: 0.9209044754225894 and parameters: {'n_d': 18, 'n_a': 46, 'n_steps': 5, 'gamma': 1.817465581684336, 'lambda_sparse': 0.000503122738671112, 'lr': 0.006017623265234505, 'weight_decay': 0.0004670905281556378}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:41:05,670] Trial 15 finished with value: 0.9183383461061742 and parameters: {'n_d': 8, 'n_a': 38, 'n_steps': 5, 'gamma': 1.7935648990468176, 'lambda_sparse': 0.002518485550151193, 'lr': 0.02526559024423104, 'weight_decay': 8.15304913349885e-05}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:41:29,785] Trial 16 finished with value: 0.9216011836755976 and parameters: {'n_d': 19, 'n_a': 9, 'n_steps': 3, 'gamma': 1.634793660384431, 'lambda_sparse': 6.0508034255858686e-05, 'lr': 0.09601503789332368, 'weight_decay': 6.484944844271936e-06}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:42:00,927] Trial 17 finished with value: 0.9154941174184069 and parameters: {'n_d': 18, 'n_a': 25, 'n_steps': 6, 'gamma': 1.9005896934122835, 'lambda_sparse': 0.0005394055077568685, 'lr': 0.03382343034648728, 'weight_decay': 0.0005548699234989125}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:42:25,001] Trial 18 finished with value: 0.8526677422688811 and parameters: {'n_d': 24, 'n_a': 50, 'n_steps': 4, 'gamma': 1.579874941918772, 'lambda_sparse': 0.002641849423113947, 'lr': 0.0002219299032063385, 'weight_decay': 0.00011211502817909113}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:42:57,304] Trial 19 finished with value: 0.9240103042515511 and parameters: {'n_d': 40, 'n_a': 34, 'n_steps': 6, 'gamma': 1.7099073688224813, 'lambda_sparse': 1.1466414378175497e-05, 'lr': 0.006446204122320261, 'weight_decay': 4.3701964805349674e-05}. Best is trial 11 with value: 0.9623548549119486.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:43:20,025] A new study created in memory with name: no-name-8bc2c067-eb0e-43a7-8bfd-d6d5e093d7c3
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:43:46,591] Trial 0 finished with value: 0.8592672785665963 and parameters: {'n_d': 26, 'n_a': 29, 'n_steps': 5, 'gamma': 1.4070738559613127, 'lambda_sparse': 0.0001781408485010132, 'lr': 0.0007261448606736014, 'weight_decay': 0.0005156422046868493}. Best is trial 0 with value: 0.8592672785665963.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:44:10,798] Trial 1 finished with value: 0.9280362437671867 and parameters: {'n_d': 54, 'n_a': 64, 'n_steps': 3, 'gamma': 1.656155978526931, 'lambda_sparse': 0.004805892868093519, 'lr': 0.027897895333682303, 'weight_decay': 1.3086104055427999e-05}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:44:35,230] Trial 2 finished with value: 0.8940554877145184 and parameters: {'n_d': 45, 'n_a': 21, 'n_steps': 4, 'gamma': 1.5921716734140696, 'lambda_sparse': 0.00022489776753518973, 'lr': 0.002587732757749871, 'weight_decay': 4.099187225078794e-05}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:45:12,122] Trial 3 finished with value: 0.8869168716263852 and parameters: {'n_d': 31, 'n_a': 41, 'n_steps': 7, 'gamma': 1.5206253014941598, 'lambda_sparse': 0.0010734492944794102, 'lr': 0.01913947805674291, 'weight_decay': 2.7512711234739804e-06}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:45:40,070] Trial 4 finished with value: 0.6025121667658273 and parameters: {'n_d': 35, 'n_a': 25, 'n_steps': 5, 'gamma': 1.2420115907008946, 'lambda_sparse': 0.00025513867242210646, 'lr': 0.00013020380054057964, 'weight_decay': 1.223984494946536e-06}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:46:07,791] Trial 5 finished with value: 0.886106869557136 and parameters: {'n_d': 64, 'n_a': 23, 'n_steps': 5, 'gamma': 1.394614777056471, 'lambda_sparse': 9.438575350873379e-05, 'lr': 0.007336570861138195, 'weight_decay': 0.0004933899818064846}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:46:50,033] Trial 6 finished with value: 0.9204793868169158 and parameters: {'n_d': 41, 'n_a': 27, 'n_steps': 9, 'gamma': 1.230978229188334, 'lambda_sparse': 6.256992885382318e-05, 'lr': 0.08883125291523113, 'weight_decay': 1.1228723237607766e-06}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:47:22,130] Trial 7 finished with value: 0.8706282069106671 and parameters: {'n_d': 8, 'n_a': 15, 'n_steps': 6, 'gamma': 1.2808827958251492, 'lambda_sparse': 0.00011519962042784284, 'lr': 0.0004899595392869922, 'weight_decay': 2.269518481656504e-06}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:47:46,482] Trial 8 finished with value: 0.9143407507005387 and parameters: {'n_d': 64, 'n_a': 60, 'n_steps': 4, 'gamma': 1.9542599120469935, 'lambda_sparse': 0.0027838376801719985, 'lr': 0.010809192304700652, 'weight_decay': 8.454468918257277e-06}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:48:10,292] Trial 9 finished with value: 0.9043599925809608 and parameters: {'n_d': 12, 'n_a': 47, 'n_steps': 3, 'gamma': 1.501915760185014, 'lambda_sparse': 0.0007285207122983045, 'lr': 0.001636523486122292, 'weight_decay': 1.433559714210191e-06}. Best is trial 1 with value: 0.9280362437671867.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:48:50,316] Trial 10 finished with value: 0.9434175822224853 and parameters: {'n_d': 50, 'n_a': 60, 'n_steps': 10, 'gamma': 1.7939810556030853, 'lambda_sparse': 1.1478905472640895e-05, 'lr': 0.09313282377940169, 'weight_decay': 5.767231312786523e-05}. Best is trial 10 with value: 0.9434175822224853.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:49:34,528] Trial 11 finished with value: 0.9424173650446718 and parameters: {'n_d': 52, 'n_a': 63, 'n_steps': 10, 'gamma': 1.8059007161429135, 'lambda_sparse': 1.1690491499091663e-05, 'lr': 0.09771130397978744, 'weight_decay': 5.6857734771828994e-05}. Best is trial 10 with value: 0.9434175822224853.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:50:13,016] Trial 12 finished with value: 0.9350649879687266 and parameters: {'n_d': 52, 'n_a': 54, 'n_steps': 10, 'gamma': 1.8661503385907945, 'lambda_sparse': 1.0231227294300898e-05, 'lr': 0.09000488002690943, 'weight_decay': 0.00011287077889121889}. Best is trial 10 with value: 0.9434175822224853.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:50:50,006] Trial 13 finished with value: 0.929623071124741 and parameters: {'n_d': 51, 'n_a': 53, 'n_steps': 8, 'gamma': 1.7794534611534627, 'lambda_sparse': 1.0520615262477133e-05, 'lr': 0.04131517456763957, 'weight_decay': 0.00010514179927049015}. Best is trial 10 with value: 0.9434175822224853.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:51:22,947] Trial 14 finished with value: 0.8972761475411248 and parameters: {'n_d': 56, 'n_a': 40, 'n_steps': 9, 'gamma': 1.755165811118902, 'lambda_sparse': 3.320623589584119e-05, 'lr': 0.042036483686709585, 'weight_decay': 9.175545030134727e-05}. Best is trial 10 with value: 0.9434175822224853.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:51:55,763] Trial 15 finished with value: 0.8582230818618 and parameters: {'n_d': 44, 'n_a': 56, 'n_steps': 10, 'gamma': 1.0787835323044737, 'lambda_sparse': 2.5665064915148664e-05, 'lr': 0.007311393498940103, 'weight_decay': 3.0985995189834006e-05}. Best is trial 10 with value: 0.9434175822224853.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:52:20,115] Trial 16 finished with value: 0.9447075334872832 and parameters: {'n_d': 23, 'n_a': 47, 'n_steps': 8, 'gamma': 1.9941572111338126, 'lambda_sparse': 3.0298977390766273e-05, 'lr': 0.06601068492351454, 'weight_decay': 0.0001892846603563365}. Best is trial 16 with value: 0.9447075334872832.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:53:00,959] Trial 17 finished with value: 0.9452326613522499 and parameters: {'n_d': 20, 'n_a': 47, 'n_steps': 8, 'gamma': 1.9865136105968377, 'lambda_sparse': 3.077766775570489e-05, 'lr': 0.013515418921838157, 'weight_decay': 0.00024008728715886016}. Best is trial 17 with value: 0.9452326613522499.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:53:37,474] Trial 18 finished with value: 0.909199179141142 and parameters: {'n_d': 20, 'n_a': 47, 'n_steps': 7, 'gamma': 1.9574094742452333, 'lambda_sparse': 3.9566403101834105e-05, 'lr': 0.014178164654342587, 'weight_decay': 0.00022435087059620806}. Best is trial 17 with value: 0.9452326613522499.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 14:54:17,645] Trial 19 finished with value: 0.8729392287653269 and parameters: {'n_d': 18, 'n_a': 36, 'n_steps': 8, 'gamma': 1.996535441763691, 'lambda_sparse': 0.0005562496946068612, 'lr': 0.004566499765582192, 'weight_decay': 0.0007796057521709306}. Best is trial 17 with value: 0.9452326613522499.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-05 14:55:16 [INFO] TabNet →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/tabnet (mean R²=0.9489)
2025-08-05 14:55:16 [INFO] Ensemble weights: TabPFN=0.338, Tree=0.339, TabNet=0.323
2025-08-05 14:55:16 [INFO] Loading individual models into memory...
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-05 14:55:20 [INFO] Saved weighted ensemble to /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-brazilian_houses/final_model.pkl
