cpu-bind=MASK - dlcgpu04, task  0  0 [2018]: mask 0xf0000000f00 set
/var/spool/slurm/job20912836/slurm_script: line 11: module: command not found
2025-08-03 16:34:26 [INFO] Using device: cuda
2025-08-03 16:34:26 [INFO] Training TabPFN model...
[I 2025-08-03 16:34:26,179] A new study created in memory with name: no-name-73461982-df82-4a57-89dc-a7b442f08bdc
2025-08-03 16:34:26 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
[I 2025-08-03 16:40:14,274] Trial 0 finished with value: 0.09061319462121231 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.09061319462121231.
2025-08-03 16:40:14 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
[I 2025-08-03 16:47:09,110] Trial 1 finished with value: 0.09075105933720162 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 1 with value: 0.09075105933720162.
2025-08-03 16:47:09 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
[I 2025-08-03 16:50:34,077] Trial 2 finished with value: 0.08868692864351724 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 1 with value: 0.09075105933720162.
2025-08-03 16:50:34 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
[I 2025-08-03 16:54:51,246] Trial 3 finished with value: 0.08603866933142179 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 1 with value: 0.09075105933720162.
2025-08-03 16:54:51 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
[I 2025-08-03 17:01:17,039] Trial 4 finished with value: 0.09074960315438918 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 1 with value: 0.09075105933720162.
2025-08-03 17:01:17 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
[I 2025-08-03 17:05:45,457] Trial 5 finished with value: 0.08641518592721775 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8909729556485984}. Best is trial 1 with value: 0.09075105933720162.
2025-08-03 17:05:45 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
2025-08-03 17:06:04 [INFO] ⏸️ Pruned trial 6 at step 1 (R²=0.0611)
[I 2025-08-03 17:06:04,697] Trial 6 pruned. 
2025-08-03 17:06:04 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
2025-08-03 17:06:23 [INFO] ⏸️ Pruned trial 7 at step 1 (R²=0.0602)
[I 2025-08-03 17:06:23,752] Trial 7 pruned. 
2025-08-03 17:06:23 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
2025-08-03 17:06:46 [INFO] ⏸️ Pruned trial 8 at step 1 (R²=0.0565)
[I 2025-08-03 17:06:46,049] Trial 8 pruned. 
2025-08-03 17:06:46 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
2025-08-03 17:07:06 [INFO] ⏸️ Pruned trial 9 at step 1 (R²=0.0588)
[I 2025-08-03 17:07:06,194] Trial 9 pruned. 
2025-08-03 17:07:06 [INFO] 🔍 Trial 10: n_bootstrap=20, sample_frac=0.74
2025-08-03 17:07:27 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.0537)
[I 2025-08-03 17:07:27,797] Trial 10 pruned. 
2025-08-03 17:07:27 [INFO] 🔍 Trial 11: n_bootstrap=17, sample_frac=0.81
2025-08-03 17:07:51 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.0544)
[I 2025-08-03 17:07:51,757] Trial 11 pruned. 
2025-08-03 17:07:51 [INFO] 🔍 Trial 12: n_bootstrap=17, sample_frac=0.81
2025-08-03 17:08:15 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.0519)
[I 2025-08-03 17:08:15,367] Trial 12 pruned. 
2025-08-03 17:08:15 [INFO] 🔍 Trial 13: n_bootstrap=17, sample_frac=0.79
2025-08-03 17:08:38 [INFO] ⏸️ Pruned trial 13 at step 1 (R²=0.0527)
[I 2025-08-03 17:08:38,786] Trial 13 pruned. 
2025-08-03 17:08:38 [INFO] 🔍 Trial 14: n_bootstrap=16, sample_frac=0.71
2025-08-03 17:08:59 [INFO] ⏸️ Pruned trial 14 at step 1 (R²=0.0552)
[I 2025-08-03 17:08:59,626] Trial 14 pruned. 
2025-08-03 17:08:59 [INFO] 🔍 Trial 15: n_bootstrap=19, sample_frac=0.83
2025-08-03 17:11:01 [INFO] ⏸️ Pruned trial 15 at step 5 (R²=0.0786)
[I 2025-08-03 17:11:01,785] Trial 15 pruned. 
2025-08-03 17:11:01 [INFO] 🔍 Trial 16: n_bootstrap=15, sample_frac=0.76
2025-08-03 17:11:23 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.0547)
[I 2025-08-03 17:11:23,924] Trial 16 pruned. 
2025-08-03 17:11:23 [INFO] 🔍 Trial 17: n_bootstrap=18, sample_frac=0.84
2025-08-03 17:12:38 [INFO] ⏸️ Pruned trial 17 at step 3 (R²=0.0747)
[I 2025-08-03 17:12:38,808] Trial 17 pruned. 
2025-08-03 17:12:38 [INFO] 🔍 Trial 18: n_bootstrap=16, sample_frac=0.78
2025-08-03 17:13:01 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.0516)
[I 2025-08-03 17:13:01,901] Trial 18 pruned. 
2025-08-03 17:13:01 [INFO] 🔍 Trial 19: n_bootstrap=19, sample_frac=0.72
2025-08-03 17:13:22 [INFO] ⏸️ Pruned trial 19 at step 1 (R²=0.0552)
[I 2025-08-03 17:13:22,916] Trial 19 pruned. 
2025-08-03 17:13:22 [INFO] 🔍 Trial 20: n_bootstrap=15, sample_frac=0.61
2025-08-03 17:13:40 [INFO] ⏸️ Pruned trial 20 at step 1 (R²=0.0589)
[I 2025-08-03 17:13:40,953] Trial 20 pruned. 
2025-08-03 17:13:40 [INFO] 🔍 Trial 21: n_bootstrap=14, sample_frac=0.88
[I 2025-08-03 17:19:51,021] Trial 21 finished with value: 0.08971304795883184 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8841404752206518}. Best is trial 1 with value: 0.09075105933720162.
2025-08-03 17:19:51 [INFO] 🔍 Trial 22: n_bootstrap=13, sample_frac=0.86
2025-08-03 17:21:08 [INFO] ⏸️ Pruned trial 22 at step 3 (R²=0.0754)
[I 2025-08-03 17:21:08,483] Trial 22 pruned. 
2025-08-03 17:21:08 [INFO] 🔍 Trial 23: n_bootstrap=16, sample_frac=0.83
2025-08-03 17:21:33 [INFO] ⏸️ Pruned trial 23 at step 1 (R²=0.0754)
[I 2025-08-03 17:21:33,378] Trial 23 pruned. 
2025-08-03 17:21:33 [INFO] 🔍 Trial 24: n_bootstrap=18, sample_frac=0.90
[I 2025-08-03 17:29:42,221] Trial 24 finished with value: 0.09212585753900082 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.8985573167261436}. Best is trial 24 with value: 0.09212585753900082.
2025-08-03 17:29:42 [INFO] 🔍 Trial 25: n_bootstrap=18, sample_frac=0.73
2025-08-03 17:30:02 [INFO] ⏸️ Pruned trial 25 at step 1 (R²=0.0556)
[I 2025-08-03 17:30:02,806] Trial 25 pruned. 
2025-08-03 17:30:02 [INFO] 🔍 Trial 26: n_bootstrap=20, sample_frac=0.78
2025-08-03 17:30:26 [INFO] ⏸️ Pruned trial 26 at step 1 (R²=0.0542)
[I 2025-08-03 17:30:26,210] Trial 26 pruned. 
2025-08-03 17:30:26 [INFO] 🔍 Trial 27: n_bootstrap=18, sample_frac=0.86
2025-08-03 17:31:43 [INFO] ⏸️ Pruned trial 27 at step 3 (R²=0.0748)
[I 2025-08-03 17:31:43,834] Trial 27 pruned. 
2025-08-03 17:31:43 [INFO] 🔍 Trial 28: n_bootstrap=17, sample_frac=0.81
2025-08-03 17:32:08 [INFO] ⏸️ Pruned trial 28 at step 1 (R²=0.0524)
[I 2025-08-03 17:32:08,041] Trial 28 pruned. 
2025-08-03 17:32:08 [INFO] 🔍 Trial 29: n_bootstrap=18, sample_frac=0.90
2025-08-03 17:32:35 [INFO] ⏸️ Pruned trial 29 at step 1 (R²=0.0769)
[I 2025-08-03 17:32:35,409] Trial 29 pruned. 
2025-08-03 17:32:35 [INFO] 🏆 Best Params: {'n_bootstrap': 18, 'sample_frac': 0.8985573167261436}, R²=0.09213
2025-08-03 17:32:35 [INFO] Bootstrap training → dataset=yprop_4_1, device=cuda
2025-08-03 17:32:35 [INFO] [1/18] bootstrap sample size=6466
2025-08-03 17:33:02 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_1.pkl
2025-08-03 17:33:02 [INFO] [2/18] bootstrap sample size=6466
2025-08-03 17:33:30 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_2.pkl
2025-08-03 17:33:30 [INFO] [3/18] bootstrap sample size=6466
2025-08-03 17:33:57 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_3.pkl
2025-08-03 17:33:57 [INFO] [4/18] bootstrap sample size=6466
2025-08-03 17:34:24 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_4.pkl
2025-08-03 17:34:24 [INFO] [5/18] bootstrap sample size=6466
2025-08-03 17:34:52 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_5.pkl
2025-08-03 17:34:53 [INFO] [6/18] bootstrap sample size=6466
2025-08-03 17:35:18 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_6.pkl
2025-08-03 17:35:18 [INFO] [7/18] bootstrap sample size=6466
2025-08-03 17:35:45 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_7.pkl
2025-08-03 17:35:45 [INFO] [8/18] bootstrap sample size=6466
2025-08-03 17:36:13 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_8.pkl
2025-08-03 17:36:13 [INFO] [9/18] bootstrap sample size=6466
2025-08-03 17:36:40 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_9.pkl
2025-08-03 17:36:41 [INFO] [10/18] bootstrap sample size=6466
2025-08-03 17:37:07 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_10.pkl
2025-08-03 17:37:08 [INFO] [11/18] bootstrap sample size=6466
2025-08-03 17:37:35 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_11.pkl
2025-08-03 17:37:35 [INFO] [12/18] bootstrap sample size=6466
2025-08-03 17:38:03 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_12.pkl
2025-08-03 17:38:03 [INFO] [13/18] bootstrap sample size=6466
2025-08-03 17:38:30 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_13.pkl
2025-08-03 17:38:30 [INFO] [14/18] bootstrap sample size=6466
2025-08-03 17:38:57 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_14.pkl
2025-08-03 17:38:57 [INFO] [15/18] bootstrap sample size=6466
2025-08-03 17:39:24 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_15.pkl
2025-08-03 17:39:25 [INFO] [16/18] bootstrap sample size=6466
2025-08-03 17:39:52 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_16.pkl
2025-08-03 17:39:52 [INFO] [17/18] bootstrap sample size=6466
2025-08-03 17:40:18 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_17.pkl
2025-08-03 17:40:18 [INFO] [18/18] bootstrap sample size=6466
2025-08-03 17:40:45 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/bootstrap_18.pkl
2025-08-03 17:40:46 [INFO] 📊 Final OOB R² = 0.09213
2025-08-03 17:40:54 [INFO] Saved ensemble → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/ensemble.pkl
2025-08-03 17:40:54 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-03 17:40:54 [INFO] Total time: 499.0s
2025-08-03 17:40:54 [INFO] TabPFN →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/yprop_4_1/ensemble.pkl (R²=0.0921)
2025-08-03 17:40:54 [INFO] Training tree-based model...
2025-08-03 17:40:54 [INFO] AutoML pipeline started
2025-08-03 17:40:54 [INFO] Output directory '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp' is ready and logging is configured.
2025-08-03 17:40:54 [INFO] Merged training data: 7196 rows
2025-08-03 17:40:54 [INFO] Split data into pool (6476 rows) and validation (720 rows)
2025-08-03 17:40:54 [INFO] Feature engineering completed: 62 features
[I 2025-08-03 17:40:54,616] A new study created in memory with name: no-name-5d72fdeb-e346-4098-8d39-47226c65b3f2
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-03 17:44:34,916] Trial 0 finished with value: -0.09555805194048865 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:44:47,986] Trial 1 finished with value: -0.07148767517201443 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:45:35,143] Trial 2 finished with value: -0.09046135776488251 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:45:39,830] Trial 3 finished with value: -0.07434306080054819 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:46:02,690] Trial 4 finished with value: -0.09043256721752142 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:46:09,387] Trial 5 finished with value: -0.07264794158734797 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:47:25,755] Trial 6 finished with value: -0.09457290398886038 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:47:32,634] Trial 7 finished with value: -0.0739934497173232 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:53:15,103] Trial 8 finished with value: -0.08722335037861093 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:53:23,975] Trial 9 finished with value: -0.0669004750155861 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:53:34,222] Trial 10 finished with value: -0.07807305922183373 and parameters: {'learning_rate': 0.24893231508461813, 'depth': 8, 'l2_leaf_reg': 8.72951024190968, 'border_count': 175}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:56:51,648] Trial 11 finished with value: -0.09466257636944363 and parameters: {'learning_rate': 0.0375842805144493, 'depth': 12, 'l2_leaf_reg': 4.804761925175269, 'border_count': 169}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 17:57:56,347] Trial 12 finished with value: -0.09286258063783966 and parameters: {'learning_rate': 0.03587090238159878, 'depth': 10, 'l2_leaf_reg': 5.411810787983999, 'border_count': 177}. Best is trial 0 with value: -0.09555805194048865.
[I 2025-08-03 18:02:32,555] Trial 13 finished with value: -0.09557519439960437 and parameters: {'learning_rate': 0.01976467195578097, 'depth': 12, 'l2_leaf_reg': 7.654700566068242, 'border_count': 172}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:03:54,461] Trial 14 finished with value: -0.08710463684075223 and parameters: {'learning_rate': 0.017235303713348287, 'depth': 10, 'l2_leaf_reg': 7.6727388333556705, 'border_count': 195}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:04:33,519] Trial 15 finished with value: -0.08547879051268191 and parameters: {'learning_rate': 0.019591565687131645, 'depth': 9, 'l2_leaf_reg': 8.005630538517241, 'border_count': 143}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:10:28,389] Trial 16 finished with value: -0.09154467588948553 and parameters: {'learning_rate': 0.01106451514566151, 'depth': 12, 'l2_leaf_reg': 6.471705425963705, 'border_count': 208}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:10:42,966] Trial 17 finished with value: -0.07718749607959144 and parameters: {'learning_rate': 0.02380074849503738, 'depth': 7, 'l2_leaf_reg': 9.99426194777396, 'border_count': 47}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:12:18,472] Trial 18 finished with value: -0.0945331938617467 and parameters: {'learning_rate': 0.05639301836472461, 'depth': 11, 'l2_leaf_reg': 8.748706317112614, 'border_count': 160}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:13:42,759] Trial 19 finished with value: -0.092795683496499 and parameters: {'learning_rate': 0.1196890828618731, 'depth': 11, 'l2_leaf_reg': 6.045952338153317, 'border_count': 255}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:14:02,118] Trial 20 finished with value: -0.07586913728971553 and parameters: {'learning_rate': 0.013522133976193926, 'depth': 7, 'l2_leaf_reg': 8.718568906390514, 'border_count': 118}. Best is trial 13 with value: -0.09557519439960437.
[I 2025-08-03 18:17:01,758] Trial 21 finished with value: -0.09760885857242618 and parameters: {'learning_rate': 0.03998303856653836, 'depth': 12, 'l2_leaf_reg': 4.278868023599101, 'border_count': 178}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:20:18,982] Trial 22 finished with value: -0.09549343613055958 and parameters: {'learning_rate': 0.04364162290897699, 'depth': 12, 'l2_leaf_reg': 4.535641010265227, 'border_count': 195}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:22:21,927] Trial 23 finished with value: -0.09388618342366935 and parameters: {'learning_rate': 0.02833739354294451, 'depth': 11, 'l2_leaf_reg': 7.161789006448416, 'border_count': 152}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:24:39,122] Trial 24 finished with value: -0.09615527170355051 and parameters: {'learning_rate': 0.05710935996729435, 'depth': 12, 'l2_leaf_reg': 3.9518678932161593, 'border_count': 179}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:25:33,008] Trial 25 finished with value: -0.09570140442974602 and parameters: {'learning_rate': 0.0600573618496282, 'depth': 10, 'l2_leaf_reg': 3.936744932234908, 'border_count': 190}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:26:06,549] Trial 26 finished with value: -0.0905128520234366 and parameters: {'learning_rate': 0.06042551538642768, 'depth': 9, 'l2_leaf_reg': 3.7915899405311166, 'border_count': 226}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:26:26,054] Trial 27 finished with value: -0.08575917774538504 and parameters: {'learning_rate': 0.1291981308548949, 'depth': 9, 'l2_leaf_reg': 3.3103624507248504, 'border_count': 189}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:27:03,798] Trial 28 finished with value: -0.08378271768773041 and parameters: {'learning_rate': 0.10549721231233104, 'depth': 10, 'l2_leaf_reg': 2.23507280480937, 'border_count': 232}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:28:25,411] Trial 29 finished with value: -0.09309791104870409 and parameters: {'learning_rate': 0.06684045952405662, 'depth': 11, 'l2_leaf_reg': 4.253229947069516, 'border_count': 205}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:30:04,809] Trial 30 finished with value: -0.0957858856637929 and parameters: {'learning_rate': 0.04919298290810883, 'depth': 11, 'l2_leaf_reg': 5.566542756837702, 'border_count': 182}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:31:59,155] Trial 31 finished with value: -0.09532328417604315 and parameters: {'learning_rate': 0.04412108778409438, 'depth': 11, 'l2_leaf_reg': 5.355513020680729, 'border_count': 185}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:34:03,079] Trial 32 finished with value: -0.09607271327437097 and parameters: {'learning_rate': 0.09656296576598081, 'depth': 12, 'l2_leaf_reg': 4.083945407238049, 'border_count': 157}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:35:38,426] Trial 33 finished with value: -0.09411396623211739 and parameters: {'learning_rate': 0.09416853320992014, 'depth': 12, 'l2_leaf_reg': 3.1472813040591605, 'border_count': 136}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:37:02,243] Trial 34 finished with value: -0.0826342905614903 and parameters: {'learning_rate': 0.14910999270278194, 'depth': 12, 'l2_leaf_reg': 2.0364242732444557, 'border_count': 159}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:38:53,561] Trial 35 finished with value: -0.09242824695955507 and parameters: {'learning_rate': 0.04948849117172664, 'depth': 11, 'l2_leaf_reg': 4.996075716497945, 'border_count': 220}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:40:24,064] Trial 36 finished with value: -0.08354199152054302 and parameters: {'learning_rate': 0.18049477993564428, 'depth': 12, 'l2_leaf_reg': 5.947807012255136, 'border_count': 160}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:41:53,371] Trial 37 finished with value: -0.09437493557659081 and parameters: {'learning_rate': 0.08794051917450568, 'depth': 11, 'l2_leaf_reg': 4.220529083348281, 'border_count': 243}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:43:33,606] Trial 38 finished with value: -0.09437243379362403 and parameters: {'learning_rate': 0.07042301129905362, 'depth': 12, 'l2_leaf_reg': 3.1776473768351035, 'border_count': 120}. Best is trial 21 with value: -0.09760885857242618.
[I 2025-08-03 18:44:16,652] Trial 39 finished with value: -0.09906584306536866 and parameters: {'learning_rate': 0.03409696250318443, 'depth': 10, 'l2_leaf_reg': 2.6142008342892975, 'border_count': 93}. Best is trial 39 with value: -0.09906584306536866.
[I 2025-08-03 18:45:02,707] Trial 40 finished with value: -0.10170066464050348 and parameters: {'learning_rate': 0.03282691041209928, 'depth': 10, 'l2_leaf_reg': 2.5078724081270263, 'border_count': 102}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:45:46,927] Trial 41 finished with value: -0.09791888300519153 and parameters: {'learning_rate': 0.03159804778743023, 'depth': 10, 'l2_leaf_reg': 1.1133471953615033, 'border_count': 94}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:46:13,924] Trial 42 finished with value: -0.09500940084558264 and parameters: {'learning_rate': 0.03186798589922312, 'depth': 9, 'l2_leaf_reg': 1.1222549355864633, 'border_count': 96}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:46:34,811] Trial 43 finished with value: -0.0903635122364164 and parameters: {'learning_rate': 0.024367468219773068, 'depth': 8, 'l2_leaf_reg': 2.0374771851686417, 'border_count': 71}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:47:12,727] Trial 44 finished with value: -0.0987135043331838 and parameters: {'learning_rate': 0.03799050188313981, 'depth': 10, 'l2_leaf_reg': 1.592996860158801, 'border_count': 92}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:47:52,261] Trial 45 finished with value: -0.09737465846108008 and parameters: {'learning_rate': 0.03701612937968974, 'depth': 10, 'l2_leaf_reg': 1.7459259593369594, 'border_count': 94}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:48:18,005] Trial 46 finished with value: -0.0932015862842506 and parameters: {'learning_rate': 0.030780225968933636, 'depth': 9, 'l2_leaf_reg': 2.6657292284638054, 'border_count': 80}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:48:58,347] Trial 47 finished with value: -0.09785992700901187 and parameters: {'learning_rate': 0.023508971408731146, 'depth': 10, 'l2_leaf_reg': 1.2447187815162586, 'border_count': 54}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:49:38,065] Trial 48 finished with value: -0.10100813843416635 and parameters: {'learning_rate': 0.02363468798899499, 'depth': 10, 'l2_leaf_reg': 1.4796824723926245, 'border_count': 44}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:49:58,636] Trial 49 finished with value: -0.09018364507431752 and parameters: {'learning_rate': 0.014719888752875403, 'depth': 8, 'l2_leaf_reg': 1.5484245669259618, 'border_count': 35}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:50:55,963] Trial 50 finished with value: -0.09852862653973862 and parameters: {'learning_rate': 0.02031644809343991, 'depth': 10, 'l2_leaf_reg': 2.4520643562623006, 'border_count': 106}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:51:51,423] Trial 51 finished with value: -0.09696477302489084 and parameters: {'learning_rate': 0.020675898238734492, 'depth': 10, 'l2_leaf_reg': 2.3683942982474946, 'border_count': 105}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:52:18,371] Trial 52 finished with value: -0.09618318139305938 and parameters: {'learning_rate': 0.032602311472248215, 'depth': 9, 'l2_leaf_reg': 1.715539414354188, 'border_count': 107}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:53:13,706] Trial 53 finished with value: -0.09708761342562487 and parameters: {'learning_rate': 0.016695592672334024, 'depth': 10, 'l2_leaf_reg': 2.833073420647806, 'border_count': 85}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:53:51,713] Trial 54 finished with value: -0.09687614898714705 and parameters: {'learning_rate': 0.02380449305383952, 'depth': 10, 'l2_leaf_reg': 1.0931359507218659, 'border_count': 59}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:54:21,919] Trial 55 finished with value: -0.09373591316502534 and parameters: {'learning_rate': 0.02614032360047345, 'depth': 9, 'l2_leaf_reg': 2.4261387002301578, 'border_count': 84}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:55:07,330] Trial 56 finished with value: -0.09884861635472669 and parameters: {'learning_rate': 0.020002784752187634, 'depth': 10, 'l2_leaf_reg': 1.9388881795534432, 'border_count': 63}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:55:38,357] Trial 57 finished with value: -0.09557083495628899 and parameters: {'learning_rate': 0.017429739923465724, 'depth': 9, 'l2_leaf_reg': 1.8370814006476182, 'border_count': 62}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:55:57,983] Trial 58 finished with value: -0.08828058497486144 and parameters: {'learning_rate': 0.020241592544518242, 'depth': 8, 'l2_leaf_reg': 3.4486600400680625, 'border_count': 40}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:56:16,482] Trial 59 finished with value: -0.07661714427776188 and parameters: {'learning_rate': 0.010072136103684867, 'depth': 7, 'l2_leaf_reg': 2.880611488732438, 'border_count': 77}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:56:56,215] Trial 60 finished with value: -0.09509266253676171 and parameters: {'learning_rate': 0.041250053295948864, 'depth': 10, 'l2_leaf_reg': 1.3932865109122199, 'border_count': 127}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:57:41,186] Trial 61 finished with value: -0.09973700239126729 and parameters: {'learning_rate': 0.028579904516147475, 'depth': 10, 'l2_leaf_reg': 1.4983700593774398, 'border_count': 91}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:57:54,112] Trial 62 finished with value: -0.08093308056330395 and parameters: {'learning_rate': 0.027560388584249827, 'depth': 6, 'l2_leaf_reg': 2.1182903660383308, 'border_count': 107}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:58:30,550] Trial 63 finished with value: -0.09754306013106001 and parameters: {'learning_rate': 0.03511463302863279, 'depth': 10, 'l2_leaf_reg': 2.518353815177719, 'border_count': 64}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:58:54,035] Trial 64 finished with value: -0.09582900148488255 and parameters: {'learning_rate': 0.02186862396099578, 'depth': 9, 'l2_leaf_reg': 1.4935361844084087, 'border_count': 45}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 18:59:49,624] Trial 65 finished with value: -0.09772545099041213 and parameters: {'learning_rate': 0.01623888499921037, 'depth': 10, 'l2_leaf_reg': 1.841860704823954, 'border_count': 88}. Best is trial 40 with value: -0.10170066464050348.
[I 2025-08-03 19:01:18,446] Trial 66 finished with value: -0.10195114707195434 and parameters: {'learning_rate': 0.028681895382979352, 'depth': 11, 'l2_leaf_reg': 2.782552577771585, 'border_count': 101}. Best is trial 66 with value: -0.10195114707195434.
[I 2025-08-03 19:02:26,823] Trial 67 finished with value: -0.09711497260614452 and parameters: {'learning_rate': 0.028694114842077005, 'depth': 11, 'l2_leaf_reg': 3.0303399137639033, 'border_count': 68}. Best is trial 66 with value: -0.10195114707195434.
[I 2025-08-03 19:03:29,212] Trial 68 finished with value: -0.10207113020613144 and parameters: {'learning_rate': 0.03475249077956616, 'depth': 11, 'l2_leaf_reg': 3.5997511078691127, 'border_count': 52}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:04:40,881] Trial 69 finished with value: -0.0993071807373132 and parameters: {'learning_rate': 0.018047097832980107, 'depth': 11, 'l2_leaf_reg': 2.792723955489886, 'border_count': 51}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:05:40,415] Trial 70 finished with value: -0.09633843329946676 and parameters: {'learning_rate': 0.02549465421365334, 'depth': 11, 'l2_leaf_reg': 3.5709273736714104, 'border_count': 49}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:06:47,522] Trial 71 finished with value: -0.09720533072678396 and parameters: {'learning_rate': 0.012301664571356771, 'depth': 11, 'l2_leaf_reg': 2.754548970724178, 'border_count': 32}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:08:11,108] Trial 72 finished with value: -0.09962336798184608 and parameters: {'learning_rate': 0.018667822189814054, 'depth': 11, 'l2_leaf_reg': 2.202366397385695, 'border_count': 76}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:09:22,858] Trial 73 finished with value: -0.09994114994220761 and parameters: {'learning_rate': 0.018227154439486096, 'depth': 11, 'l2_leaf_reg': 2.201232061957378, 'border_count': 53}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:10:43,283] Trial 74 finished with value: -0.09914408975434101 and parameters: {'learning_rate': 0.012836926242870215, 'depth': 11, 'l2_leaf_reg': 2.1525005743243275, 'border_count': 55}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:12:17,162] Trial 75 finished with value: -0.09755785213696064 and parameters: {'learning_rate': 0.014486845796271927, 'depth': 11, 'l2_leaf_reg': 3.6978993915542104, 'border_count': 76}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:13:24,003] Trial 76 finished with value: -0.09916069942357136 and parameters: {'learning_rate': 0.018064133756219857, 'depth': 11, 'l2_leaf_reg': 3.074331860005448, 'border_count': 40}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:14:37,581] Trial 77 finished with value: -0.09915791705946621 and parameters: {'learning_rate': 0.015122108592269532, 'depth': 11, 'l2_leaf_reg': 2.2204947013369547, 'border_count': 53}. Best is trial 68 with value: -0.10207113020613144.
[I 2025-08-03 19:15:55,751] Trial 78 finished with value: -0.10354248844067412 and parameters: {'learning_rate': 0.01829492711507947, 'depth': 11, 'l2_leaf_reg': 1.3176957710579822, 'border_count': 70}. Best is trial 78 with value: -0.10354248844067412.
[I 2025-08-03 19:17:54,726] Trial 79 finished with value: -0.10031430650987144 and parameters: {'learning_rate': 0.02229899930477302, 'depth': 12, 'l2_leaf_reg': 1.4136604538212532, 'border_count': 72}. Best is trial 78 with value: -0.10354248844067412.
[I 2025-08-03 19:19:56,225] Trial 80 finished with value: -0.10365123870621788 and parameters: {'learning_rate': 0.022371133114933436, 'depth': 12, 'l2_leaf_reg': 1.2976581611728855, 'border_count': 69}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:21:41,930] Trial 81 finished with value: -0.09862555046368454 and parameters: {'learning_rate': 0.02970566873944049, 'depth': 12, 'l2_leaf_reg': 1.3793145136103393, 'border_count': 69}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:24:13,600] Trial 82 finished with value: -0.09981889523778513 and parameters: {'learning_rate': 0.02293925400642185, 'depth': 12, 'l2_leaf_reg': 1.0487083114803204, 'border_count': 100}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:26:11,449] Trial 83 finished with value: -0.1009470752060033 and parameters: {'learning_rate': 0.021912374310760135, 'depth': 12, 'l2_leaf_reg': 1.215193777350828, 'border_count': 58}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:27:48,942] Trial 84 finished with value: -0.10325694293227497 and parameters: {'learning_rate': 0.022748834206278212, 'depth': 12, 'l2_leaf_reg': 1.33645482629477, 'border_count': 43}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:29:29,976] Trial 85 finished with value: -0.1029389494153265 and parameters: {'learning_rate': 0.02161725650803811, 'depth': 12, 'l2_leaf_reg': 1.286438216546966, 'border_count': 45}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:30:58,743] Trial 86 finished with value: -0.10048849870284758 and parameters: {'learning_rate': 0.02632383111756225, 'depth': 12, 'l2_leaf_reg': 1.2501736827029526, 'border_count': 40}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:32:41,993] Trial 87 finished with value: -0.1015681262303693 and parameters: {'learning_rate': 0.021991518328238008, 'depth': 12, 'l2_leaf_reg': 1.6974247174508825, 'border_count': 41}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:34:19,119] Trial 88 finished with value: -0.09847230566703677 and parameters: {'learning_rate': 0.024666431157654618, 'depth': 12, 'l2_leaf_reg': 1.647138116366385, 'border_count': 45}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:35:29,142] Trial 89 finished with value: -0.09895013603628083 and parameters: {'learning_rate': 0.03384792469921079, 'depth': 12, 'l2_leaf_reg': 1.6656054706856747, 'border_count': 34}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:37:26,294] Trial 90 finished with value: -0.09947719142695685 and parameters: {'learning_rate': 0.015859591514545118, 'depth': 12, 'l2_leaf_reg': 1.9229610480355908, 'border_count': 44}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:39:20,851] Trial 91 finished with value: -0.10122500076180939 and parameters: {'learning_rate': 0.020730124210922025, 'depth': 12, 'l2_leaf_reg': 1.3045170231401044, 'border_count': 59}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:41:06,133] Trial 92 finished with value: -0.10287786363352319 and parameters: {'learning_rate': 0.02628893797557224, 'depth': 12, 'l2_leaf_reg': 1.0129328507055102, 'border_count': 65}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:43:07,200] Trial 93 finished with value: -0.09726834638792344 and parameters: {'learning_rate': 0.020937155259515138, 'depth': 12, 'l2_leaf_reg': 1.0318448550879804, 'border_count': 65}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:43:43,197] Trial 94 finished with value: -0.06157971526921132 and parameters: {'learning_rate': 0.29704325056516656, 'depth': 12, 'l2_leaf_reg': 1.2475279977017808, 'border_count': 58}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:45:15,282] Trial 95 finished with value: -0.10010100448304768 and parameters: {'learning_rate': 0.027489406952004126, 'depth': 12, 'l2_leaf_reg': 1.7457545020815806, 'border_count': 49}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:46:57,746] Trial 96 finished with value: -0.10115401331857404 and parameters: {'learning_rate': 0.01920656940433989, 'depth': 12, 'l2_leaf_reg': 1.0276801466824756, 'border_count': 37}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:49:14,564] Trial 97 finished with value: -0.09998978529056582 and parameters: {'learning_rate': 0.026065038645114388, 'depth': 12, 'l2_leaf_reg': 1.924941499078998, 'border_count': 81}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:50:32,219] Trial 98 finished with value: -0.09934868573848418 and parameters: {'learning_rate': 0.04551732153732879, 'depth': 12, 'l2_leaf_reg': 1.3177688846668634, 'border_count': 59}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:52:39,893] Trial 99 finished with value: -0.0992064952420717 and parameters: {'learning_rate': 0.03941499671675378, 'depth': 12, 'l2_leaf_reg': 2.360981857077233, 'border_count': 114}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:53:39,693] Trial 100 finished with value: -0.09884702805562087 and parameters: {'learning_rate': 0.03099082124090023, 'depth': 11, 'l2_leaf_reg': 1.5985681627084225, 'border_count': 66}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:55:20,504] Trial 101 finished with value: -0.10014669840849752 and parameters: {'learning_rate': 0.019744500364111277, 'depth': 12, 'l2_leaf_reg': 1.0232285564008299, 'border_count': 41}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:56:58,120] Trial 102 finished with value: -0.10199000416724838 and parameters: {'learning_rate': 0.02163397066071987, 'depth': 12, 'l2_leaf_reg': 1.3165105268007316, 'border_count': 37}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:58:36,326] Trial 103 finished with value: -0.09879646384225342 and parameters: {'learning_rate': 0.022108573077860457, 'depth': 12, 'l2_leaf_reg': 1.3582748009020023, 'border_count': 47}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 19:59:55,573] Trial 104 finished with value: -0.09741528161349819 and parameters: {'learning_rate': 0.02532128340094265, 'depth': 12, 'l2_leaf_reg': 1.8126423377949448, 'border_count': 36}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:03:15,633] Trial 105 finished with value: -0.09893888974476805 and parameters: {'learning_rate': 0.02116855932894771, 'depth': 12, 'l2_leaf_reg': 1.5893265159184702, 'border_count': 136}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:03:25,857] Trial 106 finished with value: -0.0656967779962005 and parameters: {'learning_rate': 0.016641731518467828, 'depth': 4, 'l2_leaf_reg': 1.9918829158181781, 'border_count': 56}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:04:26,907] Trial 107 finished with value: -0.09509524555663407 and parameters: {'learning_rate': 0.02364468972879267, 'depth': 11, 'l2_leaf_reg': 1.2480635330557552, 'border_count': 62}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:05:26,132] Trial 108 finished with value: -0.09651408273184932 and parameters: {'learning_rate': 0.029910431365239992, 'depth': 11, 'l2_leaf_reg': 3.317826712717756, 'border_count': 50}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:07:00,278] Trial 109 finished with value: -0.0951681484335474 and parameters: {'learning_rate': 0.051925289943304295, 'depth': 12, 'l2_leaf_reg': 4.445003153981912, 'border_count': 73}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:07:09,612] Trial 110 finished with value: -0.07679291978598062 and parameters: {'learning_rate': 0.03271235499624902, 'depth': 5, 'l2_leaf_reg': 2.544407538373517, 'border_count': 32}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:08:54,410] Trial 111 finished with value: -0.1018417375994245 and parameters: {'learning_rate': 0.019256087784134297, 'depth': 12, 'l2_leaf_reg': 1.011720004658795, 'border_count': 40}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:10:16,961] Trial 112 finished with value: -0.10109031923626353 and parameters: {'learning_rate': 0.02737743994029645, 'depth': 12, 'l2_leaf_reg': 1.4426677455575463, 'border_count': 42}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:11:50,110] Trial 113 finished with value: -0.10029468115605636 and parameters: {'learning_rate': 0.019256288605623662, 'depth': 12, 'l2_leaf_reg': 1.149455250200219, 'border_count': 37}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:13:57,861] Trial 114 finished with value: -0.09850226293748898 and parameters: {'learning_rate': 0.013867472365514331, 'depth': 12, 'l2_leaf_reg': 1.747317598963896, 'border_count': 48}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:15:09,027] Trial 115 finished with value: -0.09736236014275153 and parameters: {'learning_rate': 0.03601227316695661, 'depth': 11, 'l2_leaf_reg': 9.090998946654427, 'border_count': 60}. Best is trial 80 with value: -0.10365123870621788.
[I 2025-08-03 20:16:24,120] Trial 116 finished with value: -0.10371396192203744 and parameters: {'learning_rate': 0.017477276058489786, 'depth': 11, 'l2_leaf_reg': 1.5647757071074364, 'border_count': 53}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:17:37,850] Trial 117 finished with value: -0.09962195310571645 and parameters: {'learning_rate': 0.01714891446752732, 'depth': 11, 'l2_leaf_reg': 1.5485447509771364, 'border_count': 53}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:19:01,278] Trial 118 finished with value: -0.09979881137116955 and parameters: {'learning_rate': 0.015300898035021411, 'depth': 11, 'l2_leaf_reg': 1.0169793925378436, 'border_count': 68}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:20:09,167] Trial 119 finished with value: -0.09675671933646751 and parameters: {'learning_rate': 0.023406432837765622, 'depth': 11, 'l2_leaf_reg': 6.682006957062267, 'border_count': 44}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:20:45,790] Trial 120 finished with value: -0.09793616527386238 and parameters: {'learning_rate': 0.04198276818497382, 'depth': 11, 'l2_leaf_reg': 2.0091653152643203, 'border_count': 38}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:22:34,570] Trial 121 finished with value: -0.10284473921586008 and parameters: {'learning_rate': 0.021134835008491122, 'depth': 12, 'l2_leaf_reg': 1.2894690317844693, 'border_count': 51}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:24:34,317] Trial 122 finished with value: -0.10005885039596597 and parameters: {'learning_rate': 0.01752367360355401, 'depth': 12, 'l2_leaf_reg': 1.5278842680831635, 'border_count': 51}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:24:46,430] Trial 123 finished with value: -0.0804307421844241 and parameters: {'learning_rate': 0.024963248921587, 'depth': 6, 'l2_leaf_reg': 1.2311194059387076, 'border_count': 47}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:27:18,669] Trial 124 finished with value: -0.09968276796317749 and parameters: {'learning_rate': 0.018971072021321374, 'depth': 12, 'l2_leaf_reg': 1.771181956759528, 'border_count': 80}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:28:43,533] Trial 125 finished with value: -0.09935457180805578 and parameters: {'learning_rate': 0.022656702186350606, 'depth': 12, 'l2_leaf_reg': 1.4184635729089174, 'border_count': 32}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:29:54,764] Trial 126 finished with value: -0.09839140356882135 and parameters: {'learning_rate': 0.021498826447759366, 'depth': 11, 'l2_leaf_reg': 1.6857147715381011, 'border_count': 55}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:32:56,324] Trial 127 finished with value: -0.09832111115480355 and parameters: {'learning_rate': 0.027219493753849102, 'depth': 12, 'l2_leaf_reg': 2.361281822906612, 'border_count': 147}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:34:05,364] Trial 128 finished with value: -0.10074091368897009 and parameters: {'learning_rate': 0.016164442746570588, 'depth': 11, 'l2_leaf_reg': 2.0544958323671128, 'border_count': 44}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:35:49,025] Trial 129 finished with value: -0.09966732199896233 and parameters: {'learning_rate': 0.029518155644771327, 'depth': 12, 'l2_leaf_reg': 1.1958397157555012, 'border_count': 64}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:38:23,386] Trial 130 finished with value: -0.10124673319169336 and parameters: {'learning_rate': 0.02499688524367108, 'depth': 12, 'l2_leaf_reg': 1.4396112669170769, 'border_count': 101}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:40:57,550] Trial 131 finished with value: -0.09967581007424041 and parameters: {'learning_rate': 0.024409011638703258, 'depth': 12, 'l2_leaf_reg': 1.420845595594299, 'border_count': 113}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:42:37,647] Trial 132 finished with value: -0.10262150675726339 and parameters: {'learning_rate': 0.020011394349375926, 'depth': 12, 'l2_leaf_reg': 1.1803585304011703, 'border_count': 41}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:44:21,863] Trial 133 finished with value: -0.10344600579690064 and parameters: {'learning_rate': 0.018495439520055865, 'depth': 12, 'l2_leaf_reg': 1.1597307158601502, 'border_count': 40}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:46:01,565] Trial 134 finished with value: -0.10219821018604111 and parameters: {'learning_rate': 0.018225851578905914, 'depth': 12, 'l2_leaf_reg': 1.2140497174605602, 'border_count': 37}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:47:52,868] Trial 135 finished with value: -0.09761378991264277 and parameters: {'learning_rate': 0.01816922659247428, 'depth': 12, 'l2_leaf_reg': 5.0865879567010115, 'border_count': 35}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:49:41,960] Trial 136 finished with value: -0.10217696113317029 and parameters: {'learning_rate': 0.019896279955370806, 'depth': 12, 'l2_leaf_reg': 1.1608991338250212, 'border_count': 50}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:51:30,773] Trial 137 finished with value: -0.09930092110635978 and parameters: {'learning_rate': 0.020705813859744543, 'depth': 12, 'l2_leaf_reg': 1.1895334439091592, 'border_count': 51}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:53:43,113] Trial 138 finished with value: -0.10165574083450982 and parameters: {'learning_rate': 0.016752632139247516, 'depth': 12, 'l2_leaf_reg': 1.339656005079056, 'border_count': 56}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:55:33,859] Trial 139 finished with value: -0.09930773992974057 and parameters: {'learning_rate': 0.020099072409745483, 'depth': 12, 'l2_leaf_reg': 1.1829246665026107, 'border_count': 46}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:57:15,375] Trial 140 finished with value: -0.10071354604798838 and parameters: {'learning_rate': 0.017953182258645263, 'depth': 12, 'l2_leaf_reg': 1.5750377518301149, 'border_count': 38}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 20:58:59,602] Trial 141 finished with value: -0.09831035783417962 and parameters: {'learning_rate': 0.019325741724936077, 'depth': 12, 'l2_leaf_reg': 1.0040526467875004, 'border_count': 42}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:01:04,849] Trial 142 finished with value: -0.10143783879580409 and parameters: {'learning_rate': 0.015371555038495674, 'depth': 12, 'l2_leaf_reg': 1.0119125580391644, 'border_count': 49}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:02:51,368] Trial 143 finished with value: -0.10169097767358222 and parameters: {'learning_rate': 0.018842949776976127, 'depth': 12, 'l2_leaf_reg': 1.3040024944101836, 'border_count': 39}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:05:07,741] Trial 144 finished with value: -0.10160370118113458 and parameters: {'learning_rate': 0.013415467376774157, 'depth': 12, 'l2_leaf_reg': 1.0002241442980875, 'border_count': 53}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:06:24,076] Trial 145 finished with value: -0.10033679588195712 and parameters: {'learning_rate': 0.022196575507151112, 'depth': 11, 'l2_leaf_reg': 1.525620445534256, 'border_count': 73}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:08:00,086] Trial 146 finished with value: -0.10078546264009154 and parameters: {'learning_rate': 0.02043507611297417, 'depth': 12, 'l2_leaf_reg': 1.8878012597401366, 'border_count': 32}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:09:39,179] Trial 147 finished with value: -0.10052232757417441 and parameters: {'learning_rate': 0.022981692862606873, 'depth': 12, 'l2_leaf_reg': 1.2297859744843462, 'border_count': 45}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:11:50,197] Trial 148 finished with value: -0.10027359810390599 and parameters: {'learning_rate': 0.01789745463707992, 'depth': 12, 'l2_leaf_reg': 1.3725959874666165, 'border_count': 62}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:12:58,371] Trial 149 finished with value: -0.10096021129693027 and parameters: {'learning_rate': 0.014708596246667868, 'depth': 11, 'l2_leaf_reg': 1.176284090137211, 'border_count': 40}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:14:59,423] Trial 150 finished with value: -0.10318727157629189 and parameters: {'learning_rate': 0.016556168918572263, 'depth': 12, 'l2_leaf_reg': 1.644438194326105, 'border_count': 50}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:17:11,464] Trial 151 finished with value: -0.10359350316851519 and parameters: {'learning_rate': 0.015763015929636148, 'depth': 12, 'l2_leaf_reg': 1.6139199119313887, 'border_count': 56}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:19:33,961] Trial 152 finished with value: -0.10073433769804065 and parameters: {'learning_rate': 0.014036305389332464, 'depth': 12, 'l2_leaf_reg': 1.711997144670065, 'border_count': 57}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:21:35,914] Trial 153 finished with value: -0.10103803386772624 and parameters: {'learning_rate': 0.01614470183936215, 'depth': 12, 'l2_leaf_reg': 1.8765713168558338, 'border_count': 50}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:23:57,285] Trial 154 finished with value: -0.0998384441008999 and parameters: {'learning_rate': 0.01721640039142828, 'depth': 12, 'l2_leaf_reg': 1.5817016162096285, 'border_count': 67}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:26:26,244] Trial 155 finished with value: -0.09772700631347185 and parameters: {'learning_rate': 0.011160805906689341, 'depth': 12, 'l2_leaf_reg': 1.3814071463046433, 'border_count': 55}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:27:35,814] Trial 156 finished with value: -0.09759561290826317 and parameters: {'learning_rate': 0.02060501925456253, 'depth': 11, 'l2_leaf_reg': 3.931436684577842, 'border_count': 46}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:29:45,032] Trial 157 finished with value: -0.10024976976076268 and parameters: {'learning_rate': 0.01651144480990908, 'depth': 12, 'l2_leaf_reg': 1.5696714784845898, 'border_count': 59}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:31:11,232] Trial 158 finished with value: -0.09689253970036006 and parameters: {'learning_rate': 0.01206123390035761, 'depth': 11, 'l2_leaf_reg': 1.8354481204564055, 'border_count': 63}. Best is trial 116 with value: -0.10371396192203744.
[I 2025-08-03 21:33:07,079] Trial 159 finished with value: -0.10492384152542526 and parameters: {'learning_rate': 0.01871379209556496, 'depth': 12, 'l2_leaf_reg': 1.3144360489232627, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:34:53,282] Trial 160 finished with value: -0.10006850645093783 and parameters: {'learning_rate': 0.01861954260923159, 'depth': 12, 'l2_leaf_reg': 1.2750681395929164, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:37:03,357] Trial 161 finished with value: -0.10235471904938086 and parameters: {'learning_rate': 0.015258672532696273, 'depth': 12, 'l2_leaf_reg': 1.4466409357855277, 'border_count': 44}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:39:08,268] Trial 162 finished with value: -0.10095113618163903 and parameters: {'learning_rate': 0.015322663389881568, 'depth': 12, 'l2_leaf_reg': 1.4712357117495007, 'border_count': 43}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:40:59,110] Trial 163 finished with value: -0.10057418614212646 and parameters: {'learning_rate': 0.013213537668182573, 'depth': 12, 'l2_leaf_reg': 1.1768268124488124, 'border_count': 36}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:43:00,211] Trial 164 finished with value: -0.10061508240218503 and parameters: {'learning_rate': 0.01712429838509724, 'depth': 12, 'l2_leaf_reg': 1.6775398537865651, 'border_count': 48}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:44:50,757] Trial 165 finished with value: -0.09803481679370589 and parameters: {'learning_rate': 0.019702434108760953, 'depth': 12, 'l2_leaf_reg': 1.3579666126906398, 'border_count': 54}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:46:53,409] Trial 166 finished with value: -0.1020715612079392 and parameters: {'learning_rate': 0.014537885797240907, 'depth': 12, 'l2_leaf_reg': 1.4395820380622362, 'border_count': 43}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:49:01,213] Trial 167 finished with value: -0.10085892017718656 and parameters: {'learning_rate': 0.014369079338065196, 'depth': 12, 'l2_leaf_reg': 1.555343518205094, 'border_count': 46}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:51:21,164] Trial 168 finished with value: -0.10076594531108247 and parameters: {'learning_rate': 0.015656702209518557, 'depth': 12, 'l2_leaf_reg': 1.160291091996458, 'border_count': 60}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:53:46,251] Trial 169 finished with value: -0.10061761552159391 and parameters: {'learning_rate': 0.017566582522850142, 'depth': 12, 'l2_leaf_reg': 2.1344207505307455, 'border_count': 70}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:56:08,112] Trial 170 finished with value: -0.09403976343104224 and parameters: {'learning_rate': 0.012648267333780118, 'depth': 12, 'l2_leaf_reg': 5.706309338236804, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:57:41,366] Trial 171 finished with value: -0.10075273260343082 and parameters: {'learning_rate': 0.020936063062166804, 'depth': 12, 'l2_leaf_reg': 1.3914201937924628, 'border_count': 37}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 21:59:24,887] Trial 172 finished with value: -0.09957116951887211 and parameters: {'learning_rate': 0.01865441838350723, 'depth': 12, 'l2_leaf_reg': 1.7310193352066794, 'border_count': 42}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:01:20,305] Trial 173 finished with value: -0.09861452526252258 and parameters: {'learning_rate': 0.015797375472831127, 'depth': 12, 'l2_leaf_reg': 1.1654367127399903, 'border_count': 43}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:02:49,905] Trial 174 finished with value: -0.1024524387162972 and parameters: {'learning_rate': 0.021937313872699055, 'depth': 12, 'l2_leaf_reg': 1.4450926248800333, 'border_count': 34}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:04:56,298] Trial 175 finished with value: -0.10074681454385456 and parameters: {'learning_rate': 0.014621089251997975, 'depth': 12, 'l2_leaf_reg': 1.4873995356934395, 'border_count': 48}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:07:02,172] Trial 176 finished with value: -0.09809836439569501 and parameters: {'learning_rate': 0.022571029414232155, 'depth': 12, 'l2_leaf_reg': 4.773158638368681, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:08:50,263] Trial 177 finished with value: -0.10315173431815153 and parameters: {'learning_rate': 0.01683620558209801, 'depth': 12, 'l2_leaf_reg': 1.9238749473062922, 'border_count': 32}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:10:38,335] Trial 178 finished with value: -0.09947594276026599 and parameters: {'learning_rate': 0.016688316695325337, 'depth': 12, 'l2_leaf_reg': 1.863137949932466, 'border_count': 33}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:12:23,544] Trial 179 finished with value: -0.09359211482126326 and parameters: {'learning_rate': 0.01795834203002118, 'depth': 12, 'l2_leaf_reg': 7.8083614459353345, 'border_count': 35}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:14:07,653] Trial 180 finished with value: -0.10214744414224743 and parameters: {'learning_rate': 0.019597980586625662, 'depth': 12, 'l2_leaf_reg': 1.5897905517471251, 'border_count': 40}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:15:51,825] Trial 181 finished with value: -0.10098777128173225 and parameters: {'learning_rate': 0.019790978044705015, 'depth': 12, 'l2_leaf_reg': 1.6405972027596532, 'border_count': 41}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:17:25,546] Trial 182 finished with value: -0.10268016214240044 and parameters: {'learning_rate': 0.019440965190685243, 'depth': 12, 'l2_leaf_reg': 1.3528876155619005, 'border_count': 32}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:19:06,138] Trial 183 finished with value: -0.09980071250855069 and parameters: {'learning_rate': 0.01949949192406898, 'depth': 12, 'l2_leaf_reg': 1.2878412118817666, 'border_count': 36}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:20:30,765] Trial 184 finished with value: -0.10174169828055021 and parameters: {'learning_rate': 0.0214361796865921, 'depth': 12, 'l2_leaf_reg': 1.0191214354713387, 'border_count': 32}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:22:16,868] Trial 185 finished with value: -0.10089827442264404 and parameters: {'learning_rate': 0.018279961085848253, 'depth': 12, 'l2_leaf_reg': 1.6648125583169402, 'border_count': 39}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:23:53,993] Trial 186 finished with value: -0.10160775176483215 and parameters: {'learning_rate': 0.023765464204451785, 'depth': 12, 'l2_leaf_reg': 1.9757087045815171, 'border_count': 38}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:25:53,415] Trial 187 finished with value: -0.09980507571204301 and parameters: {'learning_rate': 0.01686409695492144, 'depth': 12, 'l2_leaf_reg': 1.1695605042841266, 'border_count': 47}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:27:21,477] Trial 188 finished with value: -0.09825261745810716 and parameters: {'learning_rate': 0.02003743538461126, 'depth': 12, 'l2_leaf_reg': 1.4250877960318105, 'border_count': 32}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:28:56,928] Trial 189 finished with value: -0.10059483432437638 and parameters: {'learning_rate': 0.01884903960400889, 'depth': 12, 'l2_leaf_reg': 1.2865175376366673, 'border_count': 42}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:30:43,862] Trial 190 finished with value: -0.0989933059690142 and parameters: {'learning_rate': 0.021903811755145632, 'depth': 12, 'l2_leaf_reg': 1.5649861439959023, 'border_count': 47}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:32:42,728] Trial 191 finished with value: -0.0995623772298228 and parameters: {'learning_rate': 0.01574920943829164, 'depth': 12, 'l2_leaf_reg': 1.4344807194961764, 'border_count': 43}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:34:42,722] Trial 192 finished with value: -0.10005722831955484 and parameters: {'learning_rate': 0.013801272695094801, 'depth': 12, 'l2_leaf_reg': 1.1758986226715713, 'border_count': 38}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:36:46,248] Trial 193 finished with value: -0.10253031960502455 and parameters: {'learning_rate': 0.017441050144637354, 'depth': 12, 'l2_leaf_reg': 1.722302686993596, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:38:58,364] Trial 194 finished with value: -0.10108246015907583 and parameters: {'learning_rate': 0.017259392030869142, 'depth': 12, 'l2_leaf_reg': 1.8153788903258197, 'border_count': 54}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:40:45,771] Trial 195 finished with value: -0.10277735968871789 and parameters: {'learning_rate': 0.02074485907242049, 'depth': 12, 'l2_leaf_reg': 1.689246616198816, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:42:36,541] Trial 196 finished with value: -0.10145885286894857 and parameters: {'learning_rate': 0.021149314205453882, 'depth': 12, 'l2_leaf_reg': 1.7544332740467108, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:44:48,753] Trial 197 finished with value: -0.10191584969149327 and parameters: {'learning_rate': 0.018051043303487915, 'depth': 12, 'l2_leaf_reg': 1.0015362730510138, 'border_count': 62}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:46:41,399] Trial 198 finished with value: -0.10406703000933414 and parameters: {'learning_rate': 0.023665807190387987, 'depth': 12, 'l2_leaf_reg': 1.3189065633112351, 'border_count': 58}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:48:40,954] Trial 199 finished with value: -0.10211070555867646 and parameters: {'learning_rate': 0.02354415494543859, 'depth': 12, 'l2_leaf_reg': 2.0139405522004754, 'border_count': 58}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:50:23,478] Trial 200 finished with value: -0.1005763507922009 and parameters: {'learning_rate': 0.025589246474080025, 'depth': 12, 'l2_leaf_reg': 1.3070861476517355, 'border_count': 59}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:52:23,463] Trial 201 finished with value: -0.10026664151762218 and parameters: {'learning_rate': 0.02055643751802681, 'depth': 12, 'l2_leaf_reg': 1.4838416058721067, 'border_count': 65}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:53:57,885] Trial 202 finished with value: -0.09862339215539796 and parameters: {'learning_rate': 0.022861826703384887, 'depth': 12, 'l2_leaf_reg': 1.263115237492878, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:55:58,795] Trial 203 finished with value: -0.10245447901186765 and parameters: {'learning_rate': 0.017207336690575007, 'depth': 12, 'l2_leaf_reg': 1.1460508170232455, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 22:58:09,960] Trial 204 finished with value: -0.10162351326209736 and parameters: {'learning_rate': 0.016241735259152564, 'depth': 12, 'l2_leaf_reg': 1.6388476656139253, 'border_count': 54}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:00:34,132] Trial 205 finished with value: -0.10005685443417096 and parameters: {'learning_rate': 0.017276494161844493, 'depth': 12, 'l2_leaf_reg': 1.48121824263723, 'border_count': 68}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:02:32,862] Trial 206 finished with value: -0.10157442412486596 and parameters: {'learning_rate': 0.016137328410101084, 'depth': 12, 'l2_leaf_reg': 1.3200540141152683, 'border_count': 46}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:04:29,063] Trial 207 finished with value: -0.10128614054925358 and parameters: {'learning_rate': 0.018559847941333373, 'depth': 12, 'l2_leaf_reg': 1.1670877682648437, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:06:23,036] Trial 208 finished with value: -0.09796333481438972 and parameters: {'learning_rate': 0.022104092445847153, 'depth': 12, 'l2_leaf_reg': 1.0069363655876713, 'border_count': 61}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:07:59,825] Trial 209 finished with value: -0.09946589081708689 and parameters: {'learning_rate': 0.01873938783391172, 'depth': 12, 'l2_leaf_reg': 1.8086270360585932, 'border_count': 32}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:10:33,908] Trial 210 finished with value: -0.10391079355688455 and parameters: {'learning_rate': 0.017724211383594646, 'depth': 12, 'l2_leaf_reg': 1.3677556400205424, 'border_count': 76}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:13:13,597] Trial 211 finished with value: -0.10167261921101281 and parameters: {'learning_rate': 0.015085787023157153, 'depth': 12, 'l2_leaf_reg': 1.385703618706854, 'border_count': 71}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:17:51,239] Trial 212 finished with value: -0.0935318804286586 and parameters: {'learning_rate': 0.017416892491053774, 'depth': 12, 'l2_leaf_reg': 7.177870469915193, 'border_count': 165}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:19:52,109] Trial 213 finished with value: -0.0992670463881069 and parameters: {'learning_rate': 0.020725615230878614, 'depth': 12, 'l2_leaf_reg': 1.5686211485559511, 'border_count': 64}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:22:28,428] Trial 214 finished with value: -0.10161379640384416 and parameters: {'learning_rate': 0.016466588135725713, 'depth': 12, 'l2_leaf_reg': 1.324875594740215, 'border_count': 77}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:26:48,764] Trial 215 finished with value: -0.09573365414588736 and parameters: {'learning_rate': 0.01899200164295842, 'depth': 12, 'l2_leaf_reg': 1.1464100137071584, 'border_count': 202}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:28:50,219] Trial 216 finished with value: -0.09959795545527793 and parameters: {'learning_rate': 0.017833529109901748, 'depth': 12, 'l2_leaf_reg': 1.6638779888572857, 'border_count': 46}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:30:45,126] Trial 217 finished with value: -0.10056394907303555 and parameters: {'learning_rate': 0.024258171128381665, 'depth': 12, 'l2_leaf_reg': 1.459205130353398, 'border_count': 57}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:32:29,805] Trial 218 finished with value: -0.10213295682996228 and parameters: {'learning_rate': 0.019923597415796346, 'depth': 12, 'l2_leaf_reg': 1.1618537276622785, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:32:46,521] Trial 219 finished with value: -0.08748401660683612 and parameters: {'learning_rate': 0.021460084160731727, 'depth': 7, 'l2_leaf_reg': 1.299844969309003, 'border_count': 75}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:34:43,739] Trial 220 finished with value: -0.10245303685904528 and parameters: {'learning_rate': 0.015350159483751527, 'depth': 12, 'l2_leaf_reg': 1.7516446851367733, 'border_count': 36}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:36:31,107] Trial 221 finished with value: -0.10032872125487395 and parameters: {'learning_rate': 0.015215883636535404, 'depth': 12, 'l2_leaf_reg': 1.767614364249491, 'border_count': 38}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:38:19,885] Trial 222 finished with value: -0.10030052473155185 and parameters: {'learning_rate': 0.01674192736432621, 'depth': 12, 'l2_leaf_reg': 1.5174415586120373, 'border_count': 35}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:40:15,549] Trial 223 finished with value: -0.10006648586229835 and parameters: {'learning_rate': 0.015580146262320365, 'depth': 12, 'l2_leaf_reg': 1.9303599664952102, 'border_count': 42}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:42:07,726] Trial 224 finished with value: -0.10052229237272113 and parameters: {'learning_rate': 0.01766827728985715, 'depth': 12, 'l2_leaf_reg': 1.38603290426532, 'border_count': 45}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:43:44,822] Trial 225 finished with value: -0.10097453233357158 and parameters: {'learning_rate': 0.018988355318445563, 'depth': 12, 'l2_leaf_reg': 1.6406283344217887, 'border_count': 36}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:45:51,672] Trial 226 finished with value: -0.09914248155975888 and parameters: {'learning_rate': 0.013824629974104706, 'depth': 12, 'l2_leaf_reg': 1.1580687293228276, 'border_count': 49}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:48:27,951] Trial 227 finished with value: -0.10135715726500077 and parameters: {'learning_rate': 0.016201940783045047, 'depth': 12, 'l2_leaf_reg': 1.5190068497296547, 'border_count': 66}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:50:03,804] Trial 228 finished with value: -0.10127854921071229 and parameters: {'learning_rate': 0.022669532898745372, 'depth': 12, 'l2_leaf_reg': 1.3221830640250982, 'border_count': 41}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:50:45,081] Trial 229 finished with value: -0.09909003601859755 and parameters: {'learning_rate': 0.07848142891143428, 'depth': 12, 'l2_leaf_reg': 1.019850300858064, 'border_count': 32}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:51:28,016] Trial 230 finished with value: -0.0894511101104407 and parameters: {'learning_rate': 0.15479196646165097, 'depth': 12, 'l2_leaf_reg': 1.6986927408152317, 'border_count': 58}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:51:40,492] Trial 231 finished with value: -0.07933796704933892 and parameters: {'learning_rate': 0.020368602499705388, 'depth': 6, 'l2_leaf_reg': 1.1773603946348328, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:52:15,383] Trial 232 finished with value: -0.07182391486446983 and parameters: {'learning_rate': 0.2049409635141326, 'depth': 12, 'l2_leaf_reg': 1.349893998030898, 'border_count': 46}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:54:11,607] Trial 233 finished with value: -0.10010707349206054 and parameters: {'learning_rate': 0.01956536635136267, 'depth': 12, 'l2_leaf_reg': 1.1966668486201144, 'border_count': 54}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:56:02,692] Trial 234 finished with value: -0.10052727755290193 and parameters: {'learning_rate': 0.018322964854554393, 'depth': 12, 'l2_leaf_reg': 1.4082594248607234, 'border_count': 49}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:57:38,476] Trial 235 finished with value: -0.10299739711855774 and parameters: {'learning_rate': 0.020941448865850927, 'depth': 12, 'l2_leaf_reg': 1.5548330160534636, 'border_count': 41}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-03 23:59:18,761] Trial 236 finished with value: -0.10285721450219422 and parameters: {'learning_rate': 0.021451994055455895, 'depth': 12, 'l2_leaf_reg': 1.903113226666829, 'border_count': 40}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:00:57,280] Trial 237 finished with value: -0.09921696052885208 and parameters: {'learning_rate': 0.023636020293663622, 'depth': 12, 'l2_leaf_reg': 2.17153456026431, 'border_count': 42}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:02:34,236] Trial 238 finished with value: -0.10321932184304067 and parameters: {'learning_rate': 0.0214880198141706, 'depth': 12, 'l2_leaf_reg': 1.7807460505636716, 'border_count': 39}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:04:07,798] Trial 239 finished with value: -0.09819958135957388 and parameters: {'learning_rate': 0.021443331272539813, 'depth': 12, 'l2_leaf_reg': 1.9734480150534894, 'border_count': 38}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:05:34,680] Trial 240 finished with value: -0.10227166075512291 and parameters: {'learning_rate': 0.026526374184046554, 'depth': 12, 'l2_leaf_reg': 1.84664537202831, 'border_count': 36}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:07:08,130] Trial 241 finished with value: -0.09895301320168667 and parameters: {'learning_rate': 0.022139464589886228, 'depth': 12, 'l2_leaf_reg': 1.7133948958980156, 'border_count': 44}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:08:41,537] Trial 242 finished with value: -0.10098655366102423 and parameters: {'learning_rate': 0.024592525561855996, 'depth': 12, 'l2_leaf_reg': 1.5644915313436552, 'border_count': 40}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:10:42,921] Trial 243 finished with value: -0.09497803295818436 and parameters: {'learning_rate': 0.020600323078244064, 'depth': 12, 'l2_leaf_reg': 8.399712624500506, 'border_count': 45}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:12:15,306] Trial 244 finished with value: -0.10168127361045828 and parameters: {'learning_rate': 0.022400391658088666, 'depth': 12, 'l2_leaf_reg': 2.098590297113867, 'border_count': 35}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:13:58,385] Trial 245 finished with value: -0.10099698831143669 and parameters: {'learning_rate': 0.02058441811352701, 'depth': 12, 'l2_leaf_reg': 1.7648317864852245, 'border_count': 41}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:15:50,904] Trial 246 finished with value: -0.09909611583314284 and parameters: {'learning_rate': 0.019272053534854824, 'depth': 12, 'l2_leaf_reg': 1.539423051779947, 'border_count': 54}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:17:51,406] Trial 247 finished with value: -0.10052600989603568 and parameters: {'learning_rate': 0.017311628789460635, 'depth': 12, 'l2_leaf_reg': 1.9453112940518629, 'border_count': 48}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:19:19,667] Trial 248 finished with value: -0.09943758985236932 and parameters: {'learning_rate': 0.023387744838072818, 'depth': 12, 'l2_leaf_reg': 1.6339250826442022, 'border_count': 32}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:21:51,569] Trial 249 finished with value: -0.09981553222286736 and parameters: {'learning_rate': 0.014796806081783506, 'depth': 12, 'l2_leaf_reg': 2.2716511454153987, 'border_count': 70}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:23:37,380] Trial 250 finished with value: -0.10006252707695662 and parameters: {'learning_rate': 0.021151095116042108, 'depth': 12, 'l2_leaf_reg': 1.422203380911122, 'border_count': 58}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:24:32,177] Trial 251 finished with value: -0.0985804787110302 and parameters: {'learning_rate': 0.06517823921672826, 'depth': 12, 'l2_leaf_reg': 1.825119059986642, 'border_count': 45}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:26:57,427] Trial 252 finished with value: -0.10169760586055829 and parameters: {'learning_rate': 0.01690565245539923, 'depth': 12, 'l2_leaf_reg': 1.4824971941868876, 'border_count': 62}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:28:39,504] Trial 253 finished with value: -0.10177627304356453 and parameters: {'learning_rate': 0.019332994889525074, 'depth': 12, 'l2_leaf_reg': 1.636901905465621, 'border_count': 39}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:30:09,203] Trial 254 finished with value: -0.10123303808915068 and parameters: {'learning_rate': 0.025106397376456948, 'depth': 12, 'l2_leaf_reg': 1.3037849789682638, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:31:55,133] Trial 255 finished with value: -0.10115759286401052 and parameters: {'learning_rate': 0.021772803992465707, 'depth': 12, 'l2_leaf_reg': 1.5012619726385137, 'border_count': 41}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:33:54,557] Trial 256 finished with value: -0.0991997957542244 and parameters: {'learning_rate': 0.018576889844959258, 'depth': 12, 'l2_leaf_reg': 1.9400673068152263, 'border_count': 48}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:36:36,889] Trial 257 finished with value: -0.10141023820278831 and parameters: {'learning_rate': 0.015429984068291769, 'depth': 12, 'l2_leaf_reg': 1.1427559065733828, 'border_count': 84}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:38:44,004] Trial 258 finished with value: -0.10287528071612942 and parameters: {'learning_rate': 0.01755923847341227, 'depth': 12, 'l2_leaf_reg': 1.3409697658838031, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:40:49,840] Trial 259 finished with value: -0.10428581405784673 and parameters: {'learning_rate': 0.01815874001758688, 'depth': 12, 'l2_leaf_reg': 1.292025873065315, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:42:51,642] Trial 260 finished with value: -0.10126853966884042 and parameters: {'learning_rate': 0.01773761423787367, 'depth': 12, 'l2_leaf_reg': 1.009063162883374, 'border_count': 57}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:45:07,483] Trial 261 finished with value: -0.1032725433273957 and parameters: {'learning_rate': 0.01655510878612347, 'depth': 12, 'l2_leaf_reg': 1.2768827589290075, 'border_count': 61}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:47:28,653] Trial 262 finished with value: -0.0985085946805003 and parameters: {'learning_rate': 0.017342249824325553, 'depth': 12, 'l2_leaf_reg': 1.3225653555496288, 'border_count': 66}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:49:40,794] Trial 263 finished with value: -0.10060414271403124 and parameters: {'learning_rate': 0.01962393237258552, 'depth': 12, 'l2_leaf_reg': 1.2243742651049982, 'border_count': 62}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:50:50,989] Trial 264 finished with value: -0.10086292268431661 and parameters: {'learning_rate': 0.01832739003193166, 'depth': 11, 'l2_leaf_reg': 1.000067130615785, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:53:04,889] Trial 265 finished with value: -0.10094196732319581 and parameters: {'learning_rate': 0.016674983304122728, 'depth': 12, 'l2_leaf_reg': 1.286526481232404, 'border_count': 58}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:55:03,050] Trial 266 finished with value: -0.09907105768813054 and parameters: {'learning_rate': 0.01995786197631263, 'depth': 12, 'l2_leaf_reg': 1.1683108022930306, 'border_count': 62}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:57:35,548] Trial 267 finished with value: -0.09181527307083502 and parameters: {'learning_rate': 0.018489614634365607, 'depth': 12, 'l2_leaf_reg': 9.498925734502611, 'border_count': 68}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 00:59:42,382] Trial 268 finished with value: -0.09954059864960199 and parameters: {'learning_rate': 0.01667524368956496, 'depth': 12, 'l2_leaf_reg': 1.3623007395820417, 'border_count': 53}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:00:04,239] Trial 269 finished with value: -0.09106492955812388 and parameters: {'learning_rate': 0.020564206812427887, 'depth': 8, 'l2_leaf_reg': 1.612200251967292, 'border_count': 73}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:02:11,688] Trial 270 finished with value: -0.10155307983458771 and parameters: {'learning_rate': 0.017970864815226036, 'depth': 12, 'l2_leaf_reg': 1.1326743343328678, 'border_count': 53}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:04:12,545] Trial 271 finished with value: -0.09971099228281183 and parameters: {'learning_rate': 0.0191129533065111, 'depth': 12, 'l2_leaf_reg': 1.4903610073439806, 'border_count': 59}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:05:17,280] Trial 272 finished with value: -0.09850331423578497 and parameters: {'learning_rate': 0.023163093505928725, 'depth': 11, 'l2_leaf_reg': 1.3038021652642238, 'border_count': 63}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:07:06,800] Trial 273 finished with value: -0.10397228957851495 and parameters: {'learning_rate': 0.02076674704595245, 'depth': 12, 'l2_leaf_reg': 1.617952822293373, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:09:13,920] Trial 274 finished with value: -0.10408348661391927 and parameters: {'learning_rate': 0.020389408670043647, 'depth': 12, 'l2_leaf_reg': 1.7668170196880444, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:11:06,199] Trial 275 finished with value: -0.1004215287052695 and parameters: {'learning_rate': 0.02129608821323785, 'depth': 12, 'l2_leaf_reg': 1.8492089757272105, 'border_count': 49}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:12:55,124] Trial 276 finished with value: -0.10052397257425548 and parameters: {'learning_rate': 0.023147670047843558, 'depth': 12, 'l2_leaf_reg': 2.1213760737472636, 'border_count': 47}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:15:01,804] Trial 277 finished with value: -0.1012523732795041 and parameters: {'learning_rate': 0.020494174187159632, 'depth': 12, 'l2_leaf_reg': 1.5885876586205812, 'border_count': 66}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:15:53,937] Trial 278 finished with value: -0.0958260445357065 and parameters: {'learning_rate': 0.02193870586746916, 'depth': 9, 'l2_leaf_reg': 1.4660870169570546, 'border_count': 252}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:16:04,727] Trial 279 finished with value: -0.07701166350031029 and parameters: {'learning_rate': 0.025351090611588835, 'depth': 5, 'l2_leaf_reg': 1.71627996209412, 'border_count': 57}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:17:53,649] Trial 280 finished with value: -0.10033855708728437 and parameters: {'learning_rate': 0.019958290887760056, 'depth': 12, 'l2_leaf_reg': 1.3227919384780749, 'border_count': 53}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:19:00,303] Trial 281 finished with value: -0.09660175942897885 and parameters: {'learning_rate': 0.023820651597997462, 'depth': 11, 'l2_leaf_reg': 6.353798633430969, 'border_count': 45}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:22:31,062] Trial 282 finished with value: -0.10237720856842271 and parameters: {'learning_rate': 0.02111084644260191, 'depth': 12, 'l2_leaf_reg': 1.5640421835388945, 'border_count': 127}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:24:28,807] Trial 283 finished with value: -0.0924745417350981 and parameters: {'learning_rate': 0.10778624170669421, 'depth': 12, 'l2_leaf_reg': 1.9754034403802008, 'border_count': 220}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:26:51,679] Trial 284 finished with value: -0.10065410643466748 and parameters: {'learning_rate': 0.01931683822422636, 'depth': 12, 'l2_leaf_reg': 1.3772281605733552, 'border_count': 77}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:28:46,026] Trial 285 finished with value: -0.10155497373658419 and parameters: {'learning_rate': 0.022160558183737283, 'depth': 12, 'l2_leaf_reg': 1.7929828542838233, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:30:49,308] Trial 286 finished with value: -0.10292645826698373 and parameters: {'learning_rate': 0.01892175927851153, 'depth': 12, 'l2_leaf_reg': 1.5952853008222538, 'border_count': 60}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:33:03,010] Trial 287 finished with value: -0.10243790432600887 and parameters: {'learning_rate': 0.018947854240040835, 'depth': 12, 'l2_leaf_reg': 1.6153148622727107, 'border_count': 60}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:35:43,235] Trial 288 finished with value: -0.1011580689779465 and parameters: {'learning_rate': 0.016312438504900998, 'depth': 12, 'l2_leaf_reg': 2.0164473342217812, 'border_count': 70}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:37:58,917] Trial 289 finished with value: -0.10010081714339128 and parameters: {'learning_rate': 0.0182201060232208, 'depth': 12, 'l2_leaf_reg': 1.77348078847166, 'border_count': 64}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:39:56,695] Trial 290 finished with value: -0.09943166250710218 and parameters: {'learning_rate': 0.020329675750512068, 'depth': 12, 'l2_leaf_reg': 1.51633434082762, 'border_count': 57}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:41:49,572] Trial 291 finished with value: -0.10189439314248724 and parameters: {'learning_rate': 0.023525781719105715, 'depth': 12, 'l2_leaf_reg': 1.6293025264727599, 'border_count': 60}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:43:25,661] Trial 292 finished with value: -0.09769066794125253 and parameters: {'learning_rate': 0.026286718758737095, 'depth': 12, 'l2_leaf_reg': 1.394832449973034, 'border_count': 54}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:44:43,886] Trial 293 finished with value: -0.09921717191286308 and parameters: {'learning_rate': 0.018473204556165957, 'depth': 11, 'l2_leaf_reg': 1.8071372649210233, 'border_count': 67}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:46:33,356] Trial 294 finished with value: -0.10017271215473984 and parameters: {'learning_rate': 0.021039492424449864, 'depth': 12, 'l2_leaf_reg': 2.3290573864285795, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:48:24,689] Trial 295 finished with value: -0.1005651677864668 and parameters: {'learning_rate': 0.022356681774422547, 'depth': 12, 'l2_leaf_reg': 1.2874202263780798, 'border_count': 61}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:50:50,138] Trial 296 finished with value: -0.10115787814539459 and parameters: {'learning_rate': 0.017361855817173682, 'depth': 12, 'l2_leaf_reg': 1.4734282094863713, 'border_count': 72}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:52:31,652] Trial 297 finished with value: -0.09907745162042533 and parameters: {'learning_rate': 0.019290914826788238, 'depth': 12, 'l2_leaf_reg': 1.1235907486068213, 'border_count': 44}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:54:19,637] Trial 298 finished with value: -0.10325744497365091 and parameters: {'learning_rate': 0.024600925348696453, 'depth': 12, 'l2_leaf_reg': 1.6280990072065147, 'border_count': 53}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:56:07,331] Trial 299 finished with value: -0.10009418643612265 and parameters: {'learning_rate': 0.02744408220939429, 'depth': 12, 'l2_leaf_reg': 1.9008230075749233, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:57:43,266] Trial 300 finished with value: -0.09876509416957778 and parameters: {'learning_rate': 0.024815358134126615, 'depth': 12, 'l2_leaf_reg': 1.6949036487566682, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 01:59:01,200] Trial 301 finished with value: -0.10290746054938313 and parameters: {'learning_rate': 0.016220803024718684, 'depth': 11, 'l2_leaf_reg': 2.059709030304828, 'border_count': 57}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:00:23,866] Trial 302 finished with value: -0.10072408488961254 and parameters: {'learning_rate': 0.016088836280309042, 'depth': 11, 'l2_leaf_reg': 2.027108483795392, 'border_count': 65}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:01:46,546] Trial 303 finished with value: -0.09887614854073297 and parameters: {'learning_rate': 0.01576279527453693, 'depth': 11, 'l2_leaf_reg': 2.172341231841684, 'border_count': 59}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:03:00,159] Trial 304 finished with value: -0.09848607178706334 and parameters: {'learning_rate': 0.01480814763698505, 'depth': 11, 'l2_leaf_reg': 1.5029927861151249, 'border_count': 55}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:04:15,056] Trial 305 finished with value: -0.09912155376492397 and parameters: {'learning_rate': 0.016734823809812525, 'depth': 11, 'l2_leaf_reg': 1.0261352924346314, 'border_count': 61}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:05:15,714] Trial 306 finished with value: -0.09892474160218777 and parameters: {'learning_rate': 0.024992127466000474, 'depth': 11, 'l2_leaf_reg': 1.8939497285750873, 'border_count': 47}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:06:03,204] Trial 307 finished with value: -0.09824202822419965 and parameters: {'learning_rate': 0.017871362606904303, 'depth': 10, 'l2_leaf_reg': 1.2673792332769866, 'border_count': 56}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:07:49,015] Trial 308 finished with value: -0.09904686000346921 and parameters: {'learning_rate': 0.023850744869594494, 'depth': 11, 'l2_leaf_reg': 1.6638570312446692, 'border_count': 136}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:10:19,831] Trial 309 finished with value: -0.10101419254637994 and parameters: {'learning_rate': 0.014515386822403846, 'depth': 12, 'l2_leaf_reg': 1.4840659833627652, 'border_count': 68}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:16:01,360] Trial 310 finished with value: -0.10219391585954495 and parameters: {'learning_rate': 0.016005979204036784, 'depth': 12, 'l2_leaf_reg': 1.842616296167852, 'border_count': 234}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:16:10,974] Trial 311 finished with value: -0.0674208408999004 and parameters: {'learning_rate': 0.0224025812266956, 'depth': 4, 'l2_leaf_reg': 2.0802991195714142, 'border_count': 53}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:18:24,959] Trial 312 finished with value: -0.10039247086257695 and parameters: {'learning_rate': 0.017388130992920525, 'depth': 12, 'l2_leaf_reg': 1.1901844588741621, 'border_count': 64}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:19:55,186] Trial 313 finished with value: -0.09799135610773926 and parameters: {'learning_rate': 0.026593061705750824, 'depth': 12, 'l2_leaf_reg': 1.37518884369369, 'border_count': 47}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:22:08,073] Trial 314 finished with value: -0.10026754492997673 and parameters: {'learning_rate': 0.018582952327622762, 'depth': 12, 'l2_leaf_reg': 1.6432972452809194, 'border_count': 59}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:23:08,392] Trial 315 finished with value: -0.09792492348681968 and parameters: {'learning_rate': 0.020801582080820193, 'depth': 11, 'l2_leaf_reg': 1.0252305546080156, 'border_count': 52}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:27:21,249] Trial 316 finished with value: -0.10074117200074213 and parameters: {'learning_rate': 0.013253454400691596, 'depth': 12, 'l2_leaf_reg': 1.2660195488333073, 'border_count': 153}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:29:54,133] Trial 317 finished with value: -0.10043664778228818 and parameters: {'learning_rate': 0.016143240633696276, 'depth': 12, 'l2_leaf_reg': 1.5520677465039705, 'border_count': 77}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:32:03,429] Trial 318 finished with value: -0.1023860672429349 and parameters: {'learning_rate': 0.022547771299600398, 'depth': 12, 'l2_leaf_reg': 2.251271467103737, 'border_count': 72}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:33:56,491] Trial 319 finished with value: -0.10157339584673507 and parameters: {'learning_rate': 0.019285163930550797, 'depth': 12, 'l2_leaf_reg': 1.8476137038299847, 'border_count': 44}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:36:06,951] Trial 320 finished with value: -0.10147987089815048 and parameters: {'learning_rate': 0.017759499097303476, 'depth': 12, 'l2_leaf_reg': 1.4423068035090012, 'border_count': 57}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:36:23,114] Trial 321 finished with value: -0.08622459794106671 and parameters: {'learning_rate': 0.021310394872765603, 'depth': 7, 'l2_leaf_reg': 1.0005916366031071, 'border_count': 48}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:38:24,262] Trial 322 finished with value: -0.09634506384247166 and parameters: {'learning_rate': 0.019877710547877608, 'depth': 12, 'l2_leaf_reg': 1.2669244828600141, 'border_count': 63}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:41:20,256] Trial 323 finished with value: -0.10451037649186064 and parameters: {'learning_rate': 0.014226830005761634, 'depth': 12, 'l2_leaf_reg': 1.6563705897680778, 'border_count': 82}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:42:55,397] Trial 324 finished with value: -0.10070737568439687 and parameters: {'learning_rate': 0.014079672120528176, 'depth': 11, 'l2_leaf_reg': 2.487283879558899, 'border_count': 81}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:45:58,879] Trial 325 finished with value: -0.10029323553918086 and parameters: {'learning_rate': 0.012028183454219828, 'depth': 12, 'l2_leaf_reg': 2.024432869477029, 'border_count': 89}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:46:32,981] Trial 326 finished with value: -0.09194697676152663 and parameters: {'learning_rate': 0.01399361780237465, 'depth': 9, 'l2_leaf_reg': 1.7392880515606428, 'border_count': 72}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:49:05,397] Trial 327 finished with value: -0.10195665059106401 and parameters: {'learning_rate': 0.015223127722434842, 'depth': 12, 'l2_leaf_reg': 1.6768401105396262, 'border_count': 74}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:51:31,928] Trial 328 finished with value: -0.09926354312987534 and parameters: {'learning_rate': 0.016970096375970918, 'depth': 12, 'l2_leaf_reg': 1.9223577224910335, 'border_count': 67}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:54:19,685] Trial 329 finished with value: -0.10039596353174544 and parameters: {'learning_rate': 0.01632137148597073, 'depth': 12, 'l2_leaf_reg': 1.5296726380554275, 'border_count': 79}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:56:19,008] Trial 330 finished with value: -0.10134303827702106 and parameters: {'learning_rate': 0.014920559442735121, 'depth': 12, 'l2_leaf_reg': 1.6151382199628856, 'border_count': 41}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 02:58:04,517] Trial 331 finished with value: -0.09974132803253276 and parameters: {'learning_rate': 0.028207999264295965, 'depth': 12, 'l2_leaf_reg': 1.825702364160782, 'border_count': 63}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:00:01,571] Trial 332 finished with value: -0.09992142419637678 and parameters: {'learning_rate': 0.012525530651983138, 'depth': 11, 'l2_leaf_reg': 1.412002549281121, 'border_count': 120}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:02:35,772] Trial 333 finished with value: -0.10294499091042789 and parameters: {'learning_rate': 0.018604045954222145, 'depth': 12, 'l2_leaf_reg': 2.1530224859458507, 'border_count': 68}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:05:19,579] Trial 334 finished with value: -0.1001711545128061 and parameters: {'learning_rate': 0.018011287358252054, 'depth': 12, 'l2_leaf_reg': 2.228852193078211, 'border_count': 85}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:07:43,659] Trial 335 finished with value: -0.10473129720753492 and parameters: {'learning_rate': 0.015775212928039635, 'depth': 12, 'l2_leaf_reg': 1.204033542318269, 'border_count': 68}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:10:24,813] Trial 336 finished with value: -0.10192283471371114 and parameters: {'learning_rate': 0.013543458703853683, 'depth': 12, 'l2_leaf_reg': 1.1574374953852287, 'border_count': 70}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:13:00,577] Trial 337 finished with value: -0.09929142990617419 and parameters: {'learning_rate': 0.01554683757977428, 'depth': 12, 'l2_leaf_reg': 1.5537363354772047, 'border_count': 74}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:15:38,306] Trial 338 finished with value: -0.09537664686878694 and parameters: {'learning_rate': 0.014592277070544361, 'depth': 12, 'l2_leaf_reg': 5.390043155764673, 'border_count': 67}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:18:13,934] Trial 339 finished with value: -0.10080592557472766 and parameters: {'learning_rate': 0.01615602538121519, 'depth': 12, 'l2_leaf_reg': 2.074665401626441, 'border_count': 78}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:19:01,209] Trial 340 finished with value: -0.09915054859330642 and parameters: {'learning_rate': 0.01682431919662885, 'depth': 10, 'l2_leaf_reg': 1.2429589027413068, 'border_count': 70}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:20:25,195] Trial 341 finished with value: -0.10434336947939761 and parameters: {'learning_rate': 0.018573078642129762, 'depth': 11, 'l2_leaf_reg': 1.4342291684153836, 'border_count': 67}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:21:44,285] Trial 342 finished with value: -0.09903218318077843 and parameters: {'learning_rate': 0.018647100164271773, 'depth': 11, 'l2_leaf_reg': 1.6530728525895446, 'border_count': 74}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:23:07,469] Trial 343 finished with value: -0.100275929279401 and parameters: {'learning_rate': 0.015720084674120102, 'depth': 11, 'l2_leaf_reg': 1.4522257293225322, 'border_count': 67}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:24:20,914] Trial 344 finished with value: -0.10152626164108411 and parameters: {'learning_rate': 0.017377870661670985, 'depth': 11, 'l2_leaf_reg': 1.734406354384104, 'border_count': 61}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:25:34,161] Trial 345 finished with value: -0.0985817863147412 and parameters: {'learning_rate': 0.018993612720897026, 'depth': 11, 'l2_leaf_reg': 1.4325729398364988, 'border_count': 68}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:27:03,523] Trial 346 finished with value: -0.09975909166288183 and parameters: {'learning_rate': 0.016602217044604385, 'depth': 11, 'l2_leaf_reg': 1.8320589605955908, 'border_count': 81}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:28:13,862] Trial 347 finished with value: -0.10072295839762889 and parameters: {'learning_rate': 0.01968205093808374, 'depth': 11, 'l2_leaf_reg': 1.5884479032544736, 'border_count': 63}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:29:27,782] Trial 348 finished with value: -0.09999716316299227 and parameters: {'learning_rate': 0.018196896851488672, 'depth': 11, 'l2_leaf_reg': 2.39341770304788, 'border_count': 58}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:32:08,733] Trial 349 finished with value: -0.10021247442758989 and parameters: {'learning_rate': 0.015634441249985347, 'depth': 12, 'l2_leaf_reg': 1.9631146283536833, 'border_count': 75}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:34:45,694] Trial 350 finished with value: -0.10256948429870337 and parameters: {'learning_rate': 0.017205692359720578, 'depth': 12, 'l2_leaf_reg': 1.317800837711469, 'border_count': 71}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:35:08,509] Trial 351 finished with value: -0.08794838086386259 and parameters: {'learning_rate': 0.014544583920050631, 'depth': 8, 'l2_leaf_reg': 1.7339512516988769, 'border_count': 60}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:35:58,832] Trial 352 finished with value: -0.09673468578706079 and parameters: {'learning_rate': 0.01309676605274908, 'depth': 10, 'l2_leaf_reg': 1.49291964932647, 'border_count': 51}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:38:06,903] Trial 353 finished with value: -0.1003078094152268 and parameters: {'learning_rate': 0.01934144284695712, 'depth': 12, 'l2_leaf_reg': 2.1381002132903077, 'border_count': 67}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:40:09,937] Trial 354 finished with value: -0.10024005649747295 and parameters: {'learning_rate': 0.018097597523114333, 'depth': 12, 'l2_leaf_reg': 1.1903971813821173, 'border_count': 56}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:42:05,566] Trial 355 finished with value: -0.10382104618732967 and parameters: {'learning_rate': 0.020310635346581056, 'depth': 12, 'l2_leaf_reg': 1.6125566675387542, 'border_count': 45}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:43:57,364] Trial 356 finished with value: -0.10181350614701573 and parameters: {'learning_rate': 0.020298622135908342, 'depth': 12, 'l2_leaf_reg': 1.401823494753348, 'border_count': 45}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:45:44,978] Trial 357 finished with value: -0.10097263215418227 and parameters: {'learning_rate': 0.02016665603245796, 'depth': 12, 'l2_leaf_reg': 1.675022442378851, 'border_count': 43}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:46:47,972] Trial 358 finished with value: -0.0955878205995723 and parameters: {'learning_rate': 0.08744271341951289, 'depth': 12, 'l2_leaf_reg': 6.880712683436039, 'border_count': 47}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:48:22,306] Trial 359 finished with value: -0.10110324817084496 and parameters: {'learning_rate': 0.021951248941908533, 'depth': 12, 'l2_leaf_reg': 1.4596889749449768, 'border_count': 41}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:50:15,675] Trial 360 finished with value: -0.10164446926486001 and parameters: {'learning_rate': 0.018791096280040085, 'depth': 12, 'l2_leaf_reg': 1.2694417275919303, 'border_count': 50}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:51:48,212] Trial 361 finished with value: -0.10034494037170266 and parameters: {'learning_rate': 0.023623047142476917, 'depth': 12, 'l2_leaf_reg': 1.5978805854903093, 'border_count': 38}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:53:50,885] Trial 362 finished with value: -0.10095752387018393 and parameters: {'learning_rate': 0.020527717846290674, 'depth': 12, 'l2_leaf_reg': 1.7899236506308904, 'border_count': 52}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:56:00,738] Trial 363 finished with value: -0.09985631602299752 and parameters: {'learning_rate': 0.018260688540608118, 'depth': 12, 'l2_leaf_reg': 1.1431726283466106, 'border_count': 63}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 03:57:30,300] Trial 364 finished with value: -0.10041755168397895 and parameters: {'learning_rate': 0.05251492404250702, 'depth': 12, 'l2_leaf_reg': 6.0098067074751995, 'border_count': 47}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:01:16,774] Trial 365 finished with value: -0.10297894756683004 and parameters: {'learning_rate': 0.021625317620822336, 'depth': 12, 'l2_leaf_reg': 1.3404476651893933, 'border_count': 177}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:05:00,302] Trial 366 finished with value: -0.09922622867238456 and parameters: {'learning_rate': 0.022713680936541285, 'depth': 12, 'l2_leaf_reg': 1.3301510175068298, 'border_count': 173}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:06:32,222] Trial 367 finished with value: -0.09969622201137887 and parameters: {'learning_rate': 0.02145759240744056, 'depth': 12, 'l2_leaf_reg': 1.165202617543339, 'border_count': 38}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:11:58,474] Trial 368 finished with value: -0.09900138875585984 and parameters: {'learning_rate': 0.011251357176401614, 'depth': 12, 'l2_leaf_reg': 1.390456989063573, 'border_count': 191}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:16:08,120] Trial 369 finished with value: -0.10244557774367438 and parameters: {'learning_rate': 0.0239466166365136, 'depth': 12, 'l2_leaf_reg': 1.4927095200516054, 'border_count': 201}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:20:57,190] Trial 370 finished with value: -0.09961237221687741 and parameters: {'learning_rate': 0.020445497198266202, 'depth': 12, 'l2_leaf_reg': 1.1522322682264607, 'border_count': 216}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:24:25,046] Trial 371 finished with value: -0.10241199586746717 and parameters: {'learning_rate': 0.021784969987373788, 'depth': 12, 'l2_leaf_reg': 1.406753978262915, 'border_count': 149}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:26:11,604] Trial 372 finished with value: -0.10082947706450958 and parameters: {'learning_rate': 0.019593327843945612, 'depth': 12, 'l2_leaf_reg': 1.628285235058549, 'border_count': 43}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:28:01,492] Trial 373 finished with value: -0.09950806519752717 and parameters: {'learning_rate': 0.023024092268581396, 'depth': 12, 'l2_leaf_reg': 4.359753243418076, 'border_count': 37}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:30:07,967] Trial 374 finished with value: -0.1029804444557702 and parameters: {'learning_rate': 0.02519767620207121, 'depth': 12, 'l2_leaf_reg': 1.2245398615875938, 'border_count': 84}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:32:43,789] Trial 375 finished with value: -0.10167376683531287 and parameters: {'learning_rate': 0.017159357760294255, 'depth': 12, 'l2_leaf_reg': 1.0059834961220542, 'border_count': 82}. Best is trial 159 with value: -0.10492384152542526.
[I 2025-08-04 04:35:22,435] Trial 376 finished with value: -0.10563905611258098 and parameters: {'learning_rate': 0.024507043895913353, 'depth': 12, 'l2_leaf_reg': 1.322319819798864, 'border_count': 96}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:37:40,346] Trial 377 finished with value: -0.09910255414415112 and parameters: {'learning_rate': 0.025043502382408198, 'depth': 12, 'l2_leaf_reg': 1.2099364602757783, 'border_count': 97}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:39:26,410] Trial 378 finished with value: -0.09506169328086185 and parameters: {'learning_rate': 0.02898370101065288, 'depth': 12, 'l2_leaf_reg': 1.318043754112277, 'border_count': 79}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:41:24,926] Trial 379 finished with value: -0.10163911633727642 and parameters: {'learning_rate': 0.02587411734451111, 'depth': 12, 'l2_leaf_reg': 1.1526413334948455, 'border_count': 84}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:43:42,573] Trial 380 finished with value: -0.10020862796598633 and parameters: {'learning_rate': 0.026635831489785218, 'depth': 12, 'l2_leaf_reg': 1.4959364788666887, 'border_count': 90}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:47:28,610] Trial 381 finished with value: -0.10221368064197538 and parameters: {'learning_rate': 0.024709851396682535, 'depth': 12, 'l2_leaf_reg': 1.269208188152658, 'border_count': 177}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:49:42,444] Trial 382 finished with value: -0.0991096915873635 and parameters: {'learning_rate': 0.023953511375463456, 'depth': 12, 'l2_leaf_reg': 1.3711525912970743, 'border_count': 91}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:52:49,932] Trial 383 finished with value: -0.09894227719906613 and parameters: {'learning_rate': 0.02334684164933047, 'depth': 12, 'l2_leaf_reg': 5.156310955056014, 'border_count': 109}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:53:03,714] Trial 384 finished with value: -0.07755085481882289 and parameters: {'learning_rate': 0.025630675757302553, 'depth': 6, 'l2_leaf_reg': 1.6101428423607456, 'border_count': 164}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:53:51,381] Trial 385 finished with value: -0.05375588846331295 and parameters: {'learning_rate': 0.2847970047874826, 'depth': 12, 'l2_leaf_reg': 1.1467391992227358, 'border_count': 86}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:55:44,546] Trial 386 finished with value: -0.09738822596619977 and parameters: {'learning_rate': 0.0302796728627755, 'depth': 12, 'l2_leaf_reg': 1.4733087967044805, 'border_count': 82}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 04:58:04,161] Trial 387 finished with value: -0.10243892720139056 and parameters: {'learning_rate': 0.022316990791399403, 'depth': 12, 'l2_leaf_reg': 1.7492814706705688, 'border_count': 78}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:00:46,277] Trial 388 finished with value: -0.10163788279620821 and parameters: {'learning_rate': 0.014125670833490136, 'depth': 12, 'l2_leaf_reg': 1.305911764002918, 'border_count': 80}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:03:35,218] Trial 389 finished with value: -0.10308427905464844 and parameters: {'learning_rate': 0.01491538535088072, 'depth': 12, 'l2_leaf_reg': 1.0322779095934715, 'border_count': 87}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:06:40,003] Trial 390 finished with value: -0.09718700444079369 and parameters: {'learning_rate': 0.014931511056205977, 'depth': 12, 'l2_leaf_reg': 4.62779462477382, 'border_count': 89}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:09:42,388] Trial 391 finished with value: -0.10257690075618146 and parameters: {'learning_rate': 0.013322028902971215, 'depth': 12, 'l2_leaf_reg': 1.0007073559721498, 'border_count': 90}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:12:43,511] Trial 392 finished with value: -0.10171179127743642 and parameters: {'learning_rate': 0.013982850067885905, 'depth': 12, 'l2_leaf_reg': 1.0210759231936055, 'border_count': 93}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:15:48,402] Trial 393 finished with value: -0.09893101268476331 and parameters: {'learning_rate': 0.016073113166161505, 'depth': 12, 'l2_leaf_reg': 1.1555451434749011, 'border_count': 101}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:18:33,977] Trial 394 finished with value: -0.10230875271550387 and parameters: {'learning_rate': 0.01569553379946386, 'depth': 12, 'l2_leaf_reg': 1.5461371387914649, 'border_count': 86}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:21:31,188] Trial 395 finished with value: -0.10142008951522682 and parameters: {'learning_rate': 0.014839542960136771, 'depth': 12, 'l2_leaf_reg': 1.0030789763766617, 'border_count': 96}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:24:20,733] Trial 396 finished with value: -0.10076494733701523 and parameters: {'learning_rate': 0.012206332728159656, 'depth': 12, 'l2_leaf_reg': 1.2678202371580174, 'border_count': 76}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:27:03,475] Trial 397 finished with value: -0.0914719609860267 and parameters: {'learning_rate': 0.01778699745464347, 'depth': 12, 'l2_leaf_reg': 9.92947971545734, 'border_count': 75}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:29:42,191] Trial 398 finished with value: -0.09959161841705076 and parameters: {'learning_rate': 0.017161826591125858, 'depth': 12, 'l2_leaf_reg': 1.7884390909767494, 'border_count': 84}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:31:18,735] Trial 399 finished with value: -0.10216107205130201 and parameters: {'learning_rate': 0.015222155125484551, 'depth': 11, 'l2_leaf_reg': 1.510601401976601, 'border_count': 84}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:33:23,844] Trial 400 finished with value: -0.10089000605341916 and parameters: {'learning_rate': 0.016598845011487028, 'depth': 12, 'l2_leaf_reg': 1.1919252492926056, 'border_count': 53}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:35:46,749] Trial 401 finished with value: -0.10103160342262447 and parameters: {'learning_rate': 0.019954429261801108, 'depth': 12, 'l2_leaf_reg': 1.6779529417750645, 'border_count': 75}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:38:40,658] Trial 402 finished with value: -0.09994519519431795 and parameters: {'learning_rate': 0.027520534374046567, 'depth': 12, 'l2_leaf_reg': 7.474434196231013, 'border_count': 88}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:40:49,131] Trial 403 finished with value: -0.09912899809126388 and parameters: {'learning_rate': 0.014009356533946644, 'depth': 12, 'l2_leaf_reg': 1.3822551990613827, 'border_count': 49}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:42:50,382] Trial 404 finished with value: -0.09458586695819694 and parameters: {'learning_rate': 0.060547685760323246, 'depth': 12, 'l2_leaf_reg': 1.8884088733037427, 'border_count': 140}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:45:21,960] Trial 405 finished with value: -0.10162811003535875 and parameters: {'learning_rate': 0.016913012387020643, 'depth': 12, 'l2_leaf_reg': 1.5436415329096393, 'border_count': 71}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:47:57,383] Trial 406 finished with value: -0.10168351792821811 and parameters: {'learning_rate': 0.015548791278558006, 'depth': 12, 'l2_leaf_reg': 1.1637553859556826, 'border_count': 79}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:49:07,600] Trial 407 finished with value: -0.09723430030615819 and parameters: {'learning_rate': 0.01827932722628905, 'depth': 11, 'l2_leaf_reg': 3.3669365989244464, 'border_count': 45}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:49:34,658] Trial 408 finished with value: -0.09308051223506417 and parameters: {'learning_rate': 0.024279563019619265, 'depth': 9, 'l2_leaf_reg': 1.3600485580965742, 'border_count': 53}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:51:35,585] Trial 409 finished with value: -0.09874300549991526 and parameters: {'learning_rate': 0.010106550103024222, 'depth': 12, 'l2_leaf_reg': 1.6822932773447135, 'border_count': 32}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:52:30,476] Trial 410 finished with value: -0.07307373603976937 and parameters: {'learning_rate': 0.20815182279319405, 'depth': 12, 'l2_leaf_reg': 1.4292334644627296, 'border_count': 94}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:54:08,152] Trial 411 finished with value: -0.09840767067076302 and parameters: {'learning_rate': 0.02037078221536978, 'depth': 12, 'l2_leaf_reg': 1.1493680102796635, 'border_count': 40}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:56:09,399] Trial 412 finished with value: -0.10056429030189004 and parameters: {'learning_rate': 0.016667502399119006, 'depth': 12, 'l2_leaf_reg': 1.5560607063586571, 'border_count': 47}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:56:20,570] Trial 413 finished with value: -0.07373850232167604 and parameters: {'learning_rate': 0.021322371574598074, 'depth': 5, 'l2_leaf_reg': 4.165036267245374, 'border_count': 57}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:57:23,996] Trial 414 finished with value: -0.09838096092912295 and parameters: {'learning_rate': 0.04559307115433142, 'depth': 11, 'l2_leaf_reg': 8.157517162758438, 'border_count': 72}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 05:58:27,714] Trial 415 finished with value: -0.09844634080184103 and parameters: {'learning_rate': 0.019073762974902965, 'depth': 10, 'l2_leaf_reg': 1.0107312593378126, 'border_count': 130}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:00:38,754] Trial 416 finished with value: -0.10273539018223413 and parameters: {'learning_rate': 0.013099058730759611, 'depth': 12, 'l2_leaf_reg': 1.8822404967046396, 'border_count': 43}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:02:34,471] Trial 417 finished with value: -0.1012283451259985 and parameters: {'learning_rate': 0.023211715563248074, 'depth': 12, 'l2_leaf_reg': 1.2923213006694252, 'border_count': 64}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:03:12,437] Trial 418 finished with value: -0.09679802928224251 and parameters: {'learning_rate': 0.12232962941306247, 'depth': 12, 'l2_leaf_reg': 1.6670330240116442, 'border_count': 36}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:05:20,954] Trial 419 finished with value: -0.10157529308042651 and parameters: {'learning_rate': 0.014783463816253804, 'depth': 12, 'l2_leaf_reg': 1.4269443791764556, 'border_count': 51}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:07:56,093] Trial 420 finished with value: -0.10119245510153757 and parameters: {'learning_rate': 0.017732564079787034, 'depth': 12, 'l2_leaf_reg': 1.2713600115825874, 'border_count': 82}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:08:58,316] Trial 421 finished with value: -0.10011292880020498 and parameters: {'learning_rate': 0.025735087333343294, 'depth': 11, 'l2_leaf_reg': 1.8041071922642213, 'border_count': 55}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:10:43,885] Trial 422 finished with value: -0.09881331178612737 and parameters: {'learning_rate': 0.019573418293972716, 'depth': 12, 'l2_leaf_reg': 1.5273779457564978, 'border_count': 48}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:12:58,073] Trial 423 finished with value: -0.10062172131859717 and parameters: {'learning_rate': 0.016215722831980833, 'depth': 12, 'l2_leaf_reg': 1.1576260959466296, 'border_count': 60}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:14:37,784] Trial 424 finished with value: -0.09978111320657372 and parameters: {'learning_rate': 0.021137316596953632, 'depth': 12, 'l2_leaf_reg': 1.3616808656142718, 'border_count': 42}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:14:57,302] Trial 425 finished with value: -0.089114125830754 and parameters: {'learning_rate': 0.017716166992511308, 'depth': 8, 'l2_leaf_reg': 1.7184621603957888, 'border_count': 66}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:17:15,157] Trial 426 finished with value: -0.10226103790519589 and parameters: {'learning_rate': 0.022236591653172506, 'depth': 12, 'l2_leaf_reg': 1.9413274879385178, 'border_count': 76}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:19:38,128] Trial 427 finished with value: -0.10094118944023901 and parameters: {'learning_rate': 0.01910956660121094, 'depth': 12, 'l2_leaf_reg': 1.5711778250710073, 'border_count': 71}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:22:35,287] Trial 428 finished with value: -0.1026044121555846 and parameters: {'learning_rate': 0.015754284083604957, 'depth': 12, 'l2_leaf_reg': 1.2570981049083412, 'border_count': 86}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:24:16,669] Trial 429 finished with value: -0.10333474129404359 and parameters: {'learning_rate': 0.02035676062882647, 'depth': 12, 'l2_leaf_reg': 1.442498338730946, 'border_count': 37}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:25:57,013] Trial 430 finished with value: -0.10268930282695889 and parameters: {'learning_rate': 0.01983847112241825, 'depth': 12, 'l2_leaf_reg': 1.688013016695917, 'border_count': 36}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:26:55,192] Trial 431 finished with value: -0.09912532620538042 and parameters: {'learning_rate': 0.01799336934856191, 'depth': 11, 'l2_leaf_reg': 1.476515785776971, 'border_count': 32}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:28:45,585] Trial 432 finished with value: -0.09977403154845474 and parameters: {'learning_rate': 0.020327646596880085, 'depth': 12, 'l2_leaf_reg': 3.8819811492192313, 'border_count': 38}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:30:47,459] Trial 433 finished with value: -0.1006946660728088 and parameters: {'learning_rate': 0.016719387976726858, 'depth': 12, 'l2_leaf_reg': 2.947621270396332, 'border_count': 41}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:32:46,057] Trial 434 finished with value: -0.10081726093500423 and parameters: {'learning_rate': 0.01845666901717478, 'depth': 12, 'l2_leaf_reg': 1.9418540188284261, 'border_count': 46}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:34:48,635] Trial 435 finished with value: -0.10244350838081756 and parameters: {'learning_rate': 0.014148133887987788, 'depth': 12, 'l2_leaf_reg': 1.555679749929695, 'border_count': 39}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:35:33,299] Trial 436 finished with value: -0.10082554617070887 and parameters: {'learning_rate': 0.021108586754800072, 'depth': 10, 'l2_leaf_reg': 1.795615942893683, 'border_count': 51}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:37:34,571] Trial 437 finished with value: -0.09644105518846853 and parameters: {'learning_rate': 0.017261903929407286, 'depth': 12, 'l2_leaf_reg': 5.635041272868451, 'border_count': 46}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:38:01,908] Trial 438 finished with value: -0.09212271353366104 and parameters: {'learning_rate': 0.07257092759460211, 'depth': 11, 'l2_leaf_reg': 1.490760315827123, 'border_count': 36}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:40:24,286] Trial 439 finished with value: -0.09148209751544127 and parameters: {'learning_rate': 0.015071605887193265, 'depth': 12, 'l2_leaf_reg': 8.933324659732847, 'border_count': 58}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:42:12,184] Trial 440 finished with value: -0.10108887771639298 and parameters: {'learning_rate': 0.019088736456061715, 'depth': 12, 'l2_leaf_reg': 1.3857142905503832, 'border_count': 44}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:43:54,413] Trial 441 finished with value: -0.0992667144829273 and parameters: {'learning_rate': 0.022838582055809194, 'depth': 12, 'l2_leaf_reg': 1.682503436471651, 'border_count': 49}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:44:10,448] Trial 442 finished with value: -0.08638162260129283 and parameters: {'learning_rate': 0.020891551482982003, 'depth': 7, 'l2_leaf_reg': 1.331584921643858, 'border_count': 54}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:45:14,865] Trial 443 finished with value: -0.0996531541714071 and parameters: {'learning_rate': 0.01621960859407818, 'depth': 11, 'l2_leaf_reg': 1.0289805173384994, 'border_count': 41}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:46:14,576] Trial 444 finished with value: -0.0963095304398851 and parameters: {'learning_rate': 0.03792854684967687, 'depth': 12, 'l2_leaf_reg': 1.1679898391403976, 'border_count': 32}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:48:32,102] Trial 445 finished with value: -0.09972911704319352 and parameters: {'learning_rate': 0.018272121843472294, 'depth': 12, 'l2_leaf_reg': 1.6159419479020591, 'border_count': 65}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:50:50,745] Trial 446 finished with value: -0.0974752354108911 and parameters: {'learning_rate': 0.019879723050049692, 'depth': 12, 'l2_leaf_reg': 6.326629480865981, 'border_count': 55}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:53:17,813] Trial 447 finished with value: -0.10441369666948236 and parameters: {'learning_rate': 0.01715574874792307, 'depth': 12, 'l2_leaf_reg': 1.8227533163033156, 'border_count': 61}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:55:46,489] Trial 448 finished with value: -0.10054665979437996 and parameters: {'learning_rate': 0.01574410948553731, 'depth': 12, 'l2_leaf_reg': 2.0325380744127326, 'border_count': 61}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:57:59,530] Trial 449 finished with value: -0.10275063552405914 and parameters: {'learning_rate': 0.016507578948080928, 'depth': 12, 'l2_leaf_reg': 1.8527810954060233, 'border_count': 61}. Best is trial 376 with value: -0.10563905611258098.
[I 2025-08-04 06:58:14,755] A new study created in memory with name: no-name-e5bc9466-3522-406d-a125-55a3a1c7b279
[I 2025-08-04 06:58:20,815] Trial 0 finished with value: -0.08546577166349086 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.08546577166349086.
[I 2025-08-04 06:58:22,646] Trial 1 finished with value: -0.07209369509537783 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.08546577166349086.
[I 2025-08-04 06:58:27,261] Trial 2 finished with value: -0.086544975032596 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:58:29,838] Trial 3 finished with value: -0.0816046551268772 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:58:41,218] Trial 4 finished with value: -0.08562946042039328 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:58:44,736] Trial 5 finished with value: -0.07012157721590272 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:58:48,691] Trial 6 finished with value: -0.07944003382459346 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:58:52,034] Trial 7 finished with value: -0.07048702454982102 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:58:56,483] Trial 8 finished with value: -0.07556524179105549 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:06,129] Trial 9 finished with value: -0.08193503039982465 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:06,881] Trial 10 finished with value: -0.04182822215409325 and parameters: {'learning_rate': 0.13388899274129873, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.7846562513261506, 'bagging_fraction': 0.721539898400351, 'reg_alpha': 4.344469108550396, 'reg_lambda': 0.010039786460205695}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:13,180] Trial 11 finished with value: -0.08367185247698944 and parameters: {'learning_rate': 0.020362778419822015, 'num_leaves': 255, 'max_depth': 9, 'min_child_samples': 34, 'feature_fraction': 0.7018012731971806, 'bagging_fraction': 0.6994762507327695, 'reg_alpha': 0.000179649519485956, 'reg_lambda': 7.113881308869642e-05}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:19,675] Trial 12 finished with value: -0.08526929179709324 and parameters: {'learning_rate': 0.019577718361487365, 'num_leaves': 129, 'max_depth': 10, 'min_child_samples': 35, 'feature_fraction': 0.8265015800721067, 'bagging_fraction': 0.5046555777845694, 'reg_alpha': 0.0001653282123997984, 'reg_lambda': 0.002930663990892253}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:27,357] Trial 13 finished with value: -0.08456522341886098 and parameters: {'learning_rate': 0.08170216566351561, 'num_leaves': 163, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.6541754319324896, 'bagging_fraction': 0.8304278626461433, 'reg_alpha': 0.037861840423533064, 'reg_lambda': 9.967459284487096e-06}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:31,145] Trial 14 finished with value: -0.08055113531416981 and parameters: {'learning_rate': 0.029839464804576145, 'num_leaves': 92, 'max_depth': 7, 'min_child_samples': 46, 'feature_fraction': 0.7408524156576866, 'bagging_fraction': 0.651723150444279, 'reg_alpha': 1.8290593430566233e-06, 'reg_lambda': 1.3349469769994882e-08}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:37,964] Trial 15 finished with value: -0.08057454406054329 and parameters: {'learning_rate': 0.01383276720433204, 'num_leaves': 225, 'max_depth': 9, 'min_child_samples': 67, 'feature_fraction': 0.8524635413007553, 'bagging_fraction': 0.8013123222722462, 'reg_alpha': 2.0577776761646817e-08, 'reg_lambda': 0.14184312049385903}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:45,801] Trial 16 finished with value: -0.08069900225450631 and parameters: {'learning_rate': 0.01033468549769335, 'num_leaves': 97, 'max_depth': 7, 'min_child_samples': 52, 'feature_fraction': 0.5077551909971134, 'bagging_fraction': 0.5669390895619841, 'reg_alpha': 0.0019415585650032921, 'reg_lambda': 7.186604565842657e-06}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:50,026] Trial 17 finished with value: -0.07264223596083405 and parameters: {'learning_rate': 0.16640556451022465, 'num_leaves': 175, 'max_depth': 11, 'min_child_samples': 25, 'feature_fraction': 0.6205291332823097, 'bagging_fraction': 0.6707750474677461, 'reg_alpha': 3.917289207081444e-05, 'reg_lambda': 0.0005144054766241233}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:51,271] Trial 18 finished with value: -0.021502258955249362 and parameters: {'learning_rate': 0.017752058501172615, 'num_leaves': 87, 'max_depth': 13, 'min_child_samples': 66, 'feature_fraction': 0.7372898166892035, 'bagging_fraction': 0.7533881284358335, 'reg_alpha': 9.067985943365022, 'reg_lambda': 0.010993417108982753}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:54,565] Trial 19 finished with value: -0.08253383575652884 and parameters: {'learning_rate': 0.02940478598337108, 'num_leaves': 24, 'max_depth': 6, 'min_child_samples': 92, 'feature_fraction': 0.9489115808853676, 'bagging_fraction': 0.5852306392660565, 'reg_alpha': 1.6551473191505545e-07, 'reg_lambda': 8.22636411232521e-05}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 06:59:58,653] Trial 20 finished with value: -0.08195894085377135 and parameters: {'learning_rate': 0.04151551658518635, 'num_leaves': 154, 'max_depth': 8, 'min_child_samples': 46, 'feature_fraction': 0.7086421037028057, 'bagging_fraction': 0.8787943061604515, 'reg_alpha': 0.013240454474943743, 'reg_lambda': 2.9065538534041106e-06}. Best is trial 2 with value: -0.086544975032596.
[I 2025-08-04 07:00:05,507] Trial 21 finished with value: -0.08754108497669488 and parameters: {'learning_rate': 0.0316751007061427, 'num_leaves': 254, 'max_depth': 15, 'min_child_samples': 62, 'feature_fraction': 0.5736306798333981, 'bagging_fraction': 0.5777886108257787, 'reg_alpha': 1.3651831039275445e-08, 'reg_lambda': 1.3538798263084824}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:09,999] Trial 22 finished with value: -0.08509183237597938 and parameters: {'learning_rate': 0.08095518480259396, 'num_leaves': 234, 'max_depth': 15, 'min_child_samples': 74, 'feature_fraction': 0.5789091709750697, 'bagging_fraction': 0.6176991219269974, 'reg_alpha': 3.2952970419991317e-07, 'reg_lambda': 0.07046713745157393}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:16,060] Trial 23 finished with value: -0.07781585692926977 and parameters: {'learning_rate': 0.025277371591363406, 'num_leaves': 207, 'max_depth': 14, 'min_child_samples': 57, 'feature_fraction': 0.5796220576949027, 'bagging_fraction': 0.5503094676918231, 'reg_alpha': 0.839358499444947, 'reg_lambda': 8.038061038966312}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:26,064] Trial 24 finished with value: -0.08646518131343224 and parameters: {'learning_rate': 0.016177917230130085, 'num_leaves': 255, 'max_depth': 13, 'min_child_samples': 28, 'feature_fraction': 0.6610679688214768, 'bagging_fraction': 0.6770072437111321, 'reg_alpha': 1.9765275273217536e-06, 'reg_lambda': 6.158203381028311e-05}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:35,976] Trial 25 finished with value: -0.08635655222100157 and parameters: {'learning_rate': 0.016410258563455352, 'num_leaves': 193, 'max_depth': 11, 'min_child_samples': 25, 'feature_fraction': 0.538557751429787, 'bagging_fraction': 0.6642478703952389, 'reg_alpha': 2.467723761283506e-06, 'reg_lambda': 0.0021327556398311573}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:45,144] Trial 26 finished with value: -0.08624417151639814 and parameters: {'learning_rate': 0.03897272682374149, 'num_leaves': 222, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.7918837823173844, 'bagging_fraction': 0.746373358666525, 'reg_alpha': 1.0769658957904248e-07, 'reg_lambda': 7.285956855272309e-05}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:50,865] Trial 27 finished with value: -0.08695884331839414 and parameters: {'learning_rate': 0.025120625576274612, 'num_leaves': 115, 'max_depth': 10, 'min_child_samples': 41, 'feature_fraction': 0.6156886502882714, 'bagging_fraction': 0.7012000322254772, 'reg_alpha': 1.151451846913146e-06, 'reg_lambda': 2.6934572591055236e-06}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:56,098] Trial 28 finished with value: -0.08536760808982838 and parameters: {'learning_rate': 0.03393507703356674, 'num_leaves': 112, 'max_depth': 10, 'min_child_samples': 46, 'feature_fraction': 0.6134923868822042, 'bagging_fraction': 0.6161265414945567, 'reg_alpha': 1.0562846361527958e-08, 'reg_lambda': 2.459502440266565e-06}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:00:59,759] Trial 29 finished with value: -0.08294894727881615 and parameters: {'learning_rate': 0.05525445933273456, 'num_leaves': 73, 'max_depth': 8, 'min_child_samples': 61, 'feature_fraction': 0.5086096066234367, 'bagging_fraction': 0.5777684561526653, 'reg_alpha': 6.487825378295779e-08, 'reg_lambda': 3.2801168505858225e-08}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:01:04,086] Trial 30 finished with value: -0.08054275929638277 and parameters: {'learning_rate': 0.026525437927163685, 'num_leaves': 107, 'max_depth': 5, 'min_child_samples': 40, 'feature_fraction': 0.548524383327409, 'bagging_fraction': 0.7643080707754748, 'reg_alpha': 5.454724514663642e-07, 'reg_lambda': 0.10575161499860215}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:01:12,752] Trial 31 finished with value: -0.08650068971226912 and parameters: {'learning_rate': 0.02106296529229294, 'num_leaves': 249, 'max_depth': 13, 'min_child_samples': 32, 'feature_fraction': 0.59126362470437, 'bagging_fraction': 0.6991815802617073, 'reg_alpha': 1.5740815852030343e-06, 'reg_lambda': 1.685700429856876e-05}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:01:20,245] Trial 32 finished with value: -0.08644971546135059 and parameters: {'learning_rate': 0.02282341921121965, 'num_leaves': 119, 'max_depth': 12, 'min_child_samples': 33, 'feature_fraction': 0.5994381751505257, 'bagging_fraction': 0.704620540304934, 'reg_alpha': 3.948352113757996e-05, 'reg_lambda': 9.174885483130005e-07}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:01:29,396] Trial 33 finished with value: -0.08732878761781511 and parameters: {'learning_rate': 0.03182536789358876, 'num_leaves': 183, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.5500349790008944, 'bagging_fraction': 0.5912090335006334, 'reg_alpha': 7.413358605105996e-07, 'reg_lambda': 2.125860857699107e-05}. Best is trial 21 with value: -0.08754108497669488.
[I 2025-08-04 07:01:38,779] Trial 34 finished with value: -0.08949373508654754 and parameters: {'learning_rate': 0.03298782856908472, 'num_leaves': 176, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.5573618365755882, 'bagging_fraction': 0.501732582309061, 'reg_alpha': 4.0198769379958027e-08, 'reg_lambda': 1.6350139435978214e-07}. Best is trial 34 with value: -0.08949373508654754.
[I 2025-08-04 07:01:47,699] Trial 35 finished with value: -0.09008784219154387 and parameters: {'learning_rate': 0.034450280424953315, 'num_leaves': 178, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.5563817759997036, 'bagging_fraction': 0.5027292876886564, 'reg_alpha': 3.838525415204741e-08, 'reg_lambda': 1.3985986386183555e-07}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:01:55,386] Trial 36 finished with value: -0.08756612636882194 and parameters: {'learning_rate': 0.06580560850702724, 'num_leaves': 179, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5544277158955945, 'bagging_fraction': 0.5021131721845533, 'reg_alpha': 3.741586151833012e-08, 'reg_lambda': 1.489310392559258e-07}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:02:02,866] Trial 37 finished with value: -0.08539914020038818 and parameters: {'learning_rate': 0.06904296058622045, 'num_leaves': 163, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5673635643173398, 'bagging_fraction': 0.5078795600969794, 'reg_alpha': 4.0556058821014075e-08, 'reg_lambda': 1.334716063398824e-07}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:02:12,074] Trial 38 finished with value: -0.08595301134157277 and parameters: {'learning_rate': 0.04789706584816287, 'num_leaves': 196, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5072406663314711, 'bagging_fraction': 0.5274370606782683, 'reg_alpha': 1.2227186499006089e-08, 'reg_lambda': 8.79128114246784e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:02:20,505] Trial 39 finished with value: -0.07624633394341165 and parameters: {'learning_rate': 0.10472447981768004, 'num_leaves': 169, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.6406089351880103, 'bagging_fraction': 0.5510843914076643, 'reg_alpha': 3.951181337255819e-08, 'reg_lambda': 1.7085670405375826e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:02:25,906] Trial 40 finished with value: -0.0802437072930612 and parameters: {'learning_rate': 0.06140026060180132, 'num_leaves': 147, 'max_depth': 12, 'min_child_samples': 22, 'feature_fraction': 0.6807649095110005, 'bagging_fraction': 0.5017983517836251, 'reg_alpha': 1.9558327000974992e-07, 'reg_lambda': 3.4758049750055147e-07}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:02:34,978] Trial 41 finished with value: -0.0879198333343033 and parameters: {'learning_rate': 0.03512289994297301, 'num_leaves': 180, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.5543932613164914, 'bagging_fraction': 0.5814677297092005, 'reg_alpha': 5.573238545947674e-08, 'reg_lambda': 4.85804402731122e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:02:44,408] Trial 42 finished with value: -0.08950968803345284 and parameters: {'learning_rate': 0.03548792818178724, 'num_leaves': 181, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5269990867329793, 'bagging_fraction': 0.5296557434856435, 'reg_alpha': 4.9642113108172104e-08, 'reg_lambda': 4.312059114941426e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:02:53,161] Trial 43 finished with value: -0.08600471822549216 and parameters: {'learning_rate': 0.04433129446830619, 'num_leaves': 183, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.52748498902818, 'bagging_fraction': 0.5291937119017603, 'reg_alpha': 7.442444867835981e-08, 'reg_lambda': 9.998082543871382e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:03:00,243] Trial 44 finished with value: -0.08804714426979303 and parameters: {'learning_rate': 0.0349127982685821, 'num_leaves': 194, 'max_depth': 13, 'min_child_samples': 27, 'feature_fraction': 0.5508602122581214, 'bagging_fraction': 0.5553718500949776, 'reg_alpha': 2.77748363427508e-07, 'reg_lambda': 5.1998416990677824e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:03:07,199] Trial 45 finished with value: -0.08815497443183175 and parameters: {'learning_rate': 0.03634955907953753, 'num_leaves': 214, 'max_depth': 13, 'min_child_samples': 29, 'feature_fraction': 0.5258625413721457, 'bagging_fraction': 0.5499779656782962, 'reg_alpha': 6.3779314956993485e-06, 'reg_lambda': 3.748608831407995e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:03:13,630] Trial 46 finished with value: -0.08359299404419641 and parameters: {'learning_rate': 0.03645336072551245, 'num_leaves': 214, 'max_depth': 11, 'min_child_samples': 30, 'feature_fraction': 0.526531115490164, 'bagging_fraction': 0.5440529489992, 'reg_alpha': 2.8494561202698465e-07, 'reg_lambda': 7.260098857324726e-07}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:03:19,938] Trial 47 finished with value: -0.08800678033144281 and parameters: {'learning_rate': 0.05197971537446858, 'num_leaves': 196, 'max_depth': 12, 'min_child_samples': 24, 'feature_fraction': 0.5025684674668875, 'bagging_fraction': 0.6088435881640017, 'reg_alpha': 7.808609007430117e-06, 'reg_lambda': 3.094176014434878e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:03:26,744] Trial 48 finished with value: -0.08783528892634468 and parameters: {'learning_rate': 0.04379855557182443, 'num_leaves': 230, 'max_depth': 13, 'min_child_samples': 29, 'feature_fraction': 0.5298141823535489, 'bagging_fraction': 0.5608202903463333, 'reg_alpha': 6.334996954008084e-06, 'reg_lambda': 1.2905925609777302e-08}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:03:34,239] Trial 49 finished with value: -0.08866476030150951 and parameters: {'learning_rate': 0.03891090464771611, 'num_leaves': 155, 'max_depth': 13, 'min_child_samples': 21, 'feature_fraction': 0.5969462458033316, 'bagging_fraction': 0.5251940384968841, 'reg_alpha': 4.9818902006025e-07, 'reg_lambda': 2.6204590637771356e-07}. Best is trial 35 with value: -0.09008784219154387.
[I 2025-08-04 07:03:41,284] Trial 50 finished with value: -0.09045244043326892 and parameters: {'learning_rate': 0.03919429967475488, 'num_leaves': 137, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.6015378861036264, 'bagging_fraction': 0.5303013683297816, 'reg_alpha': 2.773115351907709e-05, 'reg_lambda': 3.243320640523907e-07}. Best is trial 50 with value: -0.09045244043326892.
[I 2025-08-04 07:03:48,879] Trial 51 finished with value: -0.09385478265523559 and parameters: {'learning_rate': 0.028120029762983688, 'num_leaves': 132, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.6036262737760412, 'bagging_fraction': 0.5240062264964098, 'reg_alpha': 1.8164208152394488e-05, 'reg_lambda': 2.956122888101116e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:03:56,693] Trial 52 finished with value: -0.09201073022185105 and parameters: {'learning_rate': 0.02831492487997852, 'num_leaves': 133, 'max_depth': 12, 'min_child_samples': 21, 'feature_fraction': 0.6098190590977659, 'bagging_fraction': 0.5211572462362685, 'reg_alpha': 0.0008845415927488416, 'reg_lambda': 2.592520510188183e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:05,397] Trial 53 finished with value: -0.09031569916372159 and parameters: {'learning_rate': 0.028797345596674646, 'num_leaves': 128, 'max_depth': 11, 'min_child_samples': 13, 'feature_fraction': 0.6684400718823597, 'bagging_fraction': 0.5219120835907283, 'reg_alpha': 0.0008322907532361805, 'reg_lambda': 1.1109068337577001e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:13,710] Trial 54 finished with value: -0.08889125421101002 and parameters: {'learning_rate': 0.027866139556944062, 'num_leaves': 145, 'max_depth': 11, 'min_child_samples': 13, 'feature_fraction': 0.6672922792461469, 'bagging_fraction': 0.5211546675205189, 'reg_alpha': 0.0003818461007832675, 'reg_lambda': 1.8690757079914088e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:22,455] Trial 55 finished with value: -0.08939313774033761 and parameters: {'learning_rate': 0.02271858153799128, 'num_leaves': 125, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.6329925766700202, 'bagging_fraction': 0.5263317028874926, 'reg_alpha': 0.0008708697598554062, 'reg_lambda': 5.455358362057288e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:33,896] Trial 56 finished with value: -0.08830162702273905 and parameters: {'learning_rate': 0.019452109881018538, 'num_leaves': 138, 'max_depth': 11, 'min_child_samples': 10, 'feature_fraction': 0.6361632167230528, 'bagging_fraction': 0.6332425716306722, 'reg_alpha': 0.007326174126076246, 'reg_lambda': 1.203120183713881e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:39,610] Trial 57 finished with value: -0.08765760630067379 and parameters: {'learning_rate': 0.029247190628170067, 'num_leaves': 134, 'max_depth': 9, 'min_child_samples': 23, 'feature_fraction': 0.602756043575209, 'bagging_fraction': 0.5943533626805185, 'reg_alpha': 0.00024774090015727455, 'reg_lambda': 3.793774192179559e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:46,165] Trial 58 finished with value: -0.08846530087055973 and parameters: {'learning_rate': 0.04933300707112193, 'num_leaves': 101, 'max_depth': 12, 'min_child_samples': 13, 'feature_fraction': 0.7194156423165753, 'bagging_fraction': 0.9197379985941248, 'reg_alpha': 8.002837717874962e-05, 'reg_lambda': 7.305795477238397e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:51,264] Trial 59 finished with value: -0.08446087520144312 and parameters: {'learning_rate': 0.0275438270935166, 'num_leaves': 125, 'max_depth': 10, 'min_child_samples': 36, 'feature_fraction': 0.7659141986672557, 'bagging_fraction': 0.56763496180922, 'reg_alpha': 0.0007467786810688681, 'reg_lambda': 4.4643318539340326e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:04:57,583] Trial 60 finished with value: -0.08699249902724947 and parameters: {'learning_rate': 0.040157813323212714, 'num_leaves': 158, 'max_depth': 11, 'min_child_samples': 20, 'feature_fraction': 0.6784734402715081, 'bagging_fraction': 0.5375417392624663, 'reg_alpha': 1.779336493130844e-05, 'reg_lambda': 2.1903399956030104e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:05:07,546] Trial 61 finished with value: -0.09075987186345084 and parameters: {'learning_rate': 0.03076934969823875, 'num_leaves': 170, 'max_depth': 12, 'min_child_samples': 13, 'feature_fraction': 0.5729274397180025, 'bagging_fraction': 0.5152335972921429, 'reg_alpha': 0.0024414375549208656, 'reg_lambda': 7.032430279953348e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:05:17,328] Trial 62 finished with value: -0.09111512010429242 and parameters: {'learning_rate': 0.03021366227524565, 'num_leaves': 148, 'max_depth': 12, 'min_child_samples': 14, 'feature_fraction': 0.5713141684826346, 'bagging_fraction': 0.5199667258259263, 'reg_alpha': 0.004884532248074326, 'reg_lambda': 7.204847250332305e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:05:27,509] Trial 63 finished with value: -0.0897208757931347 and parameters: {'learning_rate': 0.023682927940905995, 'num_leaves': 145, 'max_depth': 12, 'min_child_samples': 14, 'feature_fraction': 0.5840606885143572, 'bagging_fraction': 0.5131417921882805, 'reg_alpha': 0.002367996761342211, 'reg_lambda': 1.4394995067946745e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:05:33,820] Trial 64 finished with value: -0.08718066889374707 and parameters: {'learning_rate': 0.029605033129948194, 'num_leaves': 168, 'max_depth': 10, 'min_child_samples': 26, 'feature_fraction': 0.6501706508230025, 'bagging_fraction': 0.5370426842646783, 'reg_alpha': 0.006550417321056642, 'reg_lambda': 1.0432953422563254e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:05:44,609] Trial 65 finished with value: -0.09181857250862921 and parameters: {'learning_rate': 0.026330912815868187, 'num_leaves': 132, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.6175044032526138, 'bagging_fraction': 0.5685860198129937, 'reg_alpha': 0.025183502209126803, 'reg_lambda': 5.04681312178458e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:05:58,448] Trial 66 finished with value: -0.08898303958291424 and parameters: {'learning_rate': 0.017865718725269295, 'num_leaves': 136, 'max_depth': 12, 'min_child_samples': 10, 'feature_fraction': 0.6252048333461295, 'bagging_fraction': 0.5664855665862302, 'reg_alpha': 0.04507427663264737, 'reg_lambda': 4.872776605214209e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:06:12,498] Trial 67 finished with value: -0.0883966013532041 and parameters: {'learning_rate': 0.021664739510529416, 'num_leaves': 128, 'max_depth': 11, 'min_child_samples': 13, 'feature_fraction': 0.6145172612630503, 'bagging_fraction': 0.5172849711805141, 'reg_alpha': 0.2005436701442829, 'reg_lambda': 7.171214550683729e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:06:19,532] Trial 68 finished with value: -0.08477004368632593 and parameters: {'learning_rate': 0.025276853938294926, 'num_leaves': 150, 'max_depth': 12, 'min_child_samples': 98, 'feature_fraction': 0.5753484559600957, 'bagging_fraction': 0.5976737101753451, 'reg_alpha': 0.0014065353048080347, 'reg_lambda': 9.88994954966911e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:06:28,125] Trial 69 finished with value: -0.09121437957483942 and parameters: {'learning_rate': 0.018946711822603643, 'num_leaves': 120, 'max_depth': 11, 'min_child_samples': 20, 'feature_fraction': 0.606066103425814, 'bagging_fraction': 0.6256265281728015, 'reg_alpha': 0.004336166728467013, 'reg_lambda': 4.876457825085612e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:06:38,410] Trial 70 finished with value: -0.08927409890004476 and parameters: {'learning_rate': 0.012064760874850049, 'num_leaves': 83, 'max_depth': 10, 'min_child_samples': 24, 'feature_fraction': 0.6072887973510401, 'bagging_fraction': 0.5677890022057608, 'reg_alpha': 0.005628314484204082, 'reg_lambda': 3.0310847336600663e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:06:48,886] Trial 71 finished with value: -0.0912092473877166 and parameters: {'learning_rate': 0.01868038458104608, 'num_leaves': 119, 'max_depth': 11, 'min_child_samples': 20, 'feature_fraction': 0.5898720846494548, 'bagging_fraction': 0.6272443983162801, 'reg_alpha': 0.019129439276694388, 'reg_lambda': 3.7906899050167582e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:07:00,683] Trial 72 finished with value: -0.08972408482385315 and parameters: {'learning_rate': 0.018677155613266248, 'num_leaves': 112, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.5891270192649852, 'bagging_fraction': 0.6363865356566889, 'reg_alpha': 0.05102067672601969, 'reg_lambda': 2.7669630857234564e-05}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:07:11,276] Trial 73 finished with value: -0.08949212244623637 and parameters: {'learning_rate': 0.014115085232010076, 'num_leaves': 102, 'max_depth': 11, 'min_child_samples': 22, 'feature_fraction': 0.5693798640304256, 'bagging_fraction': 0.5427606367263307, 'reg_alpha': 0.023562970214936772, 'reg_lambda': 5.0082839619096225e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:07:18,047] Trial 74 finished with value: -0.08694000807536235 and parameters: {'learning_rate': 0.020700565785281875, 'num_leaves': 119, 'max_depth': 9, 'min_child_samples': 26, 'feature_fraction': 0.648905464299699, 'bagging_fraction': 0.6248312825482429, 'reg_alpha': 0.00406895557057421, 'reg_lambda': 2.0652371240006744e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:07:27,261] Trial 75 finished with value: -0.08329298918712388 and parameters: {'learning_rate': 0.01588336473105741, 'num_leaves': 121, 'max_depth': 13, 'min_child_samples': 31, 'feature_fraction': 0.9000835900091857, 'bagging_fraction': 0.6611759764573841, 'reg_alpha': 0.016326289921739966, 'reg_lambda': 0.0001527473256519788}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:07:39,026] Trial 76 finished with value: -0.08594718018359186 and parameters: {'learning_rate': 0.026173946096612846, 'num_leaves': 138, 'max_depth': 12, 'min_child_samples': 19, 'feature_fraction': 0.6236631542546867, 'bagging_fraction': 0.6009129140007525, 'reg_alpha': 0.12196600837056137, 'reg_lambda': 5.953679876088361e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:07:46,686] Trial 77 finished with value: -0.09085647016916516 and parameters: {'learning_rate': 0.031227144163406544, 'num_leaves': 108, 'max_depth': 11, 'min_child_samples': 15, 'feature_fraction': 0.5873425282227823, 'bagging_fraction': 0.6479490446892806, 'reg_alpha': 7.238478510376767e-05, 'reg_lambda': 3.893257625397704e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:07:56,836] Trial 78 finished with value: -0.08916349338423683 and parameters: {'learning_rate': 0.01553083030341772, 'num_leaves': 91, 'max_depth': 11, 'min_child_samples': 15, 'feature_fraction': 0.5690485952772034, 'bagging_fraction': 0.6829259708954617, 'reg_alpha': 8.380644610124499e-05, 'reg_lambda': 3.935034382107958e-05}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:03,945] Trial 79 finished with value: -0.09085497338778047 and parameters: {'learning_rate': 0.03192045015807971, 'num_leaves': 77, 'max_depth': 10, 'min_child_samples': 11, 'feature_fraction': 0.8208080545300545, 'bagging_fraction': 0.6406992624879626, 'reg_alpha': 0.012125118336042575, 'reg_lambda': 2.2289273582632183e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:10,110] Trial 80 finished with value: -0.0832607043641636 and parameters: {'learning_rate': 0.023760858462315383, 'num_leaves': 55, 'max_depth': 9, 'min_child_samples': 51, 'feature_fraction': 0.8209971212259914, 'bagging_fraction': 0.6462623395101168, 'reg_alpha': 0.6946550168090528, 'reg_lambda': 8.127291380591244e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:16,339] Trial 81 finished with value: -0.08710131563836139 and parameters: {'learning_rate': 0.03231062825710857, 'num_leaves': 65, 'max_depth': 10, 'min_child_samples': 12, 'feature_fraction': 0.8428905811793955, 'bagging_fraction': 0.7224471789772474, 'reg_alpha': 0.009609390020046734, 'reg_lambda': 4.432642160184774e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:22,214] Trial 82 finished with value: -0.08620831390808124 and parameters: {'learning_rate': 0.03078906453001892, 'num_leaves': 40, 'max_depth': 11, 'min_child_samples': 10, 'feature_fraction': 0.5874214769993424, 'bagging_fraction': 0.6100422330114638, 'reg_alpha': 0.025652805015628496, 'reg_lambda': 1.8720757527485749e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:32,936] Trial 83 finished with value: -0.08941195070599148 and parameters: {'learning_rate': 0.017273961533856307, 'num_leaves': 114, 'max_depth': 11, 'min_child_samples': 15, 'feature_fraction': 0.8691466129114628, 'bagging_fraction': 0.6508988350144472, 'reg_alpha': 0.0014840681160242398, 'reg_lambda': 3.1604513133190324e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:40,017] Trial 84 finished with value: -0.08755181483908495 and parameters: {'learning_rate': 0.026762317319495552, 'num_leaves': 80, 'max_depth': 10, 'min_child_samples': 18, 'feature_fraction': 0.7651646483441268, 'bagging_fraction': 0.6825721878308414, 'reg_alpha': 0.003710547187458754, 'reg_lambda': 1.2193580735881708e-05}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:50,277] Trial 85 finished with value: -0.089085294641906 and parameters: {'learning_rate': 0.024498261351229178, 'num_leaves': 110, 'max_depth': 12, 'min_child_samples': 23, 'feature_fraction': 0.6138871990238202, 'bagging_fraction': 0.5783146408392713, 'reg_alpha': 0.08604909305438334, 'reg_lambda': 7.208629911282429e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:08:58,821] Trial 86 finished with value: -0.08703464186324883 and parameters: {'learning_rate': 0.021720394093795, 'num_leaves': 103, 'max_depth': 10, 'min_child_samples': 12, 'feature_fraction': 0.9984325435524664, 'bagging_fraction': 0.6221362093508306, 'reg_alpha': 0.0003382768130160338, 'reg_lambda': 1.5396708927586436e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:09:04,229] Trial 87 finished with value: -0.08365796705863598 and parameters: {'learning_rate': 0.03126348334756478, 'num_leaves': 97, 'max_depth': 11, 'min_child_samples': 71, 'feature_fraction': 0.9223015258914176, 'bagging_fraction': 0.6351604191512898, 'reg_alpha': 0.012356954243110894, 'reg_lambda': 0.0008665911254283926}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:09:18,796] Trial 88 finished with value: -0.09301937645024837 and parameters: {'learning_rate': 0.01274797584564629, 'num_leaves': 160, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.540448959338315, 'bagging_fraction': 0.5827950259144536, 'reg_alpha': 0.00010276578681894422, 'reg_lambda': 6.91019831325072e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:09:34,489] Trial 89 finished with value: -0.08993594570560365 and parameters: {'learning_rate': 0.010902871848563131, 'num_leaves': 160, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.5601706999713832, 'bagging_fraction': 0.5864055349711823, 'reg_alpha': 7.060310153426877e-05, 'reg_lambda': 1.2475979351035483e-05}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:09:47,579] Trial 90 finished with value: -0.08854947064793439 and parameters: {'learning_rate': 0.012565298667351243, 'num_leaves': 154, 'max_depth': 13, 'min_child_samples': 22, 'feature_fraction': 0.5175348224005976, 'bagging_fraction': 0.6621848488543515, 'reg_alpha': 0.0001377407407342052, 'reg_lambda': 2.102272224225909e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:10:02,532] Trial 91 finished with value: -0.09040230818199983 and parameters: {'learning_rate': 0.01449876955828566, 'num_leaves': 170, 'max_depth': 12, 'min_child_samples': 15, 'feature_fraction': 0.5410763194264189, 'bagging_fraction': 0.5551996082950391, 'reg_alpha': 0.0006252098077839076, 'reg_lambda': 7.63799192633658e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:10:17,896] Trial 92 finished with value: -0.09097151168862369 and parameters: {'learning_rate': 0.01130057185812571, 'num_leaves': 142, 'max_depth': 12, 'min_child_samples': 18, 'feature_fraction': 0.5838771897280659, 'bagging_fraction': 0.6064875541422432, 'reg_alpha': 0.0023893921695927033, 'reg_lambda': 1.945870079550569e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:10:33,891] Trial 93 finished with value: -0.08950785252052154 and parameters: {'learning_rate': 0.010920964494363822, 'num_leaves': 143, 'max_depth': 11, 'min_child_samples': 19, 'feature_fraction': 0.5921818661991879, 'bagging_fraction': 0.6029493204782563, 'reg_alpha': 0.02057401744840127, 'reg_lambda': 2.1423072736370499e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:10:47,432] Trial 94 finished with value: -0.09050570923163613 and parameters: {'learning_rate': 0.011506966243361219, 'num_leaves': 132, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.6435755747419489, 'bagging_fraction': 0.8010317391624056, 'reg_alpha': 0.000497000699064195, 'reg_lambda': 3.1871259925405987e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:10:58,517] Trial 95 finished with value: -0.08824292640033858 and parameters: {'learning_rate': 0.013391112068469088, 'num_leaves': 152, 'max_depth': 12, 'min_child_samples': 27, 'feature_fraction': 0.5394880246720166, 'bagging_fraction': 0.6247666249194965, 'reg_alpha': 0.00014478944676881263, 'reg_lambda': 4.721487347185719e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:11:06,576] Trial 96 finished with value: -0.08616818298207958 and parameters: {'learning_rate': 0.019330535396309446, 'num_leaves': 120, 'max_depth': 11, 'min_child_samples': 25, 'feature_fraction': 0.5793272502214399, 'bagging_fraction': 0.6463518641996956, 'reg_alpha': 0.0012461810394242753, 'reg_lambda': 8.463477886086837e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:11:11,609] Trial 97 finished with value: -0.06553850304087978 and parameters: {'learning_rate': 0.19254494286514284, 'num_leaves': 141, 'max_depth': 10, 'min_child_samples': 11, 'feature_fraction': 0.6071041137114521, 'bagging_fraction': 0.5761224960020801, 'reg_alpha': 1.1523300235047488e-05, 'reg_lambda': 1.5014813667476911e-06}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:11:22,820] Trial 98 finished with value: -0.092638762308997 and parameters: {'learning_rate': 0.01493764977423967, 'num_leaves': 106, 'max_depth': 13, 'min_child_samples': 21, 'feature_fraction': 0.5634469065537885, 'bagging_fraction': 0.5922974446382864, 'reg_alpha': 4.1551908244367534e-05, 'reg_lambda': 1.9222980452586307e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:11:33,370] Trial 99 finished with value: -0.09149873754166092 and parameters: {'learning_rate': 0.015447189396572357, 'num_leaves': 106, 'max_depth': 13, 'min_child_samples': 21, 'feature_fraction': 0.5624452206807751, 'bagging_fraction': 0.6128060087012651, 'reg_alpha': 4.0866338282313685e-05, 'reg_lambda': 2.2960319635994014e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:11:45,086] Trial 100 finished with value: -0.09049900760119953 and parameters: {'learning_rate': 0.014913056144244534, 'num_leaves': 131, 'max_depth': 13, 'min_child_samples': 21, 'feature_fraction': 0.5615890119522374, 'bagging_fraction': 0.5914749973260477, 'reg_alpha': 1.775063291348617e-05, 'reg_lambda': 1.0242966189943853e-07}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:11:56,232] Trial 101 finished with value: -0.08862845308041696 and parameters: {'learning_rate': 0.013040832293117978, 'num_leaves': 105, 'max_depth': 13, 'min_child_samples': 24, 'feature_fraction': 0.5429049682051733, 'bagging_fraction': 0.6151646304647714, 'reg_alpha': 3.4667624669453802e-06, 'reg_lambda': 2.172992238316463e-08}. Best is trial 51 with value: -0.09385478265523559.
[I 2025-08-04 07:12:07,692] Trial 102 finished with value: -0.0949217032687709 and parameters: {'learning_rate': 0.016371263566904312, 'num_leaves': 108, 'max_depth': 13, 'min_child_samples': 19, 'feature_fraction': 0.5947532796119693, 'bagging_fraction': 0.5887004468078083, 'reg_alpha': 3.936662432326445e-05, 'reg_lambda': 2.4159579356351655e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:12:18,209] Trial 103 finished with value: -0.09017612498661992 and parameters: {'learning_rate': 0.01680893849864144, 'num_leaves': 123, 'max_depth': 13, 'min_child_samples': 19, 'feature_fraction': 0.6273746992700924, 'bagging_fraction': 0.5859700267018402, 'reg_alpha': 5.113664722005314e-05, 'reg_lambda': 1.83646100070508e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:12:26,272] Trial 104 finished with value: -0.08636099587080777 and parameters: {'learning_rate': 0.018434660253883156, 'num_leaves': 95, 'max_depth': 14, 'min_child_samples': 84, 'feature_fraction': 0.5945809237037903, 'bagging_fraction': 0.5571388835093334, 'reg_alpha': 3.26646225213174e-05, 'reg_lambda': 2.7243406839492486e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:12:38,679] Trial 105 finished with value: -0.09109824270939 and parameters: {'learning_rate': 0.012258777261282794, 'num_leaves': 117, 'max_depth': 13, 'min_child_samples': 22, 'feature_fraction': 0.5153923984055561, 'bagging_fraction': 0.574206286959427, 'reg_alpha': 0.00025876132148167373, 'reg_lambda': 5.311490634648279e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:12:48,753] Trial 106 finished with value: -0.08826567536136419 and parameters: {'learning_rate': 0.015497002173221176, 'num_leaves': 115, 'max_depth': 13, 'min_child_samples': 28, 'feature_fraction': 0.513127663212098, 'bagging_fraction': 0.544310785457342, 'reg_alpha': 0.00018289703608590608, 'reg_lambda': 5.158115237645331e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:13:02,851] Trial 107 finished with value: -0.08910874144467695 and parameters: {'learning_rate': 0.010174812936642047, 'num_leaves': 116, 'max_depth': 14, 'min_child_samples': 22, 'feature_fraction': 0.5320508110595208, 'bagging_fraction': 0.5641379576511355, 'reg_alpha': 0.00023495003581559934, 'reg_lambda': 3.145938333639809e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:13:13,145] Trial 108 finished with value: -0.08636588324720511 and parameters: {'learning_rate': 0.0137315215346088, 'num_leaves': 90, 'max_depth': 13, 'min_child_samples': 33, 'feature_fraction': 0.5634281892165295, 'bagging_fraction': 0.5965384997320021, 'reg_alpha': 2.210364895697281e-05, 'reg_lambda': 1.0693175064872808e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:13:25,970] Trial 109 finished with value: -0.08850825485350165 and parameters: {'learning_rate': 0.012079682808728018, 'num_leaves': 128, 'max_depth': 13, 'min_child_samples': 25, 'feature_fraction': 0.5494647577234848, 'bagging_fraction': 0.575951350862712, 'reg_alpha': 0.00011510892794335415, 'reg_lambda': 1.5138459303350094e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:13:36,423] Trial 110 finished with value: -0.08591885502179866 and parameters: {'learning_rate': 0.016783641631486438, 'num_leaves': 148, 'max_depth': 14, 'min_child_samples': 31, 'feature_fraction': 0.5011651331379573, 'bagging_fraction': 0.5399689162518312, 'reg_alpha': 4.5824459710744156e-05, 'reg_lambda': 5.6349232084562004e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:13:50,398] Trial 111 finished with value: -0.08970910308263749 and parameters: {'learning_rate': 0.012562566222734071, 'num_leaves': 133, 'max_depth': 12, 'min_child_samples': 18, 'feature_fraction': 0.5188534274980622, 'bagging_fraction': 0.6262905399473092, 'reg_alpha': 1.1374388021594991e-05, 'reg_lambda': 3.583106928552794e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:14:02,046] Trial 112 finished with value: -0.08935701228755129 and parameters: {'learning_rate': 0.011630036935223275, 'num_leaves': 98, 'max_depth': 12, 'min_child_samples': 23, 'feature_fraction': 0.5779140868817659, 'bagging_fraction': 0.607733625037139, 'reg_alpha': 0.00043572514571527094, 'reg_lambda': 2.1842639131315257e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:14:13,332] Trial 113 finished with value: -0.09138359903557042 and parameters: {'learning_rate': 0.014468179251204387, 'num_leaves': 125, 'max_depth': 12, 'min_child_samples': 21, 'feature_fraction': 0.6064917275055992, 'bagging_fraction': 0.5702630844399339, 'reg_alpha': 0.008092001488359233, 'reg_lambda': 1.2203109080300518e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:14:23,732] Trial 114 finished with value: -0.09127937410698497 and parameters: {'learning_rate': 0.014931676054801715, 'num_leaves': 108, 'max_depth': 12, 'min_child_samples': 21, 'feature_fraction': 0.6073465730681549, 'bagging_fraction': 0.5744653584136954, 'reg_alpha': 0.004405949277462796, 'reg_lambda': 1.238565506700698e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:14:33,746] Trial 115 finished with value: -0.0935619311198787 and parameters: {'learning_rate': 0.017460640204901227, 'num_leaves': 125, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.6057473483292095, 'bagging_fraction': 0.5506829071684514, 'reg_alpha': 0.004673026929518549, 'reg_lambda': 1.212450920980683e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:14:47,013] Trial 116 finished with value: -0.0911190333782547 and parameters: {'learning_rate': 0.014919662917445294, 'num_leaves': 108, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.6187681600404754, 'bagging_fraction': 0.5516980699259152, 'reg_alpha': 0.06528807171489655, 'reg_lambda': 3.658853765153911e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:14:57,022] Trial 117 finished with value: -0.08624786406269648 and parameters: {'learning_rate': 0.017832392782412856, 'num_leaves': 123, 'max_depth': 12, 'min_child_samples': 36, 'feature_fraction': 0.605510520033384, 'bagging_fraction': 0.5865330421695883, 'reg_alpha': 0.03751517484240318, 'reg_lambda': 1.1720477568613655e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:15:05,995] Trial 118 finished with value: -0.0902051175528601 and parameters: {'learning_rate': 0.01995073981852218, 'num_leaves': 110, 'max_depth': 13, 'min_child_samples': 27, 'feature_fraction': 0.6345942349646916, 'bagging_fraction': 0.5615844897399392, 'reg_alpha': 0.0038587789542153337, 'reg_lambda': 4.843762606782131e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:15:15,185] Trial 119 finished with value: -0.08671538600721057 and parameters: {'learning_rate': 0.015856988900738195, 'num_leaves': 127, 'max_depth': 12, 'min_child_samples': 29, 'feature_fraction': 0.6603694202440921, 'bagging_fraction': 0.5734259955628647, 'reg_alpha': 0.01011517224156579, 'reg_lambda': 7.518775693318138e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:15:27,418] Trial 120 finished with value: -0.09058577682185094 and parameters: {'learning_rate': 0.014411519657257638, 'num_leaves': 87, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.5996664815924492, 'bagging_fraction': 0.9898135011473204, 'reg_alpha': 0.008643828704971258, 'reg_lambda': 1.4096573931199876e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:15:41,275] Trial 121 finished with value: -0.09072182085085966 and parameters: {'learning_rate': 0.015150465206177629, 'num_leaves': 105, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.616784009216273, 'bagging_fraction': 0.5477268070808885, 'reg_alpha': 0.06420135807987505, 'reg_lambda': 3.5959188407077634e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:15:52,642] Trial 122 finished with value: -0.09118995474448366 and parameters: {'learning_rate': 0.013779878003950117, 'num_leaves': 111, 'max_depth': 12, 'min_child_samples': 21, 'feature_fraction': 0.6227501479999515, 'bagging_fraction': 0.5338586103616644, 'reg_alpha': 0.006993271739844585, 'reg_lambda': 1.1820106772081486e-06}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:16:02,356] Trial 123 finished with value: -0.08905366550501474 and parameters: {'learning_rate': 0.01651760183343341, 'num_leaves': 120, 'max_depth': 12, 'min_child_samples': 24, 'feature_fraction': 0.6281816898617242, 'bagging_fraction': 0.5341839622068189, 'reg_alpha': 0.0054166575178367085, 'reg_lambda': 9.817633015552623e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:16:07,639] Trial 124 finished with value: -0.07918510130658787 and parameters: {'learning_rate': 0.013788592477499731, 'num_leaves': 101, 'max_depth': 5, 'min_child_samples': 21, 'feature_fraction': 0.6111023519384151, 'bagging_fraction': 0.5113035066650394, 'reg_alpha': 0.0016958271590126524, 'reg_lambda': 5.156868635275629e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:16:17,115] Trial 125 finished with value: -0.08954339566703036 and parameters: {'learning_rate': 0.01906747362356417, 'num_leaves': 113, 'max_depth': 13, 'min_child_samples': 26, 'feature_fraction': 0.5982960925298818, 'bagging_fraction': 0.563231946582708, 'reg_alpha': 0.028992472757673842, 'reg_lambda': 2.4586452968748267e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:16:31,612] Trial 126 finished with value: -0.0906219149341059 and parameters: {'learning_rate': 0.013142659361444875, 'num_leaves': 134, 'max_depth': 12, 'min_child_samples': 17, 'feature_fraction': 0.6382748093128043, 'bagging_fraction': 0.5911496910903886, 'reg_alpha': 0.017548455785360132, 'reg_lambda': 0.01147893368696456}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:16:35,486] Trial 127 finished with value: -0.07776551847966906 and parameters: {'learning_rate': 0.021882347866368418, 'num_leaves': 126, 'max_depth': 4, 'min_child_samples': 14, 'feature_fraction': 0.6225809186821939, 'bagging_fraction': 0.6162480290097334, 'reg_alpha': 1.134006297498583e-05, 'reg_lambda': 1.4171210819140628e-06}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:16:44,176] Trial 128 finished with value: -0.08908468353884959 and parameters: {'learning_rate': 0.018070783644586197, 'num_leaves': 109, 'max_depth': 11, 'min_child_samples': 23, 'feature_fraction': 0.5928802196330286, 'bagging_fraction': 0.5829862004469126, 'reg_alpha': 0.0034360086984973745, 'reg_lambda': 8.797266738000193e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:16:55,077] Trial 129 finished with value: -0.0908878811037526 and parameters: {'learning_rate': 0.01688753163331937, 'num_leaves': 97, 'max_depth': 12, 'min_child_samples': 19, 'feature_fraction': 0.5785346910440684, 'bagging_fraction': 0.530814302239682, 'reg_alpha': 2.896781023507285e-05, 'reg_lambda': 6.223117431474709e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:17:06,075] Trial 130 finished with value: -0.08944754435315548 and parameters: {'learning_rate': 0.019925705058530807, 'num_leaves': 120, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.6562613324754231, 'bagging_fraction': 0.5976649554767934, 'reg_alpha': 0.007117171192265739, 'reg_lambda': 1.4269273484476645e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:17:18,051] Trial 131 finished with value: -0.08824138028763905 and parameters: {'learning_rate': 0.014806430582722888, 'num_leaves': 109, 'max_depth': 8, 'min_child_samples': 21, 'feature_fraction': 0.6187837716189281, 'bagging_fraction': 0.5558714562695606, 'reg_alpha': 0.1629906528843248, 'reg_lambda': 4.4773249319421464e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:17:28,946] Trial 132 finished with value: -0.09366489492992455 and parameters: {'learning_rate': 0.015934472494923062, 'num_leaves': 106, 'max_depth': 12, 'min_child_samples': 20, 'feature_fraction': 0.6085341231821507, 'bagging_fraction': 0.5512981432997703, 'reg_alpha': 0.0010417291160667397, 'reg_lambda': 2.666270211125822e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:17:38,057] Trial 133 finished with value: -0.08923514611349433 and parameters: {'learning_rate': 0.016056998126401937, 'num_leaves': 102, 'max_depth': 12, 'min_child_samples': 25, 'feature_fraction': 0.6044027572359914, 'bagging_fraction': 0.5427425456290693, 'reg_alpha': 0.0008727766999478575, 'reg_lambda': 2.8639398807804003e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:17:50,477] Trial 134 finished with value: -0.09058158140430844 and parameters: {'learning_rate': 0.0139654155584626, 'num_leaves': 117, 'max_depth': 12, 'min_child_samples': 19, 'feature_fraction': 0.5862000847381332, 'bagging_fraction': 0.5703664000686084, 'reg_alpha': 0.0024656410778126528, 'reg_lambda': 5.997826837314208e-06}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:17:59,841] Trial 135 finished with value: -0.09082112166600617 and parameters: {'learning_rate': 0.02074986062160845, 'num_leaves': 93, 'max_depth': 11, 'min_child_samples': 17, 'feature_fraction': 0.566091485640836, 'bagging_fraction': 0.8647437675288968, 'reg_alpha': 5.462677866065489e-05, 'reg_lambda': 1.2962169193977928e-06}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:18:08,377] Trial 136 finished with value: -0.08697623409143304 and parameters: {'learning_rate': 0.01747849715286188, 'num_leaves': 139, 'max_depth': 13, 'min_child_samples': 43, 'feature_fraction': 0.6070779283915284, 'bagging_fraction': 0.5219516359890006, 'reg_alpha': 0.000977501133404482, 'reg_lambda': 2.126410470535776e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:18:19,009] Trial 137 finished with value: -0.09114489953031599 and parameters: {'learning_rate': 0.013194476442196368, 'num_leaves': 85, 'max_depth': 12, 'min_child_samples': 21, 'feature_fraction': 0.6409894559568131, 'bagging_fraction': 0.5082751238951073, 'reg_alpha': 0.01595583535373173, 'reg_lambda': 8.890381070947579e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:18:28,734] Trial 138 finished with value: -0.08812104634442515 and parameters: {'learning_rate': 0.01575846051592806, 'num_leaves': 130, 'max_depth': 11, 'min_child_samples': 23, 'feature_fraction': 0.5956961296812843, 'bagging_fraction': 0.5542566637438396, 'reg_alpha': 9.692391111672279e-05, 'reg_lambda': 7.067684303505506e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:18:40,012] Trial 139 finished with value: -0.09197554970674325 and parameters: {'learning_rate': 0.0185806912857192, 'num_leaves': 114, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.5545155306647451, 'bagging_fraction': 0.5362289946848394, 'reg_alpha': 0.005590965902966225, 'reg_lambda': 2.6556746277987865e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:18:50,932] Trial 140 finished with value: -0.09447738052371095 and parameters: {'learning_rate': 0.022612564781885842, 'num_leaves': 124, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5544026378144584, 'bagging_fraction': 0.5655945731657936, 'reg_alpha': 0.00306275625885995, 'reg_lambda': 3.585923339649695e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:19:02,222] Trial 141 finished with value: -0.09096897114482558 and parameters: {'learning_rate': 0.023636558211608445, 'num_leaves': 121, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5608604668207415, 'bagging_fraction': 0.5666059822928698, 'reg_alpha': 0.001671742629472957, 'reg_lambda': 2.245046296850157e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:19:14,890] Trial 142 finished with value: -0.09040451422742497 and parameters: {'learning_rate': 0.018499056226085428, 'num_leaves': 115, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5530209673185026, 'bagging_fraction': 0.5861197348338829, 'reg_alpha': 0.003437339434143813, 'reg_lambda': 3.846281003091964e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:19:26,704] Trial 143 finished with value: -0.09099797541750045 and parameters: {'learning_rate': 0.02237553923582262, 'num_leaves': 128, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5710395627354632, 'bagging_fraction': 0.5990350144838608, 'reg_alpha': 0.005184617399804602, 'reg_lambda': 1.2210937027276093e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:19:36,982] Trial 144 finished with value: -0.09175628047123631 and parameters: {'learning_rate': 0.020861682196310072, 'num_leaves': 135, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.5821681916008528, 'bagging_fraction': 0.5498479220600058, 'reg_alpha': 0.0012313367171564679, 'reg_lambda': 6.389540670557827e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:19:44,019] Trial 145 finished with value: -0.08689769245782371 and parameters: {'learning_rate': 0.026140143110482957, 'num_leaves': 136, 'max_depth': 14, 'min_child_samples': 94, 'feature_fraction': 0.5815978816106948, 'bagging_fraction': 0.5469048636080979, 'reg_alpha': 0.0011570603104382267, 'reg_lambda': 2.729194047899074e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:19:52,640] Trial 146 finished with value: -0.08992727411448677 and parameters: {'learning_rate': 0.02811607956818529, 'num_leaves': 126, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.5431738959085751, 'bagging_fraction': 0.5799109608379175, 'reg_alpha': 0.002229261223563774, 'reg_lambda': 5.695809220129659e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:20:03,779] Trial 147 finished with value: -0.09079280188658383 and parameters: {'learning_rate': 0.02023805861485512, 'num_leaves': 104, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5345850503923412, 'bagging_fraction': 0.5595990508559586, 'reg_alpha': 0.0005265724778387102, 'reg_lambda': 3.7039386794911644e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:20:13,893] Trial 148 finished with value: -0.09127216846540855 and parameters: {'learning_rate': 0.02089230974401541, 'num_leaves': 133, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.5528524504474137, 'bagging_fraction': 0.5371755727318893, 'reg_alpha': 3.5713547766795716e-05, 'reg_lambda': 1.2139982964691745e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:20:23,086] Trial 149 finished with value: -0.09041834002192166 and parameters: {'learning_rate': 0.02504226001708015, 'num_leaves': 143, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.5503371843768888, 'bagging_fraction': 0.537231177239385, 'reg_alpha': 3.0975149555725654e-05, 'reg_lambda': 1.230064575673841e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:20:31,276] Trial 150 finished with value: -0.08809418475214745 and parameters: {'learning_rate': 0.021102811018524285, 'num_leaves': 135, 'max_depth': 13, 'min_child_samples': 59, 'feature_fraction': 0.5577564377724458, 'bagging_fraction': 0.5232640391853859, 'reg_alpha': 2.0351557182162532e-05, 'reg_lambda': 7.328692002631333e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:20:42,258] Trial 151 finished with value: -0.09091557513892991 and parameters: {'learning_rate': 0.022811646634024605, 'num_leaves': 124, 'max_depth': 13, 'min_child_samples': 15, 'feature_fraction': 0.565731950877003, 'bagging_fraction': 0.5677332266758338, 'reg_alpha': 5.904641197706588e-05, 'reg_lambda': 1.6980623622036617e-07}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:20:53,199] Trial 152 finished with value: -0.08978438242848015 and parameters: {'learning_rate': 0.017260995300086686, 'num_leaves': 130, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.5740877779377941, 'bagging_fraction': 0.5497438183668744, 'reg_alpha': 4.115607677903368e-05, 'reg_lambda': 9.295264894810497e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:21:04,494] Trial 153 finished with value: -0.09074185058732592 and parameters: {'learning_rate': 0.019401717925163254, 'num_leaves': 115, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5993977675580469, 'bagging_fraction': 0.5402541109177692, 'reg_alpha': 0.00155337263392823, 'reg_lambda': 4.785121468009609e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:21:17,968] Trial 154 finished with value: -0.09262967411389582 and parameters: {'learning_rate': 0.01663530224627153, 'num_leaves': 188, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5849440900215958, 'bagging_fraction': 0.5148959255468971, 'reg_alpha': 0.004694909652112831, 'reg_lambda': 1.7937303877164127e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:21:24,735] Trial 155 finished with value: -0.07708319148532501 and parameters: {'learning_rate': 0.11887106897619293, 'num_leaves': 162, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5443456245501762, 'bagging_fraction': 0.5145544625674441, 'reg_alpha': 8.225827987071221e-06, 'reg_lambda': 1.3765334503352806e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:21:39,531] Trial 156 finished with value: -0.09287072683533348 and parameters: {'learning_rate': 0.015133002162154172, 'num_leaves': 139, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5845854273352465, 'bagging_fraction': 0.5000122847194706, 'reg_alpha': 4.559882611927403e-06, 'reg_lambda': 2.7150781230736522e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:21:54,823] Trial 157 finished with value: -0.09365765846413784 and parameters: {'learning_rate': 0.01516960108606026, 'num_leaves': 138, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5846685836546529, 'bagging_fraction': 0.5094394781681902, 'reg_alpha': 0.002736390370501611, 'reg_lambda': 1.831463104940992e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:22:09,983] Trial 158 finished with value: -0.08960634249441994 and parameters: {'learning_rate': 0.01717933967435203, 'num_leaves': 204, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.585318710085845, 'bagging_fraction': 0.5113113959985245, 'reg_alpha': 2.3439423324645594e-06, 'reg_lambda': 1.9175956801815998e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:22:25,920] Trial 159 finished with value: -0.09299914211702422 and parameters: {'learning_rate': 0.015958108727454037, 'num_leaves': 151, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5772544039635534, 'bagging_fraction': 0.5024764152257342, 'reg_alpha': 0.0024353977780566956, 'reg_lambda': 1.1308867661714367e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:22:42,031] Trial 160 finished with value: -0.09160143787409583 and parameters: {'learning_rate': 0.015989020071283448, 'num_leaves': 157, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5729858553214726, 'bagging_fraction': 0.5036067444643252, 'reg_alpha': 0.0006991738065573473, 'reg_lambda': 1.694254404473733e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:22:56,551] Trial 161 finished with value: -0.09343540642443914 and parameters: {'learning_rate': 0.016166321243654143, 'num_leaves': 157, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5699723465503083, 'bagging_fraction': 0.5071357444939182, 'reg_alpha': 0.000632579640551532, 'reg_lambda': 1.0520139948856813e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:23:11,101] Trial 162 finished with value: -0.09261938604885019 and parameters: {'learning_rate': 0.01617268023952145, 'num_leaves': 152, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5755598271116461, 'bagging_fraction': 0.5016362879918527, 'reg_alpha': 0.0006115555625648567, 'reg_lambda': 1.1446662734849169e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:23:27,306] Trial 163 finished with value: -0.09061691647476804 and parameters: {'learning_rate': 0.016268942110930915, 'num_leaves': 189, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5794295659180333, 'bagging_fraction': 0.5010497039665621, 'reg_alpha': 0.0006044151351856719, 'reg_lambda': 1.1411348034672854e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:23:42,021] Trial 164 finished with value: -0.09251177383098268 and parameters: {'learning_rate': 0.017640336937574465, 'num_leaves': 147, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5897115952508523, 'bagging_fraction': 0.528469338382433, 'reg_alpha': 0.0022416535449333594, 'reg_lambda': 1.024720570605417e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:23:56,397] Trial 165 finished with value: -0.08998844817024192 and parameters: {'learning_rate': 0.017763020432442034, 'num_leaves': 165, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5918221899017959, 'bagging_fraction': 0.5185162811461734, 'reg_alpha': 0.0003536445140267858, 'reg_lambda': 1.014702256779665e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:24:11,878] Trial 166 finished with value: -0.09037402980443844 and parameters: {'learning_rate': 0.016350544625239286, 'num_leaves': 150, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5685369414880174, 'bagging_fraction': 0.5014396484896266, 'reg_alpha': 0.0021896945114438103, 'reg_lambda': 2.7592813709186568e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:24:27,405] Trial 167 finished with value: -0.09255618859515181 and parameters: {'learning_rate': 0.014417232496326385, 'num_leaves': 153, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5905722291278523, 'bagging_fraction': 0.5257369370060178, 'reg_alpha': 0.002692821736740448, 'reg_lambda': 1.7116774323092417e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:24:43,655] Trial 168 finished with value: -0.0919361014370932 and parameters: {'learning_rate': 0.014642148635905726, 'num_leaves': 151, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.58826526431171, 'bagging_fraction': 0.5232061065952919, 'reg_alpha': 0.0026745784147068304, 'reg_lambda': 1.6879466612770205e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:24:58,189] Trial 169 finished with value: -0.09280688088778088 and parameters: {'learning_rate': 0.016875486524692132, 'num_leaves': 156, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5738838120331833, 'bagging_fraction': 0.5139376515023213, 'reg_alpha': 0.00019191933372445218, 'reg_lambda': 3.007783231044171e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:25:14,931] Trial 170 finished with value: -0.09165572716741259 and parameters: {'learning_rate': 0.012827676063729296, 'num_leaves': 157, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.575350682985873, 'bagging_fraction': 0.5116440845117032, 'reg_alpha': 0.0003295873531516535, 'reg_lambda': 1.0771075210441688e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:25:30,506] Trial 171 finished with value: -0.09349644808935893 and parameters: {'learning_rate': 0.015395905012727865, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.561725448995588, 'bagging_fraction': 0.5272897820528927, 'reg_alpha': 0.00017185594993591107, 'reg_lambda': 2.7434903285014853e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:25:44,471] Trial 172 finished with value: -0.09147557613380448 and parameters: {'learning_rate': 0.015302413688395067, 'num_leaves': 163, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5922594810636054, 'bagging_fraction': 0.5254982153352947, 'reg_alpha': 0.0001822247492045109, 'reg_lambda': 1.6768877664049922e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:26:01,224] Trial 173 finished with value: -0.09066607617591803 and parameters: {'learning_rate': 0.013805424970102086, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5632455299854796, 'bagging_fraction': 0.5132532042354312, 'reg_alpha': 0.0002343387130387523, 'reg_lambda': 3.483519265455672e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:26:15,966] Trial 174 finished with value: -0.09420695259717808 and parameters: {'learning_rate': 0.01662976981002314, 'num_leaves': 146, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5788199323514865, 'bagging_fraction': 0.5002738317791293, 'reg_alpha': 9.224595172379378e-07, 'reg_lambda': 1.665232137808838e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:26:29,767] Trial 175 finished with value: -0.09415997909649872 and parameters: {'learning_rate': 0.016790330039265552, 'num_leaves': 146, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5758215650667226, 'bagging_fraction': 0.5014706328175212, 'reg_alpha': 4.342682366437113e-06, 'reg_lambda': 1.755332977364369e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:26:45,496] Trial 176 finished with value: -0.09328216951946594 and parameters: {'learning_rate': 0.015588114296082046, 'num_leaves': 176, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5334578252202353, 'bagging_fraction': 0.5002341485367952, 'reg_alpha': 6.238501716459716e-07, 'reg_lambda': 2.0848084219268907e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:26:59,480] Trial 177 finished with value: -0.08929828238025347 and parameters: {'learning_rate': 0.016739478141037566, 'num_leaves': 190, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5588565018883311, 'bagging_fraction': 0.5025386009819346, 'reg_alpha': 1.3014855244347496e-06, 'reg_lambda': 2.5699150257631297e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:27:15,383] Trial 178 finished with value: -0.09418443111517336 and parameters: {'learning_rate': 0.01580503948377071, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5351596215486976, 'bagging_fraction': 0.501380006972312, 'reg_alpha': 2.957286050581688e-06, 'reg_lambda': 1.9442168721922307e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:27:31,403] Trial 179 finished with value: -0.09353542195359381 and parameters: {'learning_rate': 0.015124657575501318, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5260497075044505, 'bagging_fraction': 0.512900964475347, 'reg_alpha': 5.99515925817303e-07, 'reg_lambda': 4.465563388412065e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:27:46,260] Trial 180 finished with value: -0.09264816521363355 and parameters: {'learning_rate': 0.015309795556196153, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5280696561039355, 'bagging_fraction': 0.5104681752010607, 'reg_alpha': 7.551011698260728e-07, 'reg_lambda': 3.890871298178845e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:28:03,006] Trial 181 finished with value: -0.09399250449617962 and parameters: {'learning_rate': 0.015155631538749353, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5271888989790109, 'bagging_fraction': 0.5105153240918342, 'reg_alpha': 5.984309147671155e-07, 'reg_lambda': 4.072929814767074e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:28:18,477] Trial 182 finished with value: -0.092040971719177 and parameters: {'learning_rate': 0.015544684999921206, 'num_leaves': 171, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5248586042878242, 'bagging_fraction': 0.5103836218860753, 'reg_alpha': 8.59275809048993e-07, 'reg_lambda': 4.1201889295789604e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:28:35,134] Trial 183 finished with value: -0.09167298231038473 and parameters: {'learning_rate': 0.014004205999863524, 'num_leaves': 180, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5330460974195976, 'bagging_fraction': 0.5007852797608097, 'reg_alpha': 4.057559049507182e-07, 'reg_lambda': 3.2281301751862625e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:28:51,086] Trial 184 finished with value: -0.09437264870898145 and parameters: {'learning_rate': 0.015105820009560986, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5229328515567846, 'bagging_fraction': 0.515303088374846, 'reg_alpha': 3.804238636499912e-06, 'reg_lambda': 4.193587280497479e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:29:07,901] Trial 185 finished with value: -0.09405095795472188 and parameters: {'learning_rate': 0.013359867251458797, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5106629847721533, 'bagging_fraction': 0.5186856576666936, 'reg_alpha': 3.2152685615825513e-06, 'reg_lambda': 2.2884039600376722e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:29:23,330] Trial 186 finished with value: -0.09274644484378285 and parameters: {'learning_rate': 0.013133239215314856, 'num_leaves': 177, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5168253039071308, 'bagging_fraction': 0.5202127374190644, 'reg_alpha': 3.2987414820791296e-06, 'reg_lambda': 2.0838073812457378e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:29:35,538] Trial 187 finished with value: -0.08660625274076615 and parameters: {'learning_rate': 0.012456340122978374, 'num_leaves': 183, 'max_depth': 15, 'min_child_samples': 53, 'feature_fraction': 0.5067000740495954, 'bagging_fraction': 0.5265939393247984, 'reg_alpha': 1.7353040755806703e-06, 'reg_lambda': 5.212455830441199e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:29:52,702] Trial 188 finished with value: -0.09329961954488614 and parameters: {'learning_rate': 0.014415884363541676, 'num_leaves': 168, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5219958744522354, 'bagging_fraction': 0.5006026652572088, 'reg_alpha': 4.5964284099341035e-06, 'reg_lambda': 2.2255356128299324e-08}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:30:09,464] Trial 189 finished with value: -0.0944081897386468 and parameters: {'learning_rate': 0.01353117110171101, 'num_leaves': 166, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5247260809137617, 'bagging_fraction': 0.5168181906564439, 'reg_alpha': 9.708396414301822e-07, 'reg_lambda': 0.4272795101031161}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:30:27,133] Trial 190 finished with value: -0.09460221352505119 and parameters: {'learning_rate': 0.013502067592216279, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5224452568164563, 'bagging_fraction': 0.5175579668929615, 'reg_alpha': 1.0891309276784987e-06, 'reg_lambda': 0.00020641501557639417}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:30:44,225] Trial 191 finished with value: -0.09432252546274761 and parameters: {'learning_rate': 0.013424795936918251, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5203478931288456, 'bagging_fraction': 0.5168630296561929, 'reg_alpha': 8.747056479415772e-07, 'reg_lambda': 0.01541107967895995}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:31:01,411] Trial 192 finished with value: -0.09269174399867554 and parameters: {'learning_rate': 0.01359089630505374, 'num_leaves': 176, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.519770022750677, 'bagging_fraction': 0.5175975702185363, 'reg_alpha': 2.0896156833501483e-07, 'reg_lambda': 0.4754256499063362}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:31:21,161] Trial 193 finished with value: -0.09439660152271474 and parameters: {'learning_rate': 0.011685260348623426, 'num_leaves': 167, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5227129617907228, 'bagging_fraction': 0.5307740605372896, 'reg_alpha': 5.95660410638669e-07, 'reg_lambda': 0.014339818679170873}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:31:39,241] Trial 194 finished with value: -0.09104440377682176 and parameters: {'learning_rate': 0.011909012039625038, 'num_leaves': 167, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5099642473273426, 'bagging_fraction': 0.5311199176262223, 'reg_alpha': 1.1872843444033624e-06, 'reg_lambda': 0.004595150097919793}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:31:56,690] Trial 195 finished with value: -0.09207524187402542 and parameters: {'learning_rate': 0.013366314437036342, 'num_leaves': 184, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5005498102004506, 'bagging_fraction': 0.5291096790477338, 'reg_alpha': 2.36272152497324e-06, 'reg_lambda': 0.01462392024501931}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:32:17,819] Trial 196 finished with value: -0.0912812144037448 and parameters: {'learning_rate': 0.010786928542356524, 'num_leaves': 168, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5230923950225298, 'bagging_fraction': 0.5150860417981318, 'reg_alpha': 5.289001094388118e-06, 'reg_lambda': 5.8814090721743275}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:32:34,455] Trial 197 finished with value: -0.0913588488181951 and parameters: {'learning_rate': 0.014116047677790818, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5113040897795238, 'bagging_fraction': 0.5200149544440394, 'reg_alpha': 9.002959587723446e-07, 'reg_lambda': 0.039255674730883226}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:32:54,020] Trial 198 finished with value: -0.09134233876568862 and parameters: {'learning_rate': 0.012475301168597238, 'num_leaves': 198, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5360211564668325, 'bagging_fraction': 0.5343929566965177, 'reg_alpha': 5.150849164558573e-07, 'reg_lambda': 0.0003895483612238074}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:33:09,167] Trial 199 finished with value: -0.09428497659110914 and parameters: {'learning_rate': 0.014611604821784403, 'num_leaves': 180, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5132752480105726, 'bagging_fraction': 0.5107969516317641, 'reg_alpha': 1.1975583709946864e-07, 'reg_lambda': 0.26226594705672046}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:33:26,547] Trial 200 finished with value: -0.09035615237158923 and parameters: {'learning_rate': 0.011529265531319506, 'num_leaves': 186, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5068369828276849, 'bagging_fraction': 0.511545882810062, 'reg_alpha': 8.332106887307155e-08, 'reg_lambda': 0.1393601967789617}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:33:42,657] Trial 201 finished with value: -0.09325134550841487 and parameters: {'learning_rate': 0.014680495222879083, 'num_leaves': 165, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5271398532366768, 'bagging_fraction': 0.522632755163897, 'reg_alpha': 1.325858138049543e-07, 'reg_lambda': 0.5719558111107559}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:33:59,860] Trial 202 finished with value: -0.0932513752901318 and parameters: {'learning_rate': 0.014453541354119918, 'num_leaves': 181, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5148500791736943, 'bagging_fraction': 0.5089810068998686, 'reg_alpha': 3.066230352925385e-07, 'reg_lambda': 0.3572180286127723}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:34:15,947] Trial 203 finished with value: -0.09191360533063822 and parameters: {'learning_rate': 0.013036727188377962, 'num_leaves': 175, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5406396771784996, 'bagging_fraction': 0.5399662175819967, 'reg_alpha': 1.5381379945441025e-06, 'reg_lambda': 0.41023867799122815}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:34:32,949] Trial 204 finished with value: -0.09386886723870344 and parameters: {'learning_rate': 0.013873686960709015, 'num_leaves': 168, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5216482129822084, 'bagging_fraction': 0.5196248137662064, 'reg_alpha': 2.125166012471702e-06, 'reg_lambda': 1.713154522013146}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:34:51,817] Trial 205 finished with value: -0.0924484516349378 and parameters: {'learning_rate': 0.013297844656541574, 'num_leaves': 182, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5291156453484422, 'bagging_fraction': 0.5301329696911814, 'reg_alpha': 1.0938607589540236e-06, 'reg_lambda': 1.3176717058511838}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:35:09,448] Trial 206 finished with value: -0.09261019566893065 and parameters: {'learning_rate': 0.011912413318354994, 'num_leaves': 164, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5020967996873364, 'bagging_fraction': 0.5194717657785214, 'reg_alpha': 3.096527099452779e-06, 'reg_lambda': 2.736369507685955}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:35:24,387] Trial 207 finished with value: -0.09302942517457609 and parameters: {'learning_rate': 0.013932044525942327, 'num_leaves': 178, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5442160420955451, 'bagging_fraction': 0.5117454322513348, 'reg_alpha': 2.0255203094697483e-08, 'reg_lambda': 0.00013369050756420595}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:35:39,890] Trial 208 finished with value: -0.0910334133160102 and parameters: {'learning_rate': 0.01518816434345517, 'num_leaves': 171, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5181557127933907, 'bagging_fraction': 0.5438201502788451, 'reg_alpha': 1.861387151356451e-06, 'reg_lambda': 0.192756048473563}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:35:55,028] Trial 209 finished with value: -0.08944567667484565 and parameters: {'learning_rate': 0.017746677192802398, 'num_leaves': 192, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5349384692998282, 'bagging_fraction': 0.5273593688068434, 'reg_alpha': 4.814815089628533e-07, 'reg_lambda': 0.047968867978935674}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:36:10,251] Trial 210 finished with value: -0.09450503530687633 and parameters: {'learning_rate': 0.016204973167060138, 'num_leaves': 159, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5207144758962542, 'bagging_fraction': 0.5343806240925615, 'reg_alpha': 6.671524961113899e-07, 'reg_lambda': 0.8727828787391719}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:36:25,486] Trial 211 finished with value: -0.09238314707220946 and parameters: {'learning_rate': 0.016336098135381595, 'num_leaves': 160, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5146366480265366, 'bagging_fraction': 0.5336409020706134, 'reg_alpha': 5.97794195418683e-07, 'reg_lambda': 1.3750362500967046}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:36:42,430] Trial 212 finished with value: -0.09449187566232516 and parameters: {'learning_rate': 0.015040577143643064, 'num_leaves': 176, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5253692414295515, 'bagging_fraction': 0.5200138573408424, 'reg_alpha': 2.5950749858358977e-07, 'reg_lambda': 1.1580401965472082}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:36:57,148] Trial 213 finished with value: -0.09232539239488384 and parameters: {'learning_rate': 0.014864998882004599, 'num_leaves': 178, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5201072742877821, 'bagging_fraction': 0.5206134332758777, 'reg_alpha': 3.9783255938039374e-07, 'reg_lambda': 0.9472677338614643}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:37:06,765] Trial 214 finished with value: -0.08888872240193342 and parameters: {'learning_rate': 0.013942728886505188, 'num_leaves': 173, 'max_depth': 7, 'min_child_samples': 14, 'feature_fraction': 0.5270192443219052, 'bagging_fraction': 0.5412483235093319, 'reg_alpha': 8.815995898208886e-07, 'reg_lambda': 2.7142983197019874}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:37:25,286] Trial 215 finished with value: -0.09172436790324132 and parameters: {'learning_rate': 0.012510171118158804, 'num_leaves': 184, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5105263305442891, 'bagging_fraction': 0.5166032748263295, 'reg_alpha': 2.714480550405317e-07, 'reg_lambda': 0.000899591604984244}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:37:39,682] Trial 216 finished with value: -0.09381890670787957 and parameters: {'learning_rate': 0.01546608058279133, 'num_leaves': 167, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5412561582798404, 'bagging_fraction': 0.5319605684255596, 'reg_alpha': 2.031799317413055e-07, 'reg_lambda': 0.8873624691362558}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:37:51,881] Trial 217 finished with value: -0.09095442234016211 and parameters: {'learning_rate': 0.017242214847546206, 'num_leaves': 167, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.534207363613191, 'bagging_fraction': 0.7712475212575121, 'reg_alpha': 1.5460908282054851e-07, 'reg_lambda': 0.2579409765630686}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:38:06,766] Trial 218 finished with value: -0.09138630147847122 and parameters: {'learning_rate': 0.013503940313102801, 'num_leaves': 162, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5004613365640683, 'bagging_fraction': 0.5458022544824445, 'reg_alpha': 1.9539774803884954e-07, 'reg_lambda': 0.8045841590894611}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:38:25,256] Trial 219 finished with value: -0.09309483263479298 and parameters: {'learning_rate': 0.014522451444157437, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5447696567452318, 'bagging_fraction': 0.5098685664078985, 'reg_alpha': 1.2419016733039463e-06, 'reg_lambda': 1.5087501620491657}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:38:43,064] Trial 220 finished with value: -0.09275604198894258 and parameters: {'learning_rate': 0.010842267567988215, 'num_leaves': 168, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.5216304966294676, 'bagging_fraction': 0.5352880623600995, 'reg_alpha': 2.7771733580072087e-06, 'reg_lambda': 0.7576406202157623}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:38:59,586] Trial 221 finished with value: -0.09333462512055017 and parameters: {'learning_rate': 0.015478925614477957, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5376045659306632, 'bagging_fraction': 0.5255256407589589, 'reg_alpha': 6.713961123159177e-07, 'reg_lambda': 2.400454769271032}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:39:15,229] Trial 222 finished with value: -0.09470727132214422 and parameters: {'learning_rate': 0.015547205627359423, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5292575400740145, 'bagging_fraction': 0.5227885906330553, 'reg_alpha': 2.8653539755578734e-07, 'reg_lambda': 0.005880295812462106}. Best is trial 102 with value: -0.0949217032687709.
[I 2025-08-04 07:39:29,258] Trial 223 finished with value: -0.09532691268294306 and parameters: {'learning_rate': 0.0165608221045234, 'num_leaves': 187, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5283659406354437, 'bagging_fraction': 0.5175805606134556, 'reg_alpha': 2.8536889305097945e-07, 'reg_lambda': 0.001648242102284381}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:39:43,721] Trial 224 finished with value: -0.09388559389845667 and parameters: {'learning_rate': 0.016782658777957413, 'num_leaves': 188, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5135745969815679, 'bagging_fraction': 0.521800707594284, 'reg_alpha': 1.0680756677185365e-07, 'reg_lambda': 0.006197883652718036}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:39:58,008] Trial 225 finished with value: -0.09359175931943214 and parameters: {'learning_rate': 0.0163325067735991, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5103792407029316, 'bagging_fraction': 0.5206878910632563, 'reg_alpha': 7.99997172532051e-08, 'reg_lambda': 0.006402493970845075}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:40:11,820] Trial 226 finished with value: -0.09402494340058952 and parameters: {'learning_rate': 0.018199716061270462, 'num_leaves': 191, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5253416032198035, 'bagging_fraction': 0.5333655981079984, 'reg_alpha': 9.645346863513339e-08, 'reg_lambda': 0.00235908302820008}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:40:25,121] Trial 227 finished with value: -0.09471786922624746 and parameters: {'learning_rate': 0.018237194663651264, 'num_leaves': 194, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5305699977025795, 'bagging_fraction': 0.5338871135371924, 'reg_alpha': 2.786917226347714e-07, 'reg_lambda': 0.008167007324665425}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:40:38,471] Trial 228 finished with value: -0.09343210611515644 and parameters: {'learning_rate': 0.018210238662358418, 'num_leaves': 197, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5295422406111344, 'bagging_fraction': 0.5327035825267121, 'reg_alpha': 2.890074016165226e-07, 'reg_lambda': 0.0020615628885983484}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:40:52,645] Trial 229 finished with value: -0.09486989319438453 and parameters: {'learning_rate': 0.01913557263355086, 'num_leaves': 204, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5212951266675346, 'bagging_fraction': 0.5212685179617961, 'reg_alpha': 9.247023572349287e-08, 'reg_lambda': 0.018566867849344082}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:41:07,151] Trial 230 finished with value: -0.09337913201244928 and parameters: {'learning_rate': 0.019800977838590063, 'num_leaves': 206, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5137611933522704, 'bagging_fraction': 0.518794545674229, 'reg_alpha': 1.4851825726701841e-07, 'reg_lambda': 0.024936582219418753}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:41:20,791] Trial 231 finished with value: -0.09285971897326613 and parameters: {'learning_rate': 0.01871056911899733, 'num_leaves': 198, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5243815392908271, 'bagging_fraction': 0.528485539576093, 'reg_alpha': 1.1120932057106367e-07, 'reg_lambda': 0.007508270497617894}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:41:34,094] Trial 232 finished with value: -0.09111850823655517 and parameters: {'learning_rate': 0.017622679937581785, 'num_leaves': 192, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.545304592477564, 'bagging_fraction': 0.5365015632739845, 'reg_alpha': 4.844192871541297e-08, 'reg_lambda': 0.0031256392058212393}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:41:48,968] Trial 233 finished with value: -0.09226652771432961 and parameters: {'learning_rate': 0.016697501380749213, 'num_leaves': 187, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5365792704902159, 'bagging_fraction': 0.5199697796589886, 'reg_alpha': 2.4762189112622026e-07, 'reg_lambda': 0.02263847829263199}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:42:02,050] Trial 234 finished with value: -0.0948091812810047 and parameters: {'learning_rate': 0.018996741624040806, 'num_leaves': 196, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5200017683195025, 'bagging_fraction': 0.5099287404503755, 'reg_alpha': 9.907829656314445e-08, 'reg_lambda': 0.0019339687682495956}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:42:16,980] Trial 235 finished with value: -0.09396598553844607 and parameters: {'learning_rate': 0.019030042083336356, 'num_leaves': 195, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5140133296485896, 'bagging_fraction': 0.5097805595562582, 'reg_alpha': 9.574149494718087e-08, 'reg_lambda': 0.0031388585004631622}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:42:32,036] Trial 236 finished with value: -0.09261621840167061 and parameters: {'learning_rate': 0.019353288298506625, 'num_leaves': 201, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5174515502339617, 'bagging_fraction': 0.5088244238206742, 'reg_alpha': 8.826971961885902e-08, 'reg_lambda': 0.0035565375280448516}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:42:38,786] Trial 237 finished with value: -0.08604098490309318 and parameters: {'learning_rate': 0.01837377842150226, 'num_leaves': 194, 'max_depth': 6, 'min_child_samples': 12, 'feature_fraction': 0.5047832079545558, 'bagging_fraction': 0.5086215348642478, 'reg_alpha': 6.770136349692651e-08, 'reg_lambda': 0.001446769437853794}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:42:47,486] Trial 238 finished with value: -0.0850015029388878 and parameters: {'learning_rate': 0.07307604835112212, 'num_leaves': 209, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5220082925182543, 'bagging_fraction': 0.5148503507828575, 'reg_alpha': 3.0054242694863574e-08, 'reg_lambda': 0.006261527308521214}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:42:56,107] Trial 239 finished with value: -0.08733834209562648 and parameters: {'learning_rate': 0.018934709404434417, 'num_leaves': 189, 'max_depth': 15, 'min_child_samples': 65, 'feature_fraction': 0.5117109418367608, 'bagging_fraction': 0.5024084109443089, 'reg_alpha': 1.1004209646813788e-07, 'reg_lambda': 0.009692103598048092}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:43:12,137] Trial 240 finished with value: -0.0931779586091743 and parameters: {'learning_rate': 0.017173626551700065, 'num_leaves': 194, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5303828890801878, 'bagging_fraction': 0.522014199962422, 'reg_alpha': 4.0168047065755845e-07, 'reg_lambda': 0.001744708551860487}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:43:28,690] Trial 241 finished with value: -0.09221501319776897 and parameters: {'learning_rate': 0.01784230356695893, 'num_leaves': 216, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5224373389117143, 'bagging_fraction': 0.5186971521677674, 'reg_alpha': 1.837538442707109e-07, 'reg_lambda': 0.01694638629801732}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:43:41,429] Trial 242 finished with value: -0.09141123509485546 and parameters: {'learning_rate': 0.01959368186069562, 'num_leaves': 203, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.513262675398463, 'bagging_fraction': 0.5095892959462723, 'reg_alpha': 1.6894720285553227e-06, 'reg_lambda': 0.0044432777414488474}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:43:56,689] Trial 243 finished with value: -0.09295316529172437 and parameters: {'learning_rate': 0.016835527852600868, 'num_leaves': 181, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5001029817956318, 'bagging_fraction': 0.5007259646882722, 'reg_alpha': 1.3503212179243824e-07, 'reg_lambda': 0.002653926087580076}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:44:12,022] Trial 244 finished with value: -0.0933914582208409 and parameters: {'learning_rate': 0.018159498406744988, 'num_leaves': 189, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5330778345619723, 'bagging_fraction': 0.5244400433042526, 'reg_alpha': 3.774929722039312e-07, 'reg_lambda': 0.008621692707835705}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:44:20,997] Trial 245 finished with value: -0.08441390623760524 and parameters: {'learning_rate': 0.016293495903810684, 'num_leaves': 198, 'max_depth': 14, 'min_child_samples': 80, 'feature_fraction': 0.5202051668225751, 'bagging_fraction': 0.510356642040442, 'reg_alpha': 5.068618673211278e-08, 'reg_lambda': 0.00457088283705738}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:44:36,268] Trial 246 finished with value: -0.09223951244222765 and parameters: {'learning_rate': 0.01681539199253105, 'num_leaves': 184, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5301839832641252, 'bagging_fraction': 0.5269562413138449, 'reg_alpha': 1.1063768321464096e-06, 'reg_lambda': 0.0009651580663126252}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:44:53,977] Trial 247 finished with value: -0.09260285289589588 and parameters: {'learning_rate': 0.014179386550025918, 'num_leaves': 193, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5132930782956288, 'bagging_fraction': 0.5409406838446451, 'reg_alpha': 7.586569425938641e-06, 'reg_lambda': 0.0006524174339386617}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:45:04,052] Trial 248 finished with value: -0.08601440791078047 and parameters: {'learning_rate': 0.013073474176707504, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 68, 'feature_fraction': 0.5492441773413744, 'bagging_fraction': 0.5102528428707177, 'reg_alpha': 2.302884970555501e-06, 'reg_lambda': 0.001313530821662759}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:45:15,719] Trial 249 finished with value: -0.09145790904778768 and parameters: {'learning_rate': 0.0200424399308984, 'num_leaves': 188, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5253407056261312, 'bagging_fraction': 0.5187253615520794, 'reg_alpha': 3.982675596796708e-06, 'reg_lambda': 0.015803574238192567}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:45:30,162] Trial 250 finished with value: -0.08823771722283207 and parameters: {'learning_rate': 0.01586292818782067, 'num_leaves': 184, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.7200021422541706, 'bagging_fraction': 0.500049788811567, 'reg_alpha': 3.0967991538003887e-07, 'reg_lambda': 0.0002491001706092136}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:45:43,941] Trial 251 finished with value: -0.09196451722547151 and parameters: {'learning_rate': 0.018617635117918255, 'num_leaves': 181, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.51064570413824, 'bagging_fraction': 0.5300524756525753, 'reg_alpha': 7.645589353026106e-07, 'reg_lambda': 0.02510119674020838}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:45:59,858] Trial 252 finished with value: -0.09308753772578834 and parameters: {'learning_rate': 0.01764126843560017, 'num_leaves': 200, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5372789812012986, 'bagging_fraction': 0.5182942635780464, 'reg_alpha': 8.519297348212492e-08, 'reg_lambda': 0.09284597191399539}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:46:17,257] Trial 253 finished with value: -0.09254944686187103 and parameters: {'learning_rate': 0.014435067501491684, 'num_leaves': 177, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.521026383026064, 'bagging_fraction': 0.5364895164692981, 'reg_alpha': 1.3277246218931126e-07, 'reg_lambda': 0.01313575989983404}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:46:31,443] Trial 254 finished with value: -0.09272527461049102 and parameters: {'learning_rate': 0.01620110458989782, 'num_leaves': 188, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5290844400733508, 'bagging_fraction': 0.5161072471702772, 'reg_alpha': 4.445311112063958e-07, 'reg_lambda': 0.002297120865598239}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:46:40,908] Trial 255 finished with value: -0.09103142656269236 and parameters: {'learning_rate': 0.05563622668246481, 'num_leaves': 195, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5089652599236127, 'bagging_fraction': 0.5246538033311211, 'reg_alpha': 1.3448245960578544e-06, 'reg_lambda': 0.005551370109781204}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:46:51,410] Trial 256 finished with value: -0.089525663131394 and parameters: {'learning_rate': 0.02191223874628909, 'num_leaves': 177, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.539428355424887, 'bagging_fraction': 0.5084647499494876, 'reg_alpha': 2.0748749371330926e-07, 'reg_lambda': 0.0085693582195774}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:47:08,283] Trial 257 finished with value: -0.09109164963949043 and parameters: {'learning_rate': 0.01343006051678473, 'num_leaves': 184, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5191355187147196, 'bagging_fraction': 0.5449759308004694, 'reg_alpha': 8.321614630146694e-07, 'reg_lambda': 0.003436107059971212}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:47:24,264] Trial 258 finished with value: -0.09107698849877917 and parameters: {'learning_rate': 0.017235049653106613, 'num_leaves': 204, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.501932790267813, 'bagging_fraction': 0.5311175505387614, 'reg_alpha': 2.127646500662092e-06, 'reg_lambda': 0.002696369489843905}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:47:42,926] Trial 259 finished with value: -0.09016553645365587 and parameters: {'learning_rate': 0.012136447951816495, 'num_leaves': 194, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5503557027533205, 'bagging_fraction': 0.5148176589982817, 'reg_alpha': 5.480150754839288e-07, 'reg_lambda': 0.04724101723708686}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:47:58,600] Trial 260 finished with value: -0.09392044980114787 and parameters: {'learning_rate': 0.014814583240787927, 'num_leaves': 190, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5299653568757672, 'bagging_fraction': 0.7202330812495221, 'reg_alpha': 5.970362912524957e-06, 'reg_lambda': 0.3117198095943011}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:48:13,910] Trial 261 finished with value: -0.09310557392554678 and parameters: {'learning_rate': 0.014832965206059543, 'num_leaves': 213, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5307516166885635, 'bagging_fraction': 0.7308766666340588, 'reg_alpha': 5.734785518716732e-06, 'reg_lambda': 0.49557482941061676}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:48:30,346] Trial 262 finished with value: -0.09133287370625594 and parameters: {'learning_rate': 0.015575393721018817, 'num_leaves': 190, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5187020152297418, 'bagging_fraction': 0.5082191205192723, 'reg_alpha': 6.294661332064062e-08, 'reg_lambda': 0.36523056292188094}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:48:47,744] Trial 263 finished with value: -0.09354336008658999 and parameters: {'learning_rate': 0.013900125564030974, 'num_leaves': 181, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5431368419828799, 'bagging_fraction': 0.5014880793406303, 'reg_alpha': 3.5493498922061634e-06, 'reg_lambda': 1.6056178155933754}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:49:07,100] Trial 264 finished with value: -0.09409359935814451 and parameters: {'learning_rate': 0.012808516619775204, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5289311016517839, 'bagging_fraction': 0.7833170304783253, 'reg_alpha': 2.47420849650779e-07, 'reg_lambda': 4.568917454954233}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:49:25,389] Trial 265 finished with value: -0.09150103155904761 and parameters: {'learning_rate': 0.012301774133333023, 'num_leaves': 176, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5343651030705027, 'bagging_fraction': 0.8164119351387886, 'reg_alpha': 2.6718039955784405e-07, 'reg_lambda': 0.19619007279664566}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:49:48,583] Trial 266 finished with value: -0.09118772012632934 and parameters: {'learning_rate': 0.011167667171584763, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5091313627614356, 'bagging_fraction': 0.759531920349213, 'reg_alpha': 1.5729417503860253e-07, 'reg_lambda': 9.031169185827025}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:50:04,704] Trial 267 finished with value: -0.09040389125282357 and parameters: {'learning_rate': 0.013116189793331848, 'num_leaves': 192, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5276155168970134, 'bagging_fraction': 0.7849484504992746, 'reg_alpha': 1.064431435664795e-07, 'reg_lambda': 0.009249837342577567}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:50:25,790] Trial 268 finished with value: -0.09328104399827178 and parameters: {'learning_rate': 0.010092198950925878, 'num_leaves': 174, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5476837569867744, 'bagging_fraction': 0.8117958289313519, 'reg_alpha': 2.8443171974699318e-08, 'reg_lambda': 0.273130658764552}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:50:43,883] Trial 269 finished with value: -0.09286629575649978 and parameters: {'learning_rate': 0.014543110529380437, 'num_leaves': 182, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5360637958368949, 'bagging_fraction': 0.5379852316937155, 'reg_alpha': 3.9628698607428954e-07, 'reg_lambda': 3.5689607710101217}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:50:58,956] Trial 270 finished with value: -0.09497047956775488 and parameters: {'learning_rate': 0.015983063494900238, 'num_leaves': 176, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.512485222863689, 'bagging_fraction': 0.8584140545396225, 'reg_alpha': 2.7759188940688663e-07, 'reg_lambda': 0.001374914985743943}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:51:13,801] Trial 271 finished with value: -0.09428725065647513 and parameters: {'learning_rate': 0.01580988248334856, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5245983550029812, 'bagging_fraction': 0.8638666810090172, 'reg_alpha': 2.605298435080575e-07, 'reg_lambda': 0.0012225161188635}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:51:29,211] Trial 272 finished with value: -0.09293346842760467 and parameters: {'learning_rate': 0.016148882689373128, 'num_leaves': 171, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.500372264583658, 'bagging_fraction': 0.8517359319452648, 'reg_alpha': 2.0559715072831773e-07, 'reg_lambda': 0.0013037476301157298}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:51:42,442] Trial 273 finished with value: -0.09222954564206862 and parameters: {'learning_rate': 0.01886159914882029, 'num_leaves': 162, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5209979620885022, 'bagging_fraction': 0.8665052236796659, 'reg_alpha': 3.4972681899200083e-07, 'reg_lambda': 0.0004945636307261592}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:51:50,158] Trial 274 finished with value: -0.08385281139627362 and parameters: {'learning_rate': 0.09538858138564994, 'num_leaves': 177, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5129512008914503, 'bagging_fraction': 0.9227538343120985, 'reg_alpha': 2.855694185767377e-07, 'reg_lambda': 0.0008299221478584236}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:52:05,974] Trial 275 finished with value: -0.09297700873375968 and parameters: {'learning_rate': 0.015547757782913023, 'num_leaves': 170, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5412187595511722, 'bagging_fraction': 0.8907049152118285, 'reg_alpha': 6.702661748634392e-07, 'reg_lambda': 0.0017500191717489506}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:52:14,934] Trial 276 finished with value: -0.08376926089736661 and parameters: {'learning_rate': 0.017534862722000968, 'num_leaves': 174, 'max_depth': 14, 'min_child_samples': 48, 'feature_fraction': 0.5247561225548599, 'bagging_fraction': 0.7857557151284794, 'reg_alpha': 4.4394308854031853e-07, 'reg_lambda': 0.0011453942225562036}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:52:33,055] Trial 277 finished with value: -0.0926084892450949 and parameters: {'learning_rate': 0.012715278273508664, 'num_leaves': 164, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5536470806779431, 'bagging_fraction': 0.9822153859452438, 'reg_alpha': 2.2334235832251125e-07, 'reg_lambda': 0.002366355058511931}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:52:40,767] Trial 278 finished with value: -0.08534587751293086 and parameters: {'learning_rate': 0.01581783876434871, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5118868185444996, 'bagging_fraction': 0.883397132125102, 'reg_alpha': 9.164530600989088e-07, 'reg_lambda': 0.0039004192972634773}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:52:56,066] Trial 279 finished with value: -0.09240682394722505 and parameters: {'learning_rate': 0.016982685216036294, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5329781620032971, 'bagging_fraction': 0.8709936958998321, 'reg_alpha': 5.683593606611592e-07, 'reg_lambda': 0.02045139016119533}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:53:02,674] Trial 280 finished with value: -0.07773584395181853 and parameters: {'learning_rate': 0.14897640392427236, 'num_leaves': 169, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5210754743173971, 'bagging_fraction': 0.8476115121032337, 'reg_alpha': 1.6084922613851883e-07, 'reg_lambda': 0.001552252083734805}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:53:06,522] Trial 281 finished with value: -0.04729213107558811 and parameters: {'learning_rate': 0.011439456892549157, 'num_leaves': 176, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5424789849765238, 'bagging_fraction': 0.8512603219890806, 'reg_alpha': 3.032706826204873, 'reg_lambda': 4.748822058969427}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:53:18,065] Trial 282 finished with value: -0.08645960495907785 and parameters: {'learning_rate': 0.020509447728807466, 'num_leaves': 184, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.7985894774966139, 'bagging_fraction': 0.5003025634882863, 'reg_alpha': 3.4697624821638796e-07, 'reg_lambda': 0.0007042008765516589}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:53:33,643] Trial 283 finished with value: -0.09209551107582567 and parameters: {'learning_rate': 0.014302115351366277, 'num_leaves': 201, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.510750458394226, 'bagging_fraction': 0.5113847875405354, 'reg_alpha': 1.2487451443976691e-06, 'reg_lambda': 5.810535338606005e-05}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:53:49,183] Trial 284 finished with value: -0.09274294258978924 and parameters: {'learning_rate': 0.018173461735082327, 'num_leaves': 208, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5281466747285077, 'bagging_fraction': 0.8444566141453478, 'reg_alpha': 2.781755246967766e-07, 'reg_lambda': 0.03112310596716786}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:54:05,710] Trial 285 finished with value: -0.09185354847202823 and parameters: {'learning_rate': 0.013445645261496938, 'num_leaves': 180, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5192840663356802, 'bagging_fraction': 0.5299595417680756, 'reg_alpha': 5.93067055347868e-08, 'reg_lambda': 0.01275731157534958}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:54:21,579] Trial 286 finished with value: -0.09184482020336691 and parameters: {'learning_rate': 0.01521847117877384, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5068181304828878, 'bagging_fraction': 0.5118444344702227, 'reg_alpha': 5.565226026725576e-07, 'reg_lambda': 0.0022043150554367057}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:54:36,344] Trial 287 finished with value: -0.09128337175720572 and parameters: {'learning_rate': 0.016814444215682706, 'num_leaves': 165, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5355046581047163, 'bagging_fraction': 0.9073678294545149, 'reg_alpha': 1.9400754593718962e-07, 'reg_lambda': 1.0103674224967112}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:54:55,449] Trial 288 finished with value: -0.09103063058436085 and parameters: {'learning_rate': 0.01190527870223073, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5486426796516848, 'bagging_fraction': 0.5249588235541454, 'reg_alpha': 1.0960121227383926e-07, 'reg_lambda': 0.08159521593437516}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:55:07,920] Trial 289 finished with value: -0.09171407408609787 and parameters: {'learning_rate': 0.018663505679150417, 'num_leaves': 157, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5255954649940657, 'bagging_fraction': 0.5467775601576145, 'reg_alpha': 8.530593348280937e-07, 'reg_lambda': 0.0034372345201833282}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:55:22,188] Trial 290 finished with value: -0.08430182095613324 and parameters: {'learning_rate': 0.016022380564159187, 'num_leaves': 197, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.9428035044451778, 'bagging_fraction': 0.5004052736656814, 'reg_alpha': 1.4740458886561693e-07, 'reg_lambda': 0.000284941760410134}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:55:40,616] Trial 291 finished with value: -0.09273482183839009 and parameters: {'learning_rate': 0.012645474265257542, 'num_leaves': 183, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5177057199557596, 'bagging_fraction': 0.8250628536048414, 'reg_alpha': 4.327978041224465e-07, 'reg_lambda': 0.006684378991958996}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:55:55,923] Trial 292 finished with value: -0.09233245112934142 and parameters: {'learning_rate': 0.014948616953758405, 'num_leaves': 170, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5394493709179564, 'bagging_fraction': 0.5178385614846283, 'reg_alpha': 1.40473088481405e-06, 'reg_lambda': 0.0018673130817378094}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:56:05,861] Trial 293 finished with value: -0.08516654698442408 and parameters: {'learning_rate': 0.013750434143106264, 'num_leaves': 243, 'max_depth': 15, 'min_child_samples': 76, 'feature_fraction': 0.5073392376454443, 'bagging_fraction': 0.5325657562569928, 'reg_alpha': 8.446070630003648e-08, 'reg_lambda': 0.6088072989330491}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:56:20,387] Trial 294 finished with value: -0.09124787116173781 and parameters: {'learning_rate': 0.0176280494809838, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.531570629776368, 'bagging_fraction': 0.5086130790419131, 'reg_alpha': 2.786180016735405e-07, 'reg_lambda': 0.004829076073343732}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:56:31,747] Trial 295 finished with value: -0.09283632819493134 and parameters: {'learning_rate': 0.01966937697154234, 'num_leaves': 160, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5184272370775668, 'bagging_fraction': 0.8572838305321072, 'reg_alpha': 9.319492396277498e-07, 'reg_lambda': 0.0011974411975911178}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:56:39,238] Trial 296 finished with value: -0.08382568850015669 and parameters: {'learning_rate': 0.016292779332014586, 'num_leaves': 184, 'max_depth': 8, 'min_child_samples': 39, 'feature_fraction': 0.501593371510735, 'bagging_fraction': 0.7382804896076365, 'reg_alpha': 6.814445405903508e-07, 'reg_lambda': 0.013491697567798486}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:56:56,769] Trial 297 finished with value: -0.09351342831219162 and parameters: {'learning_rate': 0.014452513058420626, 'num_leaves': 145, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5531050761084689, 'bagging_fraction': 0.5226013269161842, 'reg_alpha': 9.700690995057648e-06, 'reg_lambda': 6.602644065607861}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:57:11,432] Trial 298 finished with value: -0.0939664317822657 and parameters: {'learning_rate': 0.01537202743912757, 'num_leaves': 167, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5241320891728838, 'bagging_fraction': 0.8751027594521873, 'reg_alpha': 1.881077708848604e-07, 'reg_lambda': 0.0028845204317746553}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:57:24,251] Trial 299 finished with value: -0.0891572852051104 and parameters: {'learning_rate': 0.01545884682280107, 'num_leaves': 166, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.6901601895123982, 'bagging_fraction': 0.8774061363165636, 'reg_alpha': 2.2354170601959055e-07, 'reg_lambda': 0.13646888722585815}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:57:39,367] Trial 300 finished with value: -0.08540724030709264 and parameters: {'learning_rate': 0.01377288475328911, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.7760102576942862, 'bagging_fraction': 0.892999023719912, 'reg_alpha': 4.5330315457853395e-07, 'reg_lambda': 4.041128694265449}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:57:52,788] Trial 301 finished with value: -0.0902381631553529 and parameters: {'learning_rate': 0.01465515048249036, 'num_leaves': 162, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.5290181717407836, 'bagging_fraction': 0.8354914278533065, 'reg_alpha': 1.8959243377432803e-06, 'reg_lambda': 0.0021677710555681852}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:58:08,080] Trial 302 finished with value: -0.09053624917732978 and parameters: {'learning_rate': 0.01317077045917024, 'num_leaves': 176, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5423919000821542, 'bagging_fraction': 0.8580034782468351, 'reg_alpha': 1.5702304762015838e-07, 'reg_lambda': 0.0006027095506230388}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:58:22,916] Trial 303 finished with value: -0.09200408547927601 and parameters: {'learning_rate': 0.01564145130523905, 'num_leaves': 166, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5250357463426499, 'bagging_fraction': 0.5540008784085467, 'reg_alpha': 2.581959821188559e-07, 'reg_lambda': 0.004563691760634701}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:58:37,273] Trial 304 finished with value: -0.09206564134288572 and parameters: {'learning_rate': 0.016550237159550233, 'num_leaves': 170, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5368912660429341, 'bagging_fraction': 0.8743029511204234, 'reg_alpha': 3.393320457643103e-07, 'reg_lambda': 0.0011141572496683194}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:58:42,145] Trial 305 finished with value: -0.0705954721890009 and parameters: {'learning_rate': 0.014924281673950763, 'num_leaves': 179, 'max_depth': 3, 'min_child_samples': 17, 'feature_fraction': 0.5472745585624017, 'bagging_fraction': 0.8876831781915498, 'reg_alpha': 1.1246222741362007e-06, 'reg_lambda': 0.06459447912300766}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:58:59,528] Trial 306 finished with value: -0.09175076346293841 and parameters: {'learning_rate': 0.012529538919351692, 'num_leaves': 158, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.524732199093968, 'bagging_fraction': 0.5304641529989317, 'reg_alpha': 3.020454902404355e-06, 'reg_lambda': 0.009838959399984358}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:59:13,872] Trial 307 finished with value: -0.09121874986481852 and parameters: {'learning_rate': 0.01688176601581914, 'num_leaves': 187, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5000272937544603, 'bagging_fraction': 0.539862453700318, 'reg_alpha': 4.960418013900976e-07, 'reg_lambda': 3.510101816977688e-08}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:59:30,802] Trial 308 finished with value: -0.09378182244226711 and parameters: {'learning_rate': 0.01367033422459359, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5182900755041078, 'bagging_fraction': 0.5195963082995799, 'reg_alpha': 1.519987931347268e-07, 'reg_lambda': 1.5766019844276785e-08}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:59:44,536] Trial 309 finished with value: -0.09164963593145385 and parameters: {'learning_rate': 0.015679522581407607, 'num_leaves': 169, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.5356486581940187, 'bagging_fraction': 0.9011466302943726, 'reg_alpha': 6.62137106317154e-07, 'reg_lambda': 0.6028582379036053}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 07:59:59,267] Trial 310 finished with value: -0.09272684528510063 and parameters: {'learning_rate': 0.014555446190861316, 'num_leaves': 181, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5552551083412552, 'bagging_fraction': 0.6873845098382011, 'reg_alpha': 3.4932166746101443e-07, 'reg_lambda': 0.0031739525267145802}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:00:13,684] Trial 311 finished with value: -0.09347228363042735 and parameters: {'learning_rate': 0.017846658202997617, 'num_leaves': 163, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5119084656957338, 'bagging_fraction': 0.9557864352327314, 'reg_alpha': 1.8376821519845362e-07, 'reg_lambda': 2.186659509589664}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:00:23,731] Trial 312 finished with value: -0.08741823874571868 and parameters: {'learning_rate': 0.016453242817033732, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 42, 'feature_fraction': 0.5293447506984108, 'bagging_fraction': 0.8386369523640634, 'reg_alpha': 6.773328080098544e-08, 'reg_lambda': 5.967645080772641e-08}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:00:41,309] Trial 313 finished with value: -0.091532767975023 and parameters: {'learning_rate': 0.011596078529097888, 'num_leaves': 184, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5169925789917466, 'bagging_fraction': 0.5407349668283404, 'reg_alpha': 4.297279514667487e-06, 'reg_lambda': 0.017761297299521178}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:00:56,401] Trial 314 finished with value: -0.09063415960308001 and parameters: {'learning_rate': 0.012921068359864576, 'num_leaves': 171, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5415189401836142, 'bagging_fraction': 0.5161085624035695, 'reg_alpha': 4.164567993308599e-08, 'reg_lambda': 0.00018075199080834974}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:01:11,943] Trial 315 finished with value: -0.093196118022305 and parameters: {'learning_rate': 0.014155372093987671, 'num_leaves': 154, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5261620983606147, 'bagging_fraction': 0.8672402415866445, 'reg_alpha': 1.5229925772020459e-06, 'reg_lambda': 0.005864283246827736}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:01:28,422] Trial 316 finished with value: -0.08943343718208528 and parameters: {'learning_rate': 0.015615164441276417, 'num_leaves': 220, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.750672883741134, 'bagging_fraction': 0.5000865324953306, 'reg_alpha': 5.67633299773602e-07, 'reg_lambda': 2.4832791032760635e-08}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:01:42,500] Trial 317 finished with value: -0.09264630708876129 and parameters: {'learning_rate': 0.01733652097834387, 'num_leaves': 191, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5113870064757724, 'bagging_fraction': 0.5280211176982774, 'reg_alpha': 1.1294840322889807e-07, 'reg_lambda': 0.001711325561721098}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:01:58,266] Trial 318 finished with value: -0.09346145241729499 and parameters: {'learning_rate': 0.015040569304216307, 'num_leaves': 180, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.532190969580654, 'bagging_fraction': 0.5078066413532856, 'reg_alpha': 2.514715589028453e-07, 'reg_lambda': 0.029560090653027078}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:02:14,707] Trial 319 finished with value: -0.09321116405040655 and parameters: {'learning_rate': 0.016308496068944838, 'num_leaves': 187, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5465394260906444, 'bagging_fraction': 0.5162991551943352, 'reg_alpha': 9.608811152332186e-07, 'reg_lambda': 0.008834319941288379}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:02:30,181] Trial 320 finished with value: -0.09251627064556815 and parameters: {'learning_rate': 0.013987562302978715, 'num_leaves': 202, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5186406129539628, 'bagging_fraction': 0.5551737867328128, 'reg_alpha': 2.8750206572603617e-06, 'reg_lambda': 1.8620241093265807e-08}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:02:46,064] Trial 321 finished with value: -0.09399322986820549 and parameters: {'learning_rate': 0.01779578575165501, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5077709834707844, 'bagging_fraction': 0.5376687482164155, 'reg_alpha': 3.955202273450337e-07, 'reg_lambda': 1.026797738451355}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:03:00,913] Trial 322 finished with value: -0.09047414295384602 and parameters: {'learning_rate': 0.01806450838136439, 'num_leaves': 177, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5046205497538466, 'bagging_fraction': 0.5452736058827132, 'reg_alpha': 4.0289806013012956e-07, 'reg_lambda': 1.0753338947153084}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:03:15,435] Trial 323 finished with value: -0.09284924695609238 and parameters: {'learning_rate': 0.019412846438893527, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5088153383315867, 'bagging_fraction': 0.5366177598763783, 'reg_alpha': 7.009355845244781e-07, 'reg_lambda': 0.9613983530546335}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:03:30,192] Trial 324 finished with value: -0.09303859539042306 and parameters: {'learning_rate': 0.017248576171358835, 'num_leaves': 185, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5006015782919734, 'bagging_fraction': 0.5271268589416594, 'reg_alpha': 1.9932003838446194e-06, 'reg_lambda': 0.6373579774719278}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:03:46,088] Trial 325 finished with value: -0.09467050526770562 and parameters: {'learning_rate': 0.018004258269479892, 'num_leaves': 192, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5353144609175213, 'bagging_fraction': 0.5338781296800901, 'reg_alpha': 3.2359013266370114e-07, 'reg_lambda': 1.9807550335185287}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:04:00,387] Trial 326 finished with value: -0.08762635922044447 and parameters: {'learning_rate': 0.020840647512618615, 'num_leaves': 192, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.8551123448728838, 'bagging_fraction': 0.5489535053618843, 'reg_alpha': 1.577624203716207e-05, 'reg_lambda': 2.9591090040671757}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:04:16,342] Trial 327 finished with value: -0.09413135521285788 and parameters: {'learning_rate': 0.01852810133296851, 'num_leaves': 201, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5363786857404498, 'bagging_fraction': 0.5370778193474494, 'reg_alpha': 3.2360095286215463e-07, 'reg_lambda': 1.1145987965150095}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:04:32,867] Trial 328 finished with value: -0.09033538420994981 and parameters: {'learning_rate': 0.01901181898749677, 'num_leaves': 200, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5495725072899257, 'bagging_fraction': 0.5609651086366781, 'reg_alpha': 2.5216861126839367e-07, 'reg_lambda': 2.5247501080411494}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:04:49,340] Trial 329 finished with value: -0.0925858886716498 and parameters: {'learning_rate': 0.018649860748555763, 'num_leaves': 206, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5608661083525381, 'bagging_fraction': 0.5286753595618445, 'reg_alpha': 1.2098422737212084e-07, 'reg_lambda': 1.9268116404467894}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:05:04,731] Trial 330 finished with value: -0.09130825845927365 and parameters: {'learning_rate': 0.020057067648770813, 'num_leaves': 191, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5361029737111035, 'bagging_fraction': 0.5370071450583477, 'reg_alpha': 3.2465454902396026e-07, 'reg_lambda': 1.5425529427067886}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:05:19,366] Trial 331 finished with value: -0.08911441716143687 and parameters: {'learning_rate': 0.016975922080957086, 'num_leaves': 195, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5399872574523299, 'bagging_fraction': 0.5204613619401475, 'reg_alpha': 1.196905786091822e-06, 'reg_lambda': 0.0004611075748735581}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:05:32,105] Trial 332 finished with value: -0.08745426818804922 and parameters: {'learning_rate': 0.010758297504290417, 'num_leaves': 208, 'max_depth': 14, 'min_child_samples': 62, 'feature_fraction': 0.5537561323432869, 'bagging_fraction': 0.548951575301451, 'reg_alpha': 1.890145643543009e-07, 'reg_lambda': 1.5832080313840453}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:05:46,992] Trial 333 finished with value: -0.09345901840416684 and parameters: {'learning_rate': 0.021866199274055375, 'num_leaves': 200, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5320060444974792, 'bagging_fraction': 0.7152358952912796, 'reg_alpha': 5.002020991231101e-07, 'reg_lambda': 0.5251827052706697}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:06:04,536] Trial 334 finished with value: -0.09208194847346345 and parameters: {'learning_rate': 0.018048362074427754, 'num_leaves': 196, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5201528486933138, 'bagging_fraction': 0.5272148483313797, 'reg_alpha': 6.851298925540832e-06, 'reg_lambda': 5.532644082844042}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:06:22,038] Trial 335 finished with value: -0.0895065173925933 and parameters: {'learning_rate': 0.012022241590380487, 'num_leaves': 188, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.5402201337494289, 'bagging_fraction': 0.5166769957283965, 'reg_alpha': 9.134108368842029e-07, 'reg_lambda': 4.187371829298472}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:06:37,301] Trial 336 finished with value: -0.09412979451098895 and parameters: {'learning_rate': 0.019930132989503805, 'num_leaves': 212, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5279222101578928, 'bagging_fraction': 0.7889821412960629, 'reg_alpha': 8.532724487638908e-08, 'reg_lambda': 1.3410657659151577}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:06:53,179] Trial 337 finished with value: -0.09369053453694486 and parameters: {'learning_rate': 0.020395097206115858, 'num_leaves': 212, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5560362828237951, 'bagging_fraction': 0.508618188947615, 'reg_alpha': 6.399819682935652e-08, 'reg_lambda': 1.373482142779194}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:07:03,314] Trial 338 finished with value: -0.0915883260969935 and parameters: {'learning_rate': 0.04514843761667801, 'num_leaves': 220, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5456098920387616, 'bagging_fraction': 0.7971468814876841, 'reg_alpha': 2.774405202029319e-07, 'reg_lambda': 0.9229557350184832}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:07:07,592] Trial 339 finished with value: -0.07440403404376764 and parameters: {'learning_rate': 0.023119014931734672, 'num_leaves': 204, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.5354760278458403, 'bagging_fraction': 0.7514512807663049, 'reg_alpha': 1.358514706109719e-07, 'reg_lambda': 0.7067224109772496}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:07:23,235] Trial 340 finished with value: -0.09169264595352503 and parameters: {'learning_rate': 0.02088439177263688, 'num_leaves': 216, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5178927201287092, 'bagging_fraction': 0.76801531596752, 'reg_alpha': 6.16203555137643e-07, 'reg_lambda': 2.314485925583762}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:07:37,783] Trial 341 finished with value: -0.09364320428019678 and parameters: {'learning_rate': 0.019544664055048244, 'num_leaves': 147, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.527995636533703, 'bagging_fraction': 0.5213724725206071, 'reg_alpha': 4.238973081838472e-06, 'reg_lambda': 9.94914894722328}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:07:59,456] Trial 342 finished with value: -0.09099666169975289 and parameters: {'learning_rate': 0.012790776036756879, 'num_leaves': 212, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5151485585852122, 'bagging_fraction': 0.78018784032441, 'reg_alpha': 1.8789728905674895e-06, 'reg_lambda': 3.623477919832453}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:08:15,531] Trial 343 finished with value: -0.0922528796021175 and parameters: {'learning_rate': 0.01659304443364566, 'num_leaves': 162, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5299949913017135, 'bagging_fraction': 0.810457289548835, 'reg_alpha': 3.2983080618811315e-07, 'reg_lambda': 1.5156872010109854}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:08:29,980] Trial 344 finished with value: -0.0944771531969941 and parameters: {'learning_rate': 0.01894688268128731, 'num_leaves': 182, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5449892884822936, 'bagging_fraction': 0.8210490595887953, 'reg_alpha': 1.9300714577851118e-07, 'reg_lambda': 0.39000945827101796}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:08:45,765] Trial 345 finished with value: -0.08843663678953813 and parameters: {'learning_rate': 0.01885847065613064, 'num_leaves': 208, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5592348077274526, 'bagging_fraction': 0.5089672752924879, 'reg_alpha': 2.1101399556112968e-07, 'reg_lambda': 0.22522557641905536}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:08:54,057] Trial 346 finished with value: -0.08662981596058555 and parameters: {'learning_rate': 0.020490919446519328, 'num_leaves': 198, 'max_depth': 14, 'min_child_samples': 57, 'feature_fraction': 0.5478101065874954, 'bagging_fraction': 0.8299409584204684, 'reg_alpha': 1.5022387356325997e-07, 'reg_lambda': 0.42988790327173715}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:09:08,437] Trial 347 finished with value: -0.09064650814385651 and parameters: {'learning_rate': 0.021500334278847472, 'num_leaves': 184, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5645444641942291, 'bagging_fraction': 0.8073347431546299, 'reg_alpha': 4.184593882250135e-07, 'reg_lambda': 0.3498429564230275}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:09:22,497] Trial 348 finished with value: -0.09263102816038751 and parameters: {'learning_rate': 0.017694914685494095, 'num_leaves': 141, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.542425880037517, 'bagging_fraction': 0.829458276730324, 'reg_alpha': 2.4255792719647524e-07, 'reg_lambda': 0.6546577190732645}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:09:37,006] Trial 349 finished with value: -0.0917886948540012 and parameters: {'learning_rate': 0.01907022719826765, 'num_leaves': 181, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5360783090178759, 'bagging_fraction': 0.7740486022235208, 'reg_alpha': 8.465377762591595e-08, 'reg_lambda': 0.9399560251991451}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:09:52,461] Trial 350 finished with value: -0.0925540132614 and parameters: {'learning_rate': 0.016995574458067556, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5462829013476932, 'bagging_fraction': 0.7971414672739021, 'reg_alpha': 7.670646288663922e-07, 'reg_lambda': 2.7644614418854202e-05}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:10:08,195] Trial 351 finished with value: -0.09386318675996362 and parameters: {'learning_rate': 0.016249268699103623, 'num_leaves': 204, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5235869939478145, 'bagging_fraction': 0.73965675518284, 'reg_alpha': 4.4673531804226264e-08, 'reg_lambda': 0.0165084300843509}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:10:18,239] Trial 352 finished with value: -0.08668942241987822 and parameters: {'learning_rate': 0.01825358101448196, 'num_leaves': 154, 'max_depth': 15, 'min_child_samples': 36, 'feature_fraction': 0.5353625805220609, 'bagging_fraction': 0.8038452606014506, 'reg_alpha': 1.331024140824923e-07, 'reg_lambda': 0.4146769886210365}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:10:26,884] Trial 353 finished with value: -0.08678611005068164 and parameters: {'learning_rate': 0.01972045851275275, 'num_leaves': 194, 'max_depth': 15, 'min_child_samples': 95, 'feature_fraction': 0.525421837303672, 'bagging_fraction': 0.7919952729559672, 'reg_alpha': 3.0192668283899205e-07, 'reg_lambda': 0.1576850280751161}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:10:41,019] Trial 354 finished with value: -0.08926185426803566 and parameters: {'learning_rate': 0.01605718073133639, 'num_leaves': 227, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.5480045769238191, 'bagging_fraction': 0.8210386082864853, 'reg_alpha': 4.7172650708244525e-07, 'reg_lambda': 1.9017478383774977}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:10:56,623] Trial 355 finished with value: -0.09134781150742984 and parameters: {'learning_rate': 0.0176277454208772, 'num_leaves': 180, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5361338282333136, 'bagging_fraction': 0.8418969699505265, 'reg_alpha': 1.8340587477054088e-07, 'reg_lambda': 1.1748638187873097}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:11:05,112] Trial 356 finished with value: -0.08709090211315887 and parameters: {'learning_rate': 0.01872575321618986, 'num_leaves': 168, 'max_depth': 15, 'min_child_samples': 89, 'feature_fraction': 0.5202027192630113, 'bagging_fraction': 0.8584212838286375, 'reg_alpha': 9.514540053762091e-08, 'reg_lambda': 0.031852288423163795}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:11:21,650] Trial 357 finished with value: -0.09251141132176173 and parameters: {'learning_rate': 0.015010618758032493, 'num_leaves': 189, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5588347992004039, 'bagging_fraction': 0.5013054712076834, 'reg_alpha': 9.939385814597617e-07, 'reg_lambda': 0.012046920119282817}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:11:37,592] Trial 358 finished with value: -0.09464804702144125 and parameters: {'learning_rate': 0.01712183971950497, 'num_leaves': 198, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5151863584989196, 'bagging_fraction': 0.5428827249240185, 'reg_alpha': 5.423068866101389e-07, 'reg_lambda': 0.6511002018032662}. Best is trial 223 with value: -0.09532691268294306.
[I 2025-08-04 08:11:52,070] Trial 359 finished with value: -0.09553885975288429 and parameters: {'learning_rate': 0.01692771404640214, 'num_leaves': 203, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5131690571749482, 'bagging_fraction': 0.5582418534553322, 'reg_alpha': 5.038538695600947e-07, 'reg_lambda': 0.2571515739177172}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:12:05,425] Trial 360 finished with value: -0.08934535468793608 and parameters: {'learning_rate': 0.016878214531475186, 'num_leaves': 198, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.5145468250883507, 'bagging_fraction': 0.5541314212611242, 'reg_alpha': 6.893546940596879e-07, 'reg_lambda': 0.3378424633242722}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:12:19,563] Trial 361 finished with value: -0.09343108568540118 and parameters: {'learning_rate': 0.015898519324841206, 'num_leaves': 203, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.5135482280976754, 'bagging_fraction': 0.557786321990702, 'reg_alpha': 4.822003295131271e-07, 'reg_lambda': 0.20354108686466846}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:12:33,500] Trial 362 finished with value: -0.09168618784538965 and parameters: {'learning_rate': 0.016878735635024053, 'num_leaves': 195, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.5086190098841484, 'bagging_fraction': 0.5628394414851604, 'reg_alpha': 1.2922792715943346e-06, 'reg_lambda': 0.13926422813815606}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:12:48,360] Trial 363 finished with value: -0.09122907263458864 and parameters: {'learning_rate': 0.015894264366488258, 'num_leaves': 200, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5003227317499415, 'bagging_fraction': 0.5441490068073739, 'reg_alpha': 6.835527788479027e-07, 'reg_lambda': 0.48519877694396046}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:13:02,130] Trial 364 finished with value: -0.0944830627823315 and parameters: {'learning_rate': 0.01764189431214388, 'num_leaves': 204, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5210135184941249, 'bagging_fraction': 0.5438539497213678, 'reg_alpha': 3.723953577760971e-07, 'reg_lambda': 0.2844873141784787}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:13:13,586] Trial 365 finished with value: -0.08239869583261969 and parameters: {'learning_rate': 0.01742399708948546, 'num_leaves': 194, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.8904328691868029, 'bagging_fraction': 0.5547097030545274, 'reg_alpha': 4.889308309923639e-07, 'reg_lambda': 0.25075524059816745}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:13:29,447] Trial 366 finished with value: -0.09282249424251814 and parameters: {'learning_rate': 0.015518959759311404, 'num_leaves': 207, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5153551534802104, 'bagging_fraction': 0.5672912380108708, 'reg_alpha': 9.806360108355556e-07, 'reg_lambda': 0.29307670353415227}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:13:42,381] Trial 367 finished with value: -0.0880076674416254 and parameters: {'learning_rate': 0.016579153889427038, 'num_leaves': 189, 'max_depth': 15, 'min_child_samples': 21, 'feature_fraction': 0.5100180641912826, 'bagging_fraction': 0.5402756185646311, 'reg_alpha': 1.324085910975201e-06, 'reg_lambda': 0.20811849981773461}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:13:56,359] Trial 368 finished with value: -0.09274650781205211 and parameters: {'learning_rate': 0.014574426051043943, 'num_leaves': 158, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5206534430098607, 'bagging_fraction': 0.5463301288451416, 'reg_alpha': 3.809434438741317e-07, 'reg_lambda': 0.11180124829970293}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:14:10,996] Trial 369 finished with value: -0.09183500873603075 and parameters: {'learning_rate': 0.01783173848552778, 'num_leaves': 183, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5216641394892192, 'bagging_fraction': 0.5325956981570791, 'reg_alpha': 7.731383222350696e-07, 'reg_lambda': 0.39586010950125045}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:14:18,619] Trial 370 finished with value: -0.08546837310565358 and parameters: {'learning_rate': 0.015962641726722748, 'num_leaves': 198, 'max_depth': 7, 'min_child_samples': 16, 'feature_fraction': 0.5081497505285603, 'bagging_fraction': 0.5270287140144645, 'reg_alpha': 4.1763098025067694e-07, 'reg_lambda': 0.6898733580116896}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:14:25,022] Trial 371 finished with value: -0.0834143295219203 and parameters: {'learning_rate': 0.015175063583890204, 'num_leaves': 206, 'max_depth': 6, 'min_child_samples': 20, 'feature_fraction': 0.5249951475629255, 'bagging_fraction': 0.54696993940729, 'reg_alpha': 6.422260687879848e-07, 'reg_lambda': 0.0008549932136724306}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:14:34,502] Trial 372 finished with value: -0.09065514150021367 and parameters: {'learning_rate': 0.017028977456178637, 'num_leaves': 65, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.512367626017983, 'bagging_fraction': 0.517554012403367, 'reg_alpha': 1.5627425145118645e-06, 'reg_lambda': 0.28362079515106947}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:14:47,274] Trial 373 finished with value: -0.09101293097914699 and parameters: {'learning_rate': 0.014208498351700804, 'num_leaves': 146, 'max_depth': 14, 'min_child_samples': 22, 'feature_fraction': 0.5304947750820792, 'bagging_fraction': 0.5325162672132179, 'reg_alpha': 2.652088828082883e-07, 'reg_lambda': 0.043490614172525706}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:15:02,035] Trial 374 finished with value: -0.0908255428257064 and parameters: {'learning_rate': 0.01641802529903147, 'num_leaves': 192, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5688720345477271, 'bagging_fraction': 0.560971995454554, 'reg_alpha': 1.892440841258153e-07, 'reg_lambda': 0.021705376163722912}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:15:16,233] Trial 375 finished with value: -0.09329219416918079 and parameters: {'learning_rate': 0.01806609063325999, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5420649396453702, 'bagging_fraction': 0.5102283065805849, 'reg_alpha': 4.4051970898454057e-07, 'reg_lambda': 0.5447691332647687}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:15:30,949] Trial 376 finished with value: -0.09403578711501151 and parameters: {'learning_rate': 0.015220890063572025, 'num_leaves': 170, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5224975695121623, 'bagging_fraction': 0.5257168846110113, 'reg_alpha': 9.550478667451367e-07, 'reg_lambda': 0.007594096691154286}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:15:45,399] Trial 377 finished with value: -0.09413618173880134 and parameters: {'learning_rate': 0.017398419415435632, 'num_leaves': 180, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.517538860934559, 'bagging_fraction': 0.5407028864027481, 'reg_alpha': 5.539513800383181e-07, 'reg_lambda': 0.18085890796653697}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:16:00,011] Trial 378 finished with value: -0.0913613146618203 and parameters: {'learning_rate': 0.014515320077514264, 'num_leaves': 163, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5524501384138083, 'bagging_fraction': 0.5008642061766057, 'reg_alpha': 1.3783536145869254e-05, 'reg_lambda': 0.06618828146444936}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:16:13,588] Trial 379 finished with value: -0.09059508618084147 and parameters: {'learning_rate': 0.01608646871944382, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5016074542579526, 'bagging_fraction': 0.5160195088471811, 'reg_alpha': 2.847267648600007e-07, 'reg_lambda': 1.497103838617835e-08}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:16:27,059] Trial 380 finished with value: -0.09335152652178476 and parameters: {'learning_rate': 0.017038244274476817, 'num_leaves': 191, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5344821696274074, 'bagging_fraction': 0.5247703771068211, 'reg_alpha': 2.285040452736383e-06, 'reg_lambda': 0.0005363740582769319}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:16:41,227] Trial 381 finished with value: -0.09428500100760218 and parameters: {'learning_rate': 0.018748587304275584, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5283752256101982, 'bagging_fraction': 0.5715986310492092, 'reg_alpha': 1.7737263939226614e-07, 'reg_lambda': 0.011451045532182664}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:16:53,899] Trial 382 finished with value: -0.0886205003764552 and parameters: {'learning_rate': 0.01924510695566973, 'num_leaves': 180, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.7112868370647347, 'bagging_fraction': 0.5774907207940585, 'reg_alpha': 1.4634731369095427e-07, 'reg_lambda': 0.012779272113754367}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:17:00,714] Trial 383 finished with value: -0.08064456108478749 and parameters: {'learning_rate': 0.018495327524856144, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 72, 'feature_fraction': 0.9900371946040163, 'bagging_fraction': 0.5604938133151087, 'reg_alpha': 2.1322656523041357e-07, 'reg_lambda': 0.009294235008062797}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:17:15,578] Trial 384 finished with value: -0.09331567831987332 and parameters: {'learning_rate': 0.013741626161748382, 'num_leaves': 177, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.5271121105108388, 'bagging_fraction': 0.5683809352856787, 'reg_alpha': 3.2191126518216024e-07, 'reg_lambda': 0.01895912242863173}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:17:29,410] Trial 385 finished with value: -0.09224397896745043 and parameters: {'learning_rate': 0.01842850772109114, 'num_leaves': 183, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5115559588349449, 'bagging_fraction': 0.5784636812186463, 'reg_alpha': 1.3691756299186977e-07, 'reg_lambda': 0.006053004660240326}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:17:41,591] Trial 386 finished with value: -0.09246528755322192 and parameters: {'learning_rate': 0.022282701125982227, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5383265806417588, 'bagging_fraction': 0.5524544601793926, 'reg_alpha': 1.8890465785219888e-07, 'reg_lambda': 0.0013158726282560126}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:17:58,101] Trial 387 finished with value: -0.08799469889779596 and parameters: {'learning_rate': 0.015233636081018045, 'num_leaves': 202, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5197529945947278, 'bagging_fraction': 0.5733608208012343, 'reg_alpha': 0.36347004505207214, 'reg_lambda': 0.4601197483973453}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:18:11,476] Trial 388 finished with value: -0.09421053750946372 and parameters: {'learning_rate': 0.01958289487297193, 'num_leaves': 167, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5270080517393877, 'bagging_fraction': 0.5475208944069481, 'reg_alpha': 5.44077621643085e-07, 'reg_lambda': 0.09803836127613413}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:18:24,850] Trial 389 finished with value: -0.08905004542058234 and parameters: {'learning_rate': 0.02022490424789605, 'num_leaves': 167, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5006801025450339, 'bagging_fraction': 0.5477375846873771, 'reg_alpha': 5.825371461101487e-07, 'reg_lambda': 0.18574505088632223}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:18:37,657] Trial 390 finished with value: -0.09474019324649416 and parameters: {'learning_rate': 0.021059449324290925, 'num_leaves': 163, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.525853348002471, 'bagging_fraction': 0.55838400069905, 'reg_alpha': 3.6315147765824606e-07, 'reg_lambda': 0.09611043307297999}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:18:45,985] Trial 391 finished with value: -0.0908186769416378 and parameters: {'learning_rate': 0.021178996906578085, 'num_leaves': 164, 'max_depth': 9, 'min_child_samples': 16, 'feature_fraction': 0.5152859316891829, 'bagging_fraction': 0.5621128406025409, 'reg_alpha': 3.283299041604772e-07, 'reg_lambda': 0.05790147686843378}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:18:58,473] Trial 392 finished with value: -0.09045333486602673 and parameters: {'learning_rate': 0.02318253974266135, 'num_leaves': 166, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5292285099543758, 'bagging_fraction': 0.5553495591720073, 'reg_alpha': 2.267111006922116e-07, 'reg_lambda': 0.10327356008396628}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:19:10,303] Trial 393 finished with value: -0.09347697801264913 and parameters: {'learning_rate': 0.019937297610693096, 'num_leaves': 160, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5220919100478109, 'bagging_fraction': 0.5626195025115326, 'reg_alpha': 4.009090209550187e-07, 'reg_lambda': 0.06955707903618498}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:19:23,766] Trial 394 finished with value: -0.09298187617991939 and parameters: {'learning_rate': 0.02182133828714646, 'num_leaves': 170, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5095655954137915, 'bagging_fraction': 0.5698494859009815, 'reg_alpha': 2.540525214567287e-07, 'reg_lambda': 0.10409896010623533}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:19:35,847] Trial 395 finished with value: -0.09194431527008519 and parameters: {'learning_rate': 0.02479905902072587, 'num_leaves': 196, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5295447843587516, 'bagging_fraction': 0.5465393791424616, 'reg_alpha': 1.058771095052834e-07, 'reg_lambda': 0.035329045425027905}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:19:46,617] Trial 396 finished with value: -0.08521714221715765 and parameters: {'learning_rate': 0.020517935573455704, 'num_leaves': 209, 'max_depth': 15, 'min_child_samples': 21, 'feature_fraction': 0.6734728078977535, 'bagging_fraction': 0.5398241398344421, 'reg_alpha': 5.340294752336407e-07, 'reg_lambda': 0.27078630707781837}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:19:59,562] Trial 397 finished with value: -0.09171760613989817 and parameters: {'learning_rate': 0.019241118877976665, 'num_leaves': 175, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5187179054140504, 'bagging_fraction': 0.5857577079184801, 'reg_alpha': 1.6999863023249166e-07, 'reg_lambda': 0.13524422644541226}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:20:09,191] Trial 398 finished with value: -0.08626501256567556 and parameters: {'learning_rate': 0.03764515469593288, 'num_leaves': 190, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5418281689548797, 'bagging_fraction': 0.5534290619314369, 'reg_alpha': 3.5887719787304003e-07, 'reg_lambda': 0.02545430866587129}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:20:18,312] Trial 399 finished with value: -0.08762983788532136 and parameters: {'learning_rate': 0.019520239309363432, 'num_leaves': 169, 'max_depth': 15, 'min_child_samples': 47, 'feature_fraction': 0.5090709004679606, 'bagging_fraction': 0.9296606375107253, 'reg_alpha': 6.490143473215883e-08, 'reg_lambda': 0.011612076513051656}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:20:33,282] Trial 400 finished with value: -0.09376771924613907 and parameters: {'learning_rate': 0.018733332965208512, 'num_leaves': 200, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5268855887030541, 'bagging_fraction': 0.5367786360778005, 'reg_alpha': 7.294473954247855e-07, 'reg_lambda': 0.2548190279609554}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:20:47,812] Trial 401 finished with value: -0.08955599746233027 and parameters: {'learning_rate': 0.019941813668099363, 'num_leaves': 177, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5004740484260763, 'bagging_fraction': 0.5463197713108419, 'reg_alpha': 3.047386099787414e-07, 'reg_lambda': 0.3750821645307478}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:21:00,829] Trial 402 finished with value: -0.09175511538856895 and parameters: {'learning_rate': 0.02122034900103257, 'num_leaves': 185, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5337276045178152, 'bagging_fraction': 0.5568027758898736, 'reg_alpha': 1.4977166612746867e-07, 'reg_lambda': 0.742074478219525}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:21:15,198] Trial 403 finished with value: -0.0935285396624916 and parameters: {'learning_rate': 0.017803963243809024, 'num_leaves': 159, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5182779271371382, 'bagging_fraction': 0.5362464774805902, 'reg_alpha': 5.139464576783003e-07, 'reg_lambda': 0.016063840699232387}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:21:28,462] Trial 404 finished with value: -0.09057662965316292 and parameters: {'learning_rate': 0.02157847531374281, 'num_leaves': 217, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5419124396773642, 'bagging_fraction': 0.5715096797320398, 'reg_alpha': 2.419500608586162e-07, 'reg_lambda': 0.04014548166919716}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:21:35,888] Trial 405 finished with value: -0.08395316350888607 and parameters: {'learning_rate': 0.08412889203928021, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5249372740958557, 'bagging_fraction': 0.5314404663780328, 'reg_alpha': 2.636381332969843e-08, 'reg_lambda': 0.14859526868128253}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:21:50,233] Trial 406 finished with value: -0.09136481253959725 and parameters: {'learning_rate': 0.01865576088402184, 'num_leaves': 196, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5112536301606675, 'bagging_fraction': 0.5467852703918932, 'reg_alpha': 3.819851070524494e-07, 'reg_lambda': 0.00558616536348875}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:22:01,397] Trial 407 finished with value: -0.09117440384777113 and parameters: {'learning_rate': 0.019586336326723602, 'num_leaves': 166, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.5335295200882525, 'bagging_fraction': 0.5639500731362106, 'reg_alpha': 1.0833388434585679e-07, 'reg_lambda': 0.00012117791455332924}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:22:16,454] Trial 408 finished with value: -0.0924621150820471 and parameters: {'learning_rate': 0.01788176377257134, 'num_leaves': 181, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5195039393576459, 'bagging_fraction': 0.5405088053943442, 'reg_alpha': 7.222643687817417e-07, 'reg_lambda': 0.541600993932846}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:22:26,661] Trial 409 finished with value: -0.08497253169843051 and parameters: {'learning_rate': 0.01743612909212159, 'num_leaves': 192, 'max_depth': 15, 'min_child_samples': 44, 'feature_fraction': 0.508907002621506, 'bagging_fraction': 0.5266175221289453, 'reg_alpha': 1.9735922277673096e-07, 'reg_lambda': 0.01044070568002717}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:22:40,777] Trial 410 finished with value: -0.0905903874586166 and parameters: {'learning_rate': 0.02069031977699429, 'num_leaves': 206, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5442986766190416, 'bagging_fraction': 0.5796588945570907, 'reg_alpha': 4.780097337306304e-07, 'reg_lambda': 0.00032827614477197594}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:22:55,575] Trial 411 finished with value: -0.08673275363298077 and parameters: {'learning_rate': 0.013543857540186739, 'num_leaves': 177, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.8153285638286045, 'bagging_fraction': 0.5348817339988274, 'reg_alpha': 5.044180958147116e-08, 'reg_lambda': 0.35217008312479514}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:23:04,048] Trial 412 finished with value: -0.06662146948844377 and parameters: {'learning_rate': 0.18953551357756604, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.529455096417843, 'bagging_fraction': 0.5569312260564391, 'reg_alpha': 2.705774058253849e-07, 'reg_lambda': 0.02038016357431592}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:23:23,961] Trial 413 finished with value: -0.09218974368616166 and parameters: {'learning_rate': 0.010733942875550653, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.515767255236976, 'bagging_fraction': 0.5263855163985879, 'reg_alpha': 1.2281496958084622e-07, 'reg_lambda': 0.08593474402899373}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:23:35,123] Trial 414 finished with value: -0.09121028699005379 and parameters: {'learning_rate': 0.024207040984331334, 'num_leaves': 163, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5255774274583473, 'bagging_fraction': 0.8624210742570828, 'reg_alpha': 8.584441820403838e-07, 'reg_lambda': 0.20069281256359}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:23:42,210] Trial 415 finished with value: -0.08664533419006824 and parameters: {'learning_rate': 0.022292102301738684, 'num_leaves': 48, 'max_depth': 15, 'min_child_samples': 23, 'feature_fraction': 0.5505390248479032, 'bagging_fraction': 0.5456094570284883, 'reg_alpha': 4.150007500236856e-07, 'reg_lambda': 0.7696039183574531}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:23:56,853] Trial 416 finished with value: -0.09139905742636506 and parameters: {'learning_rate': 0.01824697393572569, 'num_leaves': 203, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.536544510312325, 'bagging_fraction': 0.534228678161054, 'reg_alpha': 2.0257116557576322e-07, 'reg_lambda': 0.0008489270092294494}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:24:11,379] Trial 417 finished with value: -0.09005552883701658 and parameters: {'learning_rate': 0.01433482689000697, 'num_leaves': 189, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5002775604606138, 'bagging_fraction': 0.5707834720403546, 'reg_alpha': 7.128946865228361e-08, 'reg_lambda': 0.0036016854648416082}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:24:20,868] Trial 418 finished with value: -0.08493569016422971 and parameters: {'learning_rate': 0.016415498946505163, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 50, 'feature_fraction': 0.517752472223548, 'bagging_fraction': 0.5218850707227344, 'reg_alpha': 5.828943775277895e-07, 'reg_lambda': 0.007307792415393901}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:24:35,036] Trial 419 finished with value: -0.09133882156613102 and parameters: {'learning_rate': 0.017360425229825817, 'num_leaves': 199, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5329487869500574, 'bagging_fraction': 0.5571281904764106, 'reg_alpha': 3.1218040365143373e-07, 'reg_lambda': 0.0017226801668227632}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:24:49,068] Trial 420 finished with value: -0.0928664313430234 and parameters: {'learning_rate': 0.019058441147059766, 'num_leaves': 168, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5230839524412948, 'bagging_fraction': 0.5476868538621474, 'reg_alpha': 1.2253869850448312e-06, 'reg_lambda': 0.5444516168146981}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:24:53,032] Trial 421 finished with value: -0.0865171554890924 and parameters: {'learning_rate': 0.12307541508106605, 'num_leaves': 212, 'max_depth': 15, 'min_child_samples': 87, 'feature_fraction': 0.5431083609620204, 'bagging_fraction': 0.5308167386503163, 'reg_alpha': 1.4589285965227475e-07, 'reg_lambda': 0.27036134463442063}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:25:08,200] Trial 422 finished with value: -0.09120673815764417 and parameters: {'learning_rate': 0.015435108755320559, 'num_leaves': 183, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5105885616982679, 'bagging_fraction': 0.5221077716337112, 'reg_alpha': 3.635480410713104e-07, 'reg_lambda': 0.056206316288172666}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:25:26,048] Trial 423 finished with value: -0.0911749944876083 and parameters: {'learning_rate': 0.011799257672010332, 'num_leaves': 195, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5291678103199494, 'bagging_fraction': 0.5409642173654017, 'reg_alpha': 8.647692434801333e-07, 'reg_lambda': 0.004348515591541944}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:25:41,915] Trial 424 finished with value: -0.0929700379840562 and parameters: {'learning_rate': 0.01468648936636895, 'num_leaves': 175, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.508965771514059, 'bagging_fraction': 0.5178213988284904, 'reg_alpha': 1.7639557517517592e-07, 'reg_lambda': 0.012274977320609842}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:25:57,861] Trial 425 finished with value: -0.09314001669122993 and parameters: {'learning_rate': 0.016379588960059248, 'num_leaves': 190, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5176108758318151, 'bagging_fraction': 0.550734673210245, 'reg_alpha': 5.872947125605002e-07, 'reg_lambda': 0.024653880708118373}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:26:13,621] Trial 426 finished with value: -0.09139220638102345 and parameters: {'learning_rate': 0.013280008925273017, 'num_leaves': 156, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5401610388621656, 'bagging_fraction': 0.5300810805470911, 'reg_alpha': 2.683795246725564e-07, 'reg_lambda': 0.11243183982950068}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:26:27,385] Trial 427 finished with value: -0.09375232867493252 and parameters: {'learning_rate': 0.020450458889065753, 'num_leaves': 171, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5256178382302877, 'bagging_fraction': 0.5900987051681102, 'reg_alpha': 1.0194247004197449e-07, 'reg_lambda': 0.39445798763048157}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:26:40,037] Trial 428 finished with value: -0.08978694703950195 and parameters: {'learning_rate': 0.01784011748570336, 'num_leaves': 182, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5359060818511481, 'bagging_fraction': 0.5641672428767446, 'reg_alpha': 4.7097978289928467e-07, 'reg_lambda': 1.819440183517033e-05}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:26:50,944] Trial 429 finished with value: -0.08895532045851492 and parameters: {'learning_rate': 0.019139941806670377, 'num_leaves': 99, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5509115957417177, 'bagging_fraction': 0.5156193676220825, 'reg_alpha': 2.4173519376868004e-07, 'reg_lambda': 0.9005605862348021}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:27:01,868] Trial 430 finished with value: -0.08730290596063317 and parameters: {'learning_rate': 0.015965554339884072, 'num_leaves': 165, 'max_depth': 15, 'min_child_samples': 39, 'feature_fraction': 0.5097794297412367, 'bagging_fraction': 0.5395098698836022, 'reg_alpha': 1.0048832606699346e-06, 'reg_lambda': 0.15561075224486717}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:27:18,716] Trial 431 finished with value: -0.0921449666341507 and parameters: {'learning_rate': 0.014058466931496292, 'num_leaves': 177, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5199370217185002, 'bagging_fraction': 0.5238635893335772, 'reg_alpha': 3.3608213743060476e-07, 'reg_lambda': 0.007948690690438121}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:27:30,942] Trial 432 finished with value: -0.09295692014597036 and parameters: {'learning_rate': 0.02301759097403922, 'num_leaves': 187, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5292751653576061, 'bagging_fraction': 0.5541114048899649, 'reg_alpha': 1.3846890808634837e-07, 'reg_lambda': 5.4768028071192975e-05}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:27:46,744] Trial 433 finished with value: -0.09119028701805633 and parameters: {'learning_rate': 0.01736477717036591, 'num_leaves': 205, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5009654160489739, 'bagging_fraction': 0.5382010889933161, 'reg_alpha': 7.011652476807293e-07, 'reg_lambda': 0.015243976891221119}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:27:59,927] Trial 434 finished with value: -0.09080218772905545 and parameters: {'learning_rate': 0.012396108827348457, 'num_leaves': 193, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.5163706965586562, 'bagging_fraction': 0.5145767911383616, 'reg_alpha': 1.9798346145066344e-07, 'reg_lambda': 0.0014272354373342873}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:28:03,229] Trial 435 finished with value: -0.08127473345809383 and parameters: {'learning_rate': 0.05286949416475313, 'num_leaves': 15, 'max_depth': 15, 'min_child_samples': 21, 'feature_fraction': 0.542552092051788, 'bagging_fraction': 0.529495868831165, 'reg_alpha': 7.899548704478237e-08, 'reg_lambda': 0.2790800467591196}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:28:16,836] Trial 436 finished with value: -0.09135693973410262 and parameters: {'learning_rate': 0.01506324997644542, 'num_leaves': 162, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.526476861107799, 'bagging_fraction': 0.5681027537669496, 'reg_alpha': 4.780797995736133e-07, 'reg_lambda': 8.473201044756508e-06}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:28:31,664] Trial 437 finished with value: -0.09147734182357631 and parameters: {'learning_rate': 0.016741380130592873, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5539458172927191, 'bagging_fraction': 0.9059021505456123, 'reg_alpha': 1.5313910158513594e-06, 'reg_lambda': 0.00096108513251739}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:28:46,028] Trial 438 finished with value: -0.09252741442705092 and parameters: {'learning_rate': 0.018702933676371963, 'num_leaves': 182, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5332619812484672, 'bagging_fraction': 0.7027091306709876, 'reg_alpha': 3.854656673288812e-07, 'reg_lambda': 0.03863463179527585}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:29:02,829] Trial 439 finished with value: -0.09078751415801894 and parameters: {'learning_rate': 0.015840269225895865, 'num_leaves': 199, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5112341796141939, 'bagging_fraction': 0.514084538161894, 'reg_alpha': 2.2950540811876295e-07, 'reg_lambda': 0.002704031474837276}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:29:15,309] Trial 440 finished with value: -0.0927933233640977 and parameters: {'learning_rate': 0.020957431407010126, 'num_leaves': 178, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5196257842905001, 'bagging_fraction': 0.5406087367174467, 'reg_alpha': 1.3344530151672538e-07, 'reg_lambda': 0.7006710230584744}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:29:30,402] Trial 441 finished with value: -0.09114969860340764 and parameters: {'learning_rate': 0.014465278486604546, 'num_leaves': 168, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.7401098979349924, 'bagging_fraction': 0.5514853656186759, 'reg_alpha': 4.2492061204804e-08, 'reg_lambda': 0.4613049508786072}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:29:41,001] Trial 442 finished with value: -0.09294036847460503 and parameters: {'learning_rate': 0.019451247657513417, 'num_leaves': 93, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5372295435730337, 'bagging_fraction': 0.8810555147334486, 'reg_alpha': 7.404639871034319e-07, 'reg_lambda': 0.08673950670539103}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:29:50,107] Trial 443 finished with value: -0.09091197597836172 and parameters: {'learning_rate': 0.03388468857750944, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.5231847088364491, 'bagging_fraction': 0.5794353306010488, 'reg_alpha': 1.090630335105439e-06, 'reg_lambda': 0.0048440171940408285}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:30:03,017] Trial 444 finished with value: -0.08789236078205445 and parameters: {'learning_rate': 0.01778771095344196, 'num_leaves': 196, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5069353077312965, 'bagging_fraction': 0.5245888597173768, 'reg_alpha': 3.2545544080452077e-07, 'reg_lambda': 0.019550956969481146}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:30:21,687] Trial 445 finished with value: -0.09185192754201318 and parameters: {'learning_rate': 0.013393289801858357, 'num_leaves': 208, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.54392016257595, 'bagging_fraction': 0.5331741516193013, 'reg_alpha': 6.158848907217663e-07, 'reg_lambda': 0.0006041816492755081}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:30:29,554] Trial 446 finished with value: -0.08902580354854667 and parameters: {'learning_rate': 0.06674387802657059, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5310261847572632, 'bagging_fraction': 0.8549454112353956, 'reg_alpha': 9.863649681280409e-08, 'reg_lambda': 0.2099102451134398}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:30:44,799] Trial 447 finished with value: -0.0934481393599033 and parameters: {'learning_rate': 0.016755700948987252, 'num_leaves': 158, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5171550110003074, 'bagging_fraction': 0.6653047995963077, 'reg_alpha': 1.793176969960732e-07, 'reg_lambda': 0.009203148825077305}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:31:01,337] Trial 448 finished with value: -0.09279537207568629 and parameters: {'learning_rate': 0.015264467194846908, 'num_leaves': 191, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5086374996472502, 'bagging_fraction': 0.5106445341128865, 'reg_alpha': 4.408910544030725e-07, 'reg_lambda': 0.028529117556351707}. Best is trial 359 with value: -0.09553885975288429.
[I 2025-08-04 08:31:12,788] Trial 449 finished with value: -0.08846194915218827 and parameters: {'learning_rate': 0.011237991522485141, 'num_leaves': 202, 'max_depth': 8, 'min_child_samples': 13, 'feature_fraction': 0.5518725240303529, 'bagging_fraction': 0.5225834898157304, 'reg_alpha': 2.2900555984330129e-07, 'reg_lambda': 0.6820976382923909}. Best is trial 359 with value: -0.09553885975288429.
2025-08-04 08:31:15 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.11942531680770385, 'val_lightgbm': 0.07190868771301362, 'val_ensemble': 0.10988414318934225}
2025-08-04 08:31:15 [INFO] Selected best model 'catboost' with validation R²=0.1194
2025-08-04 08:31:15 [INFO] Retraining best model 'catboost' on full dataset
2025-08-04 08:31:30 [INFO] Retraining completed in 15.47s
2025-08-04 08:31:31 [INFO] Saved final model to '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/final_catboost.pkl'
2025-08-04 08:31:31 [INFO] Tree-based → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/final_catboost.pkl (R²=0.1194)
2025-08-04 08:31:31 [INFO] Training TabNet model...
[I 2025-08-04 08:31:31,326] A new study created in memory with name: no-name-f38b1d57-5852-4f6b-857e-c08f338adca6
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:31:48,831] Trial 0 finished with value: -0.0019907262600802333 and parameters: {'n_d': 14, 'n_a': 58, 'n_steps': 7, 'gamma': 1.2188038045780452, 'lambda_sparse': 2.2578923150142348e-05, 'lr': 0.0005125437610223044, 'weight_decay': 2.629293745521355e-05}. Best is trial 0 with value: -0.0019907262600802333.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:32:05,907] Trial 1 finished with value: -0.019828454578677768 and parameters: {'n_d': 51, 'n_a': 9, 'n_steps': 10, 'gamma': 1.284507369342855, 'lambda_sparse': 0.00026452147145758243, 'lr': 0.00014592628405839952, 'weight_decay': 1.4372654199646797e-06}. Best is trial 0 with value: -0.0019907262600802333.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:32:26,990] Trial 2 finished with value: -0.0009198059396910985 and parameters: {'n_d': 32, 'n_a': 13, 'n_steps': 3, 'gamma': 1.870523543779231, 'lambda_sparse': 0.0034997847913274876, 'lr': 0.0003005144398938253, 'weight_decay': 0.00017140688686282364}. Best is trial 2 with value: -0.0009198059396910985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:33:29,463] Trial 3 finished with value: 0.0849935346751135 and parameters: {'n_d': 26, 'n_a': 18, 'n_steps': 9, 'gamma': 1.058552468989312, 'lambda_sparse': 8.790520202072768e-05, 'lr': 0.04393574738049435, 'weight_decay': 0.0005448482100406778}. Best is trial 3 with value: 0.0849935346751135.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:33:57,783] Trial 4 finished with value: 0.0916576260540688 and parameters: {'n_d': 20, 'n_a': 47, 'n_steps': 3, 'gamma': 1.1244810537243448, 'lambda_sparse': 0.00015039920917057003, 'lr': 0.01066533128088967, 'weight_decay': 3.814859336964282e-05}. Best is trial 4 with value: 0.0916576260540688.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:34:19,571] Trial 5 finished with value: 0.013634183370739072 and parameters: {'n_d': 40, 'n_a': 47, 'n_steps': 9, 'gamma': 1.8813710572300277, 'lambda_sparse': 0.0005178907409905035, 'lr': 0.0013606216428135752, 'weight_decay': 2.919124562341344e-05}. Best is trial 4 with value: 0.0916576260540688.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:34:41,099] Trial 6 finished with value: -0.011417876418557737 and parameters: {'n_d': 30, 'n_a': 61, 'n_steps': 6, 'gamma': 1.7005703578933256, 'lambda_sparse': 0.000255705933503583, 'lr': 0.00014669093582253114, 'weight_decay': 3.0013564598446124e-06}. Best is trial 4 with value: 0.0916576260540688.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:35:30,874] Trial 7 finished with value: 0.0379940382677606 and parameters: {'n_d': 49, 'n_a': 48, 'n_steps': 7, 'gamma': 1.733592556573523, 'lambda_sparse': 6.573423343413452e-05, 'lr': 0.001684085380415024, 'weight_decay': 9.111590158575867e-05}. Best is trial 4 with value: 0.0916576260540688.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:35:42,397] Trial 8 finished with value: -0.05063216912512791 and parameters: {'n_d': 26, 'n_a': 8, 'n_steps': 6, 'gamma': 1.1958923294991906, 'lambda_sparse': 0.000342426282199716, 'lr': 0.00030780037868577555, 'weight_decay': 0.00022526286674250516}. Best is trial 4 with value: 0.0916576260540688.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:36:12,644] Trial 9 finished with value: 0.07342535414466267 and parameters: {'n_d': 14, 'n_a': 34, 'n_steps': 4, 'gamma': 1.8973716864093095, 'lambda_sparse': 0.0012826146052082607, 'lr': 0.07127810029380248, 'weight_decay': 7.641085175745326e-06}. Best is trial 4 with value: 0.0916576260540688.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:36:49,167] Trial 10 finished with value: 0.06957064393036472 and parameters: {'n_d': 61, 'n_a': 31, 'n_steps': 4, 'gamma': 1.4751644142482017, 'lambda_sparse': 0.009664005877046961, 'lr': 0.01129116320044104, 'weight_decay': 9.394300808268968e-06}. Best is trial 4 with value: 0.0916576260540688.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:37:55,650] Trial 11 finished with value: 0.09749683050485602 and parameters: {'n_d': 8, 'n_a': 24, 'n_steps': 9, 'gamma': 1.0258599810635323, 'lambda_sparse': 6.185341347958384e-05, 'lr': 0.019087981737426013, 'weight_decay': 0.0008316218314275001}. Best is trial 11 with value: 0.09749683050485602.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:38:48,541] Trial 12 finished with value: 0.10263349713439174 and parameters: {'n_d': 10, 'n_a': 24, 'n_steps': 8, 'gamma': 1.0114682272979847, 'lambda_sparse': 1.0845328703474128e-05, 'lr': 0.010374599820271387, 'weight_decay': 0.0008972473461391973}. Best is trial 12 with value: 0.10263349713439174.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:39:55,472] Trial 13 finished with value: 0.12607178007242403 and parameters: {'n_d': 10, 'n_a': 24, 'n_steps': 8, 'gamma': 1.0056632155448348, 'lambda_sparse': 1.0437082086836223e-05, 'lr': 0.010809876431030844, 'weight_decay': 0.000730893716337265}. Best is trial 13 with value: 0.12607178007242403.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:40:10,532] Trial 14 finished with value: 0.005520010416608878 and parameters: {'n_d': 9, 'n_a': 26, 'n_steps': 8, 'gamma': 1.3826578701756662, 'lambda_sparse': 1.1513236909267392e-05, 'lr': 0.005064171990309933, 'weight_decay': 0.0004410387975658312}. Best is trial 13 with value: 0.12607178007242403.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:40:28,755] Trial 15 finished with value: -0.0033498910196239073 and parameters: {'n_d': 19, 'n_a': 21, 'n_steps': 8, 'gamma': 1.0066183936056867, 'lambda_sparse': 2.2364992459335882e-05, 'lr': 0.0035288111701470637, 'weight_decay': 0.00021746615753320727}. Best is trial 13 with value: 0.12607178007242403.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:41:36,090] Trial 16 finished with value: 0.07936285500623286 and parameters: {'n_d': 40, 'n_a': 39, 'n_steps': 10, 'gamma': 1.330665407801809, 'lambda_sparse': 1.1288809460655518e-05, 'lr': 0.03131386508065368, 'weight_decay': 0.0008359028789234015}. Best is trial 13 with value: 0.12607178007242403.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:42:43,011] Trial 17 finished with value: 0.06446695423854887 and parameters: {'n_d': 19, 'n_a': 28, 'n_steps': 8, 'gamma': 1.5480398967804414, 'lambda_sparse': 3.0708652082086845e-05, 'lr': 0.005831917656150533, 'weight_decay': 9.321534416081804e-05}. Best is trial 13 with value: 0.12607178007242403.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:43:00,664] Trial 18 finished with value: -0.013220797482063729 and parameters: {'n_d': 13, 'n_a': 40, 'n_steps': 5, 'gamma': 1.1588764755618217, 'lambda_sparse': 3.838215198733447e-05, 'lr': 0.001519146006158768, 'weight_decay': 0.00036493431231422014}. Best is trial 13 with value: 0.12607178007242403.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:43:49,224] Trial 19 finished with value: 0.07149639778813544 and parameters: {'n_d': 24, 'n_a': 18, 'n_steps': 7, 'gamma': 1.4564359950443118, 'lambda_sparse': 1.1717062975894293e-05, 'lr': 0.01378704376562583, 'weight_decay': 9.125744108651006e-05}. Best is trial 13 with value: 0.12607178007242403.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:45:10,198] A new study created in memory with name: no-name-1fd56b9e-4e78-4078-ad0d-f31ba6afa16b
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:45:21,570] Trial 0 finished with value: 0.021780216379474027 and parameters: {'n_d': 60, 'n_a': 28, 'n_steps': 4, 'gamma': 1.729169131562899, 'lambda_sparse': 0.002304141259846235, 'lr': 0.00027224839914139913, 'weight_decay': 1.4068317891230146e-06}. Best is trial 0 with value: 0.021780216379474027.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:45:44,823] Trial 1 finished with value: 0.06654935947837415 and parameters: {'n_d': 50, 'n_a': 43, 'n_steps': 4, 'gamma': 1.2459649758410727, 'lambda_sparse': 0.0029620142973163007, 'lr': 0.03785153463367984, 'weight_decay': 0.0004103138494993406}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:45:56,487] Trial 2 finished with value: -0.0063729284518190266 and parameters: {'n_d': 31, 'n_a': 63, 'n_steps': 4, 'gamma': 1.882581374630652, 'lambda_sparse': 0.008622539225896878, 'lr': 0.00023403352795174447, 'weight_decay': 4.743753720682122e-05}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:46:28,242] Trial 3 finished with value: 0.03752853258647659 and parameters: {'n_d': 11, 'n_a': 17, 'n_steps': 3, 'gamma': 1.0449574073078718, 'lambda_sparse': 1.26947959398713e-05, 'lr': 0.002229030649083455, 'weight_decay': 3.0261412288674135e-05}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:47:08,202] Trial 4 finished with value: 0.05594412472175214 and parameters: {'n_d': 34, 'n_a': 44, 'n_steps': 4, 'gamma': 1.9084233485658477, 'lambda_sparse': 0.006532580261850808, 'lr': 0.006656329061385361, 'weight_decay': 3.64056385630363e-05}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:47:34,016] Trial 5 finished with value: -0.08617722104324765 and parameters: {'n_d': 28, 'n_a': 39, 'n_steps': 6, 'gamma': 1.2221880823506428, 'lambda_sparse': 0.006914506146015168, 'lr': 0.00011554481329392474, 'weight_decay': 2.5078033290770798e-05}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:47:56,266] Trial 6 finished with value: 0.011535645387506066 and parameters: {'n_d': 16, 'n_a': 39, 'n_steps': 9, 'gamma': 1.0766739626755073, 'lambda_sparse': 0.0011549747335278583, 'lr': 0.000910262568921528, 'weight_decay': 7.1897180854850545e-06}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:48:47,783] Trial 7 finished with value: 0.04283670638983117 and parameters: {'n_d': 60, 'n_a': 19, 'n_steps': 10, 'gamma': 1.5326306941985672, 'lambda_sparse': 0.0002524072988381682, 'lr': 0.043944098082706155, 'weight_decay': 1.7265578073027917e-05}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:49:25,481] Trial 8 finished with value: 0.04617790350036055 and parameters: {'n_d': 56, 'n_a': 13, 'n_steps': 6, 'gamma': 1.3695537749052984, 'lambda_sparse': 0.008810566577187526, 'lr': 0.08901729831043853, 'weight_decay': 9.4383966471306e-06}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:49:46,637] Trial 9 finished with value: 0.031637216392619516 and parameters: {'n_d': 47, 'n_a': 27, 'n_steps': 4, 'gamma': 1.5180334261450827, 'lambda_sparse': 2.9383266488915038e-05, 'lr': 0.06538909082059384, 'weight_decay': 5.389953237936282e-06}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:50:50,531] Trial 10 finished with value: 0.05539827150094978 and parameters: {'n_d': 46, 'n_a': 55, 'n_steps': 8, 'gamma': 1.3043748116703358, 'lambda_sparse': 0.0002951944036886126, 'lr': 0.016205967099247643, 'weight_decay': 0.00042065964708832876}. Best is trial 1 with value: 0.06654935947837415.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:51:27,357] Trial 11 finished with value: 0.07478458921409925 and parameters: {'n_d': 42, 'n_a': 48, 'n_steps': 5, 'gamma': 1.9941681121436816, 'lambda_sparse': 0.0016022794889580616, 'lr': 0.011339922897695306, 'weight_decay': 0.0009902727965337347}. Best is trial 11 with value: 0.07478458921409925.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:52:29,202] Trial 12 finished with value: 0.08538066299525471 and parameters: {'n_d': 45, 'n_a': 50, 'n_steps': 7, 'gamma': 1.7673244883716153, 'lambda_sparse': 0.0011473558394225181, 'lr': 0.017205567656621214, 'weight_decay': 0.0009714728642859647}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:53:30,792] Trial 13 finished with value: 0.0775411547205328 and parameters: {'n_d': 41, 'n_a': 53, 'n_steps': 7, 'gamma': 1.9998020191252057, 'lambda_sparse': 0.0008714849566265953, 'lr': 0.009719909928310571, 'weight_decay': 0.0009304053451281424}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:53:47,975] Trial 14 finished with value: 0.020191049136382255 and parameters: {'n_d': 23, 'n_a': 54, 'n_steps': 8, 'gamma': 1.7209597803441037, 'lambda_sparse': 0.000688581031125566, 'lr': 0.0026560878923628612, 'weight_decay': 0.00013809860856426007}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:54:48,473] Trial 15 finished with value: 0.08531334180985672 and parameters: {'n_d': 39, 'n_a': 62, 'n_steps': 7, 'gamma': 1.7005389859408917, 'lambda_sparse': 0.00011059951495578398, 'lr': 0.019948960983471486, 'weight_decay': 0.0009296867569286727}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:55:21,616] Trial 16 finished with value: 0.05907912410873106 and parameters: {'n_d': 38, 'n_a': 63, 'n_steps': 7, 'gamma': 1.6793258151259038, 'lambda_sparse': 0.00013591232113117698, 'lr': 0.02051243696138081, 'weight_decay': 0.00013544330987126177}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:56:13,313] Trial 17 finished with value: 0.04648647772736947 and parameters: {'n_d': 54, 'n_a': 59, 'n_steps': 8, 'gamma': 1.6386796097180447, 'lambda_sparse': 7.383115521006047e-05, 'lr': 0.004859560624202948, 'weight_decay': 0.0001550465334711436}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:56:58,774] Trial 18 finished with value: 0.054302755129383984 and parameters: {'n_d': 24, 'n_a': 30, 'n_steps': 9, 'gamma': 1.8320171060906987, 'lambda_sparse': 5.5067132334358396e-05, 'lr': 0.02660761990152245, 'weight_decay': 0.0004253299677070816}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:57:11,484] Trial 19 finished with value: 5.761475995735843e-06 and parameters: {'n_d': 35, 'n_a': 49, 'n_steps': 6, 'gamma': 1.5968075935139188, 'lambda_sparse': 0.0005637130195912499, 'lr': 0.0012416816838273085, 'weight_decay': 7.364700503659543e-05}. Best is trial 12 with value: 0.08538066299525471.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:58:31,536] A new study created in memory with name: no-name-b4ae53f0-bda8-4a3c-bbd5-9f840471a2df
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 08:59:23,338] Trial 0 finished with value: 0.06628381623204838 and parameters: {'n_d': 13, 'n_a': 11, 'n_steps': 6, 'gamma': 1.1074553472709567, 'lambda_sparse': 0.0007976687144482501, 'lr': 0.019158157832921047, 'weight_decay': 0.00042974445616853304}. Best is trial 0 with value: 0.06628381623204838.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:00:35,467] Trial 1 finished with value: 0.07595050981401907 and parameters: {'n_d': 59, 'n_a': 10, 'n_steps': 9, 'gamma': 1.1726314349049125, 'lambda_sparse': 0.009985526356473757, 'lr': 0.005523984871250267, 'weight_decay': 0.0007108178340430673}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:01:01,087] Trial 2 finished with value: 0.04016137948947829 and parameters: {'n_d': 14, 'n_a': 46, 'n_steps': 3, 'gamma': 1.5495967077681778, 'lambda_sparse': 0.00013495114163132905, 'lr': 0.0026970020560481834, 'weight_decay': 0.0008271040842908635}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:01:31,566] Trial 3 finished with value: 0.0734073315342405 and parameters: {'n_d': 53, 'n_a': 36, 'n_steps': 3, 'gamma': 1.61301752106781, 'lambda_sparse': 0.0009677640256696347, 'lr': 0.09333681733576743, 'weight_decay': 0.00024107904904801145}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:02:15,085] Trial 4 finished with value: 0.047352837312139906 and parameters: {'n_d': 44, 'n_a': 36, 'n_steps': 5, 'gamma': 1.440347990632747, 'lambda_sparse': 0.0023414410635802315, 'lr': 0.03594766382422295, 'weight_decay': 0.00015404318488883786}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:03:27,193] Trial 5 finished with value: 0.06645568740448804 and parameters: {'n_d': 44, 'n_a': 29, 'n_steps': 10, 'gamma': 1.918609056658655, 'lambda_sparse': 3.804677475374879e-05, 'lr': 0.04655227022570807, 'weight_decay': 0.000709825138947411}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:03:57,163] Trial 6 finished with value: 0.05152982723574895 and parameters: {'n_d': 36, 'n_a': 12, 'n_steps': 4, 'gamma': 1.7344669577922929, 'lambda_sparse': 0.009789209739788356, 'lr': 0.05846514623569194, 'weight_decay': 3.7534510257277034e-05}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:04:29,015] Trial 7 finished with value: 0.03994265438317146 and parameters: {'n_d': 58, 'n_a': 46, 'n_steps': 4, 'gamma': 1.338054876615963, 'lambda_sparse': 0.00742567831502968, 'lr': 0.013269474519067528, 'weight_decay': 2.895260061314807e-05}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:05:02,588] Trial 8 finished with value: 0.02343200917907806 and parameters: {'n_d': 10, 'n_a': 23, 'n_steps': 3, 'gamma': 1.314923505912244, 'lambda_sparse': 0.009102072253766448, 'lr': 0.0006829858170378558, 'weight_decay': 4.057187436249658e-06}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:05:56,994] Trial 9 finished with value: 0.041507088027590844 and parameters: {'n_d': 13, 'n_a': 26, 'n_steps': 6, 'gamma': 1.6677292687182041, 'lambda_sparse': 1.0674587686738693e-05, 'lr': 0.006775618602146569, 'weight_decay': 2.9146845323928154e-05}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:06:16,440] Trial 10 finished with value: 0.0022090489936565927 and parameters: {'n_d': 64, 'n_a': 58, 'n_steps': 9, 'gamma': 1.0206013738543032, 'lambda_sparse': 0.0002215748659860655, 'lr': 0.00018108042388523366, 'weight_decay': 1.1215931729493257e-06}. Best is trial 1 with value: 0.07595050981401907.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:07:30,832] Trial 11 finished with value: 0.08395968620982797 and parameters: {'n_d': 53, 'n_a': 63, 'n_steps': 9, 'gamma': 1.1582379876780342, 'lambda_sparse': 0.0012606502512084831, 'lr': 0.0018505494873379666, 'weight_decay': 0.00018564135497593505}. Best is trial 11 with value: 0.08395968620982797.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:08:38,539] Trial 12 finished with value: 0.08513469557505304 and parameters: {'n_d': 50, 'n_a': 63, 'n_steps': 8, 'gamma': 1.1908106128611065, 'lambda_sparse': 0.0021739952272249122, 'lr': 0.0020127619796109263, 'weight_decay': 0.0001011564080793769}. Best is trial 12 with value: 0.08513469557505304.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:09:45,930] Trial 13 finished with value: 0.05012830489938014 and parameters: {'n_d': 32, 'n_a': 64, 'n_steps': 8, 'gamma': 1.1768827552802168, 'lambda_sparse': 0.0018112711263073614, 'lr': 0.0012141623641701517, 'weight_decay': 8.468635403803185e-05}. Best is trial 12 with value: 0.08513469557505304.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:10:00,253] Trial 14 finished with value: -0.0064839972640715615 and parameters: {'n_d': 47, 'n_a': 54, 'n_steps': 8, 'gamma': 1.2964743655411273, 'lambda_sparse': 0.0003948111411683862, 'lr': 0.0004615310452086177, 'weight_decay': 9.34495170340431e-05}. Best is trial 12 with value: 0.08513469557505304.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:11:01,309] Trial 15 finished with value: 0.049258600864701685 and parameters: {'n_d': 27, 'n_a': 64, 'n_steps': 7, 'gamma': 1.087339452614921, 'lambda_sparse': 0.0029109421307907217, 'lr': 0.0017543331662988864, 'weight_decay': 7.473903738315996e-06}. Best is trial 12 with value: 0.08513469557505304.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:11:33,958] Trial 16 finished with value: -0.08967159611573994 and parameters: {'n_d': 50, 'n_a': 50, 'n_steps': 10, 'gamma': 1.2306116913462795, 'lambda_sparse': 0.0006131356097315776, 'lr': 0.0001359359426970279, 'weight_decay': 6.168457593677475e-05}. Best is trial 12 with value: 0.08513469557505304.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:11:55,790] Trial 17 finished with value: -0.04626225887121027 and parameters: {'n_d': 40, 'n_a': 57, 'n_steps': 8, 'gamma': 1.4244427277211504, 'lambda_sparse': 0.00010475091550977328, 'lr': 0.00036896238851107056, 'weight_decay': 1.1883962502334473e-05}. Best is trial 12 with value: 0.08513469557505304.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:12:57,684] Trial 18 finished with value: 0.09965173850557985 and parameters: {'n_d': 55, 'n_a': 42, 'n_steps': 7, 'gamma': 1.0099250437774066, 'lambda_sparse': 0.004344635124617683, 'lr': 0.004648348481071654, 'weight_decay': 0.00023071331875048053}. Best is trial 18 with value: 0.09965173850557985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:13:51,846] Trial 19 finished with value: 0.0770385285991162 and parameters: {'n_d': 25, 'n_a': 42, 'n_steps': 7, 'gamma': 1.0552565191930885, 'lambda_sparse': 0.003860083132468038, 'lr': 0.004972130288941574, 'weight_decay': 0.00033951506865020307}. Best is trial 18 with value: 0.09965173850557985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:15:04,790] A new study created in memory with name: no-name-37a38c2d-b5a1-414b-a09e-ecfcf7e62b91
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:15:43,016] Trial 0 finished with value: 0.10596603911848446 and parameters: {'n_d': 45, 'n_a': 48, 'n_steps': 4, 'gamma': 1.5074028031532005, 'lambda_sparse': 0.008049975212801192, 'lr': 0.01162567071360272, 'weight_decay': 0.0005705015655347898}. Best is trial 0 with value: 0.10596603911848446.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:15:55,112] Trial 1 finished with value: 0.0011809878495736559 and parameters: {'n_d': 34, 'n_a': 53, 'n_steps': 3, 'gamma': 1.1635636752375258, 'lambda_sparse': 1.942543985006347e-05, 'lr': 0.0004198093858583141, 'weight_decay': 0.0004982988419473978}. Best is trial 0 with value: 0.10596603911848446.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:16:05,156] Trial 2 finished with value: -0.042577159025996014 and parameters: {'n_d': 15, 'n_a': 26, 'n_steps': 5, 'gamma': 1.9090844323890914, 'lambda_sparse': 1.6254651873504422e-05, 'lr': 0.0004598224139187861, 'weight_decay': 5.18178157328158e-05}. Best is trial 0 with value: 0.10596603911848446.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:16:44,272] Trial 3 finished with value: 0.10056340970256428 and parameters: {'n_d': 59, 'n_a': 37, 'n_steps': 5, 'gamma': 1.7843948716019353, 'lambda_sparse': 6.759793620557251e-05, 'lr': 0.06544505941643047, 'weight_decay': 2.500456685813464e-05}. Best is trial 0 with value: 0.10596603911848446.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:17:51,805] Trial 4 finished with value: 0.10758599541166614 and parameters: {'n_d': 64, 'n_a': 34, 'n_steps': 8, 'gamma': 1.0503971459290766, 'lambda_sparse': 0.000808156463352341, 'lr': 0.004839522246313971, 'weight_decay': 0.00013532742378831358}. Best is trial 4 with value: 0.10758599541166614.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:18:06,229] Trial 5 finished with value: 0.002996062100811381 and parameters: {'n_d': 37, 'n_a': 35, 'n_steps': 7, 'gamma': 1.595874171528266, 'lambda_sparse': 7.901813751330529e-05, 'lr': 0.000617483750229815, 'weight_decay': 5.360254477302148e-06}. Best is trial 4 with value: 0.10758599541166614.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:18:40,351] Trial 6 finished with value: -0.06560592373882379 and parameters: {'n_d': 9, 'n_a': 40, 'n_steps': 9, 'gamma': 1.293220595375458, 'lambda_sparse': 1.4863553734151464e-05, 'lr': 0.00014457920043904282, 'weight_decay': 4.725605016781292e-06}. Best is trial 4 with value: 0.10758599541166614.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:19:23,472] Trial 7 finished with value: 0.04489959769942797 and parameters: {'n_d': 28, 'n_a': 25, 'n_steps': 8, 'gamma': 1.5263006064882976, 'lambda_sparse': 0.00018055460053538106, 'lr': 0.06576086948972244, 'weight_decay': 3.1553997195637324e-06}. Best is trial 4 with value: 0.10758599541166614.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:20:24,689] Trial 8 finished with value: 0.08819004922162976 and parameters: {'n_d': 32, 'n_a': 20, 'n_steps': 7, 'gamma': 1.4358293101405328, 'lambda_sparse': 0.00020282943979661156, 'lr': 0.024506952942091553, 'weight_decay': 7.1350353950136e-06}. Best is trial 4 with value: 0.10758599541166614.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:20:44,302] Trial 9 finished with value: 0.007618415230240316 and parameters: {'n_d': 54, 'n_a': 12, 'n_steps': 3, 'gamma': 1.6853927966622815, 'lambda_sparse': 0.0002674343000749746, 'lr': 0.00020840161416335885, 'weight_decay': 0.0005210112102174425}. Best is trial 4 with value: 0.10758599541166614.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:21:52,502] Trial 10 finished with value: 0.11463770035135235 and parameters: {'n_d': 63, 'n_a': 64, 'n_steps': 10, 'gamma': 1.0682971830769195, 'lambda_sparse': 0.0017606957331270296, 'lr': 0.0032668764630653813, 'weight_decay': 0.00010106437263709704}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:23:10,036] Trial 11 finished with value: 0.09801398916041004 and parameters: {'n_d': 64, 'n_a': 62, 'n_steps': 10, 'gamma': 1.0076727720240173, 'lambda_sparse': 0.0015812303370857169, 'lr': 0.0033377057290771193, 'weight_decay': 0.00010251604347063938}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:24:31,471] Trial 12 finished with value: 0.11327468950648578 and parameters: {'n_d': 51, 'n_a': 64, 'n_steps': 10, 'gamma': 1.0166170168229982, 'lambda_sparse': 0.0014293017482799237, 'lr': 0.002833678070751303, 'weight_decay': 0.00014820833818043622}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:25:52,238] Trial 13 finished with value: 0.008025080664257778 and parameters: {'n_d': 50, 'n_a': 63, 'n_steps': 10, 'gamma': 1.244524441322746, 'lambda_sparse': 0.0035522718039421443, 'lr': 0.0009500787474307995, 'weight_decay': 0.00014509804456614114}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:27:06,859] Trial 14 finished with value: 0.056708384760543185 and parameters: {'n_d': 44, 'n_a': 54, 'n_steps': 9, 'gamma': 1.1569160329015538, 'lambda_sparse': 0.0010072415702710353, 'lr': 0.0022315066618819536, 'weight_decay': 1.691728783501846e-05}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:28:27,956] Trial 15 finished with value: 0.062107914895662586 and parameters: {'n_d': 53, 'n_a': 57, 'n_steps': 10, 'gamma': 1.3494723317321662, 'lambda_sparse': 0.0025465740924445804, 'lr': 0.007150157728398448, 'weight_decay': 1.2501211847036388e-06}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:29:42,374] Trial 16 finished with value: 0.06395574056685338 and parameters: {'n_d': 57, 'n_a': 46, 'n_steps': 9, 'gamma': 1.09667824975394, 'lambda_sparse': 0.0056208122580088515, 'lr': 0.0014797180995120434, 'weight_decay': 5.3507867464434805e-05}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:30:32,695] Trial 17 finished with value: 0.10015986628773077 and parameters: {'n_d': 46, 'n_a': 64, 'n_steps': 8, 'gamma': 1.0037751492898936, 'lambda_sparse': 0.0007185112564500529, 'lr': 0.013422910242097488, 'weight_decay': 0.00026392512823671593}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:31:19,418] Trial 18 finished with value: 0.05972018590323602 and parameters: {'n_d': 23, 'n_a': 45, 'n_steps': 6, 'gamma': 1.3738029114347663, 'lambda_sparse': 0.0004974707130214446, 'lr': 0.0019641614025983347, 'weight_decay': 0.0002394931315174044}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:32:26,602] Trial 19 finished with value: 0.10198204337140282 and parameters: {'n_d': 40, 'n_a': 57, 'n_steps': 10, 'gamma': 1.2058117672674071, 'lambda_sparse': 0.001910487926066497, 'lr': 0.022923594706056694, 'weight_decay': 0.000978398474096093}. Best is trial 10 with value: 0.11463770035135235.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:33:55,191] A new study created in memory with name: no-name-85199e08-89ff-4d4a-8958-2d1f1e54ee63
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:34:16,104] Trial 0 finished with value: 0.02860753537699534 and parameters: {'n_d': 60, 'n_a': 54, 'n_steps': 4, 'gamma': 1.6574947078369853, 'lambda_sparse': 0.00022645550128605303, 'lr': 0.06988593509610073, 'weight_decay': 1.0050269187624264e-05}. Best is trial 0 with value: 0.02860753537699534.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:34:31,851] Trial 1 finished with value: 0.0053065966184215885 and parameters: {'n_d': 8, 'n_a': 45, 'n_steps': 9, 'gamma': 1.6577233689875719, 'lambda_sparse': 4.636537330239158e-05, 'lr': 0.0015655443134867549, 'weight_decay': 3.786221319566079e-05}. Best is trial 0 with value: 0.02860753537699534.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:34:44,283] Trial 2 finished with value: 0.0034620229407147374 and parameters: {'n_d': 14, 'n_a': 16, 'n_steps': 6, 'gamma': 1.4575978912135792, 'lambda_sparse': 0.0019395553211922565, 'lr': 0.0008700599242857968, 'weight_decay': 0.00013190843209202982}. Best is trial 0 with value: 0.02860753537699534.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:35:48,406] Trial 3 finished with value: 0.06644563216932686 and parameters: {'n_d': 37, 'n_a': 20, 'n_steps': 9, 'gamma': 1.894012302441035, 'lambda_sparse': 0.00014503693834456774, 'lr': 0.013185244226976311, 'weight_decay': 0.0006895118151336059}. Best is trial 3 with value: 0.06644563216932686.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:36:22,462] Trial 4 finished with value: 0.031117284438462733 and parameters: {'n_d': 14, 'n_a': 49, 'n_steps': 6, 'gamma': 1.9987731782838838, 'lambda_sparse': 0.00013629026239727707, 'lr': 0.03795204517566793, 'weight_decay': 1.5562561340475155e-05}. Best is trial 3 with value: 0.06644563216932686.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:36:56,612] Trial 5 finished with value: 0.08395094249088242 and parameters: {'n_d': 54, 'n_a': 53, 'n_steps': 3, 'gamma': 1.5703252603496765, 'lambda_sparse': 0.001915860342383409, 'lr': 0.004741415663510558, 'weight_decay': 0.0006541346314312084}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:38:02,092] Trial 6 finished with value: 0.05704273261641757 and parameters: {'n_d': 39, 'n_a': 64, 'n_steps': 8, 'gamma': 1.5544741815673917, 'lambda_sparse': 0.0009093280477605989, 'lr': 0.010622451286048072, 'weight_decay': 0.00013292963692003082}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:38:54,918] Trial 7 finished with value: 0.018991584619043933 and parameters: {'n_d': 52, 'n_a': 43, 'n_steps': 10, 'gamma': 1.5862807920309507, 'lambda_sparse': 0.007642441107068665, 'lr': 0.0053923305383973795, 'weight_decay': 8.034272789274596e-06}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:39:03,138] Trial 8 finished with value: -0.004529065161894996 and parameters: {'n_d': 35, 'n_a': 18, 'n_steps': 3, 'gamma': 1.1535666214552815, 'lambda_sparse': 0.002694845238271911, 'lr': 0.00021474742061644998, 'weight_decay': 6.418302083304803e-06}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:40:10,259] Trial 9 finished with value: 0.07181135910834457 and parameters: {'n_d': 26, 'n_a': 29, 'n_steps': 8, 'gamma': 1.9503071126668803, 'lambda_sparse': 0.00028208458448159327, 'lr': 0.008830838600561155, 'weight_decay': 0.00044160147116011257}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:40:25,518] Trial 10 finished with value: -0.0014537907172855746 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 4, 'gamma': 1.2264988238466397, 'lambda_sparse': 1.0250299808817792e-05, 'lr': 0.00010747296322441283, 'weight_decay': 1.6185518294256871e-06}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:40:45,318] Trial 11 finished with value: 0.014264298203113812 and parameters: {'n_d': 26, 'n_a': 30, 'n_steps': 7, 'gamma': 1.817673759221067, 'lambda_sparse': 0.0008802332243148426, 'lr': 0.0028891033908377286, 'weight_decay': 0.0008838682160895246}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:41:28,661] Trial 12 finished with value: 0.06661451948614083 and parameters: {'n_d': 50, 'n_a': 32, 'n_steps': 5, 'gamma': 1.3643619929961521, 'lambda_sparse': 0.0005529393209711826, 'lr': 0.019384343524719128, 'weight_decay': 0.0002526128265350819}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:42:09,142] Trial 13 finished with value: 0.01219338693558103 and parameters: {'n_d': 27, 'n_a': 8, 'n_steps': 7, 'gamma': 1.7571814401536132, 'lambda_sparse': 0.008008895336882187, 'lr': 0.0006653562197249708, 'weight_decay': 0.0003284156068690286}. Best is trial 5 with value: 0.08395094249088242.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:43:16,653] Trial 14 finished with value: 0.08967293349637717 and parameters: {'n_d': 49, 'n_a': 37, 'n_steps': 8, 'gamma': 1.0321042836437688, 'lambda_sparse': 5.66159364885388e-05, 'lr': 0.004937216625840678, 'weight_decay': 8.839005978704996e-05}. Best is trial 14 with value: 0.08967293349637717.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:43:51,838] Trial 15 finished with value: 0.06438564928246227 and parameters: {'n_d': 49, 'n_a': 54, 'n_steps': 3, 'gamma': 1.0367959969596288, 'lambda_sparse': 3.487111563050877e-05, 'lr': 0.002864649981027639, 'weight_decay': 4.9903321811064375e-05}. Best is trial 14 with value: 0.08967293349637717.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:44:38,517] Trial 16 finished with value: 0.05122100188120815 and parameters: {'n_d': 57, 'n_a': 43, 'n_steps': 5, 'gamma': 1.3510737717065955, 'lambda_sparse': 4.373041957275264e-05, 'lr': 0.004808278513182151, 'weight_decay': 0.00014375495536831935}. Best is trial 14 with value: 0.08967293349637717.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:45:45,724] Trial 17 finished with value: 0.07969879301805938 and parameters: {'n_d': 43, 'n_a': 38, 'n_steps': 8, 'gamma': 1.0157616658419657, 'lambda_sparse': 1.4817493151222584e-05, 'lr': 0.027629113641113142, 'weight_decay': 5.5998806181533424e-05}. Best is trial 14 with value: 0.08967293349637717.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:46:02,933] Trial 18 finished with value: -0.012032319848146233 and parameters: {'n_d': 45, 'n_a': 57, 'n_steps': 10, 'gamma': 1.4096577828737245, 'lambda_sparse': 0.003503061707536629, 'lr': 0.0005476742522622196, 'weight_decay': 1.6667044476955602e-06}. Best is trial 14 with value: 0.08967293349637717.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:46:13,064] Trial 19 finished with value: 0.012122995011095483 and parameters: {'n_d': 55, 'n_a': 37, 'n_steps': 5, 'gamma': 1.2453078720811273, 'lambda_sparse': 8.509114668303478e-05, 'lr': 0.0015961585297148103, 'weight_decay': 2.186048421041426e-05}. Best is trial 14 with value: 0.08967293349637717.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:47:48,183] A new study created in memory with name: no-name-01e09403-0adb-453d-b476-3ec59e7d80b0
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:48:13,589] Trial 0 finished with value: 0.06032357130651056 and parameters: {'n_d': 16, 'n_a': 41, 'n_steps': 5, 'gamma': 1.3163069271827454, 'lambda_sparse': 2.4777919976626566e-05, 'lr': 0.05756360332810862, 'weight_decay': 0.00026559440688676513}. Best is trial 0 with value: 0.06032357130651056.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:48:31,065] Trial 1 finished with value: 0.010577339795009522 and parameters: {'n_d': 21, 'n_a': 27, 'n_steps': 10, 'gamma': 1.077330008249866, 'lambda_sparse': 3.61604294866965e-05, 'lr': 0.00032437206517173657, 'weight_decay': 1.4041676231647913e-06}. Best is trial 0 with value: 0.06032357130651056.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:48:55,280] Trial 2 finished with value: 0.09879641110752746 and parameters: {'n_d': 34, 'n_a': 28, 'n_steps': 3, 'gamma': 1.5372457335358338, 'lambda_sparse': 0.0015700010052061722, 'lr': 0.005332381508831207, 'weight_decay': 5.613236856760331e-05}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:49:42,975] Trial 3 finished with value: 0.05429107496616259 and parameters: {'n_d': 33, 'n_a': 12, 'n_steps': 5, 'gamma': 1.6059630054284797, 'lambda_sparse': 0.004847905804944398, 'lr': 0.002663739899343922, 'weight_decay': 2.4990745343554162e-05}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:49:55,086] Trial 4 finished with value: -0.014540418028160085 and parameters: {'n_d': 58, 'n_a': 39, 'n_steps': 6, 'gamma': 1.401388916929896, 'lambda_sparse': 0.00032413771699455916, 'lr': 0.0004105442269616059, 'weight_decay': 9.632800021282405e-05}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:50:27,309] Trial 5 finished with value: -0.09978465477459864 and parameters: {'n_d': 54, 'n_a': 33, 'n_steps': 9, 'gamma': 1.53059248170046, 'lambda_sparse': 4.8842056351926114e-05, 'lr': 0.00011366261442019918, 'weight_decay': 1.6166555251525287e-06}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:51:46,173] Trial 6 finished with value: 0.0812315377409849 and parameters: {'n_d': 59, 'n_a': 18, 'n_steps': 10, 'gamma': 1.9161096764677374, 'lambda_sparse': 0.009999703337325161, 'lr': 0.03866706156790405, 'weight_decay': 6.146428571562665e-05}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:52:52,336] Trial 7 finished with value: 0.06392254474527326 and parameters: {'n_d': 14, 'n_a': 21, 'n_steps': 9, 'gamma': 1.3582240954289158, 'lambda_sparse': 0.0011690870386004226, 'lr': 0.04104525258817171, 'weight_decay': 2.431560369495442e-06}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:53:40,119] Trial 8 finished with value: 0.08080254364226447 and parameters: {'n_d': 21, 'n_a': 44, 'n_steps': 5, 'gamma': 1.0169875607234071, 'lambda_sparse': 0.0058325413792851295, 'lr': 0.003510500928024281, 'weight_decay': 7.385438534888835e-06}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:54:29,436] Trial 9 finished with value: 0.022871137741544034 and parameters: {'n_d': 30, 'n_a': 37, 'n_steps': 9, 'gamma': 1.2715737958816833, 'lambda_sparse': 0.0016040313450139212, 'lr': 0.0010605635813103502, 'weight_decay': 0.0004746684290515332}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:54:54,713] Trial 10 finished with value: 0.08019264233173673 and parameters: {'n_d': 44, 'n_a': 58, 'n_steps': 3, 'gamma': 1.8537263275512146, 'lambda_sparse': 0.00019692798508601589, 'lr': 0.011293933412496116, 'weight_decay': 1.7760340290169882e-05}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:55:24,203] Trial 11 finished with value: 0.08513822590603437 and parameters: {'n_d': 44, 'n_a': 9, 'n_steps': 3, 'gamma': 1.9762126096070314, 'lambda_sparse': 0.009653445264468973, 'lr': 0.014172103343865303, 'weight_decay': 0.00011177180796334094}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:55:51,215] Trial 12 finished with value: 0.058588452407992375 and parameters: {'n_d': 45, 'n_a': 9, 'n_steps': 3, 'gamma': 1.7379876218086372, 'lambda_sparse': 0.001956998456509835, 'lr': 0.010352414641979453, 'weight_decay': 0.0001423230371654877}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:56:20,337] Trial 13 finished with value: 0.09138899086436758 and parameters: {'n_d': 44, 'n_a': 55, 'n_steps': 3, 'gamma': 1.9999482456284647, 'lambda_sparse': 0.0004555829352527409, 'lr': 0.00932813024917088, 'weight_decay': 0.0006770578418921725}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:57:01,976] Trial 14 finished with value: 0.06519401230713273 and parameters: {'n_d': 37, 'n_a': 53, 'n_steps': 4, 'gamma': 1.6770136131188862, 'lambda_sparse': 0.00037030313749119307, 'lr': 0.0032554495479945066, 'weight_decay': 0.000777546646915787}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:57:51,422] Trial 15 finished with value: 0.06801527583595146 and parameters: {'n_d': 27, 'n_a': 50, 'n_steps': 7, 'gamma': 1.7710298955362525, 'lambda_sparse': 9.407109332098417e-05, 'lr': 0.006638883539582669, 'weight_decay': 0.0009690182636087323}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:58:04,574] Trial 16 finished with value: -0.024861330943603877 and parameters: {'n_d': 51, 'n_a': 60, 'n_steps': 7, 'gamma': 1.1799995341382323, 'lambda_sparse': 0.0005254694342257263, 'lr': 0.0012811708228082023, 'weight_decay': 8.181434882528177e-06}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:58:35,801] Trial 17 finished with value: 0.07601460496065504 and parameters: {'n_d': 37, 'n_a': 29, 'n_steps': 4, 'gamma': 1.4849570032880106, 'lambda_sparse': 1.2649847967134073e-05, 'lr': 0.023443664891656713, 'weight_decay': 0.0002909586885076121}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:59:10,489] Trial 18 finished with value: 0.0693298331967469 and parameters: {'n_d': 63, 'n_a': 48, 'n_steps': 4, 'gamma': 1.9861710852159185, 'lambda_sparse': 0.0008171969917220349, 'lr': 0.0051678827485888154, 'weight_decay': 4.650703928443056e-05}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 09:59:31,497] Trial 19 finished with value: 0.026320766280542918 and parameters: {'n_d': 49, 'n_a': 64, 'n_steps': 6, 'gamma': 1.8074866116215036, 'lambda_sparse': 0.00016017864534650743, 'lr': 0.0880670091266983, 'weight_decay': 9.595976022982728e-06}. Best is trial 2 with value: 0.09879641110752746.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:00:01,216] A new study created in memory with name: no-name-35b30fc7-449d-41f6-a12f-2cbbb9c0d1b0
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:00:40,711] Trial 0 finished with value: 0.047730639974140066 and parameters: {'n_d': 23, 'n_a': 28, 'n_steps': 6, 'gamma': 1.625072362439072, 'lambda_sparse': 0.00019220924012524322, 'lr': 0.0036261997694443282, 'weight_decay': 4.691982962666779e-05}. Best is trial 0 with value: 0.047730639974140066.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:01:13,170] Trial 1 finished with value: 0.0886220103821963 and parameters: {'n_d': 36, 'n_a': 38, 'n_steps': 4, 'gamma': 1.3585212451075297, 'lambda_sparse': 1.655444680898649e-05, 'lr': 0.03242726259383366, 'weight_decay': 0.00042725418303114884}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:01:52,111] Trial 2 finished with value: 0.08724962716485507 and parameters: {'n_d': 40, 'n_a': 54, 'n_steps': 4, 'gamma': 1.2564115110626717, 'lambda_sparse': 0.0052825101581005715, 'lr': 0.005236104230110323, 'weight_decay': 5.813768575207021e-06}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:03:06,270] Trial 3 finished with value: 0.06799392020866402 and parameters: {'n_d': 28, 'n_a': 48, 'n_steps': 9, 'gamma': 1.9841583857235727, 'lambda_sparse': 2.7668289940641313e-05, 'lr': 0.008732759985466017, 'weight_decay': 0.00014228759081218184}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:03:56,660] Trial 4 finished with value: 0.035496926241933346 and parameters: {'n_d': 31, 'n_a': 22, 'n_steps': 8, 'gamma': 1.6995224187374236, 'lambda_sparse': 0.0032101748840659143, 'lr': 0.0054785168269489756, 'weight_decay': 8.894923421292885e-06}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:04:12,137] Trial 5 finished with value: -0.013078463742744573 and parameters: {'n_d': 41, 'n_a': 28, 'n_steps': 9, 'gamma': 1.2675622658429329, 'lambda_sparse': 0.002983303269292917, 'lr': 0.00015335715786286304, 'weight_decay': 2.59582652650555e-05}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:05:26,446] Trial 6 finished with value: 0.0729657962576381 and parameters: {'n_d': 28, 'n_a': 20, 'n_steps': 9, 'gamma': 1.5363586338501092, 'lambda_sparse': 0.0023392899236295427, 'lr': 0.008393028050598538, 'weight_decay': 5.279901322619503e-05}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:05:32,357] Trial 7 finished with value: -0.0029261383151870657 and parameters: {'n_d': 16, 'n_a': 30, 'n_steps': 3, 'gamma': 1.1661201799253869, 'lambda_sparse': 0.008786616926527893, 'lr': 0.00035055607479907294, 'weight_decay': 8.121776043047707e-06}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:05:45,200] Trial 8 finished with value: 0.014934680635542485 and parameters: {'n_d': 57, 'n_a': 17, 'n_steps': 5, 'gamma': 1.8928733988989213, 'lambda_sparse': 8.469299719297482e-05, 'lr': 0.0017737756575149487, 'weight_decay': 4.9446305202480544e-05}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:06:09,236] Trial 9 finished with value: 0.07676281425390985 and parameters: {'n_d': 63, 'n_a': 63, 'n_steps': 3, 'gamma': 1.6465469955127974, 'lambda_sparse': 0.0034876213897879834, 'lr': 0.001145186120066341, 'weight_decay': 5.779475966624451e-06}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:06:46,140] Trial 10 finished with value: 0.05652637645934344 and parameters: {'n_d': 9, 'n_a': 42, 'n_steps': 7, 'gamma': 1.0185695220539397, 'lambda_sparse': 1.645985883905288e-05, 'lr': 0.07663365329533689, 'weight_decay': 0.0006580430747402533}. Best is trial 1 with value: 0.0886220103821963.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:07:32,783] Trial 11 finished with value: 0.12229760177456939 and parameters: {'n_d': 46, 'n_a': 58, 'n_steps': 5, 'gamma': 1.358390915327553, 'lambda_sparse': 0.0004776917075091991, 'lr': 0.03657314055627895, 'weight_decay': 1.402506752230148e-06}. Best is trial 11 with value: 0.12229760177456939.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:08:15,350] Trial 12 finished with value: 0.12501607507678014 and parameters: {'n_d': 50, 'n_a': 61, 'n_steps': 5, 'gamma': 1.4018354505148038, 'lambda_sparse': 0.0007387840622224854, 'lr': 0.07258821334706592, 'weight_decay': 1.0217885477984024e-06}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:08:57,184] Trial 13 finished with value: 0.08637433763127222 and parameters: {'n_d': 50, 'n_a': 64, 'n_steps': 6, 'gamma': 1.4180788957476655, 'lambda_sparse': 0.0006926192213920196, 'lr': 0.09465049977347414, 'weight_decay': 1.3652222680965096e-06}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:09:22,395] Trial 14 finished with value: 0.06057494508134664 and parameters: {'n_d': 50, 'n_a': 55, 'n_steps': 5, 'gamma': 1.4820998451427234, 'lambda_sparse': 0.0006696506798379772, 'lr': 0.025507484459727166, 'weight_decay': 1.0815234628422217e-06}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:10:12,332] Trial 15 finished with value: 0.0929078607691568 and parameters: {'n_d': 49, 'n_a': 56, 'n_steps': 7, 'gamma': 1.082782329276367, 'lambda_sparse': 0.0007175546433526084, 'lr': 0.02255598068325611, 'weight_decay': 1.971366504413797e-06}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:10:57,199] Trial 16 finished with value: 0.10480060367998478 and parameters: {'n_d': 45, 'n_a': 46, 'n_steps': 5, 'gamma': 1.3462332110645332, 'lambda_sparse': 0.00019725952619549386, 'lr': 0.047715027223817014, 'weight_decay': 2.905904653052707e-06}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:11:32,856] Trial 17 finished with value: 0.07416377035594357 and parameters: {'n_d': 58, 'n_a': 8, 'n_steps': 4, 'gamma': 1.7811033130593388, 'lambda_sparse': 0.0011419824563533442, 'lr': 0.014225687667325826, 'weight_decay': 3.0690942245184627e-06}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:12:15,408] Trial 18 finished with value: 0.1053760723407473 and parameters: {'n_d': 56, 'n_a': 59, 'n_steps': 6, 'gamma': 1.522998531103399, 'lambda_sparse': 7.896265367787036e-05, 'lr': 0.05162353052516306, 'weight_decay': 1.795171102330198e-05}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:13:34,762] Trial 19 finished with value: 0.06256523806565994 and parameters: {'n_d': 44, 'n_a': 49, 'n_steps': 10, 'gamma': 1.207285525896067, 'lambda_sparse': 0.0002691709282257581, 'lr': 0.015627040977099743, 'weight_decay': 3.143661240111419e-06}. Best is trial 12 with value: 0.12501607507678014.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:14:23,286] A new study created in memory with name: no-name-ee419220-7d85-4565-a1f8-774ee1884387
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:15:21,038] Trial 0 finished with value: 0.040511418512091946 and parameters: {'n_d': 53, 'n_a': 41, 'n_steps': 7, 'gamma': 1.311438117135154, 'lambda_sparse': 0.0025414182394114006, 'lr': 0.004369117667964735, 'weight_decay': 7.266980531407982e-06}. Best is trial 0 with value: 0.040511418512091946.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:15:56,749] Trial 1 finished with value: 0.05471229781876774 and parameters: {'n_d': 40, 'n_a': 62, 'n_steps': 4, 'gamma': 1.7374839426599156, 'lambda_sparse': 0.004180968276050222, 'lr': 0.01793836368125575, 'weight_decay': 3.4719692870308316e-06}. Best is trial 1 with value: 0.05471229781876774.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:16:20,070] Trial 2 finished with value: -0.0059614688254754356 and parameters: {'n_d': 52, 'n_a': 22, 'n_steps': 9, 'gamma': 1.8411318029663342, 'lambda_sparse': 0.008320858267803223, 'lr': 0.000290308269427886, 'weight_decay': 3.7274518007096687e-06}. Best is trial 1 with value: 0.05471229781876774.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:16:41,264] Trial 3 finished with value: 0.033253829722650674 and parameters: {'n_d': 39, 'n_a': 26, 'n_steps': 3, 'gamma': 1.3873974565155633, 'lambda_sparse': 2.8009315054523915e-05, 'lr': 0.003002010447309483, 'weight_decay': 2.626431843323519e-05}. Best is trial 1 with value: 0.05471229781876774.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:17:21,361] Trial 4 finished with value: 0.04514103921622892 and parameters: {'n_d': 59, 'n_a': 21, 'n_steps': 5, 'gamma': 1.2992608720290164, 'lambda_sparse': 1.3615392039191154e-05, 'lr': 0.001158257418217018, 'weight_decay': 1.4082414781931653e-05}. Best is trial 1 with value: 0.05471229781876774.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:18:14,561] Trial 5 finished with value: -0.0074175337650921325 and parameters: {'n_d': 54, 'n_a': 53, 'n_steps': 8, 'gamma': 1.3648469123729443, 'lambda_sparse': 5.953241194995705e-05, 'lr': 0.000554375730279698, 'weight_decay': 0.00011449651659233332}. Best is trial 1 with value: 0.05471229781876774.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:18:43,041] Trial 6 finished with value: 0.022039668149520297 and parameters: {'n_d': 15, 'n_a': 30, 'n_steps': 6, 'gamma': 1.3931696660291149, 'lambda_sparse': 0.0010611971635422666, 'lr': 0.0016449486671776198, 'weight_decay': 1.1266580842804608e-05}. Best is trial 1 with value: 0.05471229781876774.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:19:20,351] Trial 7 finished with value: 0.05559718565822569 and parameters: {'n_d': 62, 'n_a': 34, 'n_steps': 4, 'gamma': 1.9952321640134505, 'lambda_sparse': 0.009613294746893309, 'lr': 0.0204743432415484, 'weight_decay': 0.0005177779811460229}. Best is trial 7 with value: 0.05559718565822569.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:19:30,787] Trial 8 finished with value: 0.01126611479484907 and parameters: {'n_d': 34, 'n_a': 53, 'n_steps': 3, 'gamma': 1.643028725569263, 'lambda_sparse': 2.752409529152111e-05, 'lr': 0.0006759713329783912, 'weight_decay': 4.0887544453611566e-05}. Best is trial 7 with value: 0.05559718565822569.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:20:09,165] Trial 9 finished with value: 0.041843079015302154 and parameters: {'n_d': 33, 'n_a': 42, 'n_steps': 3, 'gamma': 1.0036942274776126, 'lambda_sparse': 6.0381665764558314e-05, 'lr': 0.0006822783307193305, 'weight_decay': 0.00022763064880392233}. Best is trial 7 with value: 0.05559718565822569.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:20:55,376] Trial 10 finished with value: 0.03943322667460192 and parameters: {'n_d': 13, 'n_a': 8, 'n_steps': 10, 'gamma': 1.855510751095566, 'lambda_sparse': 0.0003931417991869139, 'lr': 0.08241739733941823, 'weight_decay': 0.0007778609986944148}. Best is trial 7 with value: 0.05559718565822569.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:21:25,201] Trial 11 finished with value: 0.04349133674633432 and parameters: {'n_d': 43, 'n_a': 64, 'n_steps': 5, 'gamma': 1.9997871386040984, 'lambda_sparse': 0.009773951334913322, 'lr': 0.021945862652089924, 'weight_decay': 1.444591983935735e-06}. Best is trial 7 with value: 0.05559718565822569.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:22:11,146] Trial 12 finished with value: 0.07472325685875358 and parameters: {'n_d': 26, 'n_a': 50, 'n_steps': 5, 'gamma': 1.694155644993899, 'lambda_sparse': 0.0029792066169404456, 'lr': 0.014895924216830534, 'weight_decay': 0.0008781814353532669}. Best is trial 12 with value: 0.07472325685875358.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:22:46,263] Trial 13 finished with value: 0.03944144142139716 and parameters: {'n_d': 24, 'n_a': 48, 'n_steps': 5, 'gamma': 1.6034441065130953, 'lambda_sparse': 0.0013163401733582297, 'lr': 0.011190276799728551, 'weight_decay': 0.0009192954795578306}. Best is trial 12 with value: 0.07472325685875358.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:23:16,416] Trial 14 finished with value: 0.0365832722123296 and parameters: {'n_d': 64, 'n_a': 34, 'n_steps': 6, 'gamma': 1.9788208401343226, 'lambda_sparse': 0.00042952784471621437, 'lr': 0.07935451234899811, 'weight_decay': 0.00024499507121272904}. Best is trial 12 with value: 0.07472325685875358.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:23:58,614] Trial 15 finished with value: 0.08261982833950277 and parameters: {'n_d': 23, 'n_a': 43, 'n_steps': 4, 'gamma': 1.8138057415792292, 'lambda_sparse': 0.003463333771042246, 'lr': 0.007783145655665339, 'weight_decay': 0.0003784292421153777}. Best is trial 15 with value: 0.08261982833950277.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:24:59,729] Trial 16 finished with value: 0.044235770121109685 and parameters: {'n_d': 23, 'n_a': 50, 'n_steps': 7, 'gamma': 1.5751121382053597, 'lambda_sparse': 0.0010467500388567958, 'lr': 0.006330422211519939, 'weight_decay': 6.96497780143475e-05}. Best is trial 15 with value: 0.08261982833950277.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:25:26,736] Trial 17 finished with value: 0.04576424161887127 and parameters: {'n_d': 23, 'n_a': 42, 'n_steps': 4, 'gamma': 1.7719740038501675, 'lambda_sparse': 0.002839992017816441, 'lr': 0.04654079901000521, 'weight_decay': 0.0003426486430388974}. Best is trial 15 with value: 0.08261982833950277.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:26:09,354] Trial 18 finished with value: 0.03975163791645209 and parameters: {'n_d': 28, 'n_a': 57, 'n_steps': 5, 'gamma': 1.4988273516467758, 'lambda_sparse': 0.0001434780191828118, 'lr': 0.008240180272315217, 'weight_decay': 0.0001423581796592278}. Best is trial 15 with value: 0.08261982833950277.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:26:34,597] Trial 19 finished with value: 0.005247397749530758 and parameters: {'n_d': 10, 'n_a': 48, 'n_steps': 6, 'gamma': 1.742279096815702, 'lambda_sparse': 0.004120368578211055, 'lr': 0.0001605243713347003, 'weight_decay': 0.00045020958818500024}. Best is trial 15 with value: 0.08261982833950277.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:27:26,133] A new study created in memory with name: no-name-966a82e4-0f47-4baa-99bb-3cd4be9d4c1f
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:27:43,310] Trial 0 finished with value: 0.006524878949210167 and parameters: {'n_d': 42, 'n_a': 21, 'n_steps': 10, 'gamma': 1.9110364465275218, 'lambda_sparse': 5.805072708786653e-05, 'lr': 0.000785114365108512, 'weight_decay': 0.0002429250076576679}. Best is trial 0 with value: 0.006524878949210167.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:28:06,951] Trial 1 finished with value: -0.02700144344046085 and parameters: {'n_d': 36, 'n_a': 9, 'n_steps': 7, 'gamma': 1.5292566220641817, 'lambda_sparse': 1.8754682544509525e-05, 'lr': 0.0001028971474716675, 'weight_decay': 4.684572943161588e-05}. Best is trial 0 with value: 0.006524878949210167.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:29:21,052] Trial 2 finished with value: 0.04604141331313849 and parameters: {'n_d': 28, 'n_a': 55, 'n_steps': 9, 'gamma': 1.645041488805489, 'lambda_sparse': 2.515243223008715e-05, 'lr': 0.08448757529864905, 'weight_decay': 0.0003030899567826357}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:29:55,145] Trial 3 finished with value: 0.044805841862639806 and parameters: {'n_d': 33, 'n_a': 36, 'n_steps': 4, 'gamma': 1.0814549376311422, 'lambda_sparse': 0.0033336380606531894, 'lr': 0.005461244460952563, 'weight_decay': 0.00042729865292455714}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:30:35,991] Trial 4 finished with value: 0.03755491783405662 and parameters: {'n_d': 55, 'n_a': 34, 'n_steps': 7, 'gamma': 1.0433753876537526, 'lambda_sparse': 0.0005788110846591102, 'lr': 0.012750070204522339, 'weight_decay': 2.7396070631697004e-06}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:31:05,238] Trial 5 finished with value: 0.02937824157673441 and parameters: {'n_d': 13, 'n_a': 64, 'n_steps': 4, 'gamma': 1.79649991821538, 'lambda_sparse': 0.0010309994401073827, 'lr': 0.005511059624503813, 'weight_decay': 1.290723658648795e-06}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:31:42,411] Trial 6 finished with value: 0.025178868894507933 and parameters: {'n_d': 44, 'n_a': 14, 'n_steps': 6, 'gamma': 1.9349032345214612, 'lambda_sparse': 6.786757540678546e-05, 'lr': 0.014902602542588662, 'weight_decay': 3.136059994481931e-05}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:31:55,535] Trial 7 finished with value: -0.005648978994991616 and parameters: {'n_d': 57, 'n_a': 38, 'n_steps': 7, 'gamma': 1.646455878551747, 'lambda_sparse': 0.0006561859552993587, 'lr': 0.0003793137759303984, 'weight_decay': 1.0617401408561253e-06}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:32:24,801] Trial 8 finished with value: 0.029277150473043245 and parameters: {'n_d': 50, 'n_a': 35, 'n_steps': 5, 'gamma': 1.0092633117609533, 'lambda_sparse': 0.0005928561513772428, 'lr': 0.023520553363817823, 'weight_decay': 8.883777052468921e-05}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:33:06,298] Trial 9 finished with value: 0.02151738313596241 and parameters: {'n_d': 21, 'n_a': 40, 'n_steps': 5, 'gamma': 1.02355019906055, 'lambda_sparse': 0.0009556624368686266, 'lr': 0.001780666721896856, 'weight_decay': 5.756457273171967e-05}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:33:47,005] Trial 10 finished with value: 0.03720879040471792 and parameters: {'n_d': 25, 'n_a': 64, 'n_steps': 10, 'gamma': 1.285786641842766, 'lambda_sparse': 1.2930113508345438e-05, 'lr': 0.0704937727069518, 'weight_decay': 0.0007503517917356845}. Best is trial 2 with value: 0.04604141331313849.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:34:17,428] Trial 11 finished with value: 0.049039882375298216 and parameters: {'n_d': 30, 'n_a': 50, 'n_steps': 3, 'gamma': 1.311848935106475, 'lambda_sparse': 0.0001333954571762047, 'lr': 0.07467703994433594, 'weight_decay': 0.0009671666527077012}. Best is trial 11 with value: 0.049039882375298216.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:34:47,845] Trial 12 finished with value: 0.026607702403611322 and parameters: {'n_d': 26, 'n_a': 51, 'n_steps': 9, 'gamma': 1.3151851454839454, 'lambda_sparse': 0.00011561901702755087, 'lr': 0.07410262595751423, 'weight_decay': 0.000955485179527813}. Best is trial 11 with value: 0.049039882375298216.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:35:10,675] Trial 13 finished with value: 0.06150573533972559 and parameters: {'n_d': 15, 'n_a': 55, 'n_steps': 3, 'gamma': 1.3574061908611896, 'lambda_sparse': 0.0001461195201557897, 'lr': 0.09906731312193284, 'weight_decay': 0.00018559551990123823}. Best is trial 13 with value: 0.06150573533972559.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:35:23,258] Trial 14 finished with value: 0.022593761539312363 and parameters: {'n_d': 10, 'n_a': 49, 'n_steps': 3, 'gamma': 1.308337636928522, 'lambda_sparse': 0.00016165186252875685, 'lr': 0.04014606520529864, 'weight_decay': 1.2611958350204924e-05}. Best is trial 13 with value: 0.06150573533972559.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:35:35,229] Trial 15 finished with value: 0.03190297926401131 and parameters: {'n_d': 17, 'n_a': 46, 'n_steps': 3, 'gamma': 1.4149319307481254, 'lambda_sparse': 0.00977628638479651, 'lr': 0.02921246592825246, 'weight_decay': 0.00018261218832594367}. Best is trial 13 with value: 0.06150573533972559.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:36:03,616] Trial 16 finished with value: 0.04084064459733738 and parameters: {'n_d': 17, 'n_a': 59, 'n_steps': 3, 'gamma': 1.1710449979663724, 'lambda_sparse': 0.00021393556289761863, 'lr': 0.009445868045839944, 'weight_decay': 0.00012063124994194216}. Best is trial 13 with value: 0.06150573533972559.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:36:39,498] Trial 17 finished with value: 0.03631713635837852 and parameters: {'n_d': 31, 'n_a': 27, 'n_steps': 4, 'gamma': 1.4668646381024182, 'lambda_sparse': 7.340658748768423e-05, 'lr': 0.0021409075659405553, 'weight_decay': 1.4488112495770922e-05}. Best is trial 13 with value: 0.06150573533972559.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:36:56,910] Trial 18 finished with value: 0.02042905471182599 and parameters: {'n_d': 8, 'n_a': 44, 'n_steps': 5, 'gamma': 1.180951721011683, 'lambda_sparse': 0.0003168246795898841, 'lr': 0.04343138620530711, 'weight_decay': 0.00044702438117396996}. Best is trial 13 with value: 0.06150573533972559.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:37:29,099] Trial 19 finished with value: 0.03897591752561813 and parameters: {'n_d': 39, 'n_a': 56, 'n_steps': 6, 'gamma': 1.60359489028448, 'lambda_sparse': 4.475822859166832e-05, 'lr': 0.020433680563002047, 'weight_decay': 0.0005654981177774435}. Best is trial 13 with value: 0.06150573533972559.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:37:55,527] A new study created in memory with name: no-name-1fc977bd-374d-4828-80e7-f82400eb81b4
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:38:53,494] Trial 0 finished with value: 0.05033993970924 and parameters: {'n_d': 64, 'n_a': 31, 'n_steps': 9, 'gamma': 1.4832480927937808, 'lambda_sparse': 4.849440381782067e-05, 'lr': 0.07137373349272509, 'weight_decay': 0.00012740338733703742}. Best is trial 0 with value: 0.05033993970924.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:40:07,696] Trial 1 finished with value: 0.029944569434434354 and parameters: {'n_d': 10, 'n_a': 27, 'n_steps': 9, 'gamma': 1.8747771757945968, 'lambda_sparse': 0.0001385756458106741, 'lr': 0.04304539881116697, 'weight_decay': 8.779147191767815e-05}. Best is trial 0 with value: 0.05033993970924.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:40:31,325] Trial 2 finished with value: -0.007400100074174576 and parameters: {'n_d': 37, 'n_a': 22, 'n_steps': 8, 'gamma': 1.2712772706882838, 'lambda_sparse': 0.000855471587991232, 'lr': 0.00010466243643774709, 'weight_decay': 4.105960738369484e-06}. Best is trial 0 with value: 0.05033993970924.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:40:42,464] Trial 3 finished with value: 0.0015461492675975519 and parameters: {'n_d': 53, 'n_a': 29, 'n_steps': 4, 'gamma': 1.6754464417503252, 'lambda_sparse': 0.0012571655447852854, 'lr': 0.0001460587580861399, 'weight_decay': 0.00018942042331922295}. Best is trial 0 with value: 0.05033993970924.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:40:58,408] Trial 4 finished with value: -0.0003073717551747013 and parameters: {'n_d': 30, 'n_a': 38, 'n_steps': 5, 'gamma': 1.4851248217750521, 'lambda_sparse': 5.5573268867094765e-05, 'lr': 0.0002275484003394031, 'weight_decay': 0.0007615583070234141}. Best is trial 0 with value: 0.05033993970924.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:42:05,953] Trial 5 finished with value: 0.05870831836710744 and parameters: {'n_d': 12, 'n_a': 59, 'n_steps': 8, 'gamma': 1.921115119222693, 'lambda_sparse': 0.004612878069608179, 'lr': 0.04511141756515824, 'weight_decay': 0.00021641484112579413}. Best is trial 5 with value: 0.05870831836710744.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:42:40,691] Trial 6 finished with value: 0.04884525189505917 and parameters: {'n_d': 18, 'n_a': 54, 'n_steps': 4, 'gamma': 1.4157183120364776, 'lambda_sparse': 0.0006855173980166928, 'lr': 0.030730674336921983, 'weight_decay': 0.00053820668588825}. Best is trial 5 with value: 0.05870831836710744.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:42:58,530] Trial 7 finished with value: -0.017488299960678466 and parameters: {'n_d': 20, 'n_a': 50, 'n_steps': 9, 'gamma': 1.6717760532913566, 'lambda_sparse': 8.516441035128355e-05, 'lr': 0.0001979471178298259, 'weight_decay': 1.1272243783958462e-05}. Best is trial 5 with value: 0.05870831836710744.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:43:42,796] Trial 8 finished with value: 0.06317475182025811 and parameters: {'n_d': 48, 'n_a': 31, 'n_steps': 5, 'gamma': 1.6852301759847432, 'lambda_sparse': 0.00413385037884906, 'lr': 0.025160041947110048, 'weight_decay': 0.00033012944043447033}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:43:58,551] Trial 9 finished with value: 0.006574843953522813 and parameters: {'n_d': 52, 'n_a': 42, 'n_steps': 9, 'gamma': 1.889875753002606, 'lambda_sparse': 0.004299664665784603, 'lr': 0.0003652555679357865, 'weight_decay': 0.00031545836043113076}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:44:40,858] Trial 10 finished with value: 0.034960477549107805 and parameters: {'n_d': 41, 'n_a': 14, 'n_steps': 6, 'gamma': 1.047680457515499, 'lambda_sparse': 0.008918366556770089, 'lr': 0.006991929871502795, 'weight_decay': 3.113668658264839e-05}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:45:36,162] Trial 11 finished with value: 0.034216154378812424 and parameters: {'n_d': 47, 'n_a': 64, 'n_steps': 7, 'gamma': 1.9968266380481279, 'lambda_sparse': 1.053527374038282e-05, 'lr': 0.01043946353300591, 'weight_decay': 5.7998654048805725e-05}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:45:47,260] Trial 12 finished with value: -0.004220523515257701 and parameters: {'n_d': 27, 'n_a': 64, 'n_steps': 6, 'gamma': 1.7103148584201993, 'lambda_sparse': 0.0026460956639045453, 'lr': 0.0011582288966671954, 'weight_decay': 1.090759257279707e-06}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:46:11,810] Trial 13 finished with value: 0.03608124716123018 and parameters: {'n_d': 63, 'n_a': 8, 'n_steps': 3, 'gamma': 1.7884754037847919, 'lambda_sparse': 0.009830434506432536, 'lr': 0.014944765936816666, 'weight_decay': 0.0002887942356277757}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:47:07,112] Trial 14 finished with value: 0.030368514335663566 and parameters: {'n_d': 10, 'n_a': 45, 'n_steps': 7, 'gamma': 1.627965118619687, 'lambda_sparse': 0.002575209493502583, 'lr': 0.003096187702579195, 'weight_decay': 3.328990947843193e-05}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:48:10,461] Trial 15 finished with value: 0.02694094483658549 and parameters: {'n_d': 44, 'n_a': 56, 'n_steps': 10, 'gamma': 1.9228595191354947, 'lambda_sparse': 0.00036097323676827805, 'lr': 0.09188788371389567, 'weight_decay': 0.0008539401162284173}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:48:58,368] Trial 16 finished with value: 0.036715255089444065 and parameters: {'n_d': 30, 'n_a': 20, 'n_steps': 5, 'gamma': 1.7835801827719455, 'lambda_sparse': 0.004009976633027136, 'lr': 0.003021640555491306, 'weight_decay': 0.0003122371637841022}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:50:05,863] Trial 17 finished with value: 0.05306873559530367 and parameters: {'n_d': 55, 'n_a': 36, 'n_steps': 8, 'gamma': 1.5846777198074866, 'lambda_sparse': 0.0013096108154382095, 'lr': 0.025982649019876392, 'weight_decay': 4.5090463273893006e-05}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:50:50,406] Trial 18 finished with value: 0.044286658333541395 and parameters: {'n_d': 19, 'n_a': 47, 'n_steps': 5, 'gamma': 1.3424464882352396, 'lambda_sparse': 0.00045137801567450895, 'lr': 0.0058938056040763135, 'weight_decay': 1.8981460827645046e-05}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-04 10:51:18,642] Trial 19 finished with value: 0.04633837574355004 and parameters: {'n_d': 37, 'n_a': 37, 'n_steps': 3, 'gamma': 1.1880603733940955, 'lambda_sparse': 0.004352309749033565, 'lr': 0.018536671732502816, 'weight_decay': 0.00012275276944529465}. Best is trial 8 with value: 0.06317475182025811.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-04 10:52:10 [INFO] TabNet →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/tabnet (mean R²=0.0962)
2025-08-04 10:52:10 [INFO] Ensemble weights: TabPFN=0.299, Tree=0.388, TabNet=0.313
2025-08-04 10:52:10 [INFO] Loading individual models into memory...
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-04 10:52:16 [INFO] Saved weighted ensemble to /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-YProp/final_model.pkl
