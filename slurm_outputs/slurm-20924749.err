cpu-bind=MASK - dlcgpu03, task  0  0 [973690]: mask 0xf0000000f00 set
/var/spool/slurm/job20924749/slurm_script: line 11: module: command not found
2025-08-05 17:19:15 [INFO] Using device: cuda
2025-08-05 17:19:15 [INFO] Training TabPFN model...
[I 2025-08-05 17:19:15,995] A new study created in memory with name: no-name-9ae78177-92d0-4bd7-a869-a2f761a53c9c
2025-08-05 17:19:15 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
[I 2025-08-05 17:20:35,842] Trial 0 finished with value: 0.3734118786424957 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.3734118786424957.
2025-08-05 17:20:35 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
[I 2025-08-05 17:21:48,192] Trial 1 finished with value: 0.37345775803104253 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 1 with value: 0.37345775803104253.
2025-08-05 17:21:48 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
[I 2025-08-05 17:22:26,291] Trial 2 finished with value: 0.3707651292238433 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 1 with value: 0.37345775803104253.
2025-08-05 17:22:26 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
[I 2025-08-05 17:23:11,516] Trial 3 finished with value: 0.3587159833648419 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 1 with value: 0.37345775803104253.
2025-08-05 17:23:11 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
[I 2025-08-05 17:24:19,376] Trial 4 finished with value: 0.37455920721073044 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 4 with value: 0.37455920721073044.
2025-08-05 17:24:19 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
[I 2025-08-05 17:25:06,449] Trial 5 finished with value: 0.36273474221849333 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8909729556485984}. Best is trial 4 with value: 0.37455920721073044.
2025-08-05 17:25:06 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
2025-08-05 17:25:17 [INFO] ⏸️ Pruned trial 6 at step 3 (R²=0.3103)
[I 2025-08-05 17:25:17,285] Trial 6 pruned. 
2025-08-05 17:25:17 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
[I 2025-08-05 17:26:00,436] Trial 7 finished with value: 0.37179591610579477 and parameters: {'n_bootstrap': 12, 'sample_frac': 0.6550213529560301}. Best is trial 4 with value: 0.37455920721073044.
2025-08-05 17:26:00 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
2025-08-05 17:26:04 [INFO] ⏸️ Pruned trial 8 at step 1 (R²=0.3038)
[I 2025-08-05 17:26:04,490] Trial 8 pruned. 
2025-08-05 17:26:04 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
[I 2025-08-05 17:26:56,951] Trial 9 finished with value: 0.3738721346576086 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.6873687420594126}. Best is trial 4 with value: 0.37455920721073044.
2025-08-05 17:26:56 [INFO] 🔍 Trial 10: n_bootstrap=17, sample_frac=0.82
2025-08-05 17:27:01 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.2985)
[I 2025-08-05 17:27:01,138] Trial 10 pruned. 
2025-08-05 17:27:01 [INFO] 🔍 Trial 11: n_bootstrap=16, sample_frac=0.71
2025-08-05 17:27:12 [INFO] ⏸️ Pruned trial 11 at step 3 (R²=0.3172)
[I 2025-08-05 17:27:12,720] Trial 11 pruned. 
2025-08-05 17:27:12 [INFO] 🔍 Trial 12: n_bootstrap=15, sample_frac=0.71
2025-08-05 17:27:20 [INFO] ⏸️ Pruned trial 12 at step 2 (R²=0.2987)
[I 2025-08-05 17:27:20,285] Trial 12 pruned. 
2025-08-05 17:27:20 [INFO] 🔍 Trial 13: n_bootstrap=20, sample_frac=0.81
2025-08-05 17:27:24 [INFO] ⏸️ Pruned trial 13 at step 1 (R²=0.3011)
[I 2025-08-05 17:27:24,623] Trial 13 pruned. 
2025-08-05 17:27:24 [INFO] 🔍 Trial 14: n_bootstrap=15, sample_frac=0.60
2025-08-05 17:28:01 [INFO] ⏸️ Pruned trial 14 at step 11 (R²=0.3684)
[I 2025-08-05 17:28:01,397] Trial 14 pruned. 
2025-08-05 17:28:01 [INFO] 🔍 Trial 15: n_bootstrap=17, sample_frac=0.71
2025-08-05 17:28:08 [INFO] ⏸️ Pruned trial 15 at step 2 (R²=0.2964)
[I 2025-08-05 17:28:08,861] Trial 15 pruned. 
2025-08-05 17:28:08 [INFO] 🔍 Trial 16: n_bootstrap=13, sample_frac=0.83
2025-08-05 17:28:13 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.2967)
[I 2025-08-05 17:28:13,125] Trial 16 pruned. 
2025-08-05 17:28:13 [INFO] 🔍 Trial 17: n_bootstrap=16, sample_frac=0.74
2025-08-05 17:28:17 [INFO] ⏸️ Pruned trial 17 at step 1 (R²=0.3061)
[I 2025-08-05 17:28:17,372] Trial 17 pruned. 
2025-08-05 17:28:17 [INFO] 🔍 Trial 18: n_bootstrap=14, sample_frac=0.78
2025-08-05 17:28:21 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.3027)
[I 2025-08-05 17:28:21,436] Trial 18 pruned. 
2025-08-05 17:28:21 [INFO] 🔍 Trial 19: n_bootstrap=17, sample_frac=0.84
2025-08-05 17:28:25 [INFO] ⏸️ Pruned trial 19 at step 1 (R²=0.3035)
[I 2025-08-05 17:28:25,834] Trial 19 pruned. 
2025-08-05 17:28:25 [INFO] 🔍 Trial 20: n_bootstrap=14, sample_frac=0.61
2025-08-05 17:28:49 [INFO] ⏸️ Pruned trial 20 at step 7 (R²=0.3499)
[I 2025-08-05 17:28:49,660] Trial 20 pruned. 
2025-08-05 17:28:49 [INFO] 🔍 Trial 21: n_bootstrap=18, sample_frac=0.79
2025-08-05 17:28:53 [INFO] ⏸️ Pruned trial 21 at step 1 (R²=0.2973)
[I 2025-08-05 17:28:53,854] Trial 21 pruned. 
2025-08-05 17:28:53 [INFO] 🔍 Trial 22: n_bootstrap=19, sample_frac=0.74
2025-08-05 17:28:57 [INFO] ⏸️ Pruned trial 22 at step 1 (R²=0.3068)
[I 2025-08-05 17:28:57,739] Trial 22 pruned. 
2025-08-05 17:28:57 [INFO] 🔍 Trial 23: n_bootstrap=18, sample_frac=0.69
[I 2025-08-05 17:30:04,608] Trial 23 finished with value: 0.3798978315148649 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.6883526733161716}. Best is trial 23 with value: 0.3798978315148649.
2025-08-05 17:30:04 [INFO] 🔍 Trial 24: n_bootstrap=16, sample_frac=0.69
[I 2025-08-05 17:31:04,039] Trial 24 finished with value: 0.3792555023223635 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.6861537389550719}. Best is trial 23 with value: 0.3798978315148649.
2025-08-05 17:31:04 [INFO] 🔍 Trial 25: n_bootstrap=16, sample_frac=0.68
2025-08-05 17:31:44 [INFO] ⏸️ Pruned trial 25 at step 11 (R²=0.3699)
[I 2025-08-05 17:31:44,792] Trial 25 pruned. 
2025-08-05 17:31:44 [INFO] 🔍 Trial 26: n_bootstrap=18, sample_frac=0.68
2025-08-05 17:32:26 [INFO] ⏸️ Pruned trial 26 at step 11 (R²=0.3703)
[I 2025-08-05 17:32:26,208] Trial 26 pruned. 
2025-08-05 17:32:26 [INFO] 🔍 Trial 27: n_bootstrap=20, sample_frac=0.63
2025-08-05 17:33:07 [INFO] ⏸️ Pruned trial 27 at step 12 (R²=0.3703)
[I 2025-08-05 17:33:07,495] Trial 27 pruned. 
2025-08-05 17:33:07 [INFO] 🔍 Trial 28: n_bootstrap=15, sample_frac=0.73
2025-08-05 17:33:11 [INFO] ⏸️ Pruned trial 28 at step 1 (R²=0.3104)
[I 2025-08-05 17:33:11,374] Trial 28 pruned. 
2025-08-05 17:33:11 [INFO] 🔍 Trial 29: n_bootstrap=16, sample_frac=0.87
2025-08-05 17:33:15 [INFO] ⏸️ Pruned trial 29 at step 1 (R²=0.3051)
[I 2025-08-05 17:33:15,884] Trial 29 pruned. 
2025-08-05 17:33:15 [INFO] 🏆 Best Params: {'n_bootstrap': 18, 'sample_frac': 0.6883526733161716}, R²=0.37990
2025-08-05 17:33:15 [INFO] Bootstrap training → dataset=wine_quality, device=cuda
2025-08-05 17:33:15 [INFO] [1/18] bootstrap sample size=2372
2025-08-05 17:33:20 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_1.pkl
2025-08-05 17:33:20 [INFO] [2/18] bootstrap sample size=2372
2025-08-05 17:33:24 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_2.pkl
2025-08-05 17:33:24 [INFO] [3/18] bootstrap sample size=2372
2025-08-05 17:33:27 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_3.pkl
2025-08-05 17:33:28 [INFO] [4/18] bootstrap sample size=2372
2025-08-05 17:33:31 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_4.pkl
2025-08-05 17:33:31 [INFO] [5/18] bootstrap sample size=2372
2025-08-05 17:33:35 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_5.pkl
2025-08-05 17:33:35 [INFO] [6/18] bootstrap sample size=2372
2025-08-05 17:33:40 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_6.pkl
2025-08-05 17:33:40 [INFO] [7/18] bootstrap sample size=2372
2025-08-05 17:33:44 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_7.pkl
2025-08-05 17:33:44 [INFO] [8/18] bootstrap sample size=2372
2025-08-05 17:33:47 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_8.pkl
2025-08-05 17:33:47 [INFO] [9/18] bootstrap sample size=2372
2025-08-05 17:33:51 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_9.pkl
2025-08-05 17:33:51 [INFO] [10/18] bootstrap sample size=2372
2025-08-05 17:33:55 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_10.pkl
2025-08-05 17:33:55 [INFO] [11/18] bootstrap sample size=2372
2025-08-05 17:33:59 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_11.pkl
2025-08-05 17:33:59 [INFO] [12/18] bootstrap sample size=2372
2025-08-05 17:34:02 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_12.pkl
2025-08-05 17:34:03 [INFO] [13/18] bootstrap sample size=2372
2025-08-05 17:34:06 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_13.pkl
2025-08-05 17:34:07 [INFO] [14/18] bootstrap sample size=2372
2025-08-05 17:34:10 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_14.pkl
2025-08-05 17:34:10 [INFO] [15/18] bootstrap sample size=2372
2025-08-05 17:34:14 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_15.pkl
2025-08-05 17:34:14 [INFO] [16/18] bootstrap sample size=2372
2025-08-05 17:34:18 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_16.pkl
2025-08-05 17:34:18 [INFO] [17/18] bootstrap sample size=2372
2025-08-05 17:34:23 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_17.pkl
2025-08-05 17:34:23 [INFO] [18/18] bootstrap sample size=2372
2025-08-05 17:34:26 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/bootstrap_18.pkl
2025-08-05 17:34:27 [INFO] 📊 Final OOB R² = 0.37990
2025-08-05 17:34:31 [INFO] Saved ensemble → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/ensemble.pkl
2025-08-05 17:34:31 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-05 17:34:31 [INFO] Total time: 75.7s
2025-08-05 17:34:31 [INFO] TabPFN →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/wine_quality/ensemble.pkl (R²=0.3799)
2025-08-05 17:34:31 [INFO] Training tree-based model...
2025-08-05 17:34:31 [INFO] AutoML pipeline started
2025-08-05 17:34:31 [INFO] Output directory '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona' is ready and logging is configured.
2025-08-05 17:34:31 [INFO] Merged training data: 3447 rows
2025-08-05 17:34:31 [INFO] Split data into pool (3102 rows) and validation (345 rows)
2025-08-05 17:34:31 [INFO] Feature engineering completed: 12 features
[I 2025-08-05 17:34:31,600] A new study created in memory with name: no-name-98a94b70-aaa4-4ba7-8813-5786d612b442
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-05 17:36:24,592] Trial 0 finished with value: -0.38855705589067446 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:36:29,660] Trial 1 finished with value: -0.37884446797269405 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:36:43,869] Trial 2 finished with value: -0.3825272035949906 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:36:45,085] Trial 3 finished with value: -0.37694139245196673 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:36:53,193] Trial 4 finished with value: -0.3873457094657553 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:36:55,312] Trial 5 finished with value: -0.38133459022307814 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:37:23,931] Trial 6 finished with value: -0.3868485432193499 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:37:25,786] Trial 7 finished with value: -0.3770864915951799 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:40:26,458] Trial 8 finished with value: -0.38371618976489685 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:40:30,311] Trial 9 finished with value: -0.3777077435614974 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:40:33,188] Trial 10 finished with value: -0.37530155665377607 and parameters: {'learning_rate': 0.24893231508461813, 'depth': 8, 'l2_leaf_reg': 8.72951024190968, 'border_count': 175}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:40:38,050] Trial 11 finished with value: -0.3852286955184933 and parameters: {'learning_rate': 0.030891520069923566, 'depth': 8, 'l2_leaf_reg': 4.804761925175269, 'border_count': 46}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:40:54,966] Trial 12 finished with value: -0.3883479566013738 and parameters: {'learning_rate': 0.0265341364576789, 'depth': 9, 'l2_leaf_reg': 7.46542343927577, 'border_count': 173}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:41:14,583] Trial 13 finished with value: -0.38727272895899734 and parameters: {'learning_rate': 0.01873129632216297, 'depth': 9, 'l2_leaf_reg': 7.654700566068242, 'border_count': 173}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:42:47,491] Trial 14 finished with value: -0.3875530514520476 and parameters: {'learning_rate': 0.04274611647600694, 'depth': 12, 'l2_leaf_reg': 8.276954761683369, 'border_count': 178}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:43:23,033] Trial 15 finished with value: -0.38781579758045953 and parameters: {'learning_rate': 0.019693934376617945, 'depth': 10, 'l2_leaf_reg': 6.323756429799193, 'border_count': 198}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:43:25,992] Trial 16 finished with value: -0.3829120034764958 and parameters: {'learning_rate': 0.12604009354889587, 'depth': 7, 'l2_leaf_reg': 9.888521960565548, 'border_count': 155}. Best is trial 0 with value: -0.38855705589067446.
[I 2025-08-05 17:43:51,417] Trial 17 finished with value: -0.392554523596341 and parameters: {'learning_rate': 0.037566448346113404, 'depth': 10, 'l2_leaf_reg': 6.079330114147569, 'border_count': 197}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:45:34,922] Trial 18 finished with value: -0.3831984481844509 and parameters: {'learning_rate': 0.010907863682082639, 'depth': 11, 'l2_leaf_reg': 5.473768542497671, 'border_count': 255}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:46:23,405] Trial 19 finished with value: -0.38823584294760627 and parameters: {'learning_rate': 0.03881098757783076, 'depth': 11, 'l2_leaf_reg': 6.045952338153317, 'border_count': 201}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:47:45,956] Trial 20 finished with value: -0.3854376839999857 and parameters: {'learning_rate': 0.06323711244782239, 'depth': 12, 'l2_leaf_reg': 8.718568906390514, 'border_count': 228}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:48:20,661] Trial 21 finished with value: -0.3897870448498123 and parameters: {'learning_rate': 0.023216901013713733, 'depth': 10, 'l2_leaf_reg': 7.679575085036238, 'border_count': 164}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:48:40,507] Trial 22 finished with value: -0.3858866577112988 and parameters: {'learning_rate': 0.03745612674981517, 'depth': 10, 'l2_leaf_reg': 6.915991327857876, 'border_count': 128}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:48:50,222] Trial 23 finished with value: -0.38496300724747984 and parameters: {'learning_rate': 0.055987054442809304, 'depth': 9, 'l2_leaf_reg': 8.07373239513967, 'border_count': 156}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:49:56,994] Trial 24 finished with value: -0.3870559293266289 and parameters: {'learning_rate': 0.021790798345787885, 'depth': 11, 'l2_leaf_reg': 5.334907331464369, 'border_count': 196}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:50:06,962] Trial 25 finished with value: -0.38229878905377657 and parameters: {'learning_rate': 0.1165201443787048, 'depth': 10, 'l2_leaf_reg': 4.225512563114876, 'border_count': 133}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:50:16,199] Trial 26 finished with value: -0.3786430857040813 and parameters: {'learning_rate': 0.013977087341011527, 'depth': 7, 'l2_leaf_reg': 9.085976472678796, 'border_count': 187}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:51:53,235] Trial 27 finished with value: -0.38669169195766295 and parameters: {'learning_rate': 0.03455988065776937, 'depth': 12, 'l2_leaf_reg': 6.706940177516324, 'border_count': 158}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:52:46,012] Trial 28 finished with value: -0.3880000431638619 and parameters: {'learning_rate': 0.022648732565425204, 'depth': 11, 'l2_leaf_reg': 5.955125012202874, 'border_count': 105}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:53:08,536] Trial 29 finished with value: -0.38591120857847133 and parameters: {'learning_rate': 0.014943558630223373, 'depth': 9, 'l2_leaf_reg': 7.769753668938152, 'border_count': 226}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:53:14,521] Trial 30 finished with value: -0.3881955222748798 and parameters: {'learning_rate': 0.048301241792401306, 'depth': 7, 'l2_leaf_reg': 9.08468440137025, 'border_count': 218}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:53:31,320] Trial 31 finished with value: -0.3905405707542521 and parameters: {'learning_rate': 0.026100150439605927, 'depth': 9, 'l2_leaf_reg': 7.365380089182549, 'border_count': 168}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:54:03,491] Trial 32 finished with value: -0.38929499027913606 and parameters: {'learning_rate': 0.024004999149198406, 'depth': 10, 'l2_leaf_reg': 7.176063967278969, 'border_count': 163}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:54:39,975] Trial 33 finished with value: -0.38796899091540815 and parameters: {'learning_rate': 0.016625280295455642, 'depth': 10, 'l2_leaf_reg': 6.965313999154629, 'border_count': 141}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:54:55,747] Trial 34 finished with value: -0.3881966950275229 and parameters: {'learning_rate': 0.024264795328234813, 'depth': 9, 'l2_leaf_reg': 8.208494137072162, 'border_count': 160}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:55:22,840] Trial 35 finished with value: -0.38716306595866323 and parameters: {'learning_rate': 0.03175357531342333, 'depth': 10, 'l2_leaf_reg': 7.327709121604001, 'border_count': 186}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:55:35,188] Trial 36 finished with value: -0.38503900008366665 and parameters: {'learning_rate': 0.019160461640718465, 'depth': 8, 'l2_leaf_reg': 6.004260544971097, 'border_count': 213}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:56:01,117] Trial 37 finished with value: -0.38763385807361295 and parameters: {'learning_rate': 0.024153783631167776, 'depth': 10, 'l2_leaf_reg': 4.919424910155775, 'border_count': 143}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:56:12,748] Trial 38 finished with value: -0.38687333507001265 and parameters: {'learning_rate': 0.054017552233338505, 'depth': 9, 'l2_leaf_reg': 6.445773275596282, 'border_count': 240}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:56:19,035] Trial 39 finished with value: -0.3809739121568281 and parameters: {'learning_rate': 0.015675758761727887, 'depth': 6, 'l2_leaf_reg': 2.479092872735521, 'border_count': 186}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:57:33,127] Trial 40 finished with value: -0.38456751376537107 and parameters: {'learning_rate': 0.010702512259365606, 'depth': 11, 'l2_leaf_reg': 7.8700130403622035, 'border_count': 115}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:58:00,892] Trial 41 finished with value: -0.38557376861418824 and parameters: {'learning_rate': 0.02913299142975713, 'depth': 10, 'l2_leaf_reg': 7.162856085054894, 'border_count': 165}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:58:10,967] Trial 42 finished with value: -0.39035406469338013 and parameters: {'learning_rate': 0.03863462183578533, 'depth': 8, 'l2_leaf_reg': 8.514498146631308, 'border_count': 167}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:58:19,661] Trial 43 finished with value: -0.38606674202537045 and parameters: {'learning_rate': 0.03844296002017322, 'depth': 8, 'l2_leaf_reg': 8.481057482663461, 'border_count': 200}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:58:27,325] Trial 44 finished with value: -0.38797032211824445 and parameters: {'learning_rate': 0.04666521850250429, 'depth': 8, 'l2_leaf_reg': 9.413383698780713, 'border_count': 149}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:58:35,295] Trial 45 finished with value: -0.38604761352336814 and parameters: {'learning_rate': 0.0712318154111799, 'depth': 9, 'l2_leaf_reg': 7.565947627200853, 'border_count': 165}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:58:51,151] Trial 46 finished with value: -0.38610952899548934 and parameters: {'learning_rate': 0.033567287606693745, 'depth': 9, 'l2_leaf_reg': 8.978798984527652, 'border_count': 180}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:58:57,755] Trial 47 finished with value: -0.38620668052104185 and parameters: {'learning_rate': 0.02769774299261787, 'depth': 7, 'l2_leaf_reg': 6.637108364172282, 'border_count': 123}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:59:07,203] Trial 48 finished with value: -0.3848075338529816 and parameters: {'learning_rate': 0.019838330588217327, 'depth': 8, 'l2_leaf_reg': 5.700915128861947, 'border_count': 92}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:59:11,826] Trial 49 finished with value: -0.3823834073821321 and parameters: {'learning_rate': 0.043066367785296565, 'depth': 6, 'l2_leaf_reg': 8.499529021873348, 'border_count': 169}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:59:23,796] Trial 50 finished with value: -0.39038619533727015 and parameters: {'learning_rate': 0.02615681490202798, 'depth': 10, 'l2_leaf_reg': 7.344546146695974, 'border_count': 35}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:59:35,797] Trial 51 finished with value: -0.3892258634931135 and parameters: {'learning_rate': 0.02610776739685159, 'depth': 10, 'l2_leaf_reg': 7.417220597433447, 'border_count': 45}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 17:59:59,800] Trial 52 finished with value: -0.3862885134454459 and parameters: {'learning_rate': 0.02127330239913486, 'depth': 10, 'l2_leaf_reg': 7.798105434425098, 'border_count': 89}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:00:09,197] Trial 53 finished with value: -0.38757243308108735 and parameters: {'learning_rate': 0.03249558485369904, 'depth': 9, 'l2_leaf_reg': 7.136455540477178, 'border_count': 68}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:00:31,243] Trial 54 finished with value: -0.38601138280959335 and parameters: {'learning_rate': 0.017751197436123342, 'depth': 11, 'l2_leaf_reg': 6.297099427613523, 'border_count': 34}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:01:49,191] Trial 55 finished with value: -0.38356651259616864 and parameters: {'learning_rate': 0.01286340126858906, 'depth': 11, 'l2_leaf_reg': 8.072332799359238, 'border_count': 149}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:02:23,153] Trial 56 finished with value: -0.38805174716047447 and parameters: {'learning_rate': 0.02685968516897515, 'depth': 10, 'l2_leaf_reg': 6.872536419082191, 'border_count': 207}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:02:36,892] Trial 57 finished with value: -0.3890241457655007 and parameters: {'learning_rate': 0.040971533394701325, 'depth': 9, 'l2_leaf_reg': 9.562136829285617, 'border_count': 191}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:02:47,189] Trial 58 finished with value: -0.3874160753766788 and parameters: {'learning_rate': 0.029765942798684088, 'depth': 8, 'l2_leaf_reg': 8.512947420809116, 'border_count': 135}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:02:54,785] Trial 59 finished with value: -0.3846194126636151 and parameters: {'learning_rate': 0.08627262968587811, 'depth': 9, 'l2_leaf_reg': 7.911152921322225, 'border_count': 179}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:03:07,097] Trial 60 finished with value: -0.37351405198168064 and parameters: {'learning_rate': 0.23796790723092823, 'depth': 11, 'l2_leaf_reg': 5.025695369493145, 'border_count': 172}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:03:20,708] Trial 61 finished with value: -0.38538621297586173 and parameters: {'learning_rate': 0.025209263872096675, 'depth': 10, 'l2_leaf_reg': 7.529867750517298, 'border_count': 53}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:03:32,012] Trial 62 finished with value: -0.38698549424019746 and parameters: {'learning_rate': 0.02225571803725601, 'depth': 10, 'l2_leaf_reg': 7.20173038047678, 'border_count': 33}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:03:41,876] Trial 63 finished with value: -0.38885961316022455 and parameters: {'learning_rate': 0.03518170115972003, 'depth': 10, 'l2_leaf_reg': 6.69321827173866, 'border_count': 47}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:03:56,778] Trial 64 finished with value: -0.3863225120872485 and parameters: {'learning_rate': 0.027342829290772284, 'depth': 10, 'l2_leaf_reg': 7.482537960110095, 'border_count': 61}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:04:03,986] Trial 65 finished with value: -0.3832218651128167 and parameters: {'learning_rate': 0.051824223397457216, 'depth': 9, 'l2_leaf_reg': 6.186081557986411, 'border_count': 84}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:04:17,842] Trial 66 finished with value: -0.3872792878174449 and parameters: {'learning_rate': 0.030569622432557914, 'depth': 11, 'l2_leaf_reg': 4.3312139032998465, 'border_count': 38}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:04:47,182] Trial 67 finished with value: -0.38800786521826713 and parameters: {'learning_rate': 0.02492529461963815, 'depth': 10, 'l2_leaf_reg': 5.778595668659855, 'border_count': 153}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:05:05,585] Trial 68 finished with value: -0.3877185799469154 and parameters: {'learning_rate': 0.06119462426833592, 'depth': 10, 'l2_leaf_reg': 8.260492588800668, 'border_count': 162}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:05:20,190] Trial 69 finished with value: -0.3852417952593341 and parameters: {'learning_rate': 0.020897161652211907, 'depth': 9, 'l2_leaf_reg': 8.702500936903288, 'border_count': 77}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:06:12,763] Trial 70 finished with value: -0.3908515484929077 and parameters: {'learning_rate': 0.036350380975824305, 'depth': 11, 'l2_leaf_reg': 7.0343053018893595, 'border_count': 138}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:06:54,319] Trial 71 finished with value: -0.3806904007853948 and parameters: {'learning_rate': 0.037604966447190094, 'depth': 12, 'l2_leaf_reg': 6.571424776257567, 'border_count': 56}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:07:29,973] Trial 72 finished with value: -0.3858733596346678 and parameters: {'learning_rate': 0.04440432440528193, 'depth': 11, 'l2_leaf_reg': 7.461701259464829, 'border_count': 105}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:08:29,077] Trial 73 finished with value: -0.3895296649480597 and parameters: {'learning_rate': 0.03494616085530875, 'depth': 11, 'l2_leaf_reg': 6.956525581034878, 'border_count': 235}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:10:11,912] Trial 74 finished with value: -0.3869945591444699 and parameters: {'learning_rate': 0.03481224848604676, 'depth': 12, 'l2_leaf_reg': 6.868693410200122, 'border_count': 233}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:11:03,692] Trial 75 finished with value: -0.38728173473223587 and parameters: {'learning_rate': 0.04064933488860427, 'depth': 11, 'l2_leaf_reg': 7.1091342207640995, 'border_count': 216}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:12:19,484] Trial 76 finished with value: -0.38725085032701556 and parameters: {'learning_rate': 0.023222104832253558, 'depth': 11, 'l2_leaf_reg': 7.998132691503456, 'border_count': 245}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:13:31,435] Trial 77 finished with value: -0.38311036181238967 and parameters: {'learning_rate': 0.048940422149341106, 'depth': 12, 'l2_leaf_reg': 6.261926973773104, 'border_count': 175}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:14:20,098] Trial 78 finished with value: -0.3874940674938313 and parameters: {'learning_rate': 0.03133761240137578, 'depth': 11, 'l2_leaf_reg': 6.8850965777699145, 'border_count': 139}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:14:32,470] Trial 79 finished with value: -0.3846245928689133 and parameters: {'learning_rate': 0.018266872190962045, 'depth': 8, 'l2_leaf_reg': 5.279591808139939, 'border_count': 222}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:14:35,175] Trial 80 finished with value: -0.375263776776119 and parameters: {'learning_rate': 0.06038901730385227, 'depth': 4, 'l2_leaf_reg': 7.633340957862242, 'border_count': 191}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:15:10,311] Trial 81 finished with value: -0.38666353192802844 and parameters: {'learning_rate': 0.02558950093212098, 'depth': 10, 'l2_leaf_reg': 7.329952695806435, 'border_count': 209}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:15:20,996] Trial 82 finished with value: -0.3895279158797351 and parameters: {'learning_rate': 0.029322715787360957, 'depth': 10, 'l2_leaf_reg': 7.723844499690962, 'border_count': 42}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:15:47,999] Trial 83 finished with value: -0.38566287830685536 and parameters: {'learning_rate': 0.029142992836439414, 'depth': 10, 'l2_leaf_reg': 7.762704257086019, 'border_count': 156}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:16:13,212] Trial 84 finished with value: -0.3891205511877577 and parameters: {'learning_rate': 0.03643773323032663, 'depth': 10, 'l2_leaf_reg': 7.086434965326651, 'border_count': 182}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:17:02,325] Trial 85 finished with value: -0.38701162603682543 and parameters: {'learning_rate': 0.03336433515175207, 'depth': 11, 'l2_leaf_reg': 1.5781516344661872, 'border_count': 254}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:17:21,303] Trial 86 finished with value: -0.3878824291727164 and parameters: {'learning_rate': 0.020392202795255634, 'depth': 9, 'l2_leaf_reg': 6.481599170317965, 'border_count': 166}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:18:19,316] Trial 87 finished with value: -0.38726828621881254 and parameters: {'learning_rate': 0.02316388699454613, 'depth': 11, 'l2_leaf_reg': 8.185126780352387, 'border_count': 119}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:18:35,976] Trial 88 finished with value: -0.38852118050483364 and parameters: {'learning_rate': 0.028417190080781266, 'depth': 9, 'l2_leaf_reg': 8.823806695111346, 'border_count': 204}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:19:16,664] Trial 89 finished with value: -0.38530687205813113 and parameters: {'learning_rate': 0.01613269806412806, 'depth': 10, 'l2_leaf_reg': 7.6813754323067585, 'border_count': 195}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:19:23,156] Trial 90 finished with value: -0.38811499173725916 and parameters: {'learning_rate': 0.04012692681577006, 'depth': 7, 'l2_leaf_reg': 8.450823332385788, 'border_count': 146}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:19:34,047] Trial 91 finished with value: -0.38616483184847405 and parameters: {'learning_rate': 0.02599496851271562, 'depth': 10, 'l2_leaf_reg': 7.2613029730558365, 'border_count': 45}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:19:42,213] Trial 92 finished with value: -0.38413711466944045 and parameters: {'learning_rate': 0.03264873622010594, 'depth': 10, 'l2_leaf_reg': 7.349703588279462, 'border_count': 41}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:20:31,063] Trial 93 finished with value: -0.38914676944658577 and parameters: {'learning_rate': 0.044941051245425995, 'depth': 11, 'l2_leaf_reg': 6.8116043118772, 'border_count': 234}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:20:37,864] Trial 94 finished with value: -0.3817153549548162 and parameters: {'learning_rate': 0.030731739483214712, 'depth': 9, 'l2_leaf_reg': 8.00136742861792, 'border_count': 50}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:20:54,663] Trial 95 finished with value: -0.38867080836927903 and parameters: {'learning_rate': 0.022383361682327768, 'depth': 10, 'l2_leaf_reg': 6.072552204637816, 'border_count': 65}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:21:04,801] Trial 96 finished with value: -0.38840928008463177 and parameters: {'learning_rate': 0.02729778362245887, 'depth': 8, 'l2_leaf_reg': 6.977469390146886, 'border_count': 171}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:21:15,290] Trial 97 finished with value: -0.38422543661941655 and parameters: {'learning_rate': 0.03784883912087407, 'depth': 10, 'l2_leaf_reg': 7.476545289221108, 'border_count': 59}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:22:13,127] Trial 98 finished with value: -0.3876792324564315 and parameters: {'learning_rate': 0.023796416683210784, 'depth': 11, 'l2_leaf_reg': 6.477822624059459, 'border_count': 151}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:22:22,734] Trial 99 finished with value: -0.38775609802938543 and parameters: {'learning_rate': 0.01940722744066724, 'depth': 9, 'l2_leaf_reg': 7.848708424810815, 'border_count': 40}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:22:50,883] Trial 100 finished with value: -0.38950478044380643 and parameters: {'learning_rate': 0.028333277347763714, 'depth': 10, 'l2_leaf_reg': 5.703297431205451, 'border_count': 161}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:23:14,211] Trial 101 finished with value: -0.38807443817334397 and parameters: {'learning_rate': 0.03550252969977292, 'depth': 10, 'l2_leaf_reg': 5.686782832748021, 'border_count': 164}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:23:40,406] Trial 102 finished with value: -0.38727629866126184 and parameters: {'learning_rate': 0.029241783019101693, 'depth': 10, 'l2_leaf_reg': 6.76763939053508, 'border_count': 160}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:24:16,856] Trial 103 finished with value: -0.38560510916527363 and parameters: {'learning_rate': 0.017265706376953623, 'depth': 10, 'l2_leaf_reg': 9.316113893385543, 'border_count': 176}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:24:47,295] Trial 104 finished with value: -0.38901417408643696 and parameters: {'learning_rate': 0.026297136971608695, 'depth': 10, 'l2_leaf_reg': 5.894010449949171, 'border_count': 185}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:25:41,323] Trial 105 finished with value: -0.3854935777339447 and parameters: {'learning_rate': 0.03200747667680512, 'depth': 11, 'l2_leaf_reg': 7.352654924239742, 'border_count': 170}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:25:59,247] Trial 106 finished with value: -0.3910732804470757 and parameters: {'learning_rate': 0.02428476612897685, 'depth': 9, 'l2_leaf_reg': 7.039368015764255, 'border_count': 155}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:26:06,236] Trial 107 finished with value: -0.3889601281876228 and parameters: {'learning_rate': 0.042223866148128904, 'depth': 8, 'l2_leaf_reg': 5.46294173964737, 'border_count': 128}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:26:22,078] Trial 108 finished with value: -0.39098887816978045 and parameters: {'learning_rate': 0.024215664081674457, 'depth': 9, 'l2_leaf_reg': 6.584943987285705, 'border_count': 137}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:26:39,825] Trial 109 finished with value: -0.3898368917501863 and parameters: {'learning_rate': 0.02161358968950168, 'depth': 9, 'l2_leaf_reg': 6.386866735563333, 'border_count': 139}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:26:57,037] Trial 110 finished with value: -0.3905609841675334 and parameters: {'learning_rate': 0.021668494870030763, 'depth': 9, 'l2_leaf_reg': 6.566100529868451, 'border_count': 147}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:27:13,695] Trial 111 finished with value: -0.38865598761363485 and parameters: {'learning_rate': 0.02021565164170531, 'depth': 9, 'l2_leaf_reg': 6.423388849414158, 'border_count': 132}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:27:33,161] Trial 112 finished with value: -0.38527769186624145 and parameters: {'learning_rate': 0.014616843170460135, 'depth': 9, 'l2_leaf_reg': 6.6435691168844695, 'border_count': 139}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:27:43,597] Trial 113 finished with value: -0.3887171591829707 and parameters: {'learning_rate': 0.02448971533387349, 'depth': 8, 'l2_leaf_reg': 6.2338198919973, 'border_count': 144}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:28:00,748] Trial 114 finished with value: -0.38599642881063584 and parameters: {'learning_rate': 0.021438295071665, 'depth': 9, 'l2_leaf_reg': 7.033598162935229, 'border_count': 137}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:28:12,115] Trial 115 finished with value: -0.38753630131638145 and parameters: {'learning_rate': 0.01796790802562844, 'depth': 8, 'l2_leaf_reg': 6.6430217381892, 'border_count': 155}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:28:27,498] Trial 116 finished with value: -0.3880392753039068 and parameters: {'learning_rate': 0.021502784371839362, 'depth': 9, 'l2_leaf_reg': 6.00057501690843, 'border_count': 129}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:28:44,830] Trial 117 finished with value: -0.3885290405931589 and parameters: {'learning_rate': 0.019223729738793213, 'depth': 9, 'l2_leaf_reg': 6.376114493174104, 'border_count': 123}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:28:59,542] Trial 118 finished with value: -0.3850413209021172 and parameters: {'learning_rate': 0.02354157561807478, 'depth': 9, 'l2_leaf_reg': 6.966239762053107, 'border_count': 104}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:29:11,643] Trial 119 finished with value: -0.38658833150703903 and parameters: {'learning_rate': 0.033814345540723614, 'depth': 9, 'l2_leaf_reg': 6.157456617691433, 'border_count': 148}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:29:20,947] Trial 120 finished with value: -0.3873319951489614 and parameters: {'learning_rate': 0.030584174121637872, 'depth': 8, 'l2_leaf_reg': 7.636194909163692, 'border_count': 152}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:29:35,225] Trial 121 finished with value: -0.3861189429632347 and parameters: {'learning_rate': 0.02818284838427748, 'depth': 9, 'l2_leaf_reg': 5.783105995280496, 'border_count': 145}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:29:50,566] Trial 122 finished with value: -0.3875062232280693 and parameters: {'learning_rate': 0.02573604795209115, 'depth': 9, 'l2_leaf_reg': 6.756960382513032, 'border_count': 158}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:30:01,313] Trial 123 finished with value: -0.38805583420706713 and parameters: {'learning_rate': 0.02740893777678065, 'depth': 8, 'l2_leaf_reg': 9.99615848667766, 'border_count': 142}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:30:15,836] Trial 124 finished with value: -0.3862974102216036 and parameters: {'learning_rate': 0.022704016217297784, 'depth': 9, 'l2_leaf_reg': 5.299370628567689, 'border_count': 168}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:30:35,828] Trial 125 finished with value: -0.38613189858694846 and parameters: {'learning_rate': 0.03623623095861153, 'depth': 10, 'l2_leaf_reg': 7.1786226612023585, 'border_count': 112}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:30:42,936] Trial 126 finished with value: -0.38598511116608447 and parameters: {'learning_rate': 0.024131047274722484, 'depth': 7, 'l2_leaf_reg': 6.548144060626345, 'border_count': 158}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:30:53,554] Trial 127 finished with value: -0.38744384880009586 and parameters: {'learning_rate': 0.050538364097050856, 'depth': 9, 'l2_leaf_reg': 6.2980903711796605, 'border_count': 151}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:31:34,707] Trial 128 finished with value: -0.38942128850099217 and parameters: {'learning_rate': 0.039284307625629636, 'depth': 11, 'l2_leaf_reg': 5.616487144679822, 'border_count': 136}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:31:49,330] Trial 129 finished with value: -0.38765899868189496 and parameters: {'learning_rate': 0.02875252001794216, 'depth': 9, 'l2_leaf_reg': 5.9292300365490735, 'border_count': 162}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:32:13,407] Trial 130 finished with value: -0.3856191899024478 and parameters: {'learning_rate': 0.03064502601978782, 'depth': 10, 'l2_leaf_reg': 8.294447198357084, 'border_count': 123}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:33:34,282] Trial 131 finished with value: -0.3876044450555265 and parameters: {'learning_rate': 0.04022870844187405, 'depth': 12, 'l2_leaf_reg': 5.105681941458278, 'border_count': 139}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:34:09,650] Trial 132 finished with value: -0.38335298248094063 and parameters: {'learning_rate': 0.04555770946268561, 'depth': 11, 'l2_leaf_reg': 4.550398085003506, 'border_count': 131}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:34:51,255] Trial 133 finished with value: -0.38784077773624326 and parameters: {'learning_rate': 0.03407863382448819, 'depth': 11, 'l2_leaf_reg': 5.511977943735819, 'border_count': 134}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:35:16,577] Trial 134 finished with value: -0.3668890922443223 and parameters: {'learning_rate': 0.29866373378393146, 'depth': 12, 'l2_leaf_reg': 5.594556330476891, 'border_count': 143}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:35:20,481] Trial 135 finished with value: -0.38020170770679523 and parameters: {'learning_rate': 0.03880269850359399, 'depth': 5, 'l2_leaf_reg': 7.056940395244628, 'border_count': 154}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:35:38,705] Trial 136 finished with value: -0.38561928558734476 and parameters: {'learning_rate': 0.021198746316064707, 'depth': 11, 'l2_leaf_reg': 6.8169744453420575, 'border_count': 32}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:35:46,621] Trial 137 finished with value: -0.3699623878790713 and parameters: {'learning_rate': 0.15116081026577535, 'depth': 10, 'l2_leaf_reg': 3.2157143727148925, 'border_count': 179}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:36:05,189] Trial 138 finished with value: -0.3866088588332515 and parameters: {'learning_rate': 0.0254224187884613, 'depth': 10, 'l2_leaf_reg': 7.269643995826569, 'border_count': 75}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:36:55,127] Trial 139 finished with value: -0.38856318163155545 and parameters: {'learning_rate': 0.03591431646423872, 'depth': 11, 'l2_leaf_reg': 7.660390423606196, 'border_count': 149}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:37:24,977] Trial 140 finished with value: -0.3889835523745747 and parameters: {'learning_rate': 0.03265683221377616, 'depth': 10, 'l2_leaf_reg': 5.874926903057644, 'border_count': 223}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:37:55,783] Trial 141 finished with value: -0.38658498121715634 and parameters: {'learning_rate': 0.022500471381086067, 'depth': 10, 'l2_leaf_reg': 6.096132656007831, 'border_count': 165}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:38:25,475] Trial 142 finished with value: -0.3892167886372263 and parameters: {'learning_rate': 0.02711537708949034, 'depth': 10, 'l2_leaf_reg': 7.493228997365518, 'border_count': 160}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:39:25,861] Trial 143 finished with value: -0.38626638217874226 and parameters: {'learning_rate': 0.02445744820795937, 'depth': 11, 'l2_leaf_reg': 6.93952564981243, 'border_count': 174}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:39:52,828] Trial 144 finished with value: -0.3912154110819599 and parameters: {'learning_rate': 0.02908899049102916, 'depth': 10, 'l2_leaf_reg': 7.223549061484254, 'border_count': 167}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:40:24,115] Trial 145 finished with value: -0.3895522776007116 and parameters: {'learning_rate': 0.030120618055074735, 'depth': 10, 'l2_leaf_reg': 7.8879825567221, 'border_count': 190}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:40:52,545] Trial 146 finished with value: -0.3870054168524281 and parameters: {'learning_rate': 0.02937296672797856, 'depth': 10, 'l2_leaf_reg': 7.909298227975602, 'border_count': 184}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:41:01,551] Trial 147 finished with value: -0.3865914083638671 and parameters: {'learning_rate': 0.0314008209862038, 'depth': 8, 'l2_leaf_reg': 8.198432994189982, 'border_count': 189}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:41:33,211] Trial 148 finished with value: -0.386458296093501 and parameters: {'learning_rate': 0.027659106055210905, 'depth': 10, 'l2_leaf_reg': 7.263228734014302, 'border_count': 195}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:42:02,643] Trial 149 finished with value: -0.38686790302574803 and parameters: {'learning_rate': 0.025810128257969238, 'depth': 10, 'l2_leaf_reg': 7.806990288077225, 'border_count': 171}. Best is trial 17 with value: -0.392554523596341.
[I 2025-08-05 18:42:07,298] A new study created in memory with name: no-name-c002bdb8-abf3-4a8e-9c49-6442d78b2816
[I 2025-08-05 18:42:08,910] Trial 0 finished with value: -0.3753897946140961 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.3753897946140961.
[I 2025-08-05 18:42:09,461] Trial 1 finished with value: -0.36283069448154703 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.3753897946140961.
[I 2025-08-05 18:42:10,745] Trial 2 finished with value: -0.37370587906574804 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 0 with value: -0.3753897946140961.
[I 2025-08-05 18:42:11,484] Trial 3 finished with value: -0.3687684150791843 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 0 with value: -0.3753897946140961.
[I 2025-08-05 18:42:13,991] Trial 4 finished with value: -0.37273963854586517 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 0 with value: -0.3753897946140961.
[I 2025-08-05 18:42:15,158] Trial 5 finished with value: -0.36388797423381486 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 0 with value: -0.3753897946140961.
[I 2025-08-05 18:42:16,143] Trial 6 finished with value: -0.3771570854873271 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:17,331] Trial 7 finished with value: -0.3637813133157222 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:18,380] Trial 8 finished with value: -0.3714480501298571 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:21,164] Trial 9 finished with value: -0.37460132604230034 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:21,686] Trial 10 finished with value: -0.36949848153695236 and parameters: {'learning_rate': 0.16917635629157515, 'num_leaves': 9, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.9919371080730972, 'bagging_fraction': 0.9538323976412588, 'reg_alpha': 4.344469108550396, 'reg_lambda': 6.178893500921428}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:22,543] Trial 11 finished with value: -0.37618498538522954 and parameters: {'learning_rate': 0.06916991586734614, 'num_leaves': 84, 'max_depth': 12, 'min_child_samples': 63, 'feature_fraction': 0.5123526693065024, 'bagging_fraction': 0.7373700149333828, 'reg_alpha': 4.077391468444027e-08, 'reg_lambda': 3.602467050688373}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:23,289] Trial 12 finished with value: -0.3745590721913696 and parameters: {'learning_rate': 0.0776318788877595, 'num_leaves': 68, 'max_depth': 12, 'min_child_samples': 68, 'feature_fraction': 0.7410047127517462, 'bagging_fraction': 0.7412611217277166, 'reg_alpha': 0.0001653282123997984, 'reg_lambda': 0.04303750200552889}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:23,990] Trial 13 finished with value: -0.3681693769443884 and parameters: {'learning_rate': 0.1030491031460727, 'num_leaves': 74, 'max_depth': 10, 'min_child_samples': 44, 'feature_fraction': 0.990864652622508, 'bagging_fraction': 0.8304278626461433, 'reg_alpha': 1.0741482674311923e-08, 'reg_lambda': 0.016221457261966058}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:24,817] Trial 14 finished with value: -0.371291776135283 and parameters: {'learning_rate': 0.05484650991094599, 'num_leaves': 22, 'max_depth': 14, 'min_child_samples': 53, 'feature_fraction': 0.5065701578589041, 'bagging_fraction': 0.7582426583781776, 'reg_alpha': 0.00044744916469555666, 'reg_lambda': 9.207736961357908}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:25,546] Trial 15 finished with value: -0.3678337810589342 and parameters: {'learning_rate': 0.12178219527414726, 'num_leaves': 108, 'max_depth': 9, 'min_child_samples': 25, 'feature_fraction': 0.8705765955899738, 'bagging_fraction': 0.6924745509172271, 'reg_alpha': 2.919597813584135e-07, 'reg_lambda': 0.14184312049385903}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:26,292] Trial 16 finished with value: -0.37303750099316024 and parameters: {'learning_rate': 0.08112800548442753, 'num_leaves': 98, 'max_depth': 13, 'min_child_samples': 69, 'feature_fraction': 0.7353633180161125, 'bagging_fraction': 0.8931545219308259, 'reg_alpha': 0.0007927681334771194, 'reg_lambda': 0.005691361824137166}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:27,269] Trial 17 finished with value: -0.37233278208325093 and parameters: {'learning_rate': 0.04271985406828157, 'num_leaves': 41, 'max_depth': 10, 'min_child_samples': 56, 'feature_fraction': 0.5988931784281101, 'bagging_fraction': 0.8331992991671378, 'reg_alpha': 9.362980685090288e-05, 'reg_lambda': 0.5668530561601127}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:27,749] Trial 18 finished with value: -0.36445685867000577 and parameters: {'learning_rate': 0.16827449065528377, 'num_leaves': 86, 'max_depth': 13, 'min_child_samples': 84, 'feature_fraction': 0.8214237152952776, 'bagging_fraction': 0.9069968527889158, 'reg_alpha': 9.523809667436613, 'reg_lambda': 0.0020222602671843134}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:28,481] Trial 19 finished with value: -0.37394715874064965 and parameters: {'learning_rate': 0.0608386577641701, 'num_leaves': 41, 'max_depth': 7, 'min_child_samples': 74, 'feature_fraction': 0.9409297232753795, 'bagging_fraction': 0.6745519836646499, 'reg_alpha': 0.012448991695575087, 'reg_lambda': 1.1011406956052172}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:29,599] Trial 20 finished with value: -0.37239794336337984 and parameters: {'learning_rate': 0.03307457821768994, 'num_leaves': 110, 'max_depth': 11, 'min_child_samples': 94, 'feature_fraction': 0.6505152466626335, 'bagging_fraction': 0.7710019007538126, 'reg_alpha': 1.1517603332498132e-06, 'reg_lambda': 0.08131727611381873}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:31,167] Trial 21 finished with value: -0.3753067077497237 and parameters: {'learning_rate': 0.0272839044530764, 'num_leaves': 163, 'max_depth': 14, 'min_child_samples': 62, 'feature_fraction': 0.5736306798333981, 'bagging_fraction': 0.7050853791947314, 'reg_alpha': 1.3651831039275445e-08, 'reg_lambda': 1.0767673259374158}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:33,029] Trial 22 finished with value: -0.3747710097569422 and parameters: {'learning_rate': 0.01984647910865896, 'num_leaves': 252, 'max_depth': 12, 'min_child_samples': 62, 'feature_fraction': 0.550726687289138, 'bagging_fraction': 0.6242933866914708, 'reg_alpha': 9.114144697754132e-08, 'reg_lambda': 0.3369697825090328}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:34,287] Trial 23 finished with value: -0.37395667188458515 and parameters: {'learning_rate': 0.03427466277366038, 'num_leaves': 38, 'max_depth': 14, 'min_child_samples': 48, 'feature_fraction': 0.5942572915365154, 'bagging_fraction': 0.7940272276538385, 'reg_alpha': 6.189776343666488e-08, 'reg_lambda': 2.5544649607427528}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:35,283] Trial 24 finished with value: -0.37286894570894 and parameters: {'learning_rate': 0.05086914479811271, 'num_leaves': 227, 'max_depth': 11, 'min_child_samples': 66, 'feature_fraction': 0.5125028387598817, 'bagging_fraction': 0.9036787212142235, 'reg_alpha': 2.8089508266239567e-05, 'reg_lambda': 8.979510276363522}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:36,026] Trial 25 finished with value: -0.37061480767928884 and parameters: {'learning_rate': 0.09065457864737839, 'num_leaves': 164, 'max_depth': 13, 'min_child_samples': 75, 'feature_fraction': 0.6795348888537289, 'bagging_fraction': 0.5916786987346601, 'reg_alpha': 1.5145009361984525e-06, 'reg_lambda': 1.4984260363555144e-08}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:37,529] Trial 26 finished with value: -0.37238070813241253 and parameters: {'learning_rate': 0.018388716872544925, 'num_leaves': 82, 'max_depth': 7, 'min_child_samples': 86, 'feature_fraction': 0.5500133587339106, 'bagging_fraction': 0.7184934342461644, 'reg_alpha': 0.002568442120100501, 'reg_lambda': 0.025642668958924805}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:38,272] Trial 27 finished with value: -0.3742283939862188 and parameters: {'learning_rate': 0.0735618113844205, 'num_leaves': 55, 'max_depth': 11, 'min_child_samples': 61, 'feature_fraction': 0.6200714947944089, 'bagging_fraction': 0.6559032873370649, 'reg_alpha': 5.570907652570733e-08, 'reg_lambda': 0.22616183249685495}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:38,961] Trial 28 finished with value: -0.37344825293890876 and parameters: {'learning_rate': 0.12833421588230168, 'num_leaves': 115, 'max_depth': 15, 'min_child_samples': 76, 'feature_fraction': 0.6925833286699146, 'bagging_fraction': 0.9954888318934101, 'reg_alpha': 0.2850837587297831, 'reg_lambda': 1.8697428543863892}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:39,888] Trial 29 finished with value: -0.3759153143187936 and parameters: {'learning_rate': 0.05773880310436543, 'num_leaves': 194, 'max_depth': 9, 'min_child_samples': 98, 'feature_fraction': 0.9466439146886472, 'bagging_fraction': 0.5013635728721908, 'reg_alpha': 3.043938196474693e-07, 'reg_lambda': 0.009327579955292337}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:40,788] Trial 30 finished with value: -0.3744483340599963 and parameters: {'learning_rate': 0.04429664901182597, 'num_leaves': 167, 'max_depth': 9, 'min_child_samples': 94, 'feature_fraction': 0.9656118250018491, 'bagging_fraction': 0.5088871925540099, 'reg_alpha': 2.0325271925810961e-07, 'reg_lambda': 0.0014140915068769782}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:41,637] Trial 31 finished with value: -0.37511726223828046 and parameters: {'learning_rate': 0.057116896485214626, 'num_leaves': 192, 'max_depth': 8, 'min_child_samples': 89, 'feature_fraction': 0.9040767307303658, 'bagging_fraction': 0.5938241184019404, 'reg_alpha': 7.970724606358874e-07, 'reg_lambda': 0.008341024441952475}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:42,487] Trial 32 finished with value: -0.37508679791986704 and parameters: {'learning_rate': 0.0665377625563212, 'num_leaves': 232, 'max_depth': 10, 'min_child_samples': 98, 'feature_fraction': 0.8479370129439808, 'bagging_fraction': 0.5718483132468063, 'reg_alpha': 2.735226109395271e-08, 'reg_lambda': 0.11559398345516102}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:43,686] Trial 33 finished with value: -0.37415897058468484 and parameters: {'learning_rate': 0.03315769151763737, 'num_leaves': 213, 'max_depth': 8, 'min_child_samples': 81, 'feature_fraction': 0.9334554428005234, 'bagging_fraction': 0.5516769716275587, 'reg_alpha': 2.485056270781598e-07, 'reg_lambda': 3.0832301836018328}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:44,425] Trial 34 finished with value: -0.3730350540149553 and parameters: {'learning_rate': 0.048254059140196356, 'num_leaves': 188, 'max_depth': 6, 'min_child_samples': 100, 'feature_fraction': 0.782059737020208, 'bagging_fraction': 0.5005958786716447, 'reg_alpha': 2.8531488180806046e-06, 'reg_lambda': 0.3527067338181995}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:45,571] Trial 35 finished with value: -0.3758183395012088 and parameters: {'learning_rate': 0.03858586389697502, 'num_leaves': 229, 'max_depth': 9, 'min_child_samples': 49, 'feature_fraction': 0.9438919321363888, 'bagging_fraction': 0.8567069358345403, 'reg_alpha': 1.457786178529654e-05, 'reg_lambda': 4.774127651300796e-05}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:46,775] Trial 36 finished with value: -0.367978012827898 and parameters: {'learning_rate': 0.04119562834878582, 'num_leaves': 226, 'max_depth': 9, 'min_child_samples': 27, 'feature_fraction': 0.9485225254209876, 'bagging_fraction': 0.9446713041292545, 'reg_alpha': 2.595683518020655e-05, 'reg_lambda': 2.8199875051992592e-05}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:47,397] Trial 37 finished with value: -0.3746095682660804 and parameters: {'learning_rate': 0.10065366730499624, 'num_leaves': 150, 'max_depth': 8, 'min_child_samples': 51, 'feature_fraction': 0.9025544357424381, 'bagging_fraction': 0.8565795808189244, 'reg_alpha': 6.220670073336869e-06, 'reg_lambda': 4.376504968483133e-05}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:48,112] Trial 38 finished with value: -0.3653383231773601 and parameters: {'learning_rate': 0.06883493673899634, 'num_leaves': 179, 'max_depth': 7, 'min_child_samples': 36, 'feature_fraction': 0.9713386595732587, 'bagging_fraction': 0.9368414355349002, 'reg_alpha': 0.0030382700106844143, 'reg_lambda': 0.00024251453231736875}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:49,143] Trial 39 finished with value: -0.3749361200968873 and parameters: {'learning_rate': 0.027109125630732523, 'num_leaves': 242, 'max_depth': 6, 'min_child_samples': 57, 'feature_fraction': 0.8557172144383619, 'bagging_fraction': 0.8667527080639706, 'reg_alpha': 6.92183211482152e-05, 'reg_lambda': 6.110600850575013e-06}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:50,313] Trial 40 finished with value: -0.3732992953477707 and parameters: {'learning_rate': 0.037474370708863704, 'num_leaves': 124, 'max_depth': 10, 'min_child_samples': 44, 'feature_fraction': 0.828028719605516, 'bagging_fraction': 0.9765733377095067, 'reg_alpha': 0.02516881779332699, 'reg_lambda': 5.531251073932811e-06}. Best is trial 6 with value: -0.3771570854873271.
[I 2025-08-05 18:42:51,633] Trial 41 finished with value: -0.3777336723790493 and parameters: {'learning_rate': 0.028493215067098704, 'num_leaves': 255, 'max_depth': 9, 'min_child_samples': 67, 'feature_fraction': 0.9173844795015199, 'bagging_fraction': 0.7951743940723177, 'reg_alpha': 1.0901931320931218e-07, 'reg_lambda': 0.0001789609201474592}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:42:53,165] Trial 42 finished with value: -0.3765467510440287 and parameters: {'learning_rate': 0.022998683830472585, 'num_leaves': 206, 'max_depth': 9, 'min_child_samples': 71, 'feature_fraction': 0.9213407629243622, 'bagging_fraction': 0.7925799213694812, 'reg_alpha': 6.058527814388194e-07, 'reg_lambda': 0.00021958846216005914}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:42:55,047] Trial 43 finished with value: -0.3757964158608355 and parameters: {'learning_rate': 0.01718296899429778, 'num_leaves': 199, 'max_depth': 11, 'min_child_samples': 73, 'feature_fraction': 0.9241170740732106, 'bagging_fraction': 0.7778735979733926, 'reg_alpha': 1.19954425965764e-07, 'reg_lambda': 0.0002900044892726593}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:42:56,595] Trial 44 finished with value: -0.37622656198255683 and parameters: {'learning_rate': 0.02229501946168631, 'num_leaves': 256, 'max_depth': 10, 'min_child_samples': 70, 'feature_fraction': 0.8937687909796095, 'bagging_fraction': 0.7461203187832993, 'reg_alpha': 5.110554453873959e-07, 'reg_lambda': 0.0007214905348276379}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:42:58,152] Trial 45 finished with value: -0.3766198980364738 and parameters: {'learning_rate': 0.02199512731072492, 'num_leaves': 252, 'max_depth': 10, 'min_child_samples': 70, 'feature_fraction': 0.8920288043110537, 'bagging_fraction': 0.7329778267476836, 'reg_alpha': 2.7617879120648952e-08, 'reg_lambda': 1.5783223736475922e-06}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:42:59,732] Trial 46 finished with value: -0.37510417748226565 and parameters: {'learning_rate': 0.023411329264321025, 'num_leaves': 253, 'max_depth': 10, 'min_child_samples': 70, 'feature_fraction': 0.8900263671944967, 'bagging_fraction': 0.8036667312163099, 'reg_alpha': 7.613755545127672e-07, 'reg_lambda': 2.4119979709747943e-06}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:00,741] Trial 47 finished with value: -0.3682851943923939 and parameters: {'learning_rate': 0.02096553971574516, 'num_leaves': 214, 'max_depth': 4, 'min_child_samples': 79, 'feature_fraction': 0.9994619932842773, 'bagging_fraction': 0.7355897213382884, 'reg_alpha': 2.076367837193366e-08, 'reg_lambda': 1.2726720884361468e-07}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:02,606] Trial 48 finished with value: -0.3770403691908321 and parameters: {'learning_rate': 0.015914819103325664, 'num_leaves': 242, 'max_depth': 8, 'min_child_samples': 70, 'feature_fraction': 0.8767551553003046, 'bagging_fraction': 0.8264270183779749, 'reg_alpha': 2.315731541193215e-06, 'reg_lambda': 9.242421588033888e-05}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:04,233] Trial 49 finished with value: -0.37549714819878194 and parameters: {'learning_rate': 0.01661559447916356, 'num_leaves': 239, 'max_depth': 6, 'min_child_samples': 79, 'feature_fraction': 0.7774546435714296, 'bagging_fraction': 0.8056831339262844, 'reg_alpha': 1.997461747056846e-06, 'reg_lambda': 0.0001430486203660916}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:06,267] Trial 50 finished with value: -0.37570219906433333 and parameters: {'learning_rate': 0.01225073982287702, 'num_leaves': 215, 'max_depth': 7, 'min_child_samples': 59, 'feature_fraction': 0.869904767218684, 'bagging_fraction': 0.8798029392055705, 'reg_alpha': 1.3290548623814046e-07, 'reg_lambda': 8.786236718974961e-07}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:08,164] Trial 51 finished with value: -0.3765851212745194 and parameters: {'learning_rate': 0.014027842526789017, 'num_leaves': 252, 'max_depth': 8, 'min_child_samples': 67, 'feature_fraction': 0.9158019503210743, 'bagging_fraction': 0.8169854642628556, 'reg_alpha': 7.964377944743309e-07, 'reg_lambda': 0.0007351595837186418}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:10,555] Trial 52 finished with value: -0.3751001285881775 and parameters: {'learning_rate': 0.010560772327758145, 'num_leaves': 243, 'max_depth': 8, 'min_child_samples': 66, 'feature_fraction': 0.9725905949934507, 'bagging_fraction': 0.8267712926504927, 'reg_alpha': 7.5133479926921845e-06, 'reg_lambda': 1.083009805789173e-05}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:12,501] Trial 53 finished with value: -0.3750809026432238 and parameters: {'learning_rate': 0.014577804342311106, 'num_leaves': 236, 'max_depth': 8, 'min_child_samples': 72, 'feature_fraction': 0.9166033475343753, 'bagging_fraction': 0.7748392163938631, 'reg_alpha': 0.0008552181206794726, 'reg_lambda': 0.00010146816050440096}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:14,486] Trial 54 finished with value: -0.37645763388498804 and parameters: {'learning_rate': 0.015050130028727779, 'num_leaves': 222, 'max_depth': 9, 'min_child_samples': 66, 'feature_fraction': 0.8679184656078904, 'bagging_fraction': 0.830900225120447, 'reg_alpha': 3.933099155606777e-06, 'reg_lambda': 0.0007452512591408707}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:15,630] Trial 55 finished with value: -0.37594341416869376 and parameters: {'learning_rate': 0.028612011544986733, 'num_leaves': 248, 'max_depth': 7, 'min_child_samples': 88, 'feature_fraction': 0.8376667760959206, 'bagging_fraction': 0.9255363912344365, 'reg_alpha': 1.0889002266739895e-08, 'reg_lambda': 2.353150129787752e-06}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:16,698] Trial 56 finished with value: -0.37305320068663284 and parameters: {'learning_rate': 0.025338044144928865, 'num_leaves': 205, 'max_depth': 5, 'min_child_samples': 79, 'feature_fraction': 0.9148510136308786, 'bagging_fraction': 0.8138895469954998, 'reg_alpha': 5.649269694525324e-07, 'reg_lambda': 0.0033008401766500143}. Best is trial 41 with value: -0.3777336723790493.
[I 2025-08-05 18:43:18,239] Trial 57 finished with value: -0.3778131968971324 and parameters: {'learning_rate': 0.01962806146068038, 'num_leaves': 247, 'max_depth': 8, 'min_child_samples': 65, 'feature_fraction': 0.8057213289898568, 'bagging_fraction': 0.7848266989760512, 'reg_alpha': 3.97103540286994e-08, 'reg_lambda': 7.865190974204919e-05}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:20,422] Trial 58 finished with value: -0.3764656220749182 and parameters: {'learning_rate': 0.013657294801998678, 'num_leaves': 243, 'max_depth': 8, 'min_child_samples': 64, 'feature_fraction': 0.8104887668962127, 'bagging_fraction': 0.7574629324017453, 'reg_alpha': 4.1948210413478836e-08, 'reg_lambda': 3.4799247778076824e-08}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:21,648] Trial 59 finished with value: -0.3687536049549774 and parameters: {'learning_rate': 0.018502618745495303, 'num_leaves': 254, 'max_depth': 5, 'min_child_samples': 55, 'feature_fraction': 0.8810888449739429, 'bagging_fraction': 0.7095394137132284, 'reg_alpha': 2.4405867122396976e-08, 'reg_lambda': 1.6264419084539487e-05}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:23,644] Trial 60 finished with value: -0.3754381272419047 and parameters: {'learning_rate': 0.011158091216585916, 'num_leaves': 219, 'max_depth': 6, 'min_child_samples': 59, 'feature_fraction': 0.7706031841810246, 'bagging_fraction': 0.6872915860152735, 'reg_alpha': 5.981891283111004e-08, 'reg_lambda': 5.319642239702903e-05}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:25,540] Trial 61 finished with value: -0.37634877709574893 and parameters: {'learning_rate': 0.016097643690968774, 'num_leaves': 236, 'max_depth': 9, 'min_child_samples': 68, 'feature_fraction': 0.9708120691403693, 'bagging_fraction': 0.7887820566024125, 'reg_alpha': 1.3148178740586527e-07, 'reg_lambda': 0.0001811775792414723}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:27,061] Trial 62 finished with value: -0.3735349415142607 and parameters: {'learning_rate': 0.02041360208063584, 'num_leaves': 245, 'max_depth': 8, 'min_child_samples': 76, 'feature_fraction': 0.930305570741614, 'bagging_fraction': 0.7293805415162744, 'reg_alpha': 2.6728861068431373e-07, 'reg_lambda': 0.0004895362200418961}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:28,233] Trial 63 finished with value: -0.37521781178432223 and parameters: {'learning_rate': 0.030637828859577033, 'num_leaves': 207, 'max_depth': 7, 'min_child_samples': 71, 'feature_fraction': 0.9063387426121996, 'bagging_fraction': 0.843492450357676, 'reg_alpha': 0.004155950396875565, 'reg_lambda': 0.002209960785685746}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:29,579] Trial 64 finished with value: -0.3768505109742716 and parameters: {'learning_rate': 0.024508477602994478, 'num_leaves': 256, 'max_depth': 9, 'min_child_samples': 65, 'feature_fraction': 0.8572643794417671, 'bagging_fraction': 0.7620675406982866, 'reg_alpha': 1.5153132115990061e-06, 'reg_lambda': 1.2428870187112276e-06}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:31,128] Trial 65 finished with value: -0.3703920863504652 and parameters: {'learning_rate': 0.013166562515318213, 'num_leaves': 11, 'max_depth': 8, 'min_child_samples': 67, 'feature_fraction': 0.8026917740282575, 'bagging_fraction': 0.7637543910688834, 'reg_alpha': 0.00022707327314013323, 'reg_lambda': 4.771732358034602e-07}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:33,285] Trial 66 finished with value: -0.37584008081947895 and parameters: {'learning_rate': 0.015452920677248542, 'num_leaves': 248, 'max_depth': 11, 'min_child_samples': 60, 'feature_fraction': 0.8457681595406766, 'bagging_fraction': 0.8198033715530975, 'reg_alpha': 8.559567997112998e-08, 'reg_lambda': 1.7479986786112797e-07}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:35,357] Trial 67 finished with value: -0.37650541061553566 and parameters: {'learning_rate': 0.018630718605918358, 'num_leaves': 256, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.8606277079502495, 'bagging_fraction': 0.7200288303915008, 'reg_alpha': 1.3174589199071708e-06, 'reg_lambda': 1.2268059499863505e-06}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:36,738] Trial 68 finished with value: -0.37427340386783403 and parameters: {'learning_rate': 0.026639079749516213, 'num_leaves': 232, 'max_depth': 10, 'min_child_samples': 84, 'feature_fraction': 0.7251951364720742, 'bagging_fraction': 0.6696054351064616, 'reg_alpha': 0.0014386035468992725, 'reg_lambda': 2.444484303591159e-07}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:38,458] Trial 69 finished with value: -0.37535795759036417 and parameters: {'learning_rate': 0.024348757770516573, 'num_leaves': 95, 'max_depth': 14, 'min_child_samples': 74, 'feature_fraction': 0.8787312344851197, 'bagging_fraction': 0.7481791020792588, 'reg_alpha': 6.821970232611567e-05, 'reg_lambda': 5.272944194842171e-08}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:39,967] Trial 70 finished with value: -0.373745021232131 and parameters: {'learning_rate': 0.02138472467870469, 'num_leaves': 222, 'max_depth': 9, 'min_child_samples': 53, 'feature_fraction': 0.9582901914387906, 'bagging_fraction': 0.7826821155253294, 'reg_alpha': 0.01792361157648005, 'reg_lambda': 8.545031261300645e-06}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:41,235] Trial 71 finished with value: -0.3748469808090806 and parameters: {'learning_rate': 0.03064572770051988, 'num_leaves': 236, 'max_depth': 9, 'min_child_samples': 78, 'feature_fraction': 0.8302250901074655, 'bagging_fraction': 0.7909831827957821, 'reg_alpha': 3.5179514956559296e-07, 'reg_lambda': 2.737830510734695e-05}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:42,805] Trial 72 finished with value: -0.3740167424310229 and parameters: {'learning_rate': 0.019266463090847518, 'num_leaves': 250, 'max_depth': 8, 'min_child_samples': 72, 'feature_fraction': 0.9846165271110247, 'bagging_fraction': 0.8017724397911334, 'reg_alpha': 1.0607783845618584e-06, 'reg_lambda': 9.840806290666634e-05}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:44,575] Trial 73 finished with value: -0.3748270660746935 and parameters: {'learning_rate': 0.022732209962092898, 'num_leaves': 228, 'max_depth': 10, 'min_child_samples': 68, 'feature_fraction': 0.8991339986343122, 'bagging_fraction': 0.9666693189316442, 'reg_alpha': 2.4886255103795802e-08, 'reg_lambda': 0.0003897620584057379}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:46,339] Trial 74 finished with value: -0.3768215585403413 and parameters: {'learning_rate': 0.01743539579867811, 'num_leaves': 246, 'max_depth': 9, 'min_child_samples': 63, 'feature_fraction': 0.9212282520180606, 'bagging_fraction': 0.7636239926572319, 'reg_alpha': 0.006492067438794321, 'reg_lambda': 2.7924935474199555e-06}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:47,972] Trial 75 finished with value: -0.3758693795080109 and parameters: {'learning_rate': 0.017382393811482544, 'num_leaves': 240, 'max_depth': 7, 'min_child_samples': 57, 'feature_fraction': 0.9551911286942176, 'bagging_fraction': 0.7687266386062853, 'reg_alpha': 0.005555200792045826, 'reg_lambda': 3.03407167196525e-06}. Best is trial 57 with value: -0.3778131968971324.
[I 2025-08-05 18:43:50,209] Trial 76 finished with value: -0.3780862354908613 and parameters: {'learning_rate': 0.017437778062078142, 'num_leaves': 248, 'max_depth': 15, 'min_child_samples': 63, 'feature_fraction': 0.8156975925518468, 'bagging_fraction': 0.8436252040362158, 'reg_alpha': 0.04167174014483159, 'reg_lambda': 1.388392672995675e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:43:52,226] Trial 77 finished with value: -0.374423041480887 and parameters: {'learning_rate': 0.01996002268129371, 'num_leaves': 246, 'max_depth': 15, 'min_child_samples': 64, 'feature_fraction': 0.7536714265332719, 'bagging_fraction': 0.8791440976564314, 'reg_alpha': 0.008331173951214597, 'reg_lambda': 1.1571392820574228e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:43:53,333] Trial 78 finished with value: -0.3772648981549389 and parameters: {'learning_rate': 0.04765546958131243, 'num_leaves': 141, 'max_depth': 15, 'min_child_samples': 62, 'feature_fraction': 0.7952508303552426, 'bagging_fraction': 0.7557551776537793, 'reg_alpha': 0.03932568683696358, 'reg_lambda': 3.450549066290769e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:43:54,455] Trial 79 finished with value: -0.37601057680093797 and parameters: {'learning_rate': 0.051399210398095634, 'num_leaves': 56, 'max_depth': 15, 'min_child_samples': 62, 'feature_fraction': 0.7918090119688853, 'bagging_fraction': 0.841335253923172, 'reg_alpha': 0.23892473485560897, 'reg_lambda': 4.814743259116292e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:43:55,628] Trial 80 finished with value: -0.3766447864193276 and parameters: {'learning_rate': 0.04741826520248476, 'num_leaves': 138, 'max_depth': 14, 'min_child_samples': 46, 'feature_fraction': 0.8209971212259914, 'bagging_fraction': 0.7537356959786671, 'reg_alpha': 0.04413500604772666, 'reg_lambda': 1.7482096385641516e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:43:57,031] Trial 81 finished with value: -0.37452745133510523 and parameters: {'learning_rate': 0.0358226302704454, 'num_leaves': 140, 'max_depth': 14, 'min_child_samples': 44, 'feature_fraction': 0.8149847444339907, 'bagging_fraction': 0.7578277307390988, 'reg_alpha': 0.045662969947568244, 'reg_lambda': 3.7592999954936424e-07}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:43:58,291] Trial 82 finished with value: -0.376094847721992 and parameters: {'learning_rate': 0.04707642777799605, 'num_leaves': 125, 'max_depth': 15, 'min_child_samples': 54, 'feature_fraction': 0.7610961386245539, 'bagging_fraction': 0.7466450506097854, 'reg_alpha': 0.0770875019809312, 'reg_lambda': 1.3437590366966546e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:43:59,446] Trial 83 finished with value: -0.3764518042019489 and parameters: {'learning_rate': 0.06078768346648244, 'num_leaves': 149, 'max_depth': 14, 'min_child_samples': 41, 'feature_fraction': 0.7901138927612977, 'bagging_fraction': 0.7766052707691653, 'reg_alpha': 0.15303284061166197, 'reg_lambda': 2.9566210074144435e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:00,548] Trial 84 finished with value: -0.3739564499767513 and parameters: {'learning_rate': 0.044863502990677824, 'num_leaves': 176, 'max_depth': 13, 'min_child_samples': 51, 'feature_fraction': 0.848912394272218, 'bagging_fraction': 0.9144270522801433, 'reg_alpha': 0.030114662618892625, 'reg_lambda': 3.8123093110857777e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:01,653] Trial 85 finished with value: -0.37586225552551367 and parameters: {'learning_rate': 0.05301166692646225, 'num_leaves': 72, 'max_depth': 15, 'min_child_samples': 60, 'feature_fraction': 0.8188559128765666, 'bagging_fraction': 0.7165497149485345, 'reg_alpha': 0.784859637346703, 'reg_lambda': 7.420914207462369e-07}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:02,877] Trial 86 finished with value: -0.3737821530200594 and parameters: {'learning_rate': 0.04273293760208006, 'num_leaves': 156, 'max_depth': 14, 'min_child_samples': 58, 'feature_fraction': 0.8376841427074774, 'bagging_fraction': 0.8476772137279747, 'reg_alpha': 0.06272953154278918, 'reg_lambda': 8.276028601801168e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:03,949] Trial 87 finished with value: -0.3768422793699108 and parameters: {'learning_rate': 0.05694365186886158, 'num_leaves': 127, 'max_depth': 15, 'min_child_samples': 63, 'feature_fraction': 0.7957064488698573, 'bagging_fraction': 0.701863329482436, 'reg_alpha': 1.1563855660017732, 'reg_lambda': 6.009516058194111e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:05,000] Trial 88 finished with value: -0.37740301660482406 and parameters: {'learning_rate': 0.06468858005638405, 'num_leaves': 63, 'max_depth': 15, 'min_child_samples': 62, 'feature_fraction': 0.8025771972980891, 'bagging_fraction': 0.6403048389276249, 'reg_alpha': 1.493015202902736, 'reg_lambda': 7.070510620491549e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:05,942] Trial 89 finished with value: -0.37434063453405325 and parameters: {'learning_rate': 0.09041638653142933, 'num_leaves': 47, 'max_depth': 15, 'min_child_samples': 61, 'feature_fraction': 0.721345566807091, 'bagging_fraction': 0.6127374228438733, 'reg_alpha': 0.6708463007662826, 'reg_lambda': 4.925451661692585e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:06,881] Trial 90 finished with value: -0.37427997968915844 and parameters: {'learning_rate': 0.07451012769884705, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 65, 'feature_fraction': 0.8022259097922089, 'bagging_fraction': 0.6305443862478749, 'reg_alpha': 1.9554446927072924, 'reg_lambda': 6.625094996066022e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:07,906] Trial 91 finished with value: -0.37435188008108866 and parameters: {'learning_rate': 0.06403795417299321, 'num_leaves': 59, 'max_depth': 15, 'min_child_samples': 64, 'feature_fraction': 0.7816597839020465, 'bagging_fraction': 0.6956204871399285, 'reg_alpha': 6.756693942420902, 'reg_lambda': 1.775610329516128e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:08,943] Trial 92 finished with value: -0.3756647669158604 and parameters: {'learning_rate': 0.054082326611344364, 'num_leaves': 79, 'max_depth': 13, 'min_child_samples': 62, 'feature_fraction': 0.797325009893214, 'bagging_fraction': 0.6611348805174772, 'reg_alpha': 2.594990000653372, 'reg_lambda': 0.00016551807910221447}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:09,922] Trial 93 finished with value: -0.37751340787533544 and parameters: {'learning_rate': 0.058006693428746973, 'num_leaves': 24, 'max_depth': 15, 'min_child_samples': 68, 'feature_fraction': 0.7409580066320787, 'bagging_fraction': 0.8002587539392312, 'reg_alpha': 0.7177885973163933, 'reg_lambda': 2.2350899402898604e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:10,642] Trial 94 finished with value: -0.3733521523793133 and parameters: {'learning_rate': 0.0641447588700549, 'num_leaves': 12, 'max_depth': 14, 'min_child_samples': 70, 'feature_fraction': 0.7398149709968587, 'bagging_fraction': 0.8077793494328025, 'reg_alpha': 0.6818583937533593, 'reg_lambda': 8.379191483059778e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:11,675] Trial 95 finished with value: -0.3760305978529004 and parameters: {'learning_rate': 0.05747679199384326, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 56, 'feature_fraction': 0.7550648586359394, 'bagging_fraction': 0.8229602456975366, 'reg_alpha': 1.2496818520044708, 'reg_lambda': 3.0317893811658785e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:12,771] Trial 96 finished with value: -0.37301489176938857 and parameters: {'learning_rate': 0.04024094406171783, 'num_leaves': 22, 'max_depth': 15, 'min_child_samples': 74, 'feature_fraction': 0.7698225928393712, 'bagging_fraction': 0.6463518641996956, 'reg_alpha': 0.13041036923626553, 'reg_lambda': 0.00012390007336327498}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:13,608] Trial 97 finished with value: -0.37365739967302264 and parameters: {'learning_rate': 0.08274664356412753, 'num_leaves': 93, 'max_depth': 14, 'min_child_samples': 66, 'feature_fraction': 0.7026449987784591, 'bagging_fraction': 0.797668473723748, 'reg_alpha': 0.35814400041821826, 'reg_lambda': 2.0390141444787272e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:14,591] Trial 98 finished with value: -0.3738022783622844 and parameters: {'learning_rate': 0.056970308249045115, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 77, 'feature_fraction': 0.8332080639519727, 'bagging_fraction': 0.8603513780703592, 'reg_alpha': 3.364099955908541, 'reg_lambda': 0.0010361691995298408}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:15,618] Trial 99 finished with value: -0.3709693104846985 and parameters: {'learning_rate': 0.04983191936868141, 'num_leaves': 105, 'max_depth': 14, 'min_child_samples': 82, 'feature_fraction': 0.7632459623408856, 'bagging_fraction': 0.6837639971561694, 'reg_alpha': 1.2534732239193493, 'reg_lambda': 0.00030387287581285785}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:16,568] Trial 100 finished with value: -0.37123795150216427 and parameters: {'learning_rate': 0.07269405399025997, 'num_leaves': 60, 'max_depth': 15, 'min_child_samples': 68, 'feature_fraction': 0.8572153980719799, 'bagging_fraction': 0.786113589180448, 'reg_alpha': 5.781159069011095, 'reg_lambda': 6.560509844653911e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:18,416] Trial 101 finished with value: -0.3761913846708398 and parameters: {'learning_rate': 0.016938718994794055, 'num_leaves': 65, 'max_depth': 9, 'min_child_samples': 63, 'feature_fraction': 0.808678621070715, 'bagging_fraction': 0.7252436750139196, 'reg_alpha': 0.0006279925189708907, 'reg_lambda': 5.585870485652065e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:20,611] Trial 102 finished with value: -0.37052433068812507 and parameters: {'learning_rate': 0.017598124637753426, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9388888207988713, 'bagging_fraction': 0.7014087275582012, 'reg_alpha': 0.001487532119250641, 'reg_lambda': 5.109065229055666e-07}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:21,375] Trial 103 finished with value: -0.3762118833913548 and parameters: {'learning_rate': 0.06619716770501503, 'num_leaves': 51, 'max_depth': 9, 'min_child_samples': 59, 'feature_fraction': 0.8787223243319678, 'bagging_fraction': 0.7400662168914701, 'reg_alpha': 0.0017656714084076238, 'reg_lambda': 9.13568241357167e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:22,867] Trial 104 finished with value: -0.3761325900294168 and parameters: {'learning_rate': 0.024783033806217932, 'num_leaves': 88, 'max_depth': 14, 'min_child_samples': 69, 'feature_fraction': 0.7441393212098505, 'bagging_fraction': 0.7649199242077128, 'reg_alpha': 0.013471749482123825, 'reg_lambda': 2.8752420644471497e-06}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:25,233] Trial 105 finished with value: -0.37701444369452775 and parameters: {'learning_rate': 0.015805703300039196, 'num_leaves': 234, 'max_depth': 15, 'min_child_samples': 62, 'feature_fraction': 0.7922804706006089, 'bagging_fraction': 0.8106127595894883, 'reg_alpha': 0.010563940561622623, 'reg_lambda': 3.3427210669033186e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:27,588] Trial 106 finished with value: -0.37532674025869517 and parameters: {'learning_rate': 0.015324014130297702, 'num_leaves': 232, 'max_depth': 15, 'min_child_samples': 66, 'feature_fraction': 0.7900636556584582, 'bagging_fraction': 0.8334577675491959, 'reg_alpha': 0.009957311168058411, 'reg_lambda': 3.7946981131375693e-05}. Best is trial 76 with value: -0.3780862354908613.
[I 2025-08-05 18:44:30,511] Trial 107 finished with value: -0.37883060756583875 and parameters: {'learning_rate': 0.011595645346859803, 'num_leaves': 114, 'max_depth': 15, 'min_child_samples': 61, 'feature_fraction': 0.7786051286692286, 'bagging_fraction': 0.8736020521198906, 'reg_alpha': 0.4777340917171173, 'reg_lambda': 0.0004929258644587612}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:33,350] Trial 108 finished with value: -0.3764101080188552 and parameters: {'learning_rate': 0.011321044189183258, 'num_leaves': 119, 'max_depth': 13, 'min_child_samples': 57, 'feature_fraction': 0.7254672680114372, 'bagging_fraction': 0.8861261415852792, 'reg_alpha': 0.3306199409261376, 'reg_lambda': 0.0002216861974409424}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:36,053] Trial 109 finished with value: -0.3766360355455392 and parameters: {'learning_rate': 0.012772905399977897, 'num_leaves': 241, 'max_depth': 14, 'min_child_samples': 60, 'feature_fraction': 0.7774683225770423, 'bagging_fraction': 0.872314792675529, 'reg_alpha': 0.025211097462192678, 'reg_lambda': 0.02767065194018781}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:38,566] Trial 110 finished with value: -0.3760197717558916 and parameters: {'learning_rate': 0.013985697762891327, 'num_leaves': 100, 'max_depth': 15, 'min_child_samples': 72, 'feature_fraction': 0.8669999981479602, 'bagging_fraction': 0.8134944473138679, 'reg_alpha': 0.1525392112420032, 'reg_lambda': 0.0001288555690712639}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:41,082] Trial 111 finished with value: -0.3780075121933125 and parameters: {'learning_rate': 0.016027761581384168, 'num_leaves': 250, 'max_depth': 15, 'min_child_samples': 61, 'feature_fraction': 0.8248839247275499, 'bagging_fraction': 0.8385049943948528, 'reg_alpha': 1.1891938106249265, 'reg_lambda': 7.841105714271139e-05}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:43,480] Trial 112 finished with value: -0.37631577575814046 and parameters: {'learning_rate': 0.015752010570948497, 'num_leaves': 256, 'max_depth': 15, 'min_child_samples': 61, 'feature_fraction': 0.8260742570649624, 'bagging_fraction': 0.8960764521861426, 'reg_alpha': 0.480680466847543, 'reg_lambda': 0.00044448634996160756}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:45,783] Trial 113 finished with value: -0.37425751765896875 and parameters: {'learning_rate': 0.019404104340742637, 'num_leaves': 237, 'max_depth': 14, 'min_child_samples': 52, 'feature_fraction': 0.8440623175536702, 'bagging_fraction': 0.8392314734825814, 'reg_alpha': 2.192575276082551, 'reg_lambda': 1.9157427580035753e-05}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:49,034] Trial 114 finished with value: -0.3761263455963131 and parameters: {'learning_rate': 0.010164797642607006, 'num_leaves': 249, 'max_depth': 15, 'min_child_samples': 65, 'feature_fraction': 0.7827599389640689, 'bagging_fraction': 0.8501285958934716, 'reg_alpha': 1.5008273909793075e-05, 'reg_lambda': 8.634724461361322e-05}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:49,733] Trial 115 finished with value: -0.3714046432424699 and parameters: {'learning_rate': 0.19720485258888784, 'num_leaves': 251, 'max_depth': 15, 'min_child_samples': 58, 'feature_fraction': 0.8040614247080314, 'bagging_fraction': 0.8265050706038839, 'reg_alpha': 0.017742934700028884, 'reg_lambda': 3.80073397037711e-05}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:52,389] Trial 116 finished with value: -0.37400211049592746 and parameters: {'learning_rate': 0.012146340087041832, 'num_leaves': 227, 'max_depth': 14, 'min_child_samples': 55, 'feature_fraction': 0.8187800161510509, 'bagging_fraction': 0.7942722352592939, 'reg_alpha': 1.4956134554997068e-08, 'reg_lambda': 1.133312659811048e-05}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:54,526] Trial 117 finished with value: -0.37564141571427834 and parameters: {'learning_rate': 0.016279442283817922, 'num_leaves': 221, 'max_depth': 15, 'min_child_samples': 68, 'feature_fraction': 0.7674150733092494, 'bagging_fraction': 0.8155013643395408, 'reg_alpha': 0.0036552485114284775, 'reg_lambda': 2.3122627040856904e-05}. Best is trial 107 with value: -0.37883060756583875.
[I 2025-08-05 18:44:56,445] Trial 118 finished with value: -0.3790857700504716 and parameters: {'learning_rate': 0.02067276298567349, 'num_leaves': 234, 'max_depth': 14, 'min_child_samples': 61, 'feature_fraction': 0.8419565672255138, 'bagging_fraction': 0.8615151466144517, 'reg_alpha': 0.23744285762860545, 'reg_lambda': 0.0554318415281263}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:44:58,309] Trial 119 finished with value: -0.37723141816465344 and parameters: {'learning_rate': 0.02080304976448287, 'num_leaves': 233, 'max_depth': 14, 'min_child_samples': 62, 'feature_fraction': 0.8084705908182418, 'bagging_fraction': 0.8616726203157732, 'reg_alpha': 0.22523141554698237, 'reg_lambda': 0.09327771026544131}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:44:59,599] Trial 120 finished with value: -0.37278705530562123 and parameters: {'learning_rate': 0.02080966234551002, 'num_leaves': 16, 'max_depth': 13, 'min_child_samples': 58, 'feature_fraction': 0.8372780771820865, 'bagging_fraction': 0.8606825389284402, 'reg_alpha': 0.24292806900635502, 'reg_lambda': 1.2323331976821212}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:02,069] Trial 121 finished with value: -0.37815667871914027 and parameters: {'learning_rate': 0.017915588815326934, 'num_leaves': 233, 'max_depth': 14, 'min_child_samples': 61, 'feature_fraction': 0.8097172566985759, 'bagging_fraction': 0.8660688695837552, 'reg_alpha': 0.11418098163599676, 'reg_lambda': 0.25468337725840173}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:04,543] Trial 122 finished with value: -0.3751390228263608 and parameters: {'learning_rate': 0.014488962289721484, 'num_leaves': 240, 'max_depth': 14, 'min_child_samples': 60, 'feature_fraction': 0.80829660667619, 'bagging_fraction': 0.9121801633277611, 'reg_alpha': 0.11522006905131238, 'reg_lambda': 0.07820804327362002}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:06,808] Trial 123 finished with value: -0.37675585370953485 and parameters: {'learning_rate': 0.01842348741065267, 'num_leaves': 246, 'max_depth': 14, 'min_child_samples': 67, 'feature_fraction': 0.8116501619411531, 'bagging_fraction': 0.8963813806570713, 'reg_alpha': 0.2331359755921449, 'reg_lambda': 4.747938704759808}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:08,918] Trial 124 finished with value: -0.3779386789106489 and parameters: {'learning_rate': 0.018123185603071513, 'num_leaves': 132, 'max_depth': 14, 'min_child_samples': 61, 'feature_fraction': 0.8254986841202706, 'bagging_fraction': 0.8749201694762414, 'reg_alpha': 0.42186997096400086, 'reg_lambda': 0.4871005621880035}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:10,789] Trial 125 finished with value: -0.3764893900809156 and parameters: {'learning_rate': 0.01911194767297325, 'num_leaves': 131, 'max_depth': 13, 'min_child_samples': 55, 'feature_fraction': 0.8295916350940986, 'bagging_fraction': 0.8714582073591133, 'reg_alpha': 0.4531978805351955, 'reg_lambda': 0.395849298519087}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:12,583] Trial 126 finished with value: -0.37692006373076564 and parameters: {'learning_rate': 0.020968863955854473, 'num_leaves': 136, 'max_depth': 14, 'min_child_samples': 62, 'feature_fraction': 0.7764467559216589, 'bagging_fraction': 0.8881492711561424, 'reg_alpha': 0.8605034098428667, 'reg_lambda': 0.22406814281319412}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:14,420] Trial 127 finished with value: -0.3762068588439734 and parameters: {'learning_rate': 0.021882347866368418, 'num_leaves': 115, 'max_depth': 14, 'min_child_samples': 50, 'feature_fraction': 0.8182992283308173, 'bagging_fraction': 0.9226913416024509, 'reg_alpha': 0.05622494970533591, 'reg_lambda': 0.6258917385012734}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:15,857] Trial 128 finished with value: -0.37676170869002 and parameters: {'learning_rate': 0.02866931941871432, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 64, 'feature_fraction': 0.7874511560377666, 'bagging_fraction': 0.8673683333157544, 'reg_alpha': 0.08799727030001689, 'reg_lambda': 0.06135637277724056}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:18,115] Trial 129 finished with value: -0.37609176950961665 and parameters: {'learning_rate': 0.017913473476183932, 'num_leaves': 77, 'max_depth': 14, 'min_child_samples': 53, 'feature_fraction': 0.800114323748655, 'bagging_fraction': 0.8525983320624139, 'reg_alpha': 0.1691739992808146, 'reg_lambda': 1.5416880350446835}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:19,878] Trial 130 finished with value: -0.37654729806855214 and parameters: {'learning_rate': 0.023315425878448717, 'num_leaves': 148, 'max_depth': 15, 'min_child_samples': 59, 'feature_fraction': 0.7503762507116737, 'bagging_fraction': 0.8780877273143842, 'reg_alpha': 1.638935526354224, 'reg_lambda': 0.11871123334071734}. Best is trial 118 with value: -0.3790857700504716.
[I 2025-08-05 18:45:21,870] Trial 131 finished with value: -0.37938395163064437 and parameters: {'learning_rate': 0.02013377656171136, 'num_leaves': 159, 'max_depth': 15, 'min_child_samples': 61, 'feature_fraction': 0.8451145350830436, 'bagging_fraction': 0.8379712112519223, 'reg_alpha': 0.5426902685434405, 'reg_lambda': 0.7750488021663446}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:23,824] Trial 132 finished with value: -0.3784281337593747 and parameters: {'learning_rate': 0.020467444541808936, 'num_leaves': 156, 'max_depth': 15, 'min_child_samples': 61, 'feature_fraction': 0.8482403991837251, 'bagging_fraction': 0.9427124825752294, 'reg_alpha': 0.5025982734053785, 'reg_lambda': 0.7731207265370359}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:25,982] Trial 133 finished with value: -0.3778437139083941 and parameters: {'learning_rate': 0.01991404575394197, 'num_leaves': 163, 'max_depth': 15, 'min_child_samples': 61, 'feature_fraction': 0.8453276122308213, 'bagging_fraction': 0.8411673158577255, 'reg_alpha': 0.5456640055267045, 'reg_lambda': 0.6720643526998236}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:27,849] Trial 134 finished with value: -0.37645227103665696 and parameters: {'learning_rate': 0.019791843975812965, 'num_leaves': 158, 'max_depth': 15, 'min_child_samples': 56, 'feature_fraction': 0.849431655689168, 'bagging_fraction': 0.8426148570088094, 'reg_alpha': 0.5338321170948013, 'reg_lambda': 0.5843472356443781}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:29,512] Trial 135 finished with value: -0.37733451808896323 and parameters: {'learning_rate': 0.02574592562263901, 'num_leaves': 168, 'max_depth': 15, 'min_child_samples': 60, 'feature_fraction': 0.8258999360922954, 'bagging_fraction': 0.9804641677863342, 'reg_alpha': 0.8344757297767933, 'reg_lambda': 0.18991688911576365}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:31,559] Trial 136 finished with value: -0.37408748884167725 and parameters: {'learning_rate': 0.02235888957306645, 'num_leaves': 158, 'max_depth': 15, 'min_child_samples': 60, 'feature_fraction': 0.837877531557956, 'bagging_fraction': 0.9820491114841903, 'reg_alpha': 3.0327846968447365, 'reg_lambda': 0.23907780057470207}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:33,195] Trial 137 finished with value: -0.3757135700234821 and parameters: {'learning_rate': 0.02600525336987869, 'num_leaves': 162, 'max_depth': 15, 'min_child_samples': 57, 'feature_fraction': 0.8592089247833531, 'bagging_fraction': 0.9581838874841754, 'reg_alpha': 0.9281148169650586, 'reg_lambda': 0.6960928700546792}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:35,283] Trial 138 finished with value: -0.3773710386749386 and parameters: {'learning_rate': 0.01831086110952102, 'num_leaves': 174, 'max_depth': 15, 'min_child_samples': 64, 'feature_fraction': 0.8274232535600928, 'bagging_fraction': 0.8376156144856578, 'reg_alpha': 0.3959245645213101, 'reg_lambda': 0.9432946289636022}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:37,433] Trial 139 finished with value: -0.3756376948393362 and parameters: {'learning_rate': 0.01791723905560797, 'num_leaves': 179, 'max_depth': 15, 'min_child_samples': 65, 'feature_fraction': 0.848124803506544, 'bagging_fraction': 0.8375720059478925, 'reg_alpha': 0.3980621441192401, 'reg_lambda': 2.184447161296405}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:40,004] Trial 140 finished with value: -0.37654609294605956 and parameters: {'learning_rate': 0.016609166373270798, 'num_leaves': 174, 'max_depth': 14, 'min_child_samples': 67, 'feature_fraction': 0.8256499184697371, 'bagging_fraction': 0.8561387501352458, 'reg_alpha': 1.5172799968564612, 'reg_lambda': 1.1522971119558483}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:41,976] Trial 141 finished with value: -0.3769755868853645 and parameters: {'learning_rate': 0.01986176682295558, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 63, 'feature_fraction': 0.837943500372294, 'bagging_fraction': 0.8496311253521333, 'reg_alpha': 0.5874853181973222, 'reg_lambda': 0.38666407793451785}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:43,714] Trial 142 finished with value: -0.375995272597809 and parameters: {'learning_rate': 0.02390951230310838, 'num_leaves': 170, 'max_depth': 15, 'min_child_samples': 60, 'feature_fraction': 0.8247669286172339, 'bagging_fraction': 0.9907537531128419, 'reg_alpha': 0.34801976757732456, 'reg_lambda': 0.20811819474336732}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:45,588] Trial 143 finished with value: -0.375177711986135 and parameters: {'learning_rate': 0.028128196312201686, 'num_leaves': 166, 'max_depth': 15, 'min_child_samples': 65, 'feature_fraction': 0.8685407319323314, 'bagging_fraction': 0.9034948295509536, 'reg_alpha': 4.500502039787951, 'reg_lambda': 0.7066197088133176}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:47,857] Trial 144 finished with value: -0.37529084591490863 and parameters: {'learning_rate': 0.018611923245285756, 'num_leaves': 153, 'max_depth': 15, 'min_child_samples': 58, 'feature_fraction': 0.8164409556405423, 'bagging_fraction': 0.5480570021168897, 'reg_alpha': 0.8459272262656578, 'reg_lambda': 4.246030298391505}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:50,181] Trial 145 finished with value: -0.37861484393064065 and parameters: {'learning_rate': 0.017171064424374553, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 64, 'feature_fraction': 0.8436356965340336, 'bagging_fraction': 0.9446266340649057, 'reg_alpha': 1.140799911227478, 'reg_lambda': 2.6668623944341534}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:52,770] Trial 146 finished with value: -0.3756795001104659 and parameters: {'learning_rate': 0.014863706900887372, 'num_leaves': 145, 'max_depth': 14, 'min_child_samples': 69, 'feature_fraction': 0.8530177877239425, 'bagging_fraction': 0.9392266197062873, 'reg_alpha': 1.9144048866209302, 'reg_lambda': 1.7286371403084606}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:55,172] Trial 147 finished with value: -0.3783807186039209 and parameters: {'learning_rate': 0.01699705962394955, 'num_leaves': 172, 'max_depth': 15, 'min_child_samples': 64, 'feature_fraction': 0.8417420275416087, 'bagging_fraction': 0.8233512901671021, 'reg_alpha': 1.2113100030750303, 'reg_lambda': 0.9216999671287971}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:45:57,530] Trial 148 finished with value: -0.3768106398974431 and parameters: {'learning_rate': 0.017014271227413395, 'num_leaves': 199, 'max_depth': 14, 'min_child_samples': 66, 'feature_fraction': 0.8414036884096635, 'bagging_fraction': 0.828208956110721, 'reg_alpha': 1.1719127230045256, 'reg_lambda': 0.34251789334128707}. Best is trial 131 with value: -0.37938395163064437.
[I 2025-08-05 18:46:00,497] Trial 149 finished with value: -0.3731955564761406 and parameters: {'learning_rate': 0.013429538004158607, 'num_leaves': 192, 'max_depth': 12, 'min_child_samples': 62, 'feature_fraction': 0.8854193995526823, 'bagging_fraction': 0.9525142031242954, 'reg_alpha': 4.164658020407134, 'reg_lambda': 9.611403882021714}. Best is trial 131 with value: -0.37938395163064437.
2025-08-05 18:46:00 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.40303157013342905, 'val_lightgbm': 0.3885738547842924, 'val_ensemble': 0.40727281489111977}
2025-08-05 18:46:00 [INFO] Selected best model 'ensemble' with validation R²=0.4073
2025-08-05 18:46:01 [INFO] Retraining best model 'ensemble' on full dataset
2025-08-05 18:46:06 [INFO] Retraining completed in 5.30s
2025-08-05 18:46:06 [INFO] Saved final model to '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/final_ensemble.pkl'
2025-08-05 18:46:06 [INFO] Tree-based → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/final_ensemble.pkl (R²=0.4073)
2025-08-05 18:46:06 [INFO] Training TabNet model...
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 18:46:06,950] A new study created in memory with name: no-name-56051444-7ce1-493f-8f93-f8a17c588e43
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:46:41,563] Trial 0 finished with value: 0.314807362678158 and parameters: {'n_d': 57, 'n_a': 32, 'n_steps': 6, 'gamma': 1.9127237419594216, 'lambda_sparse': 1.0813157972083917e-05, 'lr': 0.004061580571048607, 'weight_decay': 0.00022594802545885257}. Best is trial 0 with value: 0.314807362678158.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:47:23,034] Trial 1 finished with value: -2.403495334611619 and parameters: {'n_d': 24, 'n_a': 37, 'n_steps': 9, 'gamma': 1.194693810181912, 'lambda_sparse': 7.345013332935562e-05, 'lr': 0.00011494253449516327, 'weight_decay': 0.0007415940897849391}. Best is trial 0 with value: 0.314807362678158.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:47:48,952] Trial 2 finished with value: 0.32366392292502655 and parameters: {'n_d': 50, 'n_a': 21, 'n_steps': 4, 'gamma': 1.8966394555720039, 'lambda_sparse': 6.227512290494734e-05, 'lr': 0.007386193516395093, 'weight_decay': 0.0003851817915786762}. Best is trial 2 with value: 0.32366392292502655.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:48:14,897] Trial 3 finished with value: 0.2921706912519205 and parameters: {'n_d': 57, 'n_a': 62, 'n_steps': 4, 'gamma': 1.487356161056895, 'lambda_sparse': 0.0023346297223746596, 'lr': 0.001110324920555219, 'weight_decay': 1.1831059454827291e-05}. Best is trial 2 with value: 0.32366392292502655.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:48:44,957] Trial 4 finished with value: 0.3396521864786859 and parameters: {'n_d': 47, 'n_a': 10, 'n_steps': 6, 'gamma': 1.6357403553686785, 'lambda_sparse': 9.096961388514235e-05, 'lr': 0.0029257716679087515, 'weight_decay': 5.482979725800118e-06}. Best is trial 4 with value: 0.3396521864786859.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:49:16,814] Trial 5 finished with value: -1.845875856152952 and parameters: {'n_d': 37, 'n_a': 15, 'n_steps': 9, 'gamma': 1.8812027915990468, 'lambda_sparse': 5.157639476455683e-05, 'lr': 0.0003326146657496228, 'weight_decay': 0.0006751738537521158}. Best is trial 4 with value: 0.3396521864786859.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:49:22,289] Trial 6 finished with value: -0.22789666433287636 and parameters: {'n_d': 18, 'n_a': 35, 'n_steps': 3, 'gamma': 1.5483799126067255, 'lambda_sparse': 3.918012432037273e-05, 'lr': 0.02706873072025961, 'weight_decay': 5.4479448251839026e-05}. Best is trial 4 with value: 0.3396521864786859.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:49:52,920] Trial 7 finished with value: 0.3049163807430363 and parameters: {'n_d': 58, 'n_a': 35, 'n_steps': 7, 'gamma': 1.4894405391780556, 'lambda_sparse': 1.0704723880258274e-05, 'lr': 0.007239111544691012, 'weight_decay': 2.3456414634309984e-05}. Best is trial 4 with value: 0.3396521864786859.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:50:00,143] Trial 8 finished with value: 0.006201716738450713 and parameters: {'n_d': 45, 'n_a': 49, 'n_steps': 5, 'gamma': 1.3491215235260319, 'lambda_sparse': 0.005158426236147618, 'lr': 0.06658598882250003, 'weight_decay': 0.0001662192396205474}. Best is trial 4 with value: 0.3396521864786859.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:50:25,878] Trial 9 finished with value: 0.2459491117183371 and parameters: {'n_d': 11, 'n_a': 13, 'n_steps': 5, 'gamma': 1.4703837213583708, 'lambda_sparse': 0.004159673048853748, 'lr': 0.003791544169964069, 'weight_decay': 1.2270963996620118e-06}. Best is trial 4 with value: 0.3396521864786859.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:50:59,560] Trial 10 finished with value: 0.20910919436083175 and parameters: {'n_d': 32, 'n_a': 8, 'n_steps': 7, 'gamma': 1.6859179821061314, 'lambda_sparse': 0.0005555166558210584, 'lr': 0.0009384333690991923, 'weight_decay': 3.113930782898749e-06}. Best is trial 4 with value: 0.3396521864786859.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:51:21,515] Trial 11 finished with value: 0.3721702583296679 and parameters: {'n_d': 46, 'n_a': 21, 'n_steps': 3, 'gamma': 1.7307185479347817, 'lambda_sparse': 0.00018422095971292726, 'lr': 0.01397056821631116, 'weight_decay': 6.4922463108197635e-06}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:51:42,955] Trial 12 finished with value: 0.35713775302638573 and parameters: {'n_d': 43, 'n_a': 24, 'n_steps': 3, 'gamma': 1.7464786074849408, 'lambda_sparse': 0.0004773104526483612, 'lr': 0.020845890185475054, 'weight_decay': 5.6106173309895675e-06}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:52:04,432] Trial 13 finished with value: 0.3286189891976544 and parameters: {'n_d': 37, 'n_a': 24, 'n_steps': 3, 'gamma': 1.7514952254144156, 'lambda_sparse': 0.0005067492550645442, 'lr': 0.022131391251016503, 'weight_decay': 5.671360278972318e-06}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:52:11,338] Trial 14 finished with value: -0.142721461829582 and parameters: {'n_d': 64, 'n_a': 24, 'n_steps': 3, 'gamma': 1.7913387275077384, 'lambda_sparse': 0.001442503592054285, 'lr': 0.02300453564622012, 'weight_decay': 1.0911027407516846e-06}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:52:18,468] Trial 15 finished with value: -0.2536511877979022 and parameters: {'n_d': 41, 'n_a': 45, 'n_steps': 4, 'gamma': 1.9820226962504177, 'lambda_sparse': 0.00024563147785435093, 'lr': 0.041366403999182, 'weight_decay': 4.7671505381192276e-05}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:53:03,239] Trial 16 finished with value: 0.36522512049525757 and parameters: {'n_d': 27, 'n_a': 19, 'n_steps': 10, 'gamma': 1.0507362415570483, 'lambda_sparse': 0.00022879134496711924, 'lr': 0.012646938316864835, 'weight_decay': 1.592905024673452e-05}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:53:47,922] Trial 17 finished with value: 0.351505701291972 and parameters: {'n_d': 27, 'n_a': 19, 'n_steps': 10, 'gamma': 1.047353290977295, 'lambda_sparse': 0.00023527498368904756, 'lr': 0.010819006907056596, 'weight_decay': 1.5137572466686017e-05}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:54:25,145] Trial 18 finished with value: 0.2799051720403388 and parameters: {'n_d': 30, 'n_a': 30, 'n_steps': 8, 'gamma': 1.3104423399521947, 'lambda_sparse': 0.00015349304206289398, 'lr': 0.001552678596507777, 'weight_decay': 8.63954518889835e-05}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:54:44,569] Trial 19 finished with value: -0.08830950703286544 and parameters: {'n_d': 20, 'n_a': 43, 'n_steps': 10, 'gamma': 1.0820426910065446, 'lambda_sparse': 2.3122685790001582e-05, 'lr': 0.07765055563869165, 'weight_decay': 2.389019893592545e-06}. Best is trial 11 with value: 0.3721702583296679.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 18:55:11,525] A new study created in memory with name: no-name-fc80218c-6d57-4079-b663-30ee288a3c56
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:55:50,739] Trial 0 finished with value: 0.30047278257539756 and parameters: {'n_d': 16, 'n_a': 17, 'n_steps': 9, 'gamma': 1.3234011933664045, 'lambda_sparse': 0.0013064414608004332, 'lr': 0.002888233235386529, 'weight_decay': 7.829659020093581e-05}. Best is trial 0 with value: 0.30047278257539756.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:56:12,229] Trial 1 finished with value: 0.3395133336061805 and parameters: {'n_d': 13, 'n_a': 42, 'n_steps': 3, 'gamma': 1.0127537981187986, 'lambda_sparse': 0.0001306316301681951, 'lr': 0.0023798142379384555, 'weight_decay': 0.0003008271553716286}. Best is trial 1 with value: 0.3395133336061805.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:56:42,558] Trial 2 finished with value: 0.38461346578618294 and parameters: {'n_d': 26, 'n_a': 28, 'n_steps': 6, 'gamma': 1.5593374255660777, 'lambda_sparse': 0.001173150925410537, 'lr': 0.015396307499603875, 'weight_decay': 1.5574554395838472e-05}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:57:01,966] Trial 3 finished with value: 0.27569499261581487 and parameters: {'n_d': 35, 'n_a': 15, 'n_steps': 3, 'gamma': 1.9582899331605401, 'lambda_sparse': 2.897137368359732e-05, 'lr': 0.012018345918131503, 'weight_decay': 0.00010115386836016024}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:57:09,651] Trial 4 finished with value: -0.017084690776830502 and parameters: {'n_d': 10, 'n_a': 58, 'n_steps': 3, 'gamma': 1.978538559800978, 'lambda_sparse': 0.0005318546822184339, 'lr': 0.07435592543072124, 'weight_decay': 3.6268763955025805e-05}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:57:55,064] Trial 5 finished with value: 0.18654611598295656 and parameters: {'n_d': 35, 'n_a': 49, 'n_steps': 10, 'gamma': 1.0949362609701045, 'lambda_sparse': 0.0011330632050020524, 'lr': 0.0009228503102796597, 'weight_decay': 1.2414293656039923e-05}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:58:16,545] Trial 6 finished with value: 0.314418904173163 and parameters: {'n_d': 21, 'n_a': 15, 'n_steps': 3, 'gamma': 1.8291633804730454, 'lambda_sparse': 0.0019137466473885761, 'lr': 0.009371170518507667, 'weight_decay': 2.698252781861111e-06}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:58:57,776] Trial 7 finished with value: -0.9353904584124952 and parameters: {'n_d': 22, 'n_a': 41, 'n_steps': 9, 'gamma': 1.981381377549517, 'lambda_sparse': 0.00674932768421638, 'lr': 0.00034736224589861634, 'weight_decay': 1.8249952675673434e-05}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 18:59:19,433] Trial 8 finished with value: 0.24909375712456205 and parameters: {'n_d': 9, 'n_a': 12, 'n_steps': 3, 'gamma': 1.7577733292538045, 'lambda_sparse': 0.00011581250908326188, 'lr': 0.000548817763847608, 'weight_decay': 4.782485598645321e-05}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:00:00,100] Trial 9 finished with value: 0.2791822606431429 and parameters: {'n_d': 30, 'n_a': 34, 'n_steps': 9, 'gamma': 1.771211944636683, 'lambda_sparse': 0.004933814073153864, 'lr': 0.005808747475713189, 'weight_decay': 3.335715784859606e-06}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:00:30,272] Trial 10 finished with value: 0.3436150195934724 and parameters: {'n_d': 54, 'n_a': 28, 'n_steps': 6, 'gamma': 1.5164274194976322, 'lambda_sparse': 1.5039458847408292e-05, 'lr': 0.038283420105964354, 'weight_decay': 0.0009058876347149096}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:01:00,373] Trial 11 finished with value: 0.34922814629313526 and parameters: {'n_d': 55, 'n_a': 27, 'n_steps': 6, 'gamma': 1.5049974283617027, 'lambda_sparse': 1.5649646715941344e-05, 'lr': 0.048206783422460354, 'weight_decay': 0.0009886755009500025}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:01:30,559] Trial 12 finished with value: 0.34429828243989613 and parameters: {'n_d': 52, 'n_a': 27, 'n_steps': 6, 'gamma': 1.5232648121748775, 'lambda_sparse': 7.094168788385492e-05, 'lr': 0.02596251385793976, 'weight_decay': 8.227114498340951e-06}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:01:57,090] Trial 13 finished with value: 0.33429367114699904 and parameters: {'n_d': 63, 'n_a': 25, 'n_steps': 5, 'gamma': 1.3068200153396845, 'lambda_sparse': 0.0003152591666215292, 'lr': 0.0936882299932335, 'weight_decay': 1.0561178437389286e-06}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:02:30,751] Trial 14 finished with value: 0.3443136641825143 and parameters: {'n_d': 45, 'n_a': 33, 'n_steps': 7, 'gamma': 1.6416050908782012, 'lambda_sparse': 0.00037879655892965206, 'lr': 0.02693533475308478, 'weight_decay': 0.0002227551628066575}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:02:57,264] Trial 15 finished with value: 0.33890591394969416 and parameters: {'n_d': 44, 'n_a': 23, 'n_steps': 5, 'gamma': 1.2982703820247656, 'lambda_sparse': 1.2733914202428083e-05, 'lr': 0.015106591054053575, 'weight_decay': 0.0007626320567219374}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:03:31,118] Trial 16 finished with value: -0.08546505319899889 and parameters: {'n_d': 64, 'n_a': 42, 'n_steps': 7, 'gamma': 1.4107442822677807, 'lambda_sparse': 0.002861412615603403, 'lr': 0.00013011358040942902, 'weight_decay': 5.340122787663905e-06}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:03:57,620] Trial 17 finished with value: 0.33489240909455575 and parameters: {'n_d': 26, 'n_a': 21, 'n_steps': 5, 'gamma': 1.6411049060621774, 'lambda_sparse': 4.554322712361026e-05, 'lr': 0.0449218385887163, 'weight_decay': 2.2283775293322854e-05}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:04:34,303] Trial 18 finished with value: 0.30400347344955136 and parameters: {'n_d': 43, 'n_a': 9, 'n_steps': 8, 'gamma': 1.5970405062167194, 'lambda_sparse': 0.00019330246322657533, 'lr': 0.005848521819313905, 'weight_decay': 0.0002217038725034155}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:04:56,346] Trial 19 finished with value: 0.34579913263213635 and parameters: {'n_d': 57, 'n_a': 62, 'n_steps': 4, 'gamma': 1.1730904164919023, 'lambda_sparse': 0.0007531705107786588, 'lr': 0.02005285393406807, 'weight_decay': 0.00010097400395823694}. Best is trial 2 with value: 0.38461346578618294.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 19:05:30,903] A new study created in memory with name: no-name-548111be-df91-4b2f-94c8-6d75926c4a43
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:05:52,213] Trial 0 finished with value: 0.33906429633587787 and parameters: {'n_d': 59, 'n_a': 57, 'n_steps': 3, 'gamma': 1.171116438699477, 'lambda_sparse': 1.5887677708614663e-05, 'lr': 0.03970658635652184, 'weight_decay': 3.1354735844583235e-05}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:06:25,505] Trial 1 finished with value: 0.32295777803933756 and parameters: {'n_d': 63, 'n_a': 63, 'n_steps': 7, 'gamma': 1.4321680770205398, 'lambda_sparse': 0.00030960700838894784, 'lr': 0.02414926574212067, 'weight_decay': 6.301993193388384e-05}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:07:02,266] Trial 2 finished with value: 0.2904131576342286 and parameters: {'n_d': 50, 'n_a': 57, 'n_steps': 8, 'gamma': 1.1105496634345375, 'lambda_sparse': 0.0074347020812365145, 'lr': 0.02208272565817303, 'weight_decay': 1.9241316235808117e-06}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:07:35,717] Trial 3 finished with value: 0.33162746557714184 and parameters: {'n_d': 49, 'n_a': 9, 'n_steps': 7, 'gamma': 1.2835259527690561, 'lambda_sparse': 0.000286891532464217, 'lr': 0.03624182069012715, 'weight_decay': 1.2458150743992274e-06}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:08:12,499] Trial 4 finished with value: 0.2868639409946592 and parameters: {'n_d': 10, 'n_a': 47, 'n_steps': 8, 'gamma': 1.7314213085996477, 'lambda_sparse': 3.440868003518413e-05, 'lr': 0.028769757099738176, 'weight_decay': 1.2197503281126742e-05}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:08:53,400] Trial 5 finished with value: 0.22479453111540526 and parameters: {'n_d': 52, 'n_a': 24, 'n_steps': 9, 'gamma': 1.7000793787468922, 'lambda_sparse': 5.806153288373391e-05, 'lr': 0.004994673672986455, 'weight_decay': 1.299346609038228e-05}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:09:30,141] Trial 6 finished with value: 0.3135511770765571 and parameters: {'n_d': 10, 'n_a': 50, 'n_steps': 8, 'gamma': 1.6163214421176177, 'lambda_sparse': 1.2098668416102127e-05, 'lr': 0.03534850489563793, 'weight_decay': 8.005653919998667e-05}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:09:53,925] Trial 7 finished with value: 0.053861745920016024 and parameters: {'n_d': 53, 'n_a': 12, 'n_steps': 4, 'gamma': 1.5530377784289138, 'lambda_sparse': 0.0006387586226719516, 'lr': 0.00016646632871060725, 'weight_decay': 0.0006859653589195177}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:10:26,824] Trial 8 finished with value: 0.2821275557637004 and parameters: {'n_d': 53, 'n_a': 36, 'n_steps': 8, 'gamma': 1.9302672421764646, 'lambda_sparse': 0.0011149707442566926, 'lr': 0.008995604826066289, 'weight_decay': 0.0002719080710053119}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:11:11,291] Trial 9 finished with value: 0.2721475683452417 and parameters: {'n_d': 23, 'n_a': 23, 'n_steps': 10, 'gamma': 1.6237575699970959, 'lambda_sparse': 2.2447150962443616e-05, 'lr': 0.025912410519739616, 'weight_decay': 1.1517051054213886e-06}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:11:32,990] Trial 10 finished with value: 0.295213795043061 and parameters: {'n_d': 34, 'n_a': 40, 'n_steps': 3, 'gamma': 1.0521058874004283, 'lambda_sparse': 0.00012301215354898202, 'lr': 0.0009250051453271624, 'weight_decay': 7.751567083699075e-06}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:11:59,441] Trial 11 finished with value: 0.3063708601993461 and parameters: {'n_d': 40, 'n_a': 9, 'n_steps': 5, 'gamma': 1.283269384932578, 'lambda_sparse': 0.002694874023567619, 'lr': 0.09075359982492073, 'weight_decay': 5.512790220672527e-06}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:12:29,531] Trial 12 finished with value: 0.2613910478420107 and parameters: {'n_d': 64, 'n_a': 27, 'n_steps': 6, 'gamma': 1.2725398771395842, 'lambda_sparse': 0.0001468960475761124, 'lr': 0.0017919416733067704, 'weight_decay': 3.9108735221853876e-05}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:12:41,558] Trial 13 finished with value: -0.05995609693891413 and parameters: {'n_d': 43, 'n_a': 34, 'n_steps': 6, 'gamma': 1.2497786198218765, 'lambda_sparse': 1.0216445658671459e-05, 'lr': 0.09464050139950429, 'weight_decay': 3.4558711010141187e-06}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:13:02,902] Trial 14 finished with value: 0.2863619319895957 and parameters: {'n_d': 31, 'n_a': 16, 'n_steps': 3, 'gamma': 1.4027398623733571, 'lambda_sparse': 7.351036168963212e-05, 'lr': 0.00713799513005462, 'weight_decay': 0.00015906231028773525}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:13:29,880] Trial 15 finished with value: 0.21062480020892793 and parameters: {'n_d': 59, 'n_a': 51, 'n_steps': 5, 'gamma': 1.1293940428228701, 'lambda_sparse': 0.0003128635015548979, 'lr': 0.0005536422310878212, 'weight_decay': 1.9869010755065467e-05}. Best is trial 0 with value: 0.33906429633587787.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:13:56,225] Trial 16 finished with value: 0.34964597511038287 and parameters: {'n_d': 46, 'n_a': 42, 'n_steps': 5, 'gamma': 1.0144367492086381, 'lambda_sparse': 0.0020803652519690483, 'lr': 0.011459030786356886, 'weight_decay': 2.7811579585587833e-06}. Best is trial 16 with value: 0.34964597511038287.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:14:21,046] Trial 17 finished with value: 0.3500189888184263 and parameters: {'n_d': 43, 'n_a': 62, 'n_steps': 4, 'gamma': 1.013197690215228, 'lambda_sparse': 0.002775085918079764, 'lr': 0.011946019413934002, 'weight_decay': 0.0009201512357359543}. Best is trial 17 with value: 0.3500189888184263.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:14:47,969] Trial 18 finished with value: 0.35314838037258356 and parameters: {'n_d': 25, 'n_a': 43, 'n_steps': 5, 'gamma': 1.0420864152023268, 'lambda_sparse': 0.008997740274602564, 'lr': 0.0032280762820640066, 'weight_decay': 0.0007252061623568631}. Best is trial 18 with value: 0.35314838037258356.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:15:10,565] Trial 19 finished with value: 0.31869357759831507 and parameters: {'n_d': 26, 'n_a': 63, 'n_steps': 4, 'gamma': 1.0219602694874719, 'lambda_sparse': 0.008135793756925839, 'lr': 0.002452007950939785, 'weight_decay': 0.0008832147036291078}. Best is trial 18 with value: 0.35314838037258356.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 19:15:45,721] A new study created in memory with name: no-name-c000f30c-1c43-46e1-ba86-495748ef67ce
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:16:20,960] Trial 0 finished with value: -1.67645465030007 and parameters: {'n_d': 64, 'n_a': 47, 'n_steps': 8, 'gamma': 1.2685337188184282, 'lambda_sparse': 0.0034547223007272416, 'lr': 0.0001914071709716608, 'weight_decay': 0.00027046627441065015}. Best is trial 0 with value: -1.67645465030007.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:16:46,461] Trial 1 finished with value: 0.27073204286599606 and parameters: {'n_d': 33, 'n_a': 34, 'n_steps': 4, 'gamma': 1.1053762188338951, 'lambda_sparse': 0.0008336798787308414, 'lr': 0.000660425252564477, 'weight_decay': 6.611822285975065e-05}. Best is trial 1 with value: 0.27073204286599606.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:16:59,316] Trial 2 finished with value: -0.7277298456706025 and parameters: {'n_d': 10, 'n_a': 25, 'n_steps': 8, 'gamma': 1.9457868825643538, 'lambda_sparse': 0.00017961437478836945, 'lr': 0.030871569705536117, 'weight_decay': 0.00046755686764060356}. Best is trial 1 with value: 0.27073204286599606.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:17:33,108] Trial 3 finished with value: 0.3102205309692371 and parameters: {'n_d': 47, 'n_a': 42, 'n_steps': 7, 'gamma': 1.086360287877369, 'lambda_sparse': 0.0003759039999748078, 'lr': 0.0006417533956676641, 'weight_decay': 1.9310396895912284e-05}. Best is trial 3 with value: 0.3102205309692371.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:18:18,566] Trial 4 finished with value: -2.634448198757863 and parameters: {'n_d': 33, 'n_a': 57, 'n_steps': 10, 'gamma': 1.7612037619141194, 'lambda_sparse': 0.00046340298950193885, 'lr': 0.0001289068325766423, 'weight_decay': 0.0005448018605192191}. Best is trial 3 with value: 0.3102205309692371.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:18:46,843] Trial 5 finished with value: 0.027689981057665403 and parameters: {'n_d': 34, 'n_a': 30, 'n_steps': 10, 'gamma': 1.591017466437505, 'lambda_sparse': 0.0006237581010698326, 'lr': 0.002542280248378992, 'weight_decay': 6.493448656913058e-05}. Best is trial 3 with value: 0.3102205309692371.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:19:23,869] Trial 6 finished with value: 0.33767966268493677 and parameters: {'n_d': 46, 'n_a': 12, 'n_steps': 8, 'gamma': 1.3687304473966468, 'lambda_sparse': 1.9322283712821796e-05, 'lr': 0.0026547729130519063, 'weight_decay': 0.0002132518837317196}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:20:08,619] Trial 7 finished with value: 0.19851525126256042 and parameters: {'n_d': 48, 'n_a': 37, 'n_steps': 10, 'gamma': 1.300057945972788, 'lambda_sparse': 1.0348575526590015e-05, 'lr': 0.0007524317144840115, 'weight_decay': 8.934777678234483e-06}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:20:22,200] Trial 8 finished with value: -0.47766479316428034 and parameters: {'n_d': 26, 'n_a': 23, 'n_steps': 7, 'gamma': 1.4245125964094336, 'lambda_sparse': 0.0031886136737726235, 'lr': 0.009748244857474466, 'weight_decay': 0.0006712565691601431}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:20:47,824] Trial 9 finished with value: 0.16540948762390317 and parameters: {'n_d': 37, 'n_a': 22, 'n_steps': 4, 'gamma': 1.8875628441777481, 'lambda_sparse': 0.0008426482729986385, 'lr': 0.00023512772624868067, 'weight_decay': 0.00010949318010483011}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:20:57,573] Trial 10 finished with value: -0.5462971299736612 and parameters: {'n_d': 64, 'n_a': 9, 'n_steps': 5, 'gamma': 1.558962818415069, 'lambda_sparse': 1.0814987301494395e-05, 'lr': 0.07992275124558923, 'weight_decay': 3.826486754626176e-06}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:21:27,768] Trial 11 finished with value: 0.30860865951743854 and parameters: {'n_d': 50, 'n_a': 48, 'n_steps': 6, 'gamma': 1.000408374916894, 'lambda_sparse': 5.338956614499203e-05, 'lr': 0.0029708862375164556, 'weight_decay': 1.5810133840931105e-05}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:22:01,519] Trial 12 finished with value: 0.22719435982657643 and parameters: {'n_d': 47, 'n_a': 8, 'n_steps': 7, 'gamma': 1.1923769983165784, 'lambda_sparse': 0.0001084234322994257, 'lr': 0.0009608574935481858, 'weight_decay': 1.557223287166979e-05}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:22:39,953] Trial 13 finished with value: 0.33521841761873106 and parameters: {'n_d': 57, 'n_a': 42, 'n_steps': 8, 'gamma': 1.3923338244612284, 'lambda_sparse': 3.9473913953729483e-05, 'lr': 0.010882195218212586, 'weight_decay': 1.1335208631944578e-06}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:23:20,819] Trial 14 finished with value: 0.3108466244521908 and parameters: {'n_d': 57, 'n_a': 15, 'n_steps': 9, 'gamma': 1.436468872234238, 'lambda_sparse': 3.710334276204172e-05, 'lr': 0.009486731707259671, 'weight_decay': 1.1273468270842081e-06}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:23:57,706] Trial 15 finished with value: 0.2946794247544682 and parameters: {'n_d': 56, 'n_a': 59, 'n_steps': 8, 'gamma': 1.666415704499565, 'lambda_sparse': 2.8240222798393965e-05, 'lr': 0.008974598685090825, 'weight_decay': 1.956497878666445e-06}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:24:37,979] Trial 16 finished with value: 0.31391568955421045 and parameters: {'n_d': 42, 'n_a': 51, 'n_steps': 9, 'gamma': 1.3642911199231755, 'lambda_sparse': 7.255693295253527e-05, 'lr': 0.020547682944011214, 'weight_decay': 0.00018948831875950946}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:25:07,139] Trial 17 finished with value: 0.3347467995563239 and parameters: {'n_d': 21, 'n_a': 40, 'n_steps': 6, 'gamma': 1.5010213385472668, 'lambda_sparse': 2.1872743911680476e-05, 'lr': 0.004515067460154993, 'weight_decay': 4.0903274169548865e-06}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:25:45,178] Trial 18 finished with value: 0.23220289969563201 and parameters: {'n_d': 55, 'n_a': 17, 'n_steps': 9, 'gamma': 1.2639112099188474, 'lambda_sparse': 0.0001582388750268973, 'lr': 0.0018551520084162016, 'weight_decay': 3.8450598341723e-05}. Best is trial 6 with value: 0.33767966268493677.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:26:04,986] Trial 19 finished with value: 0.35110508763397674 and parameters: {'n_d': 40, 'n_a': 30, 'n_steps': 3, 'gamma': 1.7000419007671843, 'lambda_sparse': 1.6448214803739543e-05, 'lr': 0.09684665331621832, 'weight_decay': 6.693138707615825e-06}. Best is trial 19 with value: 0.35110508763397674.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 19:26:37,532] A new study created in memory with name: no-name-af25bbd2-22fb-4438-b253-16d58006915a
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:27:11,366] Trial 0 finished with value: -8.94598058766246 and parameters: {'n_d': 24, 'n_a': 38, 'n_steps': 7, 'gamma': 1.9622784970585556, 'lambda_sparse': 2.3887720428187684e-05, 'lr': 0.00010155574568385945, 'weight_decay': 3.437164351466261e-05}. Best is trial 0 with value: -8.94598058766246.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:27:44,837] Trial 1 finished with value: 0.28664130528485376 and parameters: {'n_d': 11, 'n_a': 39, 'n_steps': 7, 'gamma': 1.0881673540060999, 'lambda_sparse': 0.00877353119398665, 'lr': 0.007414668252650017, 'weight_decay': 1.208740670541074e-05}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:28:05,643] Trial 2 finished with value: 0.2798341667442601 and parameters: {'n_d': 18, 'n_a': 16, 'n_steps': 3, 'gamma': 1.0604548071854292, 'lambda_sparse': 0.0003347701206464764, 'lr': 0.01070903307762446, 'weight_decay': 0.00014471970057377168}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:28:32,500] Trial 3 finished with value: 0.20215198260496903 and parameters: {'n_d': 35, 'n_a': 37, 'n_steps': 5, 'gamma': 1.4445033203728648, 'lambda_sparse': 0.007794981670313799, 'lr': 0.00238668049220743, 'weight_decay': 1.5754308929093098e-06}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:29:13,180] Trial 4 finished with value: 0.28207004971058347 and parameters: {'n_d': 13, 'n_a': 39, 'n_steps': 9, 'gamma': 1.1006912047262705, 'lambda_sparse': 0.0008793946408934503, 'lr': 0.018735434543370993, 'weight_decay': 0.0008137901608168169}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:29:46,979] Trial 5 finished with value: 0.23036797461338832 and parameters: {'n_d': 18, 'n_a': 12, 'n_steps': 7, 'gamma': 1.359314974708756, 'lambda_sparse': 3.264312821141976e-05, 'lr': 0.0010441758190539651, 'weight_decay': 0.0002942050981875707}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:30:12,424] Trial 6 finished with value: 0.25463996163985436 and parameters: {'n_d': 31, 'n_a': 18, 'n_steps': 4, 'gamma': 1.8993390765708047, 'lambda_sparse': 0.00020619852141021068, 'lr': 0.01182880454283825, 'weight_decay': 0.000925354149575578}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:30:53,546] Trial 7 finished with value: 0.18429131964429724 and parameters: {'n_d': 55, 'n_a': 63, 'n_steps': 9, 'gamma': 1.5150290345558557, 'lambda_sparse': 0.003019259696656491, 'lr': 0.0013480042709037537, 'weight_decay': 0.0006505456433484948}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:31:00,819] Trial 8 finished with value: -1.5342697603690123 and parameters: {'n_d': 13, 'n_a': 25, 'n_steps': 3, 'gamma': 1.9346278508864183, 'lambda_sparse': 0.007989584247174426, 'lr': 0.003473910999966358, 'weight_decay': 6.36011216963648e-06}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:31:31,334] Trial 9 finished with value: 0.24164960619416254 and parameters: {'n_d': 27, 'n_a': 51, 'n_steps': 6, 'gamma': 1.7628900519678339, 'lambda_sparse': 0.0006225000119295235, 'lr': 0.015987632672879736, 'weight_decay': 1.7552413691368235e-06}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:32:15,972] Trial 10 finished with value: 0.21779456628452887 and parameters: {'n_d': 48, 'n_a': 49, 'n_steps': 10, 'gamma': 1.2713786540344272, 'lambda_sparse': 7.871661120150718e-05, 'lr': 0.08168789378964732, 'weight_decay': 1.4859102599407543e-05}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:32:52,786] Trial 11 finished with value: 0.2815642244894965 and parameters: {'n_d': 8, 'n_a': 31, 'n_steps': 8, 'gamma': 1.0068716987523778, 'lambda_sparse': 0.0014359098637544325, 'lr': 0.05207811286551823, 'weight_decay': 5.700283489812323e-05}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:33:33,618] Trial 12 finished with value: 0.2717358517540114 and parameters: {'n_d': 46, 'n_a': 46, 'n_steps': 9, 'gamma': 1.2097480393419016, 'lambda_sparse': 0.0015095036165296803, 'lr': 0.027169586881533987, 'weight_decay': 7.5552367217720136e-06}. Best is trial 1 with value: 0.28664130528485376.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:34:10,804] Trial 13 finished with value: 0.29377390891802213 and parameters: {'n_d': 8, 'n_a': 42, 'n_steps': 8, 'gamma': 1.170579698463126, 'lambda_sparse': 0.002506931116916893, 'lr': 0.005443269550996875, 'weight_decay': 0.00012780786285204209}. Best is trial 13 with value: 0.29377390891802213.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:34:41,165] Trial 14 finished with value: 0.26224766005273414 and parameters: {'n_d': 21, 'n_a': 60, 'n_steps': 6, 'gamma': 1.6251422901807295, 'lambda_sparse': 0.003415146812390948, 'lr': 0.00495549604825483, 'weight_decay': 6.495514418312924e-05}. Best is trial 13 with value: 0.29377390891802213.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:35:18,737] Trial 15 finished with value: 0.004405196271506595 and parameters: {'n_d': 8, 'n_a': 29, 'n_steps': 8, 'gamma': 1.2048346982569944, 'lambda_sparse': 0.00401845781642447, 'lr': 0.00048310640761324727, 'weight_decay': 0.0001483541876014201}. Best is trial 13 with value: 0.29377390891802213.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:35:55,709] Trial 16 finished with value: 0.3138749388420744 and parameters: {'n_d': 41, 'n_a': 43, 'n_steps': 8, 'gamma': 1.1369156751142453, 'lambda_sparse': 0.007345815199750351, 'lr': 0.00737891328987999, 'weight_decay': 1.450979138292739e-05}. Best is trial 16 with value: 0.3138749388420744.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:36:41,331] Trial 17 finished with value: 0.021494142445391717 and parameters: {'n_d': 42, 'n_a': 57, 'n_steps': 10, 'gamma': 1.3587917834209664, 'lambda_sparse': 0.0023020622155540365, 'lr': 0.0004133731932498755, 'weight_decay': 3.7294023429161445e-06}. Best is trial 16 with value: 0.3138749388420744.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:36:59,386] Trial 18 finished with value: -0.1511223257793186 and parameters: {'n_d': 63, 'n_a': 45, 'n_steps': 8, 'gamma': 1.185251912012923, 'lambda_sparse': 0.00021608961638427967, 'lr': 0.03541968493782578, 'weight_decay': 2.5157692807372476e-05}. Best is trial 16 with value: 0.3138749388420744.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:37:26,151] Trial 19 finished with value: 0.23613718246713267 and parameters: {'n_d': 37, 'n_a': 52, 'n_steps': 5, 'gamma': 1.5910946253541618, 'lambda_sparse': 0.0005316480305525502, 'lr': 0.0020230484271768316, 'weight_decay': 0.00011512894759404273}. Best is trial 16 with value: 0.3138749388420744.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 19:38:19,804] A new study created in memory with name: no-name-cc27a27b-fd39-4577-a5d8-c81174fbe0a6
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:38:53,650] Trial 0 finished with value: -0.7361850535938315 and parameters: {'n_d': 57, 'n_a': 32, 'n_steps': 7, 'gamma': 1.861253699282848, 'lambda_sparse': 0.0018401683927371263, 'lr': 0.0001810212318986929, 'weight_decay': 0.0005112015617019861}. Best is trial 0 with value: -0.7361850535938315.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:39:30,571] Trial 1 finished with value: 0.29479792533296223 and parameters: {'n_d': 59, 'n_a': 18, 'n_steps': 8, 'gamma': 1.7433239610525377, 'lambda_sparse': 0.0007899058304588124, 'lr': 0.009007021182676581, 'weight_decay': 0.00022299398061784934}. Best is trial 1 with value: 0.29479792533296223.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:40:04,428] Trial 2 finished with value: 0.07345253464144108 and parameters: {'n_d': 51, 'n_a': 28, 'n_steps': 7, 'gamma': 1.6432488669017213, 'lambda_sparse': 0.005089069875541009, 'lr': 0.0004566906160410662, 'weight_decay': 0.0006560956418611393}. Best is trial 1 with value: 0.29479792533296223.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:40:22,663] Trial 3 finished with value: 0.06380588766647377 and parameters: {'n_d': 23, 'n_a': 35, 'n_steps': 4, 'gamma': 1.7611644623434488, 'lambda_sparse': 0.0020588117590415603, 'lr': 0.00031054215345003303, 'weight_decay': 7.715166790673646e-05}. Best is trial 1 with value: 0.29479792533296223.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:40:53,016] Trial 4 finished with value: 0.1650842221383968 and parameters: {'n_d': 18, 'n_a': 36, 'n_steps': 6, 'gamma': 1.2990573602790438, 'lambda_sparse': 1.3473050395777237e-05, 'lr': 0.0003343905394698445, 'weight_decay': 0.00010540545790450824}. Best is trial 1 with value: 0.29479792533296223.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:41:38,035] Trial 5 finished with value: 0.29325461674098385 and parameters: {'n_d': 42, 'n_a': 41, 'n_steps': 10, 'gamma': 1.5959207855023496, 'lambda_sparse': 0.005573546058511251, 'lr': 0.004499383946999176, 'weight_decay': 1.8772678150576776e-05}. Best is trial 1 with value: 0.29479792533296223.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:41:59,327] Trial 6 finished with value: 0.32389442315466466 and parameters: {'n_d': 58, 'n_a': 50, 'n_steps': 3, 'gamma': 1.9900305357251038, 'lambda_sparse': 8.571216711584606e-05, 'lr': 0.01000302007998334, 'weight_decay': 3.5537290194451856e-06}. Best is trial 6 with value: 0.32389442315466466.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:42:39,603] Trial 7 finished with value: 0.3048901511303189 and parameters: {'n_d': 25, 'n_a': 19, 'n_steps': 9, 'gamma': 1.5654853759062166, 'lambda_sparse': 0.000720276591841433, 'lr': 0.00820131966010386, 'weight_decay': 7.025234190339189e-05}. Best is trial 6 with value: 0.32389442315466466.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:42:46,587] Trial 8 finished with value: -0.36660237549210284 and parameters: {'n_d': 19, 'n_a': 53, 'n_steps': 4, 'gamma': 1.4998851906226545, 'lambda_sparse': 0.00022698175594874397, 'lr': 0.03540110626659285, 'weight_decay': 0.0007589067666375572}. Best is trial 6 with value: 0.32389442315466466.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:43:27,484] Trial 9 finished with value: 0.34752069872484737 and parameters: {'n_d': 28, 'n_a': 51, 'n_steps': 9, 'gamma': 1.5397663729345756, 'lambda_sparse': 0.001288345808215582, 'lr': 0.00899198446750457, 'weight_decay': 3.0231962103549274e-05}. Best is trial 9 with value: 0.34752069872484737.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:43:42,337] Trial 10 finished with value: -0.20959042521758908 and parameters: {'n_d': 31, 'n_a': 64, 'n_steps': 10, 'gamma': 1.0477133555874367, 'lambda_sparse': 6.912685418265583e-05, 'lr': 0.09687898843096575, 'weight_decay': 7.1475413195081565e-06}. Best is trial 9 with value: 0.34752069872484737.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:44:04,001] Trial 11 finished with value: 0.3116020967048664 and parameters: {'n_d': 8, 'n_a': 52, 'n_steps': 3, 'gamma': 1.9025464360984903, 'lambda_sparse': 9.556084273380428e-05, 'lr': 0.001142941118452417, 'weight_decay': 1.1137289475923377e-06}. Best is trial 9 with value: 0.34752069872484737.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:44:30,677] Trial 12 finished with value: 0.3782240757247295 and parameters: {'n_d': 41, 'n_a': 49, 'n_steps': 5, 'gamma': 1.3724804976549994, 'lambda_sparse': 3.646096758732593e-05, 'lr': 0.01612260943981935, 'weight_decay': 4.30046938325885e-06}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:44:40,531] Trial 13 finished with value: -0.27503726310353027 and parameters: {'n_d': 41, 'n_a': 64, 'n_steps': 5, 'gamma': 1.323400184435129, 'lambda_sparse': 1.5463972394159108e-05, 'lr': 0.030804330419739987, 'weight_decay': 1.6921296734090203e-05}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:45:10,970] Trial 14 finished with value: 0.32627303096173277 and parameters: {'n_d': 36, 'n_a': 45, 'n_steps': 6, 'gamma': 1.3626992079581852, 'lambda_sparse': 2.6465315788321407e-05, 'lr': 0.001591769285061874, 'weight_decay': 3.7940998037297414e-06}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:45:47,661] Trial 15 finished with value: 0.3361675290876278 and parameters: {'n_d': 46, 'n_a': 8, 'n_steps': 8, 'gamma': 1.1671032019126275, 'lambda_sparse': 0.0003269592093292338, 'lr': 0.025384297442843245, 'weight_decay': 1.3655139020191395e-06}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:46:14,233] Trial 16 finished with value: 0.32849080676104647 and parameters: {'n_d': 32, 'n_a': 56, 'n_steps': 5, 'gamma': 1.4416910356827854, 'lambda_sparse': 3.741966948056696e-05, 'lr': 0.002348802924407978, 'weight_decay': 9.146295844501309e-06}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:46:51,252] Trial 17 finished with value: 0.3557085432490483 and parameters: {'n_d': 50, 'n_a': 45, 'n_steps': 8, 'gamma': 1.2038536669479296, 'lambda_sparse': 0.0002296275353381377, 'lr': 0.015311957309207414, 'weight_decay': 2.975269931676953e-05}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:47:17,881] Trial 18 finished with value: 0.3629650448334283 and parameters: {'n_d': 49, 'n_a': 43, 'n_steps': 5, 'gamma': 1.1786233916488862, 'lambda_sparse': 0.0002707800556494888, 'lr': 0.06178164452240478, 'weight_decay': 3.907646350634333e-06}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:47:44,261] Trial 19 finished with value: 0.3715922920745579 and parameters: {'n_d': 51, 'n_a': 58, 'n_steps': 5, 'gamma': 1.0158967397122447, 'lambda_sparse': 4.66155407611719e-05, 'lr': 0.08856968406465333, 'weight_decay': 2.5760735448356475e-06}. Best is trial 12 with value: 0.3782240757247295.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 19:48:14,471] A new study created in memory with name: no-name-c2402d15-eded-4d88-af32-a02c116b96e4
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:48:51,129] Trial 0 finished with value: 0.4031662593182672 and parameters: {'n_d': 12, 'n_a': 39, 'n_steps': 8, 'gamma': 1.0871980538204948, 'lambda_sparse': 0.00040679096800989807, 'lr': 0.07882384726524762, 'weight_decay': 3.4940674870618754e-05}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:49:24,516] Trial 1 finished with value: 0.37102440992992614 and parameters: {'n_d': 27, 'n_a': 18, 'n_steps': 7, 'gamma': 1.5613504571560926, 'lambda_sparse': 0.0077222272268469205, 'lr': 0.04133029315068338, 'weight_decay': 5.65669542102975e-05}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:50:05,714] Trial 2 finished with value: -0.5746056409882361 and parameters: {'n_d': 27, 'n_a': 26, 'n_steps': 9, 'gamma': 1.305204658968261, 'lambda_sparse': 1.1139180209870875e-05, 'lr': 0.00015339100558337448, 'weight_decay': 3.683420369150862e-06}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:50:42,648] Trial 3 finished with value: 0.2900782301306226 and parameters: {'n_d': 12, 'n_a': 32, 'n_steps': 8, 'gamma': 1.9694809559632713, 'lambda_sparse': 0.0015897137852650802, 'lr': 0.0029482963873094193, 'weight_decay': 7.7300349045462e-06}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:51:05,708] Trial 4 finished with value: 0.3213854244360931 and parameters: {'n_d': 44, 'n_a': 22, 'n_steps': 4, 'gamma': 1.3398550176909225, 'lambda_sparse': 0.00010632843684722266, 'lr': 0.000731191375499345, 'weight_decay': 5.8177435831207425e-06}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:51:42,494] Trial 5 finished with value: 0.3851076506366534 and parameters: {'n_d': 10, 'n_a': 24, 'n_steps': 8, 'gamma': 1.4402798102247347, 'lambda_sparse': 9.313162429154832e-05, 'lr': 0.010232434488295587, 'weight_decay': 0.0008808113306885355}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:52:19,768] Trial 6 finished with value: -0.02389791661021201 and parameters: {'n_d': 46, 'n_a': 12, 'n_steps': 8, 'gamma': 1.9344683537884597, 'lambda_sparse': 0.0037916407977557423, 'lr': 0.0009334903589719867, 'weight_decay': 0.0008568779886958968}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:52:29,298] Trial 7 finished with value: -0.41427958923345964 and parameters: {'n_d': 52, 'n_a': 38, 'n_steps': 4, 'gamma': 1.9425292618210697, 'lambda_sparse': 0.002223374763065589, 'lr': 0.005609250819199986, 'weight_decay': 0.00010063505437382906}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:52:50,855] Trial 8 finished with value: 0.22154007752798444 and parameters: {'n_d': 47, 'n_a': 17, 'n_steps': 3, 'gamma': 1.3467413875266505, 'lambda_sparse': 5.1958558935606145e-05, 'lr': 0.00021533354916013957, 'weight_decay': 0.0005979247510375056}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:53:35,694] Trial 9 finished with value: 0.3832992066027928 and parameters: {'n_d': 26, 'n_a': 31, 'n_steps': 10, 'gamma': 1.0528053316177424, 'lambda_sparse': 0.00020242225446501257, 'lr': 0.00877916166343588, 'weight_decay': 0.00014511607789150706}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:54:05,530] Trial 10 finished with value: 0.3802300689812367 and parameters: {'n_d': 19, 'n_a': 53, 'n_steps': 6, 'gamma': 1.0313420138734062, 'lambda_sparse': 0.0005532535326894569, 'lr': 0.09002500811786036, 'weight_decay': 1.005241070642067e-06}. Best is trial 0 with value: 0.4031662593182672.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:54:35,754] Trial 11 finished with value: 0.40575128671682426 and parameters: {'n_d': 9, 'n_a': 45, 'n_steps': 6, 'gamma': 1.6513130257064934, 'lambda_sparse': 0.0005488460372931461, 'lr': 0.022569580303004606, 'weight_decay': 1.8396053802910533e-05}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:55:01,937] Trial 12 finished with value: 0.32761705332184776 and parameters: {'n_d': 8, 'n_a': 48, 'n_steps': 6, 'gamma': 1.6902071167169408, 'lambda_sparse': 0.0006890778295280542, 'lr': 0.025298364315621363, 'weight_decay': 1.4585307722125525e-05}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:55:11,113] Trial 13 finished with value: 0.1119593734854748 and parameters: {'n_d': 17, 'n_a': 43, 'n_steps': 5, 'gamma': 1.6632304484627844, 'lambda_sparse': 0.0004939136583481603, 'lr': 0.09898512074514608, 'weight_decay': 2.3292227545678517e-05}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:55:44,579] Trial 14 finished with value: 0.39689718481778313 and parameters: {'n_d': 63, 'n_a': 56, 'n_steps': 7, 'gamma': 1.7533534077253994, 'lambda_sparse': 0.0011162985208259364, 'lr': 0.02123508904693316, 'weight_decay': 0.00020096679017682036}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:56:27,353] Trial 15 finished with value: 0.35065501274049227 and parameters: {'n_d': 33, 'n_a': 43, 'n_steps': 10, 'gamma': 1.1677399574639662, 'lambda_sparse': 0.00022114483353332515, 'lr': 0.045213207346302554, 'weight_decay': 4.562938299582787e-05}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:56:38,628] Trial 16 finished with value: 0.06850656949048173 and parameters: {'n_d': 19, 'n_a': 58, 'n_steps': 5, 'gamma': 1.520085521149345, 'lambda_sparse': 4.0841486247592305e-05, 'lr': 0.0192992807224448, 'weight_decay': 2.0156810271927548e-05}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:57:19,584] Trial 17 finished with value: 0.26570865932053067 and parameters: {'n_d': 36, 'n_a': 64, 'n_steps': 9, 'gamma': 1.8185391985785613, 'lambda_sparse': 0.00029094094229777833, 'lr': 0.0026693212486373383, 'weight_decay': 2.253570709671084e-06}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:57:52,948] Trial 18 finished with value: 0.3788974519167252 and parameters: {'n_d': 15, 'n_a': 38, 'n_steps': 7, 'gamma': 1.181205752170656, 'lambda_sparse': 0.004035573651940428, 'lr': 0.04858612929264119, 'weight_decay': 1.0436382367745447e-05}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:58:18,041] Trial 19 finished with value: 0.3639754003255057 and parameters: {'n_d': 23, 'n_a': 47, 'n_steps': 5, 'gamma': 1.6214846042967737, 'lambda_sparse': 1.6539994867027043e-05, 'lr': 0.01237534399051961, 'weight_decay': 0.00035160319511813907}. Best is trial 11 with value: 0.40575128671682426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 19:58:53,839] A new study created in memory with name: no-name-dd2773d8-25d2-4077-801b-d0b5b00ecd57
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:59:15,695] Trial 0 finished with value: 0.33630664792213794 and parameters: {'n_d': 26, 'n_a': 41, 'n_steps': 3, 'gamma': 1.7530488482717361, 'lambda_sparse': 0.0015140385437936565, 'lr': 0.001067956779343206, 'weight_decay': 1.1408334154591932e-06}. Best is trial 0 with value: 0.33630664792213794.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 19:59:57,318] Trial 1 finished with value: 0.24929216213339556 and parameters: {'n_d': 44, 'n_a': 21, 'n_steps': 9, 'gamma': 1.0110407158953278, 'lambda_sparse': 4.253436394547692e-05, 'lr': 0.0009786093998457766, 'weight_decay': 0.0009111821745400729}. Best is trial 0 with value: 0.33630664792213794.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:00:30,959] Trial 2 finished with value: 0.30056204738627257 and parameters: {'n_d': 31, 'n_a': 54, 'n_steps': 7, 'gamma': 1.7727666423525983, 'lambda_sparse': 0.00022337167130235167, 'lr': 0.00939013057931853, 'weight_decay': 1.5173116587707631e-06}. Best is trial 0 with value: 0.33630664792213794.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:00:54,966] Trial 3 finished with value: 0.2893981883989577 and parameters: {'n_d': 58, 'n_a': 27, 'n_steps': 5, 'gamma': 1.3830508022598451, 'lambda_sparse': 0.0045875027328065145, 'lr': 0.004697567398064341, 'weight_decay': 0.0008843419997093363}. Best is trial 0 with value: 0.33630664792213794.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:01:06,127] Trial 4 finished with value: -0.2589670691588648 and parameters: {'n_d': 37, 'n_a': 64, 'n_steps': 5, 'gamma': 1.9177114956032746, 'lambda_sparse': 3.5227736563062434e-05, 'lr': 0.01749466316442169, 'weight_decay': 0.0002572663526719513}. Best is trial 0 with value: 0.33630664792213794.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:01:28,703] Trial 5 finished with value: 0.3378437166229541 and parameters: {'n_d': 52, 'n_a': 44, 'n_steps': 4, 'gamma': 1.337178973951167, 'lambda_sparse': 7.227515558924897e-05, 'lr': 0.01873312370972393, 'weight_decay': 5.188284737351958e-05}. Best is trial 5 with value: 0.3378437166229541.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:01:58,189] Trial 6 finished with value: 0.29657427637886946 and parameters: {'n_d': 30, 'n_a': 14, 'n_steps': 6, 'gamma': 1.318648211984978, 'lambda_sparse': 0.004506577101149618, 'lr': 0.001877170858387664, 'weight_decay': 1.1637792144508877e-06}. Best is trial 5 with value: 0.3378437166229541.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:02:24,968] Trial 7 finished with value: 0.25684659310791436 and parameters: {'n_d': 63, 'n_a': 20, 'n_steps': 5, 'gamma': 1.736114448451752, 'lambda_sparse': 0.0015152870561076486, 'lr': 0.001883984271715479, 'weight_decay': 3.288299173901827e-05}. Best is trial 5 with value: 0.3378437166229541.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:03:05,565] Trial 8 finished with value: 0.3324618580430715 and parameters: {'n_d': 15, 'n_a': 26, 'n_steps': 9, 'gamma': 1.6894449076262577, 'lambda_sparse': 4.9878776781468445e-05, 'lr': 0.011701384117807119, 'weight_decay': 0.00042707212194944817}. Best is trial 5 with value: 0.3378437166229541.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:03:30,229] Trial 9 finished with value: -0.009360775916088082 and parameters: {'n_d': 24, 'n_a': 55, 'n_steps': 4, 'gamma': 1.493797046733051, 'lambda_sparse': 0.00586494443573814, 'lr': 0.00016897731288730122, 'weight_decay': 1.4065564997611225e-06}. Best is trial 5 with value: 0.3378437166229541.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:03:51,443] Trial 10 finished with value: 0.33506714291155293 and parameters: {'n_d': 52, 'n_a': 41, 'n_steps': 3, 'gamma': 1.1306021319870472, 'lambda_sparse': 1.050537062599554e-05, 'lr': 0.09050505484669259, 'weight_decay': 3.926028353296935e-05}. Best is trial 5 with value: 0.3378437166229541.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:04:13,234] Trial 11 finished with value: 0.1963436535062878 and parameters: {'n_d': 11, 'n_a': 40, 'n_steps': 3, 'gamma': 1.6051692692789699, 'lambda_sparse': 0.00042853721384707497, 'lr': 0.00037411576093446383, 'weight_decay': 8.545128873808818e-06}. Best is trial 5 with value: 0.3378437166229541.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:04:34,560] Trial 12 finished with value: 0.34256718389477847 and parameters: {'n_d': 45, 'n_a': 49, 'n_steps': 3, 'gamma': 1.968827871102305, 'lambda_sparse': 0.0006088813738752225, 'lr': 0.0536827703879184, 'weight_decay': 8.83966963924601e-06}. Best is trial 12 with value: 0.34256718389477847.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:04:47,224] Trial 13 finished with value: 0.024148542077455093 and parameters: {'n_d': 49, 'n_a': 50, 'n_steps': 7, 'gamma': 1.9881054781584049, 'lambda_sparse': 0.0002271494302277867, 'lr': 0.06445228246620224, 'weight_decay': 7.773551905589841e-06}. Best is trial 12 with value: 0.34256718389477847.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:05:10,195] Trial 14 finished with value: 0.3609434323840264 and parameters: {'n_d': 41, 'n_a': 48, 'n_steps': 4, 'gamma': 1.295311767385108, 'lambda_sparse': 0.0005638288091821502, 'lr': 0.038050939860993054, 'weight_decay': 9.438535881627873e-05}. Best is trial 14 with value: 0.3609434323840264.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:05:35,425] Trial 15 finished with value: 0.34513498839467427 and parameters: {'n_d': 41, 'n_a': 64, 'n_steps': 4, 'gamma': 1.167486280377203, 'lambda_sparse': 0.0007190175117046176, 'lr': 0.04061492688382279, 'weight_decay': 6.6091604708725525e-06}. Best is trial 14 with value: 0.3609434323840264.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:05:48,786] Trial 16 finished with value: 0.16171281389280978 and parameters: {'n_d': 39, 'n_a': 63, 'n_steps': 6, 'gamma': 1.1891861867615143, 'lambda_sparse': 0.0012028289473497403, 'lr': 0.030615603733709102, 'weight_decay': 0.00012513889053069843}. Best is trial 14 with value: 0.3609434323840264.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:06:25,701] Trial 17 finished with value: 0.34300357704431716 and parameters: {'n_d': 42, 'n_a': 58, 'n_steps': 8, 'gamma': 1.210413355327194, 'lambda_sparse': 0.00011990856521857857, 'lr': 0.00592319795164757, 'weight_decay': 9.59839628047781e-05}. Best is trial 14 with value: 0.3609434323840264.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:06:32,599] Trial 18 finished with value: -0.06876179540557814 and parameters: {'n_d': 33, 'n_a': 35, 'n_steps': 4, 'gamma': 1.0184350443349026, 'lambda_sparse': 0.0007791530020494987, 'lr': 0.040918121278954, 'weight_decay': 1.722764986146019e-05}. Best is trial 14 with value: 0.3609434323840264.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:07:08,652] Trial 19 finished with value: 0.34345034420280773 and parameters: {'n_d': 24, 'n_a': 34, 'n_steps': 10, 'gamma': 1.46222013152359, 'lambda_sparse': 0.0027776679488749722, 'lr': 0.029228308653850996, 'weight_decay': 2.8046169795467357e-06}. Best is trial 14 with value: 0.3609434323840264.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 20:07:29,683] A new study created in memory with name: no-name-9939c17b-f914-495f-a5f8-451e6e417d5f
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:08:03,464] Trial 0 finished with value: 0.3199175374025167 and parameters: {'n_d': 60, 'n_a': 38, 'n_steps': 9, 'gamma': 1.6762133071472873, 'lambda_sparse': 0.0002061453009334475, 'lr': 0.02202151600013337, 'weight_decay': 6.8622014364772826e-06}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:08:44,988] Trial 1 finished with value: 0.1255915254940474 and parameters: {'n_d': 45, 'n_a': 34, 'n_steps': 9, 'gamma': 1.3773883098152995, 'lambda_sparse': 0.0009672599016794095, 'lr': 0.0006164258464914183, 'weight_decay': 4.41150557498208e-06}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:09:22,564] Trial 2 finished with value: -0.2328903723554514 and parameters: {'n_d': 14, 'n_a': 49, 'n_steps': 8, 'gamma': 1.9462387505208363, 'lambda_sparse': 0.0010091227964887312, 'lr': 0.0004947091505698709, 'weight_decay': 0.00013508890118533957}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:09:48,041] Trial 3 finished with value: 0.24776982215373022 and parameters: {'n_d': 35, 'n_a': 13, 'n_steps': 6, 'gamma': 1.8111301190799058, 'lambda_sparse': 0.0001406066505771732, 'lr': 0.07031230059859976, 'weight_decay': 0.00010934187952430092}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:10:09,650] Trial 4 finished with value: 0.29360082750892147 and parameters: {'n_d': 57, 'n_a': 8, 'n_steps': 3, 'gamma': 1.3186951746182527, 'lambda_sparse': 5.027945282790886e-05, 'lr': 0.0007521086540882588, 'weight_decay': 5.02138232032524e-05}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:10:54,684] Trial 5 finished with value: -0.789759557189105 and parameters: {'n_d': 12, 'n_a': 10, 'n_steps': 10, 'gamma': 1.6720771772494991, 'lambda_sparse': 0.00018524928424351928, 'lr': 0.0008101334777546113, 'weight_decay': 8.743458851203684e-05}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:11:16,287] Trial 6 finished with value: 0.30553913155060164 and parameters: {'n_d': 8, 'n_a': 55, 'n_steps': 3, 'gamma': 1.8647259704519727, 'lambda_sparse': 0.006221495596140131, 'lr': 0.0016556824552344375, 'weight_decay': 0.000888345072424844}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:11:57,177] Trial 7 finished with value: 0.2564788913161721 and parameters: {'n_d': 47, 'n_a': 43, 'n_steps': 9, 'gamma': 1.8470280561721708, 'lambda_sparse': 0.0003654071559396439, 'lr': 0.09917607539532367, 'weight_decay': 8.095415709180532e-06}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:12:23,996] Trial 8 finished with value: 0.2696102574848259 and parameters: {'n_d': 63, 'n_a': 56, 'n_steps': 5, 'gamma': 1.7591222231727845, 'lambda_sparse': 2.546990198756194e-05, 'lr': 0.0017827294592231498, 'weight_decay': 0.0001056063532946965}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:12:31,216] Trial 9 finished with value: -0.10988924604414385 and parameters: {'n_d': 55, 'n_a': 32, 'n_steps': 5, 'gamma': 1.1587893626556784, 'lambda_sparse': 0.00855140248447255, 'lr': 0.07663531446071524, 'weight_decay': 3.58806049338806e-05}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:13:04,874] Trial 10 finished with value: 0.2996736615192048 and parameters: {'n_d': 28, 'n_a': 23, 'n_steps': 7, 'gamma': 1.5573606272097558, 'lambda_sparse': 1.633075921471757e-05, 'lr': 0.012107949205629048, 'weight_decay': 1.4942817021010105e-06}. Best is trial 0 with value: 0.3199175374025167.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:13:26,293] Trial 11 finished with value: 0.3401201742508101 and parameters: {'n_d': 26, 'n_a': 59, 'n_steps': 3, 'gamma': 1.9933545119943132, 'lambda_sparse': 0.007690946239113861, 'lr': 0.00929058588439229, 'weight_decay': 0.000834656008955504}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:13:52,266] Trial 12 finished with value: 0.31862944198808474 and parameters: {'n_d': 28, 'n_a': 64, 'n_steps': 4, 'gamma': 1.988134301325942, 'lambda_sparse': 0.002332537049490931, 'lr': 0.00926755503162916, 'weight_decay': 0.0009248074821224613}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:14:26,075] Trial 13 finished with value: -0.2233788831691781 and parameters: {'n_d': 22, 'n_a': 41, 'n_steps': 7, 'gamma': 1.605349211527623, 'lambda_sparse': 8.61855881711017e-05, 'lr': 0.00012447663787571004, 'weight_decay': 1.0453833727633433e-05}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:15:10,767] Trial 14 finished with value: 0.31602977747521377 and parameters: {'n_d': 42, 'n_a': 22, 'n_steps': 10, 'gamma': 1.4428097652416247, 'lambda_sparse': 0.0007692394995108551, 'lr': 0.013687101631779627, 'weight_decay': 1.0157002531938033e-06}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:15:23,422] Trial 15 finished with value: -0.06253175113663945 and parameters: {'n_d': 36, 'n_a': 64, 'n_steps': 8, 'gamma': 1.1238267884497914, 'lambda_sparse': 0.002479923877987608, 'lr': 0.02807265950758599, 'weight_decay': 0.0003734920300828295}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:15:53,713] Trial 16 finished with value: 0.3079283369998116 and parameters: {'n_d': 24, 'n_a': 27, 'n_steps': 6, 'gamma': 1.7084900751540268, 'lambda_sparse': 0.00040932452679227986, 'lr': 0.004517347191875093, 'weight_decay': 1.0178186941969986e-05}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:16:16,374] Trial 17 finished with value: 0.32044929010761614 and parameters: {'n_d': 51, 'n_a': 47, 'n_steps': 4, 'gamma': 1.2398877551155856, 'lambda_sparse': 0.002910038748695199, 'lr': 0.027316247921793456, 'weight_decay': 3.0527907857952684e-06}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:16:40,299] Trial 18 finished with value: 0.33658232774970154 and parameters: {'n_d': 51, 'n_a': 49, 'n_steps': 4, 'gamma': 1.2158353631545447, 'lambda_sparse': 0.004297310623953863, 'lr': 0.0046911963627080415, 'weight_decay': 2.174484069331263e-06}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:16:47,864] Trial 19 finished with value: -0.35051869074132536 and parameters: {'n_d': 37, 'n_a': 57, 'n_steps': 4, 'gamma': 1.0036426105041663, 'lambda_sparse': 0.004790022622657013, 'lr': 0.005256481653666792, 'weight_decay': 0.00030878834169991093}. Best is trial 11 with value: 0.3401201742508101.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/src/models/tabnet/tabnet_train.py:37: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method="ffill").fillna(method="bfill").fillna(0)
[I 2025-08-05 20:17:14,684] A new study created in memory with name: no-name-389d32e4-31eb-4ddd-a0c1-af2ed01eb9b0
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:17:51,556] Trial 0 finished with value: 0.2804576418599355 and parameters: {'n_d': 49, 'n_a': 12, 'n_steps': 8, 'gamma': 1.4156999376079311, 'lambda_sparse': 0.00023399951861252096, 'lr': 0.0529675320835894, 'weight_decay': 5.512495610563113e-06}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:18:18,530] Trial 1 finished with value: 0.21856562570186722 and parameters: {'n_d': 34, 'n_a': 58, 'n_steps': 5, 'gamma': 1.2354442711573435, 'lambda_sparse': 0.00018656571004215246, 'lr': 0.00026759504782579126, 'weight_decay': 8.456397806829124e-06}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:18:49,081] Trial 2 finished with value: -0.9832568660775081 and parameters: {'n_d': 24, 'n_a': 16, 'n_steps': 7, 'gamma': 1.787838593946936, 'lambda_sparse': 0.001826775414470064, 'lr': 0.0001895645802222359, 'weight_decay': 0.00018520776011595063}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:19:13,948] Trial 3 finished with value: -0.03110238067046578 and parameters: {'n_d': 8, 'n_a': 47, 'n_steps': 4, 'gamma': 1.2345723621397975, 'lambda_sparse': 0.0005717725530919593, 'lr': 0.00012667007190056775, 'weight_decay': 0.0006814728766079116}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:19:21,334] Trial 4 finished with value: -0.585458039272444 and parameters: {'n_d': 55, 'n_a': 19, 'n_steps': 5, 'gamma': 1.2738592469893524, 'lambda_sparse': 0.0001909626714469006, 'lr': 0.051499443185465635, 'weight_decay': 4.7505315659663345e-05}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:19:42,696] Trial 5 finished with value: 0.27289500410872003 and parameters: {'n_d': 11, 'n_a': 33, 'n_steps': 4, 'gamma': 1.8350421807107575, 'lambda_sparse': 6.275877348695062e-05, 'lr': 0.012506990176871376, 'weight_decay': 1.0146230653580592e-06}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:20:21,100] Trial 6 finished with value: 0.2668866598894971 and parameters: {'n_d': 33, 'n_a': 18, 'n_steps': 9, 'gamma': 1.2196605323270449, 'lambda_sparse': 0.0006257235866293287, 'lr': 0.004729818851909512, 'weight_decay': 0.00043339840199401033}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:20:45,313] Trial 7 finished with value: 0.2156605171399476 and parameters: {'n_d': 55, 'n_a': 56, 'n_steps': 4, 'gamma': 1.3713588383602184, 'lambda_sparse': 0.00360696239068077, 'lr': 0.00046898785150873237, 'weight_decay': 1.470925869268484e-06}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:21:19,088] Trial 8 finished with value: 0.09297833401034383 and parameters: {'n_d': 32, 'n_a': 58, 'n_steps': 7, 'gamma': 1.9259828672690205, 'lambda_sparse': 0.0006434794588833081, 'lr': 0.00021879279510496254, 'weight_decay': 1.367610321701065e-06}. Best is trial 0 with value: 0.2804576418599355.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:21:52,067] Trial 9 finished with value: 0.30473519515146097 and parameters: {'n_d': 64, 'n_a': 40, 'n_steps': 7, 'gamma': 1.9697612966094118, 'lambda_sparse': 0.000309232319012858, 'lr': 0.012303711500170574, 'weight_decay': 8.204378504198177e-06}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:22:34,323] Trial 10 finished with value: 0.12866572189311942 and parameters: {'n_d': 61, 'n_a': 33, 'n_steps': 10, 'gamma': 1.6067711838352352, 'lambda_sparse': 1.242975920093084e-05, 'lr': 0.0019488381725514324, 'weight_decay': 2.087814909937496e-05}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:23:06,074] Trial 11 finished with value: 0.27134265389032497 and parameters: {'n_d': 47, 'n_a': 43, 'n_steps': 8, 'gamma': 1.0338208923975385, 'lambda_sparse': 4.8765757508791016e-05, 'lr': 0.08138133787731519, 'weight_decay': 6.720324685129472e-06}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:23:43,018] Trial 12 finished with value: 0.2700879735823749 and parameters: {'n_d': 47, 'n_a': 28, 'n_steps': 8, 'gamma': 1.5689550409144897, 'lambda_sparse': 0.008790284199158171, 'lr': 0.017808076492148182, 'weight_decay': 4.236670627550296e-06}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:24:13,216] Trial 13 finished with value: 0.2740283803478776 and parameters: {'n_d': 64, 'n_a': 8, 'n_steps': 6, 'gamma': 1.7087954540386576, 'lambda_sparse': 7.700497561338234e-05, 'lr': 0.021088861126967076, 'weight_decay': 2.945977138663444e-05}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:24:54,163] Trial 14 finished with value: 0.23969855944815788 and parameters: {'n_d': 44, 'n_a': 43, 'n_steps': 9, 'gamma': 1.4118805774494132, 'lambda_sparse': 0.0015581979970607954, 'lr': 0.005284510228483688, 'weight_decay': 4.232462592103565e-06}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:25:24,579] Trial 15 finished with value: 0.2919195671281354 and parameters: {'n_d': 55, 'n_a': 49, 'n_steps': 6, 'gamma': 1.4786838735846126, 'lambda_sparse': 2.1342223756612444e-05, 'lr': 0.0011738398941800467, 'weight_decay': 9.040351275575082e-05}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:25:55,019] Trial 16 finished with value: 0.18463058625293904 and parameters: {'n_d': 57, 'n_a': 48, 'n_steps': 6, 'gamma': 1.988043956251026, 'lambda_sparse': 1.0979226255852183e-05, 'lr': 0.0012024545996381201, 'weight_decay': 0.00010160608289412604}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:26:16,537] Trial 17 finished with value: 0.28936591924160626 and parameters: {'n_d': 41, 'n_a': 51, 'n_steps': 3, 'gamma': 1.652295128946807, 'lambda_sparse': 3.0407181730422742e-05, 'lr': 0.0008751715017682679, 'weight_decay': 8.449553873857659e-05}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:26:46,804] Trial 18 finished with value: 0.29733411941129984 and parameters: {'n_d': 63, 'n_a': 64, 'n_steps': 6, 'gamma': 1.4942864466510986, 'lambda_sparse': 2.2027226494401286e-05, 'lr': 0.008569350446841081, 'weight_decay': 1.5398751404806734e-05}. Best is trial 9 with value: 0.30473519515146097.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 20:27:20,463] Trial 19 finished with value: 0.3197137307578978 and parameters: {'n_d': 24, 'n_a': 62, 'n_steps': 7, 'gamma': 1.04234489555503, 'lambda_sparse': 0.00011070953074426902, 'lr': 0.00845763130352116, 'weight_decay': 1.4852548086432475e-05}. Best is trial 19 with value: 0.3197137307578978.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-05 20:28:08 [INFO] TabNet →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/tabnet (mean R²=0.3615)
2025-08-05 20:28:08 [INFO] Ensemble weights: TabPFN=0.331, Tree=0.355, TabNet=0.315
2025-08-05 20:28:08 [INFO] Loading individual models into memory...
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-05 20:28:12 [INFO] Saved weighted ensemble to /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-wine_quality_rona/final_model.pkl
