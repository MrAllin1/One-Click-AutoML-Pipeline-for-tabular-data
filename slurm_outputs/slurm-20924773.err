cpu-bind=MASK - dlcgpu03, task  0  0 [976231]: mask 0xf0000000f0000 set
/var/spool/slurm/job20924773/slurm_script: line 11: module: command not found
/var/spool/slurm/job20924773/slurm_script: line 14: cd: /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template: Permission denied
2025-08-05 17:20:21 [INFO] Using device: cuda
2025-08-05 17:20:21 [INFO] Training TabPFN model...
[I 2025-08-05 17:20:21,738] A new study created in memory with name: no-name-6ac962bc-3025-4fc4-bfef-0a8aba0f898d
2025-08-05 17:20:21 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 17:28:49,628] Trial 0 finished with value: 0.9140322809394642 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 17:28:49 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 17:38:10,511] Trial 1 finished with value: 0.913498753745007 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 17:38:10 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 17:42:52,466] Trial 2 finished with value: 0.9114342890963931 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 17:42:52 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 17:48:39,803] Trial 3 finished with value: 0.9125964902200712 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 17:48:39 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
[I 2025-08-05 17:57:22,137] Trial 4 finished with value: 0.9133333008354605 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 17:57:22 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
2025-08-05 17:59:46 [INFO] ⏸️ Pruned trial 5 at step 4 (R²=0.9074)
[I 2025-08-05 17:59:46,254] Trial 5 pruned. 
2025-08-05 17:59:46 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
2025-08-05 18:00:12 [INFO] ⏸️ Pruned trial 6 at step 1 (R²=0.8993)
[I 2025-08-05 18:00:12,804] Trial 6 pruned. 
2025-08-05 18:00:12 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
2025-08-05 18:00:39 [INFO] ⏸️ Pruned trial 7 at step 1 (R²=0.8994)
[I 2025-08-05 18:00:39,026] Trial 7 pruned. 
2025-08-05 18:00:39 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
2025-08-05 18:01:09 [INFO] ⏸️ Pruned trial 8 at step 1 (R²=0.9027)
[I 2025-08-05 18:01:09,244] Trial 8 pruned. 
2025-08-05 18:01:09 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
2025-08-05 18:01:36 [INFO] ⏸️ Pruned trial 9 at step 1 (R²=0.8998)
[I 2025-08-05 18:01:36,768] Trial 9 pruned. 
2025-08-05 18:01:36 [INFO] 🔍 Trial 10: n_bootstrap=16, sample_frac=0.83
2025-08-05 18:03:16 [INFO] ⏸️ Pruned trial 10 at step 3 (R²=0.9070)
[I 2025-08-05 18:03:16,871] Trial 10 pruned. 
2025-08-05 18:03:16 [INFO] 🔍 Trial 11: n_bootstrap=19, sample_frac=0.77
2025-08-05 18:03:47 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.9024)
[I 2025-08-05 18:03:47,363] Trial 11 pruned. 
2025-08-05 18:03:47 [INFO] 🔍 Trial 12: n_bootstrap=17, sample_frac=0.72
2025-08-05 18:04:16 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.8996)
[I 2025-08-05 18:04:16,090] Trial 12 pruned. 
2025-08-05 18:04:16 [INFO] 🔍 Trial 13: n_bootstrap=20, sample_frac=0.79
2025-08-05 18:04:47 [INFO] ⏸️ Pruned trial 13 at step 1 (R²=0.9027)
[I 2025-08-05 18:04:47,652] Trial 13 pruned. 
2025-08-05 18:04:47 [INFO] 🔍 Trial 14: n_bootstrap=17, sample_frac=0.60
2025-08-05 18:05:11 [INFO] ⏸️ Pruned trial 14 at step 1 (R²=0.9025)
[I 2025-08-05 18:05:11,892] Trial 14 pruned. 
2025-08-05 18:05:11 [INFO] 🔍 Trial 15: n_bootstrap=14, sample_frac=0.88
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 18:13:33,389] Trial 15 finished with value: 0.9140103724359592 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.883742915992114}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 18:13:33 [INFO] 🔍 Trial 16: n_bootstrap=14, sample_frac=0.90
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
2025-08-05 18:15:59 [INFO] ⏸️ Pruned trial 16 at step 4 (R²=0.9071)
[I 2025-08-05 18:15:59,137] Trial 16 pruned. 
2025-08-05 18:15:59 [INFO] 🔍 Trial 17: n_bootstrap=14, sample_frac=0.85
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 18:23:59,319] Trial 17 finished with value: 0.9138299983981739 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8541004060157665}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 18:23:59 [INFO] 🔍 Trial 18: n_bootstrap=15, sample_frac=0.86
2025-08-05 18:25:07 [INFO] ⏸️ Pruned trial 18 at step 2 (R²=0.9051)
[I 2025-08-05 18:25:07,799] Trial 18 pruned. 
2025-08-05 18:25:07 [INFO] 🔍 Trial 19: n_bootstrap=12, sample_frac=0.72
2025-08-05 18:25:36 [INFO] ⏸️ Pruned trial 19 at step 1 (R²=0.8994)
[I 2025-08-05 18:25:36,270] Trial 19 pruned. 
2025-08-05 18:25:36 [INFO] 🔍 Trial 20: n_bootstrap=13, sample_frac=0.87
2025-08-05 18:26:15 [INFO] ⏸️ Pruned trial 20 at step 1 (R²=0.9041)
[I 2025-08-05 18:26:15,129] Trial 20 pruned. 
2025-08-05 18:26:15 [INFO] 🔍 Trial 21: n_bootstrap=14, sample_frac=0.83
2025-08-05 18:26:51 [INFO] ⏸️ Pruned trial 21 at step 1 (R²=0.9034)
[I 2025-08-05 18:26:51,298] Trial 21 pruned. 
2025-08-05 18:26:51 [INFO] 🔍 Trial 22: n_bootstrap=15, sample_frac=0.88
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 18:35:46,104] Trial 22 finished with value: 0.9138363814110603 and parameters: {'n_bootstrap': 15, 'sample_frac': 0.8805135587540488}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 18:35:46 [INFO] 🔍 Trial 23: n_bootstrap=15, sample_frac=0.88
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
[I 2025-08-05 18:44:35,772] Trial 23 finished with value: 0.9138480181315451 and parameters: {'n_bootstrap': 15, 'sample_frac': 0.8771282527511987}. Best is trial 0 with value: 0.9140322809394642.
2025-08-05 18:44:35 [INFO] 🔍 Trial 24: n_bootstrap=16, sample_frac=0.84
2025-08-05 18:45:09 [INFO] ⏸️ Pruned trial 24 at step 1 (R²=0.9040)
[I 2025-08-05 18:45:09,334] Trial 24 pruned. 
2025-08-05 18:45:09 [INFO] 🔍 Trial 25: n_bootstrap=13, sample_frac=0.80
2025-08-05 18:45:41 [INFO] ⏸️ Pruned trial 25 at step 1 (R²=0.9035)
[I 2025-08-05 18:45:41,402] Trial 25 pruned. 
2025-08-05 18:45:41 [INFO] 🔍 Trial 26: n_bootstrap=15, sample_frac=0.90
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
2025-08-05 18:48:08 [INFO] ⏸️ Pruned trial 26 at step 4 (R²=0.9070)
[I 2025-08-05 18:48:08,916] Trial 26 pruned. 
2025-08-05 18:48:08 [INFO] 🔍 Trial 27: n_bootstrap=12, sample_frac=0.87
2025-08-05 18:48:44 [INFO] ⏸️ Pruned trial 27 at step 1 (R²=0.9044)
[I 2025-08-05 18:48:44,186] Trial 27 pruned. 
2025-08-05 18:48:44 [INFO] 🔍 Trial 28: n_bootstrap=17, sample_frac=0.84
2025-08-05 18:49:19 [INFO] ⏸️ Pruned trial 28 at step 1 (R²=0.9039)
[I 2025-08-05 18:49:19,046] Trial 28 pruned. 
2025-08-05 18:49:19 [INFO] 🔍 Trial 29: n_bootstrap=15, sample_frac=0.78
2025-08-05 18:49:50 [INFO] ⏸️ Pruned trial 29 at step 1 (R²=0.9025)
[I 2025-08-05 18:49:50,334] Trial 29 pruned. 
2025-08-05 18:49:50 [INFO] 🏆 Best Params: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}, R²=0.91403
2025-08-05 18:49:50 [INFO] Bootstrap training → dataset=superconductivity, device=cuda
2025-08-05 18:49:50 [INFO] [1/14] bootstrap sample size=7613
2025-08-05 18:50:28 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_1.pkl
2025-08-05 18:50:28 [INFO] [2/14] bootstrap sample size=7613
2025-08-05 18:51:04 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_2.pkl
2025-08-05 18:51:04 [INFO] [3/14] bootstrap sample size=7613
2025-08-05 18:51:40 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_3.pkl
2025-08-05 18:51:40 [INFO] [4/14] bootstrap sample size=7613
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
2025-08-05 18:52:16 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_4.pkl
2025-08-05 18:52:16 [INFO] [5/14] bootstrap sample size=7613
2025-08-05 18:52:51 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_5.pkl
2025-08-05 18:52:51 [INFO] [6/14] bootstrap sample size=7613
2025-08-05 18:53:27 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_6.pkl
2025-08-05 18:53:27 [INFO] [7/14] bootstrap sample size=7613
2025-08-05 18:54:02 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_7.pkl
2025-08-05 18:54:02 [INFO] [8/14] bootstrap sample size=7613
2025-08-05 18:54:37 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_8.pkl
2025-08-05 18:54:38 [INFO] [9/14] bootstrap sample size=7613
2025-08-05 18:55:13 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_9.pkl
2025-08-05 18:55:13 [INFO] [10/14] bootstrap sample size=7613
2025-08-05 18:55:48 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_10.pkl
2025-08-05 18:55:48 [INFO] [11/14] bootstrap sample size=7613
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
2025-08-05 18:56:24 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_11.pkl
2025-08-05 18:56:24 [INFO] [12/14] bootstrap sample size=7613
2025-08-05 18:56:59 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_12.pkl
2025-08-05 18:56:59 [INFO] [13/14] bootstrap sample size=7613
2025-08-05 18:57:34 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_13.pkl
2025-08-05 18:57:35 [INFO] [14/14] bootstrap sample size=7613
2025-08-05 18:58:10 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/bootstrap_14.pkl
2025-08-05 18:58:10 [INFO] 📊 Final OOB R² = 0.91403
2025-08-05 18:58:16 [INFO] Saved ensemble → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/ensemble.pkl
2025-08-05 18:58:16 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-05 18:58:16 [INFO] Total time: 506.2s
2025-08-05 18:58:16 [INFO] TabPFN →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/superconductivity/ensemble.pkl (R²=0.9140)
2025-08-05 18:58:16 [INFO] Training tree-based model...
2025-08-05 18:58:16 [INFO] AutoML pipeline started
2025-08-05 18:58:16 [INFO] Output directory '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity' is ready and logging is configured.
2025-08-05 18:58:16 [INFO] Merged training data: 8601 rows
2025-08-05 18:58:16 [INFO] Split data into pool (7740 rows) and validation (861 rows)
2025-08-05 18:58:16 [INFO] Feature engineering completed: 81 features
[I 2025-08-05 18:58:16,760] A new study created in memory with name: no-name-fb2bb84f-f194-40a7-8311-c3cc4ab4e404
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-05 19:21:23,737] Trial 0 finished with value: -0.9035348998658476 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.9035348998658476.
[I 2025-08-05 19:21:49,389] Trial 1 finished with value: -0.881112791492493 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 0 with value: -0.9035348998658476.
[I 2025-08-05 19:26:09,159] Trial 2 finished with value: -0.9054630928760208 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 19:26:22,096] Trial 3 finished with value: -0.9033774392259813 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 19:27:21,392] Trial 4 finished with value: -0.9021292610359591 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 19:27:39,480] Trial 5 finished with value: -0.9018120958132398 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 19:36:04,715] Trial 6 finished with value: -0.904797138674262 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 19:36:17,101] Trial 7 finished with value: -0.8945970786019426 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 20:06:20,059] Trial 8 finished with value: -0.8926738508716866 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 20:06:34,774] Trial 9 finished with value: -0.879681879635745 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 20:07:45,685] Trial 10 finished with value: -0.8977996399039594 and parameters: {'learning_rate': 0.2565418558482462, 'depth': 9, 'l2_leaf_reg': 1.0679258738466366, 'border_count': 245}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 20:10:39,675] Trial 11 finished with value: -0.904514103625071 and parameters: {'learning_rate': 0.11386552028513468, 'depth': 10, 'l2_leaf_reg': 3.2989911288867892, 'border_count': 174}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 20:11:50,530] Trial 12 finished with value: -0.9049626837448024 and parameters: {'learning_rate': 0.05033186585861864, 'depth': 10, 'l2_leaf_reg': 2.289400076603518, 'border_count': 41}. Best is trial 2 with value: -0.9054630928760208.
[I 2025-08-05 20:12:17,017] Trial 13 finished with value: -0.9057326041034607 and parameters: {'learning_rate': 0.07122029027347643, 'depth': 8, 'l2_leaf_reg': 4.828669263061995, 'border_count': 36}. Best is trial 13 with value: -0.9057326041034607.
[I 2025-08-05 20:13:56,926] Trial 14 finished with value: -0.9045533012648113 and parameters: {'learning_rate': 0.11282606173806252, 'depth': 8, 'l2_leaf_reg': 4.959648726075822, 'border_count': 200}. Best is trial 13 with value: -0.9057326041034607.
[I 2025-08-05 20:14:20,641] Trial 15 finished with value: -0.904560745982901 and parameters: {'learning_rate': 0.0798741166181051, 'depth': 7, 'l2_leaf_reg': 9.305634269324253, 'border_count': 51}. Best is trial 13 with value: -0.9057326041034607.
[I 2025-08-05 20:15:18,072] Trial 16 finished with value: -0.9043189544147315 and parameters: {'learning_rate': 0.13811007646509937, 'depth': 7, 'l2_leaf_reg': 4.206703796942942, 'border_count': 255}. Best is trial 13 with value: -0.9057326041034607.
[I 2025-08-05 20:16:11,873] Trial 17 finished with value: -0.9012641840747284 and parameters: {'learning_rate': 0.246063214941863, 'depth': 9, 'l2_leaf_reg': 6.079330114147569, 'border_count': 94}. Best is trial 13 with value: -0.9057326041034607.
[I 2025-08-05 20:17:10,126] Trial 18 finished with value: -0.9034551461743568 and parameters: {'learning_rate': 0.06296662033709352, 'depth': 7, 'l2_leaf_reg': 8.28621026517803, 'border_count': 187}. Best is trial 13 with value: -0.9057326041034607.
[I 2025-08-05 20:21:09,924] Trial 19 finished with value: -0.9058724660543348 and parameters: {'learning_rate': 0.038872073654814585, 'depth': 10, 'l2_leaf_reg': 2.0063211811004935, 'border_count': 150}. Best is trial 19 with value: -0.9058724660543348.
[I 2025-08-05 20:31:04,515] Trial 20 finished with value: -0.9026965879421583 and parameters: {'learning_rate': 0.01923706733849963, 'depth': 11, 'l2_leaf_reg': 4.251746574908432, 'border_count': 154}. Best is trial 19 with value: -0.9058724660543348.
[I 2025-08-05 20:33:30,715] Trial 21 finished with value: -0.9061684225335739 and parameters: {'learning_rate': 0.040460206635110234, 'depth': 9, 'l2_leaf_reg': 2.135345942225476, 'border_count': 133}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 20:35:51,624] Trial 22 finished with value: -0.9057550170984848 and parameters: {'learning_rate': 0.03745612674981517, 'depth': 9, 'l2_leaf_reg': 1.9791679201792076, 'border_count': 125}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 20:38:12,237] Trial 23 finished with value: -0.9056136130935878 and parameters: {'learning_rate': 0.032338403828834426, 'depth': 9, 'l2_leaf_reg': 1.9084588333020602, 'border_count': 126}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 20:45:16,251] Trial 24 finished with value: -0.9053490388925713 and parameters: {'learning_rate': 0.03934033584426251, 'depth': 11, 'l2_leaf_reg': 3.187389802652512, 'border_count': 116}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 20:47:51,527] Trial 25 finished with value: -0.9038054963669253 and parameters: {'learning_rate': 0.02193735028131287, 'depth': 9, 'l2_leaf_reg': 2.024504289043972, 'border_count': 140}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 20:50:22,990] Trial 26 finished with value: -0.9048126091856303 and parameters: {'learning_rate': 0.04420741311989277, 'depth': 10, 'l2_leaf_reg': 3.7334960899626215, 'border_count': 97}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 20:53:26,027] Trial 27 finished with value: -0.9043281364358959 and parameters: {'learning_rate': 0.02476814477318309, 'depth': 9, 'l2_leaf_reg': 1.8221889826067132, 'border_count': 164}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 20:53:59,641] Trial 28 finished with value: -0.8837169719702589 and parameters: {'learning_rate': 0.014181787025195142, 'depth': 6, 'l2_leaf_reg': 2.630938518940405, 'border_count': 183}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 21:12:16,005] Trial 29 finished with value: -0.9034729393069709 and parameters: {'learning_rate': 0.033038385497562876, 'depth': 12, 'l2_leaf_reg': 1.0598975780138133, 'border_count': 167}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 21:13:21,850] Trial 30 finished with value: -0.9057222203534439 and parameters: {'learning_rate': 0.057740116037039636, 'depth': 8, 'l2_leaf_reg': 5.7327003561495795, 'border_count': 110}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 21:14:10,856] Trial 31 finished with value: -0.904121265363244 and parameters: {'learning_rate': 0.04196728559376899, 'depth': 8, 'l2_leaf_reg': 4.322664702508494, 'border_count': 77}. Best is trial 21 with value: -0.9061684225335739.
[I 2025-08-05 21:14:38,137] Trial 32 finished with value: -0.906209439490536 and parameters: {'learning_rate': 0.057501390005252596, 'depth': 8, 'l2_leaf_reg': 2.9523505882982746, 'border_count': 32}. Best is trial 32 with value: -0.906209439490536.
[I 2025-08-05 21:18:25,241] Trial 33 finished with value: -0.9058402913777777 and parameters: {'learning_rate': 0.03628878126170727, 'depth': 10, 'l2_leaf_reg': 1.5391434875365013, 'border_count': 140}. Best is trial 32 with value: -0.906209439490536.
[I 2025-08-05 21:19:51,329] Trial 34 finished with value: -0.9062160891500698 and parameters: {'learning_rate': 0.05270722251252176, 'depth': 10, 'l2_leaf_reg': 1.6446852293868814, 'border_count': 57}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:21:21,269] Trial 35 finished with value: -0.9033530459205685 and parameters: {'learning_rate': 0.10165711465203642, 'depth': 11, 'l2_leaf_reg': 2.6961942776200942, 'border_count': 57}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:23:18,896] Trial 36 finished with value: -0.9056783196982578 and parameters: {'learning_rate': 0.05499722800708357, 'depth': 10, 'l2_leaf_reg': 3.1444149744248344, 'border_count': 83}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:23:35,905] Trial 37 finished with value: -0.903848960659132 and parameters: {'learning_rate': 0.09399665050928128, 'depth': 6, 'l2_leaf_reg': 1.3756738510939974, 'border_count': 59}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:25:02,711] Trial 38 finished with value: -0.9052585293790084 and parameters: {'learning_rate': 0.05963618878696584, 'depth': 11, 'l2_leaf_reg': 2.5390035915665847, 'border_count': 34}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:26:19,287] Trial 39 finished with value: -0.9053215034178086 and parameters: {'learning_rate': 0.02991120025264205, 'depth': 9, 'l2_leaf_reg': 1.6027471616251896, 'border_count': 65}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:32:05,948] Trial 40 finished with value: -0.9035191152416966 and parameters: {'learning_rate': 0.02352628804054321, 'depth': 12, 'l2_leaf_reg': 3.5879526659283183, 'border_count': 49}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:35:26,902] Trial 41 finished with value: -0.9059046199508994 and parameters: {'learning_rate': 0.04799698839653821, 'depth': 10, 'l2_leaf_reg': 1.455149385171377, 'border_count': 143}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:39:28,031] Trial 42 finished with value: -0.9055918311569368 and parameters: {'learning_rate': 0.044394940341378114, 'depth': 10, 'l2_leaf_reg': 2.309222238037279, 'border_count': 151}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:43:59,362] Trial 43 finished with value: -0.9046372473820329 and parameters: {'learning_rate': 0.04974672402335829, 'depth': 11, 'l2_leaf_reg': 1.4296636780513556, 'border_count': 91}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:47:25,235] Trial 44 finished with value: -0.9051976839830754 and parameters: {'learning_rate': 0.06865305426775603, 'depth': 10, 'l2_leaf_reg': 2.1491043924823825, 'border_count': 156}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:54:10,901] Trial 45 finished with value: -0.905205174042368 and parameters: {'learning_rate': 0.02702738964384708, 'depth': 10, 'l2_leaf_reg': 1.1541797841104646, 'border_count': 221}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:55:06,906] Trial 46 finished with value: -0.9061003129229951 and parameters: {'learning_rate': 0.08836372911481052, 'depth': 8, 'l2_leaf_reg': 3.0696319599631545, 'border_count': 107}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:55:44,011] Trial 47 finished with value: -0.9056412834273463 and parameters: {'learning_rate': 0.08804063094866992, 'depth': 7, 'l2_leaf_reg': 2.9761018604334786, 'border_count': 115}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:56:01,443] Trial 48 finished with value: -0.9030776841307603 and parameters: {'learning_rate': 0.18554319334337205, 'depth': 8, 'l2_leaf_reg': 3.58013415548446, 'border_count': 44}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:56:22,708] Trial 49 finished with value: -0.9039045881752819 and parameters: {'learning_rate': 0.14149006779882917, 'depth': 6, 'l2_leaf_reg': 2.4834358303579025, 'border_count': 108}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:57:53,835] Trial 50 finished with value: -0.905072061799746 and parameters: {'learning_rate': 0.051296254731770866, 'depth': 9, 'l2_leaf_reg': 3.7999698920245475, 'border_count': 85}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 21:59:02,708] Trial 51 finished with value: -0.9061102853341794 and parameters: {'learning_rate': 0.06677814652125544, 'depth': 8, 'l2_leaf_reg': 1.650310125878033, 'border_count': 135}. Best is trial 34 with value: -0.9062160891500698.
[I 2025-08-05 22:00:16,274] Trial 52 finished with value: -0.9068188563851789 and parameters: {'learning_rate': 0.06729774876608531, 'depth': 8, 'l2_leaf_reg': 1.6760180187041454, 'border_count': 135}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:01:27,447] Trial 53 finished with value: -0.906121801613373 and parameters: {'learning_rate': 0.06657837414255267, 'depth': 8, 'l2_leaf_reg': 2.850136297854033, 'border_count': 127}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:02:38,030] Trial 54 finished with value: -0.906596496472926 and parameters: {'learning_rate': 0.06756317142263359, 'depth': 8, 'l2_leaf_reg': 1.729958107606389, 'border_count': 135}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:03:18,720] Trial 55 finished with value: -0.9058975512993918 and parameters: {'learning_rate': 0.07752076827682941, 'depth': 7, 'l2_leaf_reg': 2.3107489973840534, 'border_count': 125}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:04:00,928] Trial 56 finished with value: -0.905679668582648 and parameters: {'learning_rate': 0.058671817284069165, 'depth': 7, 'l2_leaf_reg': 1.0208796355185359, 'border_count': 132}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:05:34,323] Trial 57 finished with value: -0.9039200384908558 and parameters: {'learning_rate': 0.07407131827528653, 'depth': 8, 'l2_leaf_reg': 7.538042161867778, 'border_count': 162}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:06:02,147] Trial 58 finished with value: -0.904907005104107 and parameters: {'learning_rate': 0.11921926255816556, 'depth': 9, 'l2_leaf_reg': 2.8618860732895577, 'border_count': 32}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:06:55,571] Trial 59 finished with value: -0.905166020326804 and parameters: {'learning_rate': 0.06719433576631097, 'depth': 7, 'l2_leaf_reg': 1.7718062119121383, 'border_count': 179}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:08:03,010] Trial 60 finished with value: -0.9064227799573221 and parameters: {'learning_rate': 0.0836156374023705, 'depth': 8, 'l2_leaf_reg': 4.70264341021404, 'border_count': 120}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:09:09,780] Trial 61 finished with value: -0.9054346635147572 and parameters: {'learning_rate': 0.08312664076951443, 'depth': 8, 'l2_leaf_reg': 5.196033671976401, 'border_count': 118}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:09:59,025] Trial 62 finished with value: -0.9058279309368409 and parameters: {'learning_rate': 0.09894446146985963, 'depth': 8, 'l2_leaf_reg': 3.4110690997248323, 'border_count': 100}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:12:22,509] Trial 63 finished with value: -0.9057170917065859 and parameters: {'learning_rate': 0.061487437684408223, 'depth': 9, 'l2_leaf_reg': 4.544824643326092, 'border_count': 131}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:13:03,386] Trial 64 finished with value: -0.904183508225857 and parameters: {'learning_rate': 0.053338670908504006, 'depth': 7, 'l2_leaf_reg': 2.809195408103099, 'border_count': 122}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:14:22,652] Trial 65 finished with value: -0.9066357798738807 and parameters: {'learning_rate': 0.07597196208461358, 'depth': 8, 'l2_leaf_reg': 6.299558661841638, 'border_count': 136}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:16:35,237] Trial 66 finished with value: -0.9053642557700485 and parameters: {'learning_rate': 0.10771841160394222, 'depth': 9, 'l2_leaf_reg': 6.409328305492649, 'border_count': 145}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:18:12,545] Trial 67 finished with value: -0.9055740470350548 and parameters: {'learning_rate': 0.07542791239808959, 'depth': 8, 'l2_leaf_reg': 6.877547515978604, 'border_count': 172}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:18:30,804] Trial 68 finished with value: -0.9051678991113414 and parameters: {'learning_rate': 0.12994143298714098, 'depth': 7, 'l2_leaf_reg': 5.669916766954907, 'border_count': 42}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:20:23,608] Trial 69 finished with value: -0.9041011230909227 and parameters: {'learning_rate': 0.04412989433794608, 'depth': 8, 'l2_leaf_reg': 5.2724392950368175, 'border_count': 194}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:24:29,323] Trial 70 finished with value: -0.9058112408938908 and parameters: {'learning_rate': 0.08145957750116374, 'depth': 9, 'l2_leaf_reg': 5.938839731509367, 'border_count': 238}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:25:46,887] Trial 71 finished with value: -0.9051769383757147 and parameters: {'learning_rate': 0.0696907512248377, 'depth': 8, 'l2_leaf_reg': 6.827125655731957, 'border_count': 135}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:27:07,907] Trial 72 finished with value: -0.9057805243968667 and parameters: {'learning_rate': 0.05496887387742258, 'depth': 8, 'l2_leaf_reg': 2.1577248445536306, 'border_count': 139}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:29:02,384] Trial 73 finished with value: -0.9060659679724221 and parameters: {'learning_rate': 0.06122915053390877, 'depth': 9, 'l2_leaf_reg': 3.928580428688408, 'border_count': 101}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:30:14,558] Trial 74 finished with value: -0.9057564271542535 and parameters: {'learning_rate': 0.03932745972586451, 'depth': 8, 'l2_leaf_reg': 1.8605824871865302, 'border_count': 120}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:30:58,894] Trial 75 finished with value: -0.9045590480962344 and parameters: {'learning_rate': 0.09366385570039883, 'depth': 7, 'l2_leaf_reg': 1.2826569455288617, 'border_count': 158}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:33:21,244] Trial 76 finished with value: -0.905829148042895 and parameters: {'learning_rate': 0.06436933282613627, 'depth': 9, 'l2_leaf_reg': 8.354235448926206, 'border_count': 128}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:34:08,177] Trial 77 finished with value: -0.905678656641278 and parameters: {'learning_rate': 0.04866574199297095, 'depth': 8, 'l2_leaf_reg': 4.034029026833317, 'border_count': 73}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:35:34,448] Trial 78 finished with value: -0.9045906668161784 and parameters: {'learning_rate': 0.054722929410611854, 'depth': 8, 'l2_leaf_reg': 6.317940021445571, 'border_count': 148}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:36:48,136] Trial 79 finished with value: -0.9061419097654431 and parameters: {'learning_rate': 0.0415990903573095, 'depth': 9, 'l2_leaf_reg': 2.515215825653515, 'border_count': 62}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:38:00,984] Trial 80 finished with value: -0.9056471093576496 and parameters: {'learning_rate': 0.03366372365119541, 'depth': 9, 'l2_leaf_reg': 2.414360215266291, 'border_count': 61}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:38:36,907] Trial 81 finished with value: -0.9053232585465103 and parameters: {'learning_rate': 0.04463303460755612, 'depth': 8, 'l2_leaf_reg': 2.0171690652454295, 'border_count': 51}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:39:42,756] Trial 82 finished with value: -0.9051954332815818 and parameters: {'learning_rate': 0.07305744034556112, 'depth': 9, 'l2_leaf_reg': 3.3099084871333218, 'border_count': 67}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:40:12,930] Trial 83 finished with value: -0.9036196458399285 and parameters: {'learning_rate': 0.041340062670804034, 'depth': 7, 'l2_leaf_reg': 2.6356179757899474, 'border_count': 80}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:41:00,651] Trial 84 finished with value: -0.9051740282113846 and parameters: {'learning_rate': 0.08503965416382792, 'depth': 8, 'l2_leaf_reg': 1.7364689769508836, 'border_count': 90}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:43:04,944] Trial 85 finished with value: -0.905529865935059 and parameters: {'learning_rate': 0.03683076492113212, 'depth': 9, 'l2_leaf_reg': 2.2129718167724772, 'border_count': 111}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:43:34,351] Trial 86 finished with value: -0.9064811232329024 and parameters: {'learning_rate': 0.04642600908716683, 'depth': 8, 'l2_leaf_reg': 1.31021183239594, 'border_count': 38}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:44:47,919] Trial 87 finished with value: -0.9056565026186645 and parameters: {'learning_rate': 0.04711835590028551, 'depth': 10, 'l2_leaf_reg': 1.2590267331243568, 'border_count': 47}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:45:36,825] Trial 88 finished with value: -0.9059097548075513 and parameters: {'learning_rate': 0.031025142741898853, 'depth': 9, 'l2_leaf_reg': 1.5927928220790946, 'border_count': 37}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:46:12,192] Trial 89 finished with value: -0.90607388078406 and parameters: {'learning_rate': 0.056978682551664266, 'depth': 8, 'l2_leaf_reg': 1.4389410780594534, 'border_count': 55}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:46:33,463] Trial 90 finished with value: -0.9023335339253531 and parameters: {'learning_rate': 0.03413728077703665, 'depth': 7, 'l2_leaf_reg': 2.0127277255649494, 'border_count': 39}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:47:55,932] Trial 91 finished with value: -0.9058798943504509 and parameters: {'learning_rate': 0.05042155292487263, 'depth': 8, 'l2_leaf_reg': 2.4205222025918847, 'border_count': 140}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:48:30,189] Trial 92 finished with value: -0.9055081969993809 and parameters: {'learning_rate': 0.06393820026242682, 'depth': 8, 'l2_leaf_reg': 2.921824452654811, 'border_count': 52}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:48:45,814] Trial 93 finished with value: -0.8896282200321093 and parameters: {'learning_rate': 0.04194086218153628, 'depth': 4, 'l2_leaf_reg': 1.7271634252670465, 'border_count': 152}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:49:03,698] Trial 94 finished with value: -0.9009447740682788 and parameters: {'learning_rate': 0.29704325056516656, 'depth': 8, 'l2_leaf_reg': 4.661561873184733, 'border_count': 63}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:50:49,711] Trial 95 finished with value: -0.9058811028553656 and parameters: {'learning_rate': 0.0719643292944082, 'depth': 9, 'l2_leaf_reg': 1.1577034941446498, 'border_count': 123}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:51:13,052] Trial 96 finished with value: -0.9060913958092888 and parameters: {'learning_rate': 0.09211857775741464, 'depth': 8, 'l2_leaf_reg': 1.9101597789846998, 'border_count': 44}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:51:32,905] Trial 97 finished with value: -0.9048622679051521 and parameters: {'learning_rate': 0.05252347601062188, 'depth': 7, 'l2_leaf_reg': 2.747705999501622, 'border_count': 32}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:52:44,767] Trial 98 finished with value: -0.9058443366725948 and parameters: {'learning_rate': 0.079156784501702, 'depth': 8, 'l2_leaf_reg': 3.1302101982906265, 'border_count': 133}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:54:00,541] Trial 99 finished with value: -0.9061235649331556 and parameters: {'learning_rate': 0.059156224170819345, 'depth': 9, 'l2_leaf_reg': 2.1604481353188985, 'border_count': 72}. Best is trial 52 with value: -0.9068188563851789.
[I 2025-08-05 22:54:08,574] A new study created in memory with name: no-name-30803975-a39b-4616-b222-ba5ea1662ea5
[I 2025-08-05 22:54:21,899] Trial 0 finished with value: -0.9062395174576533 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:54:26,863] Trial 1 finished with value: -0.8907605853331118 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:54:41,203] Trial 2 finished with value: -0.9061979275579212 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:54:48,968] Trial 3 finished with value: -0.9007808790400859 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:55:06,012] Trial 4 finished with value: -0.9019584960955459 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:55:10,258] Trial 5 finished with value: -0.8656274175837169 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:55:22,277] Trial 6 finished with value: -0.9045083839432371 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:55:26,911] Trial 7 finished with value: -0.8676803497058145 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:55:32,121] Trial 8 finished with value: -0.8891574794206386 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:55:51,103] Trial 9 finished with value: -0.8999101231655962 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:55:55,625] Trial 10 finished with value: -0.9030570718253553 and parameters: {'learning_rate': 0.1461184609693756, 'num_leaves': 9, 'max_depth': 11, 'min_child_samples': 11, 'feature_fraction': 0.5076838686640521, 'bagging_fraction': 0.7190404637309149, 'reg_alpha': 1.3686680646913219e-08, 'reg_lambda': 6.0990065353308305}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:56:09,088] Trial 11 finished with value: -0.9050300246305749 and parameters: {'learning_rate': 0.027263309051458524, 'num_leaves': 139, 'max_depth': 8, 'min_child_samples': 44, 'feature_fraction': 0.7986071567487325, 'bagging_fraction': 0.6975337768549552, 'reg_alpha': 2.627125079295737e-08, 'reg_lambda': 0.01936911547410478}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:56:15,524] Trial 12 finished with value: -0.9052720618214645 and parameters: {'learning_rate': 0.08886042858349513, 'num_leaves': 255, 'max_depth': 8, 'min_child_samples': 23, 'feature_fraction': 0.7556685276542436, 'bagging_fraction': 0.620403968750455, 'reg_alpha': 3.311633884874788e-05, 'reg_lambda': 0.012341345845574348}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:56:29,961] Trial 13 finished with value: -0.9060456036140895 and parameters: {'learning_rate': 0.02479720834993828, 'num_leaves': 108, 'max_depth': 10, 'min_child_samples': 60, 'feature_fraction': 0.5856019492388042, 'bagging_fraction': 0.8304278626461433, 'reg_alpha': 9.86874546485378, 'reg_lambda': 0.11819808903555597}. Best is trial 0 with value: -0.9062395174576533.
[I 2025-08-05 22:56:45,576] Trial 14 finished with value: -0.907487670226771 and parameters: {'learning_rate': 0.03529649428770168, 'num_leaves': 173, 'max_depth': 13, 'min_child_samples': 38, 'feature_fraction': 0.8649174147658507, 'bagging_fraction': 0.6575732465227238, 'reg_alpha': 4.648765661147256e-07, 'reg_lambda': 0.0011295097078834412}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:57:01,638] Trial 15 finished with value: -0.9055352055911596 and parameters: {'learning_rate': 0.036915136228759214, 'num_leaves': 180, 'max_depth': 13, 'min_child_samples': 67, 'feature_fraction': 0.8705765955899738, 'bagging_fraction': 0.6872289764832304, 'reg_alpha': 5.482417813288472e-07, 'reg_lambda': 0.00223805164663709}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:57:09,960] Trial 16 finished with value: -0.9063820339518991 and parameters: {'learning_rate': 0.07277037581026277, 'num_leaves': 225, 'max_depth': 13, 'min_child_samples': 46, 'feature_fraction': 0.7022026073374503, 'bagging_fraction': 0.7912554411220166, 'reg_alpha': 2.938443588102301e-07, 'reg_lambda': 0.2818936773599525}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:57:17,110] Trial 17 finished with value: -0.9043123512292055 and parameters: {'learning_rate': 0.1011542365472881, 'num_leaves': 216, 'max_depth': 13, 'min_child_samples': 46, 'feature_fraction': 0.7393903604929561, 'bagging_fraction': 0.7976550672993057, 'reg_alpha': 3.519504718702662e-07, 'reg_lambda': 0.1456879018934785}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:57:27,059] Trial 18 finished with value: -0.9049746390132501 and parameters: {'learning_rate': 0.08508814259284037, 'num_leaves': 173, 'max_depth': 14, 'min_child_samples': 26, 'feature_fraction': 0.9874510992942994, 'bagging_fraction': 0.7776414655275035, 'reg_alpha': 0.00014521002876919587, 'reg_lambda': 0.0020222602671843134}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:57:31,657] Trial 19 finished with value: -0.9039211455926092 and parameters: {'learning_rate': 0.19769695209390345, 'num_leaves': 100, 'max_depth': 10, 'min_child_samples': 28, 'feature_fraction': 0.8498872707989745, 'bagging_fraction': 0.8898110952317553, 'reg_alpha': 1.342119385535504e-06, 'reg_lambda': 0.035784974628801716}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:57:39,151] Trial 20 finished with value: -0.9042239044073896 and parameters: {'learning_rate': 0.0674917946844153, 'num_leaves': 232, 'max_depth': 6, 'min_child_samples': 48, 'feature_fraction': 0.7159288929998384, 'bagging_fraction': 0.7367150311425937, 'reg_alpha': 0.000164679477119501, 'reg_lambda': 1.0011228379279944e-05}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:57:52,228] Trial 21 finished with value: -0.9064960728354062 and parameters: {'learning_rate': 0.03278824675924449, 'num_leaves': 228, 'max_depth': 12, 'min_child_samples': 70, 'feature_fraction': 0.5962392336019754, 'bagging_fraction': 0.6580513567891269, 'reg_alpha': 6.214164829522708e-08, 'reg_lambda': 0.6419147052053719}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:58:08,093] Trial 22 finished with value: -0.9053292928508079 and parameters: {'learning_rate': 0.019307383172041035, 'num_leaves': 194, 'max_depth': 13, 'min_child_samples': 69, 'feature_fraction': 0.6619048657962279, 'bagging_fraction': 0.6533676066838328, 'reg_alpha': 1.1579508107571383e-07, 'reg_lambda': 0.5055508903505158}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:58:19,361] Trial 23 finished with value: -0.9065761907768992 and parameters: {'learning_rate': 0.0469089547476871, 'num_leaves': 166, 'max_depth': 11, 'min_child_samples': 52, 'feature_fraction': 0.6095871068327156, 'bagging_fraction': 0.678522736123004, 'reg_alpha': 7.392758648636143e-08, 'reg_lambda': 8.038061038966312}. Best is trial 14 with value: -0.907487670226771.
[I 2025-08-05 22:58:30,076] Trial 24 finished with value: -0.9081796343548628 and parameters: {'learning_rate': 0.046190830647000004, 'num_leaves': 169, 'max_depth': 10, 'min_child_samples': 34, 'feature_fraction': 0.6008702039867763, 'bagging_fraction': 0.6836380459367555, 'reg_alpha': 6.737421498849302e-08, 'reg_lambda': 7.265376941838606}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:58:40,839] Trial 25 finished with value: -0.9077483536453503 and parameters: {'learning_rate': 0.0463222122743926, 'num_leaves': 160, 'max_depth': 10, 'min_child_samples': 32, 'feature_fraction': 0.5474717297804558, 'bagging_fraction': 0.6872765865692698, 'reg_alpha': 2.467723761283506e-06, 'reg_lambda': 9.879192474391198}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:58:50,078] Trial 26 finished with value: -0.9077019757157265 and parameters: {'learning_rate': 0.05319380261269459, 'num_leaves': 154, 'max_depth': 7, 'min_child_samples': 17, 'feature_fraction': 0.5439210829881591, 'bagging_fraction': 0.7449560141947525, 'reg_alpha': 1.9712784780108168e-06, 'reg_lambda': 9.599114234402482}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:58:58,700] Trial 27 finished with value: -0.9061872144846083 and parameters: {'learning_rate': 0.052563657213184296, 'num_leaves': 158, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.5460101277993694, 'bagging_fraction': 0.7390310897251646, 'reg_alpha': 3.488383131670746e-06, 'reg_lambda': 2.764904901558571}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:59:03,314] Trial 28 finished with value: -0.9063657954754609 and parameters: {'learning_rate': 0.12354486423701516, 'num_leaves': 109, 'max_depth': 9, 'min_child_samples': 19, 'feature_fraction': 0.5191347796341133, 'bagging_fraction': 0.7665776789456951, 'reg_alpha': 1.8813966925434903e-05, 'reg_lambda': 1.6902749588425065e-08}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:59:12,166] Trial 29 finished with value: -0.9062940541791891 and parameters: {'learning_rate': 0.04336916626266124, 'num_leaves': 89, 'max_depth': 6, 'min_child_samples': 32, 'feature_fraction': 0.5610266110678486, 'bagging_fraction': 0.6008969541990026, 'reg_alpha': 4.807552790027495e-05, 'reg_lambda': 1.45776026056089}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:59:21,871] Trial 30 finished with value: -0.9078169104646537 and parameters: {'learning_rate': 0.05716754928186009, 'num_leaves': 125, 'max_depth': 9, 'min_child_samples': 18, 'feature_fraction': 0.5008223297880297, 'bagging_fraction': 0.8600004349033858, 'reg_alpha': 0.0009024463365983395, 'reg_lambda': 8.998517706807965}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:59:30,797] Trial 31 finished with value: -0.9077679392503691 and parameters: {'learning_rate': 0.059113829964257986, 'num_leaves': 158, 'max_depth': 9, 'min_child_samples': 17, 'feature_fraction': 0.5046991706866294, 'bagging_fraction': 0.8595628562897957, 'reg_alpha': 0.0005775859340676626, 'reg_lambda': 9.400750601997483}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:59:38,349] Trial 32 finished with value: -0.9076245659611079 and parameters: {'learning_rate': 0.060367673643222715, 'num_leaves': 121, 'max_depth': 9, 'min_child_samples': 19, 'feature_fraction': 0.5009728307189619, 'bagging_fraction': 0.9058204306647039, 'reg_alpha': 0.0006617068912876942, 'reg_lambda': 1.4071703360612748}. Best is trial 24 with value: -0.9081796343548628.
[I 2025-08-05 22:59:46,405] Trial 33 finished with value: -0.9084743262398363 and parameters: {'learning_rate': 0.07096674907079562, 'num_leaves': 189, 'max_depth': 10, 'min_child_samples': 31, 'feature_fraction': 0.5722081763565906, 'bagging_fraction': 0.8647850923781163, 'reg_alpha': 0.000761677616809736, 'reg_lambda': 3.97531577198092}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 22:59:53,150] Trial 34 finished with value: -0.9061440699877382 and parameters: {'learning_rate': 0.07491551859216794, 'num_leaves': 193, 'max_depth': 9, 'min_child_samples': 23, 'feature_fraction': 0.5786542319093593, 'bagging_fraction': 0.8664753413946731, 'reg_alpha': 0.0006819117063621031, 'reg_lambda': 0.05445572930948782}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 23:00:01,734] Trial 35 finished with value: -0.9070539419580921 and parameters: {'learning_rate': 0.060782278329659704, 'num_leaves': 84, 'max_depth': 11, 'min_child_samples': 33, 'feature_fraction': 0.6224411700596307, 'bagging_fraction': 0.9424333141500364, 'reg_alpha': 0.002559091491404955, 'reg_lambda': 0.6902259728991694}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 23:00:08,422] Trial 36 finished with value: -0.9056910953476722 and parameters: {'learning_rate': 0.10960055026647238, 'num_leaves': 189, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.660769563406926, 'bagging_fraction': 0.8354544782035798, 'reg_alpha': 0.018905216754490823, 'reg_lambda': 2.445562400421796}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 23:00:14,675] Trial 37 finished with value: -0.9071515386889735 and parameters: {'learning_rate': 0.08421668508261378, 'num_leaves': 126, 'max_depth': 8, 'min_child_samples': 26, 'feature_fraction': 0.5719287818579143, 'bagging_fraction': 0.8629891793322497, 'reg_alpha': 0.010181259337356216, 'reg_lambda': 0.007454640146566137}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 23:00:22,920] Trial 38 finished with value: -0.9071170758303977 and parameters: {'learning_rate': 0.06193358903571701, 'num_leaves': 146, 'max_depth': 10, 'min_child_samples': 41, 'feature_fraction': 0.5234990225573745, 'bagging_fraction': 0.5013339806386407, 'reg_alpha': 0.00033893979708191454, 'reg_lambda': 0.1805973417294544}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 23:00:34,612] Trial 39 finished with value: -0.9059901660185634 and parameters: {'learning_rate': 0.04087616121302868, 'num_leaves': 203, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.6406089351880103, 'bagging_fraction': 0.9354492238547845, 'reg_alpha': 0.036980007509097856, 'reg_lambda': 2.718755069186668}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 23:00:49,812] Trial 40 finished with value: -0.9079827542361645 and parameters: {'learning_rate': 0.029295285477265346, 'num_leaves': 151, 'max_depth': 11, 'min_child_samples': 17, 'feature_fraction': 0.5006113940042964, 'bagging_fraction': 0.9951875422103529, 'reg_alpha': 0.6017550679705532, 'reg_lambda': 6.11200763140353e-05}. Best is trial 33 with value: -0.9084743262398363.
[I 2025-08-05 23:01:04,726] Trial 41 finished with value: -0.9088780470526705 and parameters: {'learning_rate': 0.030324536592560476, 'num_leaves': 148, 'max_depth': 11, 'min_child_samples': 17, 'feature_fraction': 0.5250801133317168, 'bagging_fraction': 0.9878680337515664, 'reg_alpha': 1.0678526883794393, 'reg_lambda': 9.341747823105507e-05}. Best is trial 41 with value: -0.9088780470526705.
[I 2025-08-05 23:01:23,768] Trial 42 finished with value: -0.9082239254728914 and parameters: {'learning_rate': 0.018698754209087617, 'num_leaves': 131, 'max_depth': 11, 'min_child_samples': 23, 'feature_fraction': 0.5608602289465148, 'bagging_fraction': 0.9969137060167707, 'reg_alpha': 1.3570279696997636, 'reg_lambda': 6.71387153818284e-05}. Best is trial 41 with value: -0.9088780470526705.
[I 2025-08-05 23:01:43,008] Trial 43 finished with value: -0.9076055794322568 and parameters: {'learning_rate': 0.018583681203696394, 'num_leaves': 145, 'max_depth': 11, 'min_child_samples': 29, 'feature_fraction': 0.5946152321734297, 'bagging_fraction': 0.9998329620424861, 'reg_alpha': 1.3761262121751299, 'reg_lambda': 7.496555274502435e-05}. Best is trial 41 with value: -0.9088780470526705.
[I 2025-08-05 23:01:58,374] Trial 44 finished with value: -0.9090428744892509 and parameters: {'learning_rate': 0.02918125923333743, 'num_leaves': 180, 'max_depth': 11, 'min_child_samples': 23, 'feature_fraction': 0.560546946157968, 'bagging_fraction': 0.9755917970015285, 'reg_alpha': 0.9199685269576556, 'reg_lambda': 6.3003243794649695e-06}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:02:18,433] Trial 45 finished with value: -0.9084905822321632 and parameters: {'learning_rate': 0.019795377732763703, 'num_leaves': 180, 'max_depth': 12, 'min_child_samples': 23, 'feature_fraction': 0.5632861419254647, 'bagging_fraction': 0.971689757492779, 'reg_alpha': 6.070543611683481, 'reg_lambda': 3.1164930022794467e-06}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:02:38,307] Trial 46 finished with value: -0.9084993728224516 and parameters: {'learning_rate': 0.019913163505687878, 'num_leaves': 178, 'max_depth': 12, 'min_child_samples': 23, 'feature_fraction': 0.5648123285172312, 'bagging_fraction': 0.9653889720933378, 'reg_alpha': 5.552661288651738, 'reg_lambda': 2.5522139269778295e-06}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:02:53,053] Trial 47 finished with value: -0.9016868754426438 and parameters: {'learning_rate': 0.014198861668638155, 'num_leaves': 204, 'max_depth': 12, 'min_child_samples': 94, 'feature_fraction': 0.6771291535654584, 'bagging_fraction': 0.9175068784617368, 'reg_alpha': 8.137544597501845, 'reg_lambda': 3.4703741092773985e-06}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:03:21,134] Trial 48 finished with value: -0.9083691672490227 and parameters: {'learning_rate': 0.016150142627436182, 'num_leaves': 181, 'max_depth': 14, 'min_child_samples': 22, 'feature_fraction': 0.6234873022059475, 'bagging_fraction': 0.9666975623858717, 'reg_alpha': 3.308551311864477, 'reg_lambda': 1.8892353168056518e-06}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:03:37,562] Trial 49 finished with value: -0.907900917205472 and parameters: {'learning_rate': 0.022149420059708665, 'num_leaves': 205, 'max_depth': 12, 'min_child_samples': 38, 'feature_fraction': 0.5288663521066846, 'bagging_fraction': 0.962995483645096, 'reg_alpha': 0.1741978172671034, 'reg_lambda': 0.000305587029185254}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:03:57,335] Trial 50 finished with value: -0.908562617143623 and parameters: {'learning_rate': 0.021140206408612656, 'num_leaves': 181, 'max_depth': 14, 'min_child_samples': 30, 'feature_fraction': 0.5682778481952957, 'bagging_fraction': 0.9688038448374808, 'reg_alpha': 0.35544201160500194, 'reg_lambda': 4.2506968886679546e-07}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:04:13,367] Trial 51 finished with value: -0.9086022152608638 and parameters: {'learning_rate': 0.027484185894987776, 'num_leaves': 180, 'max_depth': 14, 'min_child_samples': 30, 'feature_fraction': 0.569308468087885, 'bagging_fraction': 0.9676324239810402, 'reg_alpha': 0.40575545896436377, 'reg_lambda': 2.5704638651274256e-07}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:04:30,517] Trial 52 finished with value: -0.9089689440450396 and parameters: {'learning_rate': 0.027192247112965754, 'num_leaves': 181, 'max_depth': 15, 'min_child_samples': 26, 'feature_fraction': 0.5571091947405361, 'bagging_fraction': 0.9682098387069266, 'reg_alpha': 0.3769896537989194, 'reg_lambda': 1.774774332644953e-07}. Best is trial 44 with value: -0.9090428744892509.
[I 2025-08-05 23:04:48,210] Trial 53 finished with value: -0.9091113424032666 and parameters: {'learning_rate': 0.027668783615986063, 'num_leaves': 173, 'max_depth': 15, 'min_child_samples': 27, 'feature_fraction': 0.5382479271908779, 'bagging_fraction': 0.9227138193483182, 'reg_alpha': 0.413963155698803, 'reg_lambda': 7.165499826438698e-08}. Best is trial 53 with value: -0.9091113424032666.
[I 2025-08-05 23:05:06,004] Trial 54 finished with value: -0.9094963844413979 and parameters: {'learning_rate': 0.027176475539049436, 'num_leaves': 217, 'max_depth': 15, 'min_child_samples': 27, 'feature_fraction': 0.5325570905314148, 'bagging_fraction': 0.9193296119833663, 'reg_alpha': 0.3546274298656642, 'reg_lambda': 1.252829945211456e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:05:25,325] Trial 55 finished with value: -0.9082671512402808 and parameters: {'learning_rate': 0.02734637379131242, 'num_leaves': 248, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5234657104299887, 'bagging_fraction': 0.9254049872281699, 'reg_alpha': 0.09344952325197438, 'reg_lambda': 1.0569545249471009e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:05:41,102] Trial 56 finished with value: -0.9090398097189876 and parameters: {'learning_rate': 0.031195372052740953, 'num_leaves': 198, 'max_depth': 15, 'min_child_samples': 27, 'feature_fraction': 0.5371293519666569, 'bagging_fraction': 0.8844935516589814, 'reg_alpha': 0.9263281851297029, 'reg_lambda': 1.772016007891776e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:05:57,249] Trial 57 finished with value: -0.9077671488521192 and parameters: {'learning_rate': 0.03262357601387672, 'num_leaves': 215, 'max_depth': 15, 'min_child_samples': 41, 'feature_fraction': 0.5407702599117948, 'bagging_fraction': 0.8942658711248118, 'reg_alpha': 1.138139835396122, 'reg_lambda': 2.1569550234963865e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:06:16,690] Trial 58 finished with value: -0.9080574624236826 and parameters: {'learning_rate': 0.02416627390297279, 'num_leaves': 234, 'max_depth': 15, 'min_child_samples': 26, 'feature_fraction': 0.6117024614204931, 'bagging_fraction': 0.9487907816320554, 'reg_alpha': 0.15045867393959622, 'reg_lambda': 4.2549716539231116e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:06:30,056] Trial 59 finished with value: -0.9089539771832122 and parameters: {'learning_rate': 0.03644906317369762, 'num_leaves': 223, 'max_depth': 14, 'min_child_samples': 26, 'feature_fraction': 0.5292932373330597, 'bagging_fraction': 0.8865960507580686, 'reg_alpha': 0.04906377431393428, 'reg_lambda': 9.456588739364051e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:06:45,216] Trial 60 finished with value: -0.907487338707129 and parameters: {'learning_rate': 0.036586275059083365, 'num_leaves': 222, 'max_depth': 15, 'min_child_samples': 35, 'feature_fraction': 0.757950589129092, 'bagging_fraction': 0.8867376837462253, 'reg_alpha': 0.045136097940431046, 'reg_lambda': 1.0721706467923482e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:07:06,194] Trial 61 finished with value: -0.9064320204333178 and parameters: {'learning_rate': 0.03099616058642368, 'num_leaves': 240, 'max_depth': 14, 'min_child_samples': 26, 'feature_fraction': 0.9454755410985063, 'bagging_fraction': 0.91558277573634, 'reg_alpha': 2.594450635395255, 'reg_lambda': 1.5473720559488873e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:07:25,006] Trial 62 finished with value: -0.9092280609722492 and parameters: {'learning_rate': 0.025763288507284463, 'num_leaves': 198, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.5321815223966333, 'bagging_fraction': 0.9456756292067313, 'reg_alpha': 0.6091090121894429, 'reg_lambda': 5.3466226557505283e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:07:42,503] Trial 63 finished with value: -0.9081008903927212 and parameters: {'learning_rate': 0.025358668030426596, 'num_leaves': 210, 'max_depth': 15, 'min_child_samples': 37, 'feature_fraction': 0.5482281611798029, 'bagging_fraction': 0.9453248282569768, 'reg_alpha': 0.006690506056965627, 'reg_lambda': 7.898278999344336e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:07:57,939] Trial 64 finished with value: -0.9077680914066416 and parameters: {'learning_rate': 0.03506474009945941, 'num_leaves': 196, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.5926624347290742, 'bagging_fraction': 0.8224847510576758, 'reg_alpha': 0.5722477856648067, 'reg_lambda': 4.322106610278296e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:08:15,387] Trial 65 finished with value: -0.908981140045485 and parameters: {'learning_rate': 0.025092914734249072, 'num_leaves': 225, 'max_depth': 13, 'min_child_samples': 28, 'feature_fraction': 0.5410785974909001, 'bagging_fraction': 0.9022792069888415, 'reg_alpha': 0.21532922768984042, 'reg_lambda': 1.0167768248574928e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:08:36,195] Trial 66 finished with value: -0.905096142821934 and parameters: {'learning_rate': 0.017051309865126388, 'num_leaves': 198, 'max_depth': 13, 'min_child_samples': 54, 'feature_fraction': 0.8196683814223185, 'bagging_fraction': 0.904442427736108, 'reg_alpha': 0.19954044344775887, 'reg_lambda': 4.278541012902934e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:08:53,453] Trial 67 finished with value: -0.9086879080234356 and parameters: {'learning_rate': 0.025426978388566415, 'num_leaves': 218, 'max_depth': 15, 'min_child_samples': 28, 'feature_fraction': 0.5463334140293321, 'bagging_fraction': 0.9328451267280684, 'reg_alpha': 2.8915828340196588, 'reg_lambda': 1.0866644854165305e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:09:00,640] Trial 68 finished with value: -0.8978048787082482 and parameters: {'learning_rate': 0.02283673302183513, 'num_leaves': 14, 'max_depth': 13, 'min_child_samples': 35, 'feature_fraction': 0.583428233082565, 'bagging_fraction': 0.9524701132823536, 'reg_alpha': 0.07923237211853404, 'reg_lambda': 1.7179191251185595e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:09:14,999] Trial 69 finished with value: -0.9085442842636672 and parameters: {'learning_rate': 0.03982216667874715, 'num_leaves': 211, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5149909677711991, 'bagging_fraction': 0.9086424286420604, 'reg_alpha': 0.537290082261744, 'reg_lambda': 2.270356640551911e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:09:30,368] Trial 70 finished with value: -0.9077055806675736 and parameters: {'learning_rate': 0.02825430615765895, 'num_leaves': 167, 'max_depth': 13, 'min_child_samples': 43, 'feature_fraction': 0.5483683993761258, 'bagging_fraction': 0.980925616088665, 'reg_alpha': 0.23499225088077053, 'reg_lambda': 8.545031261300645e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:09:44,766] Trial 71 finished with value: -0.9094771553102043 and parameters: {'learning_rate': 0.03294556653445975, 'num_leaves': 235, 'max_depth': 14, 'min_child_samples': 26, 'feature_fraction': 0.535710465884169, 'bagging_fraction': 0.8815572125316921, 'reg_alpha': 0.041103920769664175, 'reg_lambda': 6.267197777467509e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:09:59,336] Trial 72 finished with value: -0.9090163678348022 and parameters: {'learning_rate': 0.03269901583691347, 'num_leaves': 249, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.5370880831540619, 'bagging_fraction': 0.8443779716148015, 'reg_alpha': 0.10675147896394027, 'reg_lambda': 2.8146816537856074e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:10:14,885] Trial 73 finished with value: -0.9083945396673936 and parameters: {'learning_rate': 0.032427870677628014, 'num_leaves': 248, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.5291612430802707, 'bagging_fraction': 0.8764718308351443, 'reg_alpha': 0.02243310797818604, 'reg_lambda': 6.749562893607028e-08}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:10:30,007] Trial 74 finished with value: -0.9083195594615183 and parameters: {'learning_rate': 0.0347261392710046, 'num_leaves': 254, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5351766094904951, 'bagging_fraction': 0.838500904358593, 'reg_alpha': 0.12959128061700692, 'reg_lambda': 3.562412961874138e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:10:43,619] Trial 75 finished with value: -0.9067224146394525 and parameters: {'learning_rate': 0.042424535240745055, 'num_leaves': 238, 'max_depth': 13, 'min_child_samples': 60, 'feature_fraction': 0.6099804260943121, 'bagging_fraction': 0.8476664296298375, 'reg_alpha': 0.845911113163994, 'reg_lambda': 5.638132629731286e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:11:02,767] Trial 76 finished with value: -0.9092973923465572 and parameters: {'learning_rate': 0.02547766618789968, 'num_leaves': 229, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.5134577788698668, 'bagging_fraction': 0.8194536517024182, 'reg_alpha': 2.0508440928202814, 'reg_lambda': 9.38017641516819e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:11:18,962] Trial 77 finished with value: -0.9091246204132505 and parameters: {'learning_rate': 0.030186776630202534, 'num_leaves': 230, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.5181564889385176, 'bagging_fraction': 0.812542768652168, 'reg_alpha': 0.005268714387711914, 'reg_lambda': 5.955221371875728e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:11:42,597] Trial 78 finished with value: -0.9079882676770845 and parameters: {'learning_rate': 0.02139601094100711, 'num_leaves': 231, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5171315912971913, 'bagging_fraction': 0.8082639249638649, 'reg_alpha': 0.004735104482013208, 'reg_lambda': 9.558129953599418e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:11:59,012] Trial 79 finished with value: -0.9092496202411203 and parameters: {'learning_rate': 0.029161045942668256, 'num_leaves': 240, 'max_depth': 15, 'min_child_samples': 24, 'feature_fraction': 0.5116960551466188, 'bagging_fraction': 0.8162621911336198, 'reg_alpha': 1.656382865733921, 'reg_lambda': 1.5121327872873148e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:12:13,467] Trial 80 finished with value: -0.9087275178722335 and parameters: {'learning_rate': 0.03840259017469949, 'num_leaves': 239, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5046964826593603, 'bagging_fraction': 0.7957716350476158, 'reg_alpha': 1.8148100305153056, 'reg_lambda': 1.5814922962580274e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:12:28,984] Trial 81 finished with value: -0.9088610889611152 and parameters: {'learning_rate': 0.029381070062916122, 'num_leaves': 218, 'max_depth': 15, 'min_child_samples': 24, 'feature_fraction': 0.512290370736585, 'bagging_fraction': 0.7745410459471638, 'reg_alpha': 4.348501417195682, 'reg_lambda': 6.773823310498391e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:12:48,986] Trial 82 finished with value: -0.9094206083343248 and parameters: {'learning_rate': 0.023820037631150825, 'num_leaves': 232, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.5140598136201724, 'bagging_fraction': 0.8058316934217518, 'reg_alpha': 2.016301190465797, 'reg_lambda': 2.257600380506476e-05}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:13:08,396] Trial 83 finished with value: -0.9088844222697461 and parameters: {'learning_rate': 0.022796284537391288, 'num_leaves': 229, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.5129260818262401, 'bagging_fraction': 0.8182115342101677, 'reg_alpha': 1.9334312423586835, 'reg_lambda': 3.703928098896805e-05}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:13:28,881] Trial 84 finished with value: -0.9080737689952472 and parameters: {'learning_rate': 0.02615189151590072, 'num_leaves': 244, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5835682499145473, 'bagging_fraction': 0.7806143225191723, 'reg_alpha': 0.6804285644636974, 'reg_lambda': 1.8343195514952553e-05}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:13:50,729] Trial 85 finished with value: -0.9090143457069872 and parameters: {'learning_rate': 0.02364468255223153, 'num_leaves': 235, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.5529643567492895, 'bagging_fraction': 0.758621895476983, 'reg_alpha': 8.86088035042051, 'reg_lambda': 4.922597792581672e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:14:06,286] Trial 86 finished with value: -0.9092804258635955 and parameters: {'learning_rate': 0.029033177224508003, 'num_leaves': 210, 'max_depth': 14, 'min_child_samples': 24, 'feature_fraction': 0.5003258343833273, 'bagging_fraction': 0.7111712606154126, 'reg_alpha': 2.2172896994612854, 'reg_lambda': 1.6071668480825828e-05}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:14:12,092] Trial 87 finished with value: -0.8895918845740647 and parameters: {'learning_rate': 0.01720277787878363, 'num_leaves': 210, 'max_depth': 4, 'min_child_samples': 32, 'feature_fraction': 0.5009060876988302, 'bagging_fraction': 0.8007419941169054, 'reg_alpha': 2.223179905294492, 'reg_lambda': 1.1935019220100671e-05}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:14:41,223] Trial 88 finished with value: -0.908908645954394 and parameters: {'learning_rate': 0.010650960647589393, 'num_leaves': 255, 'max_depth': 14, 'min_child_samples': 24, 'feature_fraction': 0.5173998488545706, 'bagging_fraction': 0.7189009699277058, 'reg_alpha': 4.849860640487143, 'reg_lambda': 3.243281486339666e-05}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:15:03,081] Trial 89 finished with value: -0.9081977421864572 and parameters: {'learning_rate': 0.02084409282843172, 'num_leaves': 221, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5302802167986193, 'bagging_fraction': 0.7252524042566294, 'reg_alpha': 0.06007392181627233, 'reg_lambda': 0.00014006288178909697}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:15:24,835] Trial 90 finished with value: -0.9058006571391747 and parameters: {'learning_rate': 0.02704721567320884, 'num_leaves': 228, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.9068315909660549, 'bagging_fraction': 0.7093186174359986, 'reg_alpha': 0.37826625348971565, 'reg_lambda': 3.0286183317959284e-05}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:15:40,783] Trial 91 finished with value: -0.9091256309938188 and parameters: {'learning_rate': 0.030025296180770496, 'num_leaves': 187, 'max_depth': 15, 'min_child_samples': 22, 'feature_fraction': 0.5125839246729011, 'bagging_fraction': 0.7533439338187692, 'reg_alpha': 1.4380318050279373, 'reg_lambda': 4.200576955524773e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:15:55,739] Trial 92 finished with value: -0.9087809939466152 and parameters: {'learning_rate': 0.03454589260293208, 'num_leaves': 187, 'max_depth': 15, 'min_child_samples': 21, 'feature_fraction': 0.516693311694698, 'bagging_fraction': 0.786077203274141, 'reg_alpha': 0.0015036520798642947, 'reg_lambda': 1.6368172014447768e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:16:13,422] Trial 93 finished with value: -0.9093289209484354 and parameters: {'learning_rate': 0.02396322982755588, 'num_leaves': 207, 'max_depth': 14, 'min_child_samples': 29, 'feature_fraction': 0.5104011524465455, 'bagging_fraction': 0.7513285955990545, 'reg_alpha': 1.750821620990183, 'reg_lambda': 7.064367973948034e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:16:30,180] Trial 94 finished with value: -0.9084230472343602 and parameters: {'learning_rate': 0.024090482817198004, 'num_leaves': 215, 'max_depth': 13, 'min_child_samples': 30, 'feature_fraction': 0.5004914043075948, 'bagging_fraction': 0.7631046336527111, 'reg_alpha': 3.6660935320890338, 'reg_lambda': 4.5918805183200276e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:16:46,655] Trial 95 finished with value: -0.9086107259513874 and parameters: {'learning_rate': 0.03022922839968717, 'num_leaves': 206, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.5213101486600393, 'bagging_fraction': 0.7554775362109852, 'reg_alpha': 1.6075534353962162, 'reg_lambda': 6.632471315689141e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:17:05,698] Trial 96 finished with value: -0.9093059047937825 and parameters: {'learning_rate': 0.022274793629381062, 'num_leaves': 231, 'max_depth': 14, 'min_child_samples': 24, 'feature_fraction': 0.509683409547121, 'bagging_fraction': 0.732286668705011, 'reg_alpha': 0.02336587581474339, 'reg_lambda': 2.504788955992e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:17:19,758] Trial 97 finished with value: -0.9043736976987061 and parameters: {'learning_rate': 0.01803181374225598, 'num_leaves': 243, 'max_depth': 13, 'min_child_samples': 76, 'feature_fraction': 0.5082233659352497, 'bagging_fraction': 0.6992647300415877, 'reg_alpha': 0.026425652385254777, 'reg_lambda': 2.379569686797676e-06}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:17:44,491] Trial 98 finished with value: -0.9083764238303402 and parameters: {'learning_rate': 0.015262191160903889, 'num_leaves': 203, 'max_depth': 14, 'min_child_samples': 25, 'feature_fraction': 0.5550166540669359, 'bagging_fraction': 0.7329611432109492, 'reg_alpha': 5.9143834314947465, 'reg_lambda': 6.741256420297137e-07}. Best is trial 54 with value: -0.9094963844413979.
[I 2025-08-05 23:18:03,461] Trial 99 finished with value: -0.9087913408734011 and parameters: {'learning_rate': 0.020504844219902153, 'num_leaves': 235, 'max_depth': 14, 'min_child_samples': 34, 'feature_fraction': 0.5289133316099284, 'bagging_fraction': 0.7411525644490574, 'reg_alpha': 0.012692004214611583, 'reg_lambda': 1.2300169530847385e-06}. Best is trial 54 with value: -0.9094963844413979.
2025-08-05 23:18:06 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.9244359689771021, 'val_lightgbm': 0.9235182255728377, 'val_ensemble': 0.9255282151154498}
2025-08-05 23:18:06 [INFO] Selected best model 'ensemble' with validation R²=0.9255
2025-08-05 23:18:06 [INFO] Retraining best model 'ensemble' on full dataset
2025-08-05 23:18:17 [INFO] Retraining completed in 10.96s
2025-08-05 23:18:17 [INFO] Saved final model to '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/final_ensemble.pkl'
2025-08-05 23:18:17 [INFO] Tree-based → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/final_ensemble.pkl (R²=0.9255)
2025-08-05 23:18:17 [INFO] Training TabNet model...
[I 2025-08-05 23:18:17,408] A new study created in memory with name: no-name-535633ae-1297-49e9-ada9-46e0693105df
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:19:33,475] Trial 0 finished with value: 0.6963632060381405 and parameters: {'n_d': 60, 'n_a': 22, 'n_steps': 7, 'gamma': 1.4303367523361494, 'lambda_sparse': 1.3814360375994873e-05, 'lr': 0.0009906327349244626, 'weight_decay': 1.4474087945982191e-05}. Best is trial 0 with value: 0.6963632060381405.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:20:06,919] Trial 1 finished with value: 0.9012133069060319 and parameters: {'n_d': 34, 'n_a': 49, 'n_steps': 3, 'gamma': 1.1802028243045695, 'lambda_sparse': 0.003241746441397981, 'lr': 0.010742033094546492, 'weight_decay': 5.961969188422239e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:21:00,105] Trial 2 finished with value: 0.7448431810117766 and parameters: {'n_d': 55, 'n_a': 62, 'n_steps': 6, 'gamma': 1.8536314630899624, 'lambda_sparse': 7.727459183876038e-05, 'lr': 0.0008356575363780275, 'weight_decay': 0.00012519811944864732}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:22:27,714] Trial 3 finished with value: 0.8770410675347822 and parameters: {'n_d': 16, 'n_a': 31, 'n_steps': 9, 'gamma': 1.0214675927568655, 'lambda_sparse': 0.002362731519491678, 'lr': 0.008515819526822508, 'weight_decay': 6.2126987709371245e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:23:40,206] Trial 4 finished with value: 0.8530931487817577 and parameters: {'n_d': 50, 'n_a': 54, 'n_steps': 7, 'gamma': 1.2469022860446521, 'lambda_sparse': 0.0002434967818504351, 'lr': 0.0035747227784963223, 'weight_decay': 5.587920305428683e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:24:43,918] Trial 5 finished with value: 0.81716110507858 and parameters: {'n_d': 13, 'n_a': 39, 'n_steps': 9, 'gamma': 1.578244612831776, 'lambda_sparse': 0.005746660469649487, 'lr': 0.0729992141722695, 'weight_decay': 3.426779641797967e-05}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:25:22,450] Trial 6 finished with value: 0.8640261287010536 and parameters: {'n_d': 14, 'n_a': 30, 'n_steps': 4, 'gamma': 1.672380415931804, 'lambda_sparse': 0.0007379839768602322, 'lr': 0.010264736515960946, 'weight_decay': 3.9358458993402856e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:26:12,434] Trial 7 finished with value: 0.8564990901570707 and parameters: {'n_d': 52, 'n_a': 45, 'n_steps': 4, 'gamma': 1.3117831783748104, 'lambda_sparse': 0.0003770232938327144, 'lr': 0.0015362199772918448, 'weight_decay': 8.896161788918704e-05}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:26:52,256] Trial 8 finished with value: 0.8672058060973584 and parameters: {'n_d': 24, 'n_a': 58, 'n_steps': 4, 'gamma': 1.8281000263269496, 'lambda_sparse': 0.009901938551198223, 'lr': 0.002728258541931462, 'weight_decay': 5.4395477100299064e-05}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:27:57,868] Trial 9 finished with value: 0.8352515714116784 and parameters: {'n_d': 17, 'n_a': 33, 'n_steps': 10, 'gamma': 1.274957883942645, 'lambda_sparse': 0.0006156279373486593, 'lr': 0.04476408472966488, 'weight_decay': 0.00037559679785170334}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:28:42,407] Trial 10 finished with value: 0.7582093843038213 and parameters: {'n_d': 40, 'n_a': 48, 'n_steps': 3, 'gamma': 1.015134674507761, 'lambda_sparse': 0.002111738089997098, 'lr': 0.0002514237982601886, 'weight_decay': 1.1506199154903374e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:30:09,280] Trial 11 finished with value: 0.8791015031391713 and parameters: {'n_d': 32, 'n_a': 12, 'n_steps': 9, 'gamma': 1.0269828250292021, 'lambda_sparse': 0.0028728990306724125, 'lr': 0.014819840030215454, 'weight_decay': 6.089837591124928e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:31:01,519] Trial 12 finished with value: 0.8589067040460047 and parameters: {'n_d': 33, 'n_a': 12, 'n_steps': 6, 'gamma': 1.1220843634907358, 'lambda_sparse': 0.0027623094920917668, 'lr': 0.02003334511432355, 'weight_decay': 1.4010877429262668e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:32:20,773] Trial 13 finished with value: 0.8570817829038828 and parameters: {'n_d': 36, 'n_a': 9, 'n_steps': 8, 'gamma': 1.1511382939200439, 'lambda_sparse': 0.0013527190759822806, 'lr': 0.02523189151625374, 'weight_decay': 1.4397449091975968e-05}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:33:17,718] Trial 14 finished with value: 0.8626550106750291 and parameters: {'n_d': 27, 'n_a': 17, 'n_steps': 5, 'gamma': 1.4156074732198083, 'lambda_sparse': 0.00014903788513345763, 'lr': 0.007660029208563472, 'weight_decay': 2.8787960884809043e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:34:53,225] Trial 15 finished with value: 0.8614128374323464 and parameters: {'n_d': 43, 'n_a': 24, 'n_steps': 10, 'gamma': 1.1483170662125253, 'lambda_sparse': 0.006702094308581672, 'lr': 0.0163453025588616, 'weight_decay': 1.4073683515649996e-05}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:35:45,237] Trial 16 finished with value: 0.8421794849536843 and parameters: {'n_d': 24, 'n_a': 41, 'n_steps': 8, 'gamma': 1.9791737478264282, 'lambda_sparse': 5.503562331014658e-05, 'lr': 0.08596048968051612, 'weight_decay': 1.0571895409793307e-05}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:36:17,504] Trial 17 finished with value: 0.44260529576136565 and parameters: {'n_d': 31, 'n_a': 53, 'n_steps': 3, 'gamma': 1.0713738199366334, 'lambda_sparse': 0.0037301840880898324, 'lr': 0.00010009650147484055, 'weight_decay': 2.2776442484244495e-06}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:37:02,725] Trial 18 finished with value: 0.873321964769798 and parameters: {'n_d': 44, 'n_a': 47, 'n_steps': 5, 'gamma': 1.343298373256286, 'lambda_sparse': 0.001091809340469199, 'lr': 0.004313849572461781, 'weight_decay': 0.0008666017416734975}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:38:16,109] Trial 19 finished with value: 0.86124323787859 and parameters: {'n_d': 28, 'n_a': 64, 'n_steps': 8, 'gamma': 1.202953859125289, 'lambda_sparse': 0.004782363856546356, 'lr': 0.033968826688278796, 'weight_decay': 2.8587343138838218e-05}. Best is trial 1 with value: 0.9012133069060319.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:39:24,229] A new study created in memory with name: no-name-0e9282d3-5dd3-4885-b2ca-dc9b361e0e89
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:40:29,287] Trial 0 finished with value: 0.7940320904575766 and parameters: {'n_d': 26, 'n_a': 42, 'n_steps': 6, 'gamma': 1.2679997889365542, 'lambda_sparse': 0.00958538455836619, 'lr': 0.001375011129156821, 'weight_decay': 4.687502013799156e-05}. Best is trial 0 with value: 0.7940320904575766.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:41:57,324] Trial 1 finished with value: 0.8140680283770592 and parameters: {'n_d': 55, 'n_a': 62, 'n_steps': 9, 'gamma': 1.259848931184547, 'lambda_sparse': 0.0051003754917493425, 'lr': 0.0033545616205606613, 'weight_decay': 4.680409421355368e-05}. Best is trial 1 with value: 0.8140680283770592.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:43:09,760] Trial 2 finished with value: 0.8393216690962999 and parameters: {'n_d': 30, 'n_a': 18, 'n_steps': 7, 'gamma': 1.146605059968665, 'lambda_sparse': 0.00848357658587225, 'lr': 0.019276137446406896, 'weight_decay': 2.0403842778041254e-05}. Best is trial 2 with value: 0.8393216690962999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:44:06,911] Trial 3 finished with value: -0.3151164751357731 and parameters: {'n_d': 36, 'n_a': 37, 'n_steps': 5, 'gamma': 1.6267663972359925, 'lambda_sparse': 3.0039334506224106e-05, 'lr': 0.000260820826475561, 'weight_decay': 0.0005970664049145005}. Best is trial 2 with value: 0.8393216690962999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:45:12,937] Trial 4 finished with value: 0.8324601479862015 and parameters: {'n_d': 40, 'n_a': 61, 'n_steps': 7, 'gamma': 1.246430387217843, 'lambda_sparse': 0.001998959233415612, 'lr': 0.010300635698149815, 'weight_decay': 2.2667451728882464e-06}. Best is trial 2 with value: 0.8393216690962999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:46:32,710] Trial 5 finished with value: -1.203603509388199 and parameters: {'n_d': 46, 'n_a': 32, 'n_steps': 8, 'gamma': 1.1402055949699492, 'lambda_sparse': 0.0005855142647952712, 'lr': 0.00015800742674509672, 'weight_decay': 2.9366162349401356e-06}. Best is trial 2 with value: 0.8393216690962999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:47:45,211] Trial 6 finished with value: -0.18998646954832776 and parameters: {'n_d': 44, 'n_a': 49, 'n_steps': 7, 'gamma': 1.1770222832010155, 'lambda_sparse': 0.00011368947990750828, 'lr': 0.000213946917400918, 'weight_decay': 7.5272589202157655e-06}. Best is trial 2 with value: 0.8393216690962999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:49:04,776] Trial 7 finished with value: -1.9712200169527039 and parameters: {'n_d': 41, 'n_a': 14, 'n_steps': 8, 'gamma': 1.9830098252467339, 'lambda_sparse': 0.0010917392400590811, 'lr': 0.00016905102317349907, 'weight_decay': 5.14729425554137e-05}. Best is trial 2 with value: 0.8393216690962999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:50:32,825] Trial 8 finished with value: 0.8229185073203726 and parameters: {'n_d': 53, 'n_a': 12, 'n_steps': 9, 'gamma': 1.839767371475733, 'lambda_sparse': 2.2834922010614462e-05, 'lr': 0.01594151481939654, 'weight_decay': 3.807207127003089e-06}. Best is trial 2 with value: 0.8393216690962999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:51:37,306] Trial 9 finished with value: 0.8442437111442579 and parameters: {'n_d': 37, 'n_a': 49, 'n_steps': 6, 'gamma': 1.8553148667920878, 'lambda_sparse': 4.690551620254609e-05, 'lr': 0.023507999294353002, 'weight_decay': 0.00020341292177765332}. Best is trial 9 with value: 0.8442437111442579.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:52:00,016] Trial 10 finished with value: 0.8003223409145752 and parameters: {'n_d': 10, 'n_a': 51, 'n_steps': 3, 'gamma': 1.543587538765149, 'lambda_sparse': 0.00011836670371354955, 'lr': 0.09099123641506628, 'weight_decay': 0.0004465545123903652}. Best is trial 9 with value: 0.8442437111442579.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:52:49,654] Trial 11 finished with value: 0.8347147165404549 and parameters: {'n_d': 27, 'n_a': 28, 'n_steps': 5, 'gamma': 1.7146776390794944, 'lambda_sparse': 0.0001858013869676263, 'lr': 0.04802548067793069, 'weight_decay': 1.7748128795426988e-05}. Best is trial 9 with value: 0.8442437111442579.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:53:46,495] Trial 12 finished with value: 0.8598078238319722 and parameters: {'n_d': 27, 'n_a': 23, 'n_steps': 5, 'gamma': 1.0205965565498922, 'lambda_sparse': 1.1000121741308566e-05, 'lr': 0.015810839688236832, 'weight_decay': 0.00016463587355975285}. Best is trial 12 with value: 0.8598078238319722.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:54:31,678] Trial 13 finished with value: 0.8561641220120488 and parameters: {'n_d': 16, 'n_a': 24, 'n_steps': 3, 'gamma': 1.4119349619625035, 'lambda_sparse': 1.070212060095797e-05, 'lr': 0.003806150192073227, 'weight_decay': 0.00018784524445810395}. Best is trial 12 with value: 0.8598078238319722.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:55:16,543] Trial 14 finished with value: 0.8548923532656466 and parameters: {'n_d': 14, 'n_a': 25, 'n_steps': 3, 'gamma': 1.402375087873862, 'lambda_sparse': 1.5123557477412019e-05, 'lr': 0.004541715047574814, 'weight_decay': 0.00016527075300896548}. Best is trial 12 with value: 0.8598078238319722.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:56:06,663] Trial 15 finished with value: 0.7300583431880299 and parameters: {'n_d': 18, 'n_a': 21, 'n_steps': 4, 'gamma': 1.0023505614028339, 'lambda_sparse': 1.0005096851863592e-05, 'lr': 0.0005673719146296867, 'weight_decay': 0.00015128024520574482}. Best is trial 12 with value: 0.8598078238319722.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:56:56,957] Trial 16 finished with value: 0.8024839696141969 and parameters: {'n_d': 19, 'n_a': 8, 'n_steps': 4, 'gamma': 1.3688255611972804, 'lambda_sparse': 5.715489086788987e-05, 'lr': 0.0013291293188505615, 'weight_decay': 0.0008766011205060504}. Best is trial 12 with value: 0.8598078238319722.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:57:43,788] Trial 17 finished with value: 0.8612590175818883 and parameters: {'n_d': 23, 'n_a': 23, 'n_steps': 4, 'gamma': 1.0098332345787056, 'lambda_sparse': 1.1112732251241736e-05, 'lr': 0.006761764423172574, 'weight_decay': 0.0001049843133323637}. Best is trial 17 with value: 0.8612590175818883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:58:40,870] Trial 18 finished with value: 0.8583187700407057 and parameters: {'n_d': 23, 'n_a': 31, 'n_steps': 5, 'gamma': 1.0043941469259312, 'lambda_sparse': 5.454926835066261e-05, 'lr': 0.007389089046524505, 'weight_decay': 8.0804372298207e-05}. Best is trial 17 with value: 0.8612590175818883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 23:59:19,704] Trial 19 finished with value: 0.8274797457264685 and parameters: {'n_d': 64, 'n_a': 37, 'n_steps': 4, 'gamma': 1.0781685230337308, 'lambda_sparse': 0.0004739267830854703, 'lr': 0.04445347148916183, 'weight_decay': 0.00042837171523722495}. Best is trial 17 with value: 0.8612590175818883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:00:34,761] A new study created in memory with name: no-name-7cb40b19-8e0e-46a4-8de6-67e8fa1c891c
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:01:18,018] Trial 0 finished with value: 0.8203854884729955 and parameters: {'n_d': 23, 'n_a': 35, 'n_steps': 4, 'gamma': 1.9607093966964546, 'lambda_sparse': 0.000192572446746287, 'lr': 0.07103122496563063, 'weight_decay': 0.00013405955901311817}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:02:20,571] Trial 1 finished with value: 0.8100773445994613 and parameters: {'n_d': 38, 'n_a': 28, 'n_steps': 7, 'gamma': 1.2422507127598879, 'lambda_sparse': 0.0053087701654198705, 'lr': 0.019706870977281913, 'weight_decay': 1.8705586175418949e-06}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:03:04,548] Trial 2 finished with value: -3.0996141238241126 and parameters: {'n_d': 63, 'n_a': 45, 'n_steps': 8, 'gamma': 1.595013989709805, 'lambda_sparse': 0.002076428795163196, 'lr': 0.00021886475945492417, 'weight_decay': 0.0001289550669953761}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:04:16,915] Trial 3 finished with value: -0.7770865793083506 and parameters: {'n_d': 11, 'n_a': 38, 'n_steps': 7, 'gamma': 1.8391603508310044, 'lambda_sparse': 0.0037677035852904214, 'lr': 0.0001381684277738208, 'weight_decay': 0.0003028735552954726}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:05:35,561] Trial 4 finished with value: 0.8179821508677565 and parameters: {'n_d': 28, 'n_a': 35, 'n_steps': 9, 'gamma': 1.6142166275107552, 'lambda_sparse': 0.00018057466869360905, 'lr': 0.023879872137647216, 'weight_decay': 4.410555142058364e-06}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:06:39,827] Trial 5 finished with value: -0.01469764868514467 and parameters: {'n_d': 34, 'n_a': 62, 'n_steps': 6, 'gamma': 1.0153766327474858, 'lambda_sparse': 0.0009736303499102646, 'lr': 0.0001513611495676494, 'weight_decay': 2.0037861653944743e-05}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:08:02,443] Trial 6 finished with value: 0.7804991491841771 and parameters: {'n_d': 16, 'n_a': 64, 'n_steps': 10, 'gamma': 1.3527097968247723, 'lambda_sparse': 0.00035272706390692993, 'lr': 0.003625608462977013, 'weight_decay': 1.7427122761306597e-05}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:09:15,500] Trial 7 finished with value: 0.796313981366235 and parameters: {'n_d': 18, 'n_a': 22, 'n_steps': 10, 'gamma': 1.1217825061299282, 'lambda_sparse': 0.007300934133682199, 'lr': 0.07806596516735854, 'weight_decay': 1.3405072863082093e-06}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:10:05,136] Trial 8 finished with value: 0.5546090248841844 and parameters: {'n_d': 53, 'n_a': 25, 'n_steps': 4, 'gamma': 1.0235358037717512, 'lambda_sparse': 1.2858318511149311e-05, 'lr': 0.00021740664476821545, 'weight_decay': 0.00021274146934479847}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:10:53,086] Trial 9 finished with value: 0.7124243866225033 and parameters: {'n_d': 49, 'n_a': 59, 'n_steps': 4, 'gamma': 1.737209861645308, 'lambda_sparse': 3.2052145072293484e-05, 'lr': 0.0005259211026542025, 'weight_decay': 0.00017100198536470866}. Best is trial 0 with value: 0.8203854884729955.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:11:34,002] Trial 10 finished with value: 0.847325208714124 and parameters: {'n_d': 25, 'n_a': 10, 'n_steps': 3, 'gamma': 1.9302288651720776, 'lambda_sparse': 9.537198324696985e-05, 'lr': 0.002583768661292347, 'weight_decay': 0.0006940824465106409}. Best is trial 10 with value: 0.847325208714124.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:12:06,180] Trial 11 finished with value: 0.8127162154298456 and parameters: {'n_d': 24, 'n_a': 9, 'n_steps': 3, 'gamma': 1.9471269877329895, 'lambda_sparse': 9.016699502464776e-05, 'lr': 0.0014269583030563021, 'weight_decay': 0.0008908089468168035}. Best is trial 10 with value: 0.847325208714124.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:12:57,144] Trial 12 finished with value: 0.8311538770018796 and parameters: {'n_d': 27, 'n_a': 8, 'n_steps': 5, 'gamma': 1.9968953452447615, 'lambda_sparse': 7.412026322549431e-05, 'lr': 0.004529266381791261, 'weight_decay': 0.0009157790854444872}. Best is trial 10 with value: 0.847325208714124.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:13:50,419] Trial 13 finished with value: 0.8364963088294715 and parameters: {'n_d': 36, 'n_a': 8, 'n_steps': 5, 'gamma': 1.8012490796962866, 'lambda_sparse': 5.8886508118913635e-05, 'lr': 0.004112740880635873, 'weight_decay': 0.000665598153540999}. Best is trial 10 with value: 0.847325208714124.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:14:27,157] Trial 14 finished with value: 0.8224832874882386 and parameters: {'n_d': 45, 'n_a': 17, 'n_steps': 3, 'gamma': 1.7733778856615774, 'lambda_sparse': 2.192286880571868e-05, 'lr': 0.001245205993268631, 'weight_decay': 0.00045345858059507506}. Best is trial 10 with value: 0.847325208714124.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:15:14,067] Trial 15 finished with value: 0.8468651077624582 and parameters: {'n_d': 37, 'n_a': 16, 'n_steps': 5, 'gamma': 1.4683447650099812, 'lambda_sparse': 5.1638967785039285e-05, 'lr': 0.009942025652364257, 'weight_decay': 5.0506189191615344e-05}. Best is trial 10 with value: 0.847325208714124.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:16:10,784] Trial 16 finished with value: 0.8529781779545268 and parameters: {'n_d': 44, 'n_a': 16, 'n_steps': 5, 'gamma': 1.4316195874412267, 'lambda_sparse': 0.0004960192112724544, 'lr': 0.013479533976389336, 'weight_decay': 4.7350892136001256e-05}. Best is trial 16 with value: 0.8529781779545268.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:16:46,749] Trial 17 finished with value: 0.8778721113153339 and parameters: {'n_d': 57, 'n_a': 17, 'n_steps': 3, 'gamma': 1.4420164717271169, 'lambda_sparse': 0.0006254674131620595, 'lr': 0.013318204283693215, 'weight_decay': 5.0366884281670625e-05}. Best is trial 17 with value: 0.8778721113153339.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:17:45,009] Trial 18 finished with value: 0.8539239245691377 and parameters: {'n_d': 63, 'n_a': 18, 'n_steps': 6, 'gamma': 1.4139297650355236, 'lambda_sparse': 0.0007673193960042576, 'lr': 0.011552264974563946, 'weight_decay': 5.417826396295679e-05}. Best is trial 17 with value: 0.8778721113153339.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:19:03,979] Trial 19 finished with value: 0.8459596048571714 and parameters: {'n_d': 64, 'n_a': 50, 'n_steps': 8, 'gamma': 1.3091811189645899, 'lambda_sparse': 0.001134464863850293, 'lr': 0.037799854104915286, 'weight_decay': 6.889900501242977e-06}. Best is trial 17 with value: 0.8778721113153339.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:19:56,999] A new study created in memory with name: no-name-0e9a9efe-8031-4a60-b216-90357c837b13
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:20:29,247] Trial 0 finished with value: 0.8530235102223073 and parameters: {'n_d': 15, 'n_a': 36, 'n_steps': 4, 'gamma': 1.5549269657475846, 'lambda_sparse': 0.002826993135018442, 'lr': 0.028682656486189843, 'weight_decay': 0.0006112671643563226}. Best is trial 0 with value: 0.8530235102223073.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:21:18,878] Trial 1 finished with value: 0.8675258918039883 and parameters: {'n_d': 35, 'n_a': 18, 'n_steps': 4, 'gamma': 1.5657449251427293, 'lambda_sparse': 1.4210174177046971e-05, 'lr': 0.002675052512466059, 'weight_decay': 3.3638526216989886e-06}. Best is trial 1 with value: 0.8675258918039883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:22:02,585] Trial 2 finished with value: 0.848362999783541 and parameters: {'n_d': 25, 'n_a': 34, 'n_steps': 4, 'gamma': 1.175854946557554, 'lambda_sparse': 0.0032549378454053823, 'lr': 0.000999477534180299, 'weight_decay': 0.0009613000372300278}. Best is trial 1 with value: 0.8675258918039883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:22:54,327] Trial 3 finished with value: -3.650697850438008 and parameters: {'n_d': 47, 'n_a': 53, 'n_steps': 8, 'gamma': 1.1552659367082652, 'lambda_sparse': 3.213888772730279e-05, 'lr': 0.0001662814280728519, 'weight_decay': 2.9442267523146352e-06}. Best is trial 1 with value: 0.8675258918039883.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:23:25,824] Trial 4 finished with value: 0.8746174567632594 and parameters: {'n_d': 44, 'n_a': 52, 'n_steps': 3, 'gamma': 1.3744449777003038, 'lambda_sparse': 2.191388415713143e-05, 'lr': 0.020244482219562716, 'weight_decay': 0.0002200736811283064}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:24:19,875] Trial 5 finished with value: -1.3718215694027132 and parameters: {'n_d': 37, 'n_a': 8, 'n_steps': 5, 'gamma': 1.9346638757859982, 'lambda_sparse': 0.004154870352022274, 'lr': 0.00011258371010602937, 'weight_decay': 3.46066710084956e-05}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:25:16,921] Trial 6 finished with value: 0.65784902462814 and parameters: {'n_d': 33, 'n_a': 38, 'n_steps': 5, 'gamma': 1.3136255838857531, 'lambda_sparse': 0.0033329316133817602, 'lr': 0.00039962289055705787, 'weight_decay': 3.711123188436494e-05}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:25:49,847] Trial 7 finished with value: 0.12053618864299476 and parameters: {'n_d': 24, 'n_a': 17, 'n_steps': 3, 'gamma': 1.2221654677963836, 'lambda_sparse': 0.0036918875365698546, 'lr': 0.00010101729465083367, 'weight_decay': 0.00010522352474177163}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:26:09,480] Trial 8 finished with value: 0.8365241095361315 and parameters: {'n_d': 46, 'n_a': 48, 'n_steps': 4, 'gamma': 1.6681965668673275, 'lambda_sparse': 0.002001180738063298, 'lr': 0.05284305575334232, 'weight_decay': 0.00012877314894970253}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:27:31,033] Trial 9 finished with value: 0.8678488879405235 and parameters: {'n_d': 28, 'n_a': 8, 'n_steps': 9, 'gamma': 1.1830712720277592, 'lambda_sparse': 4.549277398183264e-05, 'lr': 0.018850249364419334, 'weight_decay': 0.0003350457606162491}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:28:43,286] Trial 10 finished with value: 0.8550537025134691 and parameters: {'n_d': 63, 'n_a': 61, 'n_steps': 7, 'gamma': 1.3805837987655283, 'lambda_sparse': 0.00022168351009973486, 'lr': 0.008972007093026974, 'weight_decay': 8.285326332902849e-06}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:30:14,574] Trial 11 finished with value: 0.8738309369547119 and parameters: {'n_d': 52, 'n_a': 63, 'n_steps': 10, 'gamma': 1.088783534103354, 'lambda_sparse': 7.950980281296852e-05, 'lr': 0.013541644431898472, 'weight_decay': 0.0002102334139789581}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:31:13,705] Trial 12 finished with value: 0.823383396004042 and parameters: {'n_d': 58, 'n_a': 63, 'n_steps': 10, 'gamma': 1.0192163086420067, 'lambda_sparse': 0.00015037279984086654, 'lr': 0.09632930374684812, 'weight_decay': 0.00017644608808130722}. Best is trial 4 with value: 0.8746174567632594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:32:25,614] Trial 13 finished with value: 0.8917115166504109 and parameters: {'n_d': 50, 'n_a': 52, 'n_steps': 7, 'gamma': 1.0072409020045083, 'lambda_sparse': 9.14226667900928e-05, 'lr': 0.006783558167532151, 'weight_decay': 6.77662435224686e-05}. Best is trial 13 with value: 0.8917115166504109.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:33:37,530] Trial 14 finished with value: 0.8441171521131923 and parameters: {'n_d': 43, 'n_a': 48, 'n_steps': 7, 'gamma': 1.7897070478886405, 'lambda_sparse': 0.0006946128285372483, 'lr': 0.005018506771096552, 'weight_decay': 1.733301919346144e-05}. Best is trial 13 with value: 0.8917115166504109.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:34:41,994] Trial 15 finished with value: 0.8552470289836196 and parameters: {'n_d': 54, 'n_a': 54, 'n_steps': 6, 'gamma': 1.4190911493848315, 'lambda_sparse': 1.2393616045104875e-05, 'lr': 0.0020161755254056186, 'weight_decay': 5.808293536980802e-05}. Best is trial 13 with value: 0.8917115166504109.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:36:01,424] Trial 16 finished with value: 0.8732693637985887 and parameters: {'n_d': 41, 'n_a': 44, 'n_steps': 8, 'gamma': 1.0124375301115345, 'lambda_sparse': 0.0005997054900058539, 'lr': 0.0057215480335997574, 'weight_decay': 1.264648102131992e-06}. Best is trial 13 with value: 0.8917115166504109.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:37:06,010] Trial 17 finished with value: 0.7762418359548307 and parameters: {'n_d': 52, 'n_a': 28, 'n_steps': 6, 'gamma': 1.3031776002977031, 'lambda_sparse': 3.1928800967257434e-05, 'lr': 0.0011742265699679964, 'weight_decay': 1.5891075402539902e-05}. Best is trial 13 with value: 0.8917115166504109.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:37:42,312] Trial 18 finished with value: 0.8630129169506695 and parameters: {'n_d': 62, 'n_a': 54, 'n_steps': 3, 'gamma': 1.4545909297793465, 'lambda_sparse': 7.43792838902344e-05, 'lr': 0.03384990472139874, 'weight_decay': 0.00035459166398956523}. Best is trial 13 with value: 0.8917115166504109.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:38:57,182] Trial 19 finished with value: 0.8451913371291044 and parameters: {'n_d': 13, 'n_a': 41, 'n_steps': 8, 'gamma': 1.7332018460407308, 'lambda_sparse': 0.0004737158416411091, 'lr': 0.009295377300948121, 'weight_decay': 6.196008759517318e-05}. Best is trial 13 with value: 0.8917115166504109.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:40:14,113] A new study created in memory with name: no-name-3549f1f0-0e2c-4e60-86d0-38f569380873
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:41:14,538] Trial 0 finished with value: 0.7103451510909122 and parameters: {'n_d': 27, 'n_a': 11, 'n_steps': 7, 'gamma': 1.9953707563950598, 'lambda_sparse': 0.0027108414200657763, 'lr': 0.0031276097086954356, 'weight_decay': 2.2943334751152958e-06}. Best is trial 0 with value: 0.7103451510909122.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:42:02,196] Trial 1 finished with value: 0.3476060994308027 and parameters: {'n_d': 32, 'n_a': 23, 'n_steps': 4, 'gamma': 1.930153258347039, 'lambda_sparse': 7.043686007996167e-05, 'lr': 0.00031289523649670063, 'weight_decay': 4.707083478134883e-06}. Best is trial 0 with value: 0.7103451510909122.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:42:59,119] Trial 2 finished with value: 0.46193942739187566 and parameters: {'n_d': 44, 'n_a': 37, 'n_steps': 5, 'gamma': 1.5386457618731035, 'lambda_sparse': 0.0004530678179803037, 'lr': 0.0003933681824678378, 'weight_decay': 5.806618546948369e-05}. Best is trial 0 with value: 0.7103451510909122.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:44:11,201] Trial 3 finished with value: 0.16453062537368168 and parameters: {'n_d': 14, 'n_a': 61, 'n_steps': 7, 'gamma': 1.8547647233799944, 'lambda_sparse': 4.486416586353476e-05, 'lr': 0.00048661525021583105, 'weight_decay': 7.049171766220154e-05}. Best is trial 0 with value: 0.7103451510909122.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:45:30,667] Trial 4 finished with value: 0.8655708308121072 and parameters: {'n_d': 61, 'n_a': 42, 'n_steps': 8, 'gamma': 1.296049994184489, 'lambda_sparse': 0.0024155983448457714, 'lr': 0.020093021382804888, 'weight_decay': 5.601426267766589e-06}. Best is trial 4 with value: 0.8655708308121072.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:46:20,244] Trial 5 finished with value: 0.5076891585996164 and parameters: {'n_d': 64, 'n_a': 44, 'n_steps': 4, 'gamma': 1.402189387932474, 'lambda_sparse': 0.003535644977058105, 'lr': 0.0001831585871828089, 'weight_decay': 1.0336873575148563e-05}. Best is trial 4 with value: 0.8655708308121072.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:47:47,292] Trial 6 finished with value: 0.6944080634181282 and parameters: {'n_d': 50, 'n_a': 40, 'n_steps': 9, 'gamma': 1.8105332730196002, 'lambda_sparse': 0.008462767695272957, 'lr': 0.0022251069308132773, 'weight_decay': 2.2418466118866786e-05}. Best is trial 4 with value: 0.8655708308121072.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:48:25,147] Trial 7 finished with value: 0.8390130632559176 and parameters: {'n_d': 60, 'n_a': 59, 'n_steps': 6, 'gamma': 1.647599196874725, 'lambda_sparse': 0.008173354552925647, 'lr': 0.014801446856995606, 'weight_decay': 3.81130208132863e-06}. Best is trial 4 with value: 0.8655708308121072.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:49:20,848] Trial 8 finished with value: 0.8398878297248559 and parameters: {'n_d': 22, 'n_a': 49, 'n_steps': 7, 'gamma': 1.7951777924824381, 'lambda_sparse': 0.0007852988853372407, 'lr': 0.03522418428068675, 'weight_decay': 5.347936800019627e-06}. Best is trial 4 with value: 0.8655708308121072.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:50:25,230] Trial 9 finished with value: 0.8464916933772391 and parameters: {'n_d': 39, 'n_a': 54, 'n_steps': 6, 'gamma': 1.360949585395053, 'lambda_sparse': 3.5470710270130563e-05, 'lr': 0.002136788103440707, 'weight_decay': 0.00016144777875165997}. Best is trial 4 with value: 0.8655708308121072.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:51:41,352] Trial 10 finished with value: 0.7823705711710734 and parameters: {'n_d': 52, 'n_a': 28, 'n_steps': 10, 'gamma': 1.1013021534246827, 'lambda_sparse': 0.001204326962629924, 'lr': 0.09140963650786253, 'weight_decay': 0.0007537296130036108}. Best is trial 4 with value: 0.8655708308121072.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:53:08,896] Trial 11 finished with value: 0.8678811473306411 and parameters: {'n_d': 39, 'n_a': 51, 'n_steps': 9, 'gamma': 1.2562546620833581, 'lambda_sparse': 1.1766610972579741e-05, 'lr': 0.009592725655953555, 'weight_decay': 0.0002243817208637833}. Best is trial 11 with value: 0.8678811473306411.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:54:36,204] Trial 12 finished with value: 0.84243434554289 and parameters: {'n_d': 10, 'n_a': 48, 'n_steps': 9, 'gamma': 1.1632371525484473, 'lambda_sparse': 0.0002004964899845591, 'lr': 0.010852454512054906, 'weight_decay': 1.145906798642726e-06}. Best is trial 11 with value: 0.8678811473306411.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:56:03,780] Trial 13 finished with value: 0.8590046465478471 and parameters: {'n_d': 54, 'n_a': 31, 'n_steps': 9, 'gamma': 1.2571404396865216, 'lambda_sparse': 1.5259009277876675e-05, 'lr': 0.010280727107342584, 'weight_decay': 0.0003831464749955852}. Best is trial 11 with value: 0.8678811473306411.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:57:23,011] Trial 14 finished with value: 0.8743011385678616 and parameters: {'n_d': 41, 'n_a': 53, 'n_steps': 8, 'gamma': 1.021945212554451, 'lambda_sparse': 0.0001336420398602979, 'lr': 0.032510085150045956, 'weight_decay': 1.7937609734559095e-05}. Best is trial 14 with value: 0.8743011385678616.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 00:58:48,700] Trial 15 finished with value: 0.8347607356560951 and parameters: {'n_d': 40, 'n_a': 64, 'n_steps': 10, 'gamma': 1.0248257880869038, 'lambda_sparse': 1.2141497929730274e-05, 'lr': 0.0907447043996038, 'weight_decay': 0.00018727551583637767}. Best is trial 14 with value: 0.8743011385678616.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:00:08,069] Trial 16 finished with value: 0.8777126203506501 and parameters: {'n_d': 31, 'n_a': 54, 'n_steps': 8, 'gamma': 1.0102930255158342, 'lambda_sparse': 0.0001596172106677304, 'lr': 0.00523984204401661, 'weight_decay': 2.682507593036776e-05}. Best is trial 16 with value: 0.8777126203506501.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:01:27,742] Trial 17 finished with value: 0.8376876307715266 and parameters: {'n_d': 31, 'n_a': 56, 'n_steps': 8, 'gamma': 1.0248037672073367, 'lambda_sparse': 0.00018414466784160747, 'lr': 0.0011467123958988456, 'weight_decay': 1.6782414683907936e-05}. Best is trial 16 with value: 0.8777126203506501.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:02:46,897] Trial 18 finished with value: 0.8570306495747141 and parameters: {'n_d': 21, 'n_a': 9, 'n_steps': 8, 'gamma': 1.1589841093118884, 'lambda_sparse': 0.00010340651036734525, 'lr': 0.03381304573344527, 'weight_decay': 4.8270946127633714e-05}. Best is trial 16 with value: 0.8777126203506501.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:03:43,738] Trial 19 finished with value: 0.8927004716648705 and parameters: {'n_d': 45, 'n_a': 18, 'n_steps': 5, 'gamma': 1.0040145724240965, 'lambda_sparse': 0.0004934157397131511, 'lr': 0.005307412304660353, 'weight_decay': 1.2458550876522375e-05}. Best is trial 19 with value: 0.8927004716648705.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:05:09,009] A new study created in memory with name: no-name-d6103dc6-b076-4331-81b2-4f054b40fd05
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:06:02,570] Trial 0 finished with value: -0.2762993286198274 and parameters: {'n_d': 11, 'n_a': 23, 'n_steps': 5, 'gamma': 1.7519731606207474, 'lambda_sparse': 3.679251834550013e-05, 'lr': 0.00011819314344901251, 'weight_decay': 3.029918266687257e-05}. Best is trial 0 with value: -0.2762993286198274.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:07:21,920] Trial 1 finished with value: 0.8441501218931161 and parameters: {'n_d': 11, 'n_a': 38, 'n_steps': 8, 'gamma': 1.061477737917129, 'lambda_sparse': 0.00036019008355015007, 'lr': 0.0037940181223030584, 'weight_decay': 6.805464948551464e-06}. Best is trial 1 with value: 0.8441501218931161.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:08:08,352] Trial 2 finished with value: 0.845153636505975 and parameters: {'n_d': 23, 'n_a': 57, 'n_steps': 4, 'gamma': 1.445425437640607, 'lambda_sparse': 0.00056813976158652, 'lr': 0.08154974042755182, 'weight_decay': 0.00016673595993901697}. Best is trial 2 with value: 0.845153636505975.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:09:35,885] Trial 3 finished with value: -3.721692248065624 and parameters: {'n_d': 38, 'n_a': 21, 'n_steps': 9, 'gamma': 1.6816133999623273, 'lambda_sparse': 0.0016265562642169256, 'lr': 0.0002228623644213441, 'weight_decay': 6.32873401034762e-05}. Best is trial 2 with value: 0.845153636505975.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:10:08,166] Trial 4 finished with value: 0.8646728321500757 and parameters: {'n_d': 33, 'n_a': 36, 'n_steps': 3, 'gamma': 1.334162098051432, 'lambda_sparse': 0.00043932270497102, 'lr': 0.05603950990009414, 'weight_decay': 7.165271106714241e-06}. Best is trial 4 with value: 0.8646728321500757.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:11:11,623] Trial 5 finished with value: 0.6037958002377256 and parameters: {'n_d': 42, 'n_a': 27, 'n_steps': 7, 'gamma': 1.545539333884019, 'lambda_sparse': 0.00010098011733047906, 'lr': 0.000807548804637918, 'weight_decay': 0.0006505086272357318}. Best is trial 4 with value: 0.8646728321500757.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:12:08,648] Trial 6 finished with value: 0.7803769490351906 and parameters: {'n_d': 54, 'n_a': 59, 'n_steps': 5, 'gamma': 1.7188711535202976, 'lambda_sparse': 1.3496911839129208e-05, 'lr': 0.0007049827343545984, 'weight_decay': 0.0003251986498660756}. Best is trial 4 with value: 0.8646728321500757.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:13:07,474] Trial 7 finished with value: 0.23808016822507128 and parameters: {'n_d': 47, 'n_a': 23, 'n_steps': 6, 'gamma': 1.552255558050942, 'lambda_sparse': 0.005262550205062761, 'lr': 0.00032534833657184655, 'weight_decay': 3.6843081977468912e-06}. Best is trial 4 with value: 0.8646728321500757.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:14:27,139] Trial 8 finished with value: 0.8493461574681169 and parameters: {'n_d': 28, 'n_a': 52, 'n_steps': 9, 'gamma': 1.1531439093918516, 'lambda_sparse': 0.00011516325965189406, 'lr': 0.057039968447248596, 'weight_decay': 2.3374002507648654e-06}. Best is trial 4 with value: 0.8646728321500757.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:15:39,394] Trial 9 finished with value: 0.8605838156476477 and parameters: {'n_d': 30, 'n_a': 34, 'n_steps': 7, 'gamma': 1.0987239214277609, 'lambda_sparse': 0.0001007618145420417, 'lr': 0.033427236294035365, 'weight_decay': 1.2354705976878846e-06}. Best is trial 4 with value: 0.8646728321500757.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:16:07,679] Trial 10 finished with value: 0.8681392088945872 and parameters: {'n_d': 64, 'n_a': 10, 'n_steps': 3, 'gamma': 1.9926685731161289, 'lambda_sparse': 0.00934881142798867, 'lr': 0.010950601713712317, 'weight_decay': 1.5122312898350557e-05}. Best is trial 10 with value: 0.8681392088945872.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:16:50,799] Trial 11 finished with value: 0.8720859506308151 and parameters: {'n_d': 60, 'n_a': 9, 'n_steps': 3, 'gamma': 1.34298864706174, 'lambda_sparse': 0.008752479743612332, 'lr': 0.013794178684597704, 'weight_decay': 1.4484050186834207e-05}. Best is trial 11 with value: 0.8720859506308151.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:17:24,613] Trial 12 finished with value: 0.8652790326139834 and parameters: {'n_d': 64, 'n_a': 8, 'n_steps': 3, 'gamma': 1.8965158860448152, 'lambda_sparse': 0.00961340276310344, 'lr': 0.010125306110355423, 'weight_decay': 2.0382198215298334e-05}. Best is trial 11 with value: 0.8720859506308151.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:17:58,515] Trial 13 finished with value: 0.8780683150475341 and parameters: {'n_d': 63, 'n_a': 10, 'n_steps': 3, 'gamma': 1.980664973072302, 'lambda_sparse': 0.00252756377214337, 'lr': 0.012399234713463896, 'weight_decay': 1.483551978763448e-05}. Best is trial 13 with value: 0.8780683150475341.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:18:45,541] Trial 14 finished with value: 0.8717102494882418 and parameters: {'n_d': 55, 'n_a': 14, 'n_steps': 4, 'gamma': 1.2775802961366902, 'lambda_sparse': 0.002271307074827912, 'lr': 0.013553472600008156, 'weight_decay': 5.554423862362227e-05}. Best is trial 13 with value: 0.8780683150475341.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:19:34,184] Trial 15 finished with value: 0.8398600476316528 and parameters: {'n_d': 56, 'n_a': 16, 'n_steps': 5, 'gamma': 1.3030736366425097, 'lambda_sparse': 0.0013209112114836786, 'lr': 0.0033835159880731902, 'weight_decay': 9.322500659154628e-06}. Best is trial 13 with value: 0.8780683150475341.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:20:12,069] Trial 16 finished with value: 0.8623802280859483 and parameters: {'n_d': 48, 'n_a': 47, 'n_steps': 4, 'gamma': 1.397027211513405, 'lambda_sparse': 0.003811098529159118, 'lr': 0.019398306618482755, 'weight_decay': 8.756344388309463e-05}. Best is trial 13 with value: 0.8780683150475341.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:21:44,981] Trial 17 finished with value: 0.8117018753234455 and parameters: {'n_d': 59, 'n_a': 16, 'n_steps': 10, 'gamma': 1.8483682279851714, 'lambda_sparse': 0.0030218732005324648, 'lr': 0.005536921109413547, 'weight_decay': 3.356179746352172e-06}. Best is trial 13 with value: 0.8780683150475341.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:22:48,338] Trial 18 finished with value: 0.7157946905053106 and parameters: {'n_d': 49, 'n_a': 28, 'n_steps': 6, 'gamma': 1.6109318124213172, 'lambda_sparse': 0.0009750163206791317, 'lr': 0.0011713438169134026, 'weight_decay': 1.3450596948335213e-05}. Best is trial 13 with value: 0.8780683150475341.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:23:09,078] Trial 19 finished with value: 0.8473495034829106 and parameters: {'n_d': 61, 'n_a': 42, 'n_steps': 3, 'gamma': 1.2304113262771543, 'lambda_sparse': 0.0055321312516201735, 'lr': 0.027848584637979287, 'weight_decay': 3.303030790564047e-05}. Best is trial 13 with value: 0.8780683150475341.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:24:06,222] A new study created in memory with name: no-name-f7d0ef6f-d4f1-4ae5-9ff7-c47ecc424021
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:25:39,784] Trial 0 finished with value: 0.8023802140928438 and parameters: {'n_d': 47, 'n_a': 59, 'n_steps': 10, 'gamma': 1.5475328562021695, 'lambda_sparse': 0.0025164050396178942, 'lr': 0.005113221615310972, 'weight_decay': 3.333688575849873e-05}. Best is trial 0 with value: 0.8023802140928438.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:26:36,814] Trial 1 finished with value: -1.3041164590061411 and parameters: {'n_d': 33, 'n_a': 26, 'n_steps': 5, 'gamma': 1.9721096481847704, 'lambda_sparse': 1.508901627865905e-05, 'lr': 0.00014255146585463144, 'weight_decay': 0.00023008831879683234}. Best is trial 0 with value: 0.8023802140928438.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:27:55,881] Trial 2 finished with value: 0.8317117768525008 and parameters: {'n_d': 20, 'n_a': 10, 'n_steps': 8, 'gamma': 1.529662998857437, 'lambda_sparse': 0.0001623253732534464, 'lr': 0.07963897273505334, 'weight_decay': 4.935033166205384e-05}. Best is trial 2 with value: 0.8317117768525008.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:28:52,917] Trial 3 finished with value: 0.6633020178913885 and parameters: {'n_d': 46, 'n_a': 56, 'n_steps': 5, 'gamma': 1.204815859072295, 'lambda_sparse': 0.00012415874450223642, 'lr': 0.0003853696932660492, 'weight_decay': 0.0002015366846348503}. Best is trial 2 with value: 0.8317117768525008.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:29:25,817] Trial 4 finished with value: 0.866312915236349 and parameters: {'n_d': 55, 'n_a': 17, 'n_steps': 3, 'gamma': 1.1974815613146395, 'lambda_sparse': 0.0020688873430395136, 'lr': 0.01344285265763612, 'weight_decay': 6.8939087676432e-06}. Best is trial 4 with value: 0.866312915236349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:30:49,845] Trial 5 finished with value: 0.6273484737265148 and parameters: {'n_d': 29, 'n_a': 56, 'n_steps': 9, 'gamma': 1.6718543515918864, 'lambda_sparse': 0.005252194703938739, 'lr': 0.0009591552707770175, 'weight_decay': 1.5766818339182137e-06}. Best is trial 4 with value: 0.866312915236349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:32:17,697] Trial 6 finished with value: -1.1118301945645142 and parameters: {'n_d': 17, 'n_a': 47, 'n_steps': 9, 'gamma': 1.9822656664898108, 'lambda_sparse': 0.008084341747958202, 'lr': 0.00023136948499562457, 'weight_decay': 3.284384943486267e-05}. Best is trial 4 with value: 0.866312915236349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:33:07,634] Trial 7 finished with value: 0.23408224753160278 and parameters: {'n_d': 17, 'n_a': 50, 'n_steps': 4, 'gamma': 1.1825306517553602, 'lambda_sparse': 2.809850064019642e-05, 'lr': 0.00014328808245181728, 'weight_decay': 5.940439450439404e-05}. Best is trial 4 with value: 0.866312915236349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:34:00,275] Trial 8 finished with value: -0.09887228364259171 and parameters: {'n_d': 51, 'n_a': 22, 'n_steps': 5, 'gamma': 1.159513524274172, 'lambda_sparse': 2.5256960853677883e-05, 'lr': 0.00017315180896784824, 'weight_decay': 3.652465544225307e-05}. Best is trial 4 with value: 0.866312915236349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:35:02,225] Trial 9 finished with value: 0.8457268849636093 and parameters: {'n_d': 10, 'n_a': 40, 'n_steps': 6, 'gamma': 1.3243772768653228, 'lambda_sparse': 0.002002319185220275, 'lr': 0.012878501492004297, 'weight_decay': 1.911613594167795e-05}. Best is trial 4 with value: 0.866312915236349.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:35:27,776] Trial 10 finished with value: 0.8668400430953342 and parameters: {'n_d': 63, 'n_a': 8, 'n_steps': 3, 'gamma': 1.0500843897900358, 'lambda_sparse': 0.0008087723274914337, 'lr': 0.03635140568175808, 'weight_decay': 2.5274988634835797e-06}. Best is trial 10 with value: 0.8668400430953342.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:36:11,022] Trial 11 finished with value: 0.8662299976327796 and parameters: {'n_d': 62, 'n_a': 9, 'n_steps': 3, 'gamma': 1.003702096675642, 'lambda_sparse': 0.0007031225239320686, 'lr': 0.03716199979432068, 'weight_decay': 2.6422335196524814e-06}. Best is trial 10 with value: 0.8668400430953342.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:36:45,814] Trial 12 finished with value: 0.8804942773232148 and parameters: {'n_d': 63, 'n_a': 19, 'n_steps': 3, 'gamma': 1.035093272187265, 'lambda_sparse': 0.000681509665640995, 'lr': 0.01617342775956406, 'weight_decay': 5.613812555722615e-06}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:37:18,056] Trial 13 finished with value: 0.8716401663593302 and parameters: {'n_d': 63, 'n_a': 31, 'n_steps': 3, 'gamma': 1.0074042312155018, 'lambda_sparse': 0.0005137815562480532, 'lr': 0.025048229644422815, 'weight_decay': 6.670069316117009e-06}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:38:23,123] Trial 14 finished with value: 0.7948636506041293 and parameters: {'n_d': 56, 'n_a': 32, 'n_steps': 7, 'gamma': 1.379586011090682, 'lambda_sparse': 0.0003656496451195172, 'lr': 0.0028145711214058273, 'weight_decay': 7.458051521401253e-06}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:39:12,765] Trial 15 finished with value: 0.8735570956100681 and parameters: {'n_d': 40, 'n_a': 32, 'n_steps': 4, 'gamma': 1.3530781255702262, 'lambda_sparse': 9.666261829507019e-05, 'lr': 0.009466013953638027, 'weight_decay': 8.193366077070661e-06}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:40:02,705] Trial 16 finished with value: 0.8512745169965229 and parameters: {'n_d': 42, 'n_a': 38, 'n_steps': 4, 'gamma': 1.742408407043523, 'lambda_sparse': 9.717148748083068e-05, 'lr': 0.004037761145276748, 'weight_decay': 1.1068811285263537e-05}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:40:44,519] Trial 17 finished with value: 0.8444900452424958 and parameters: {'n_d': 39, 'n_a': 19, 'n_steps': 4, 'gamma': 1.369326880567304, 'lambda_sparse': 6.0748262385743465e-05, 'lr': 0.0017367137234122264, 'weight_decay': 3.61255804868934e-06}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:41:48,371] Trial 18 finished with value: 0.8497964350855274 and parameters: {'n_d': 27, 'n_a': 26, 'n_steps': 6, 'gamma': 1.291838004121659, 'lambda_sparse': 5.6608691628838474e-05, 'lr': 0.013114375657238686, 'weight_decay': 0.0008571279145531496}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:42:31,908] Trial 19 finished with value: 0.8402417527452093 and parameters: {'n_d': 34, 'n_a': 43, 'n_steps': 4, 'gamma': 1.4418318125926854, 'lambda_sparse': 0.00023548533664472115, 'lr': 0.08492221660591687, 'weight_decay': 1.425382514106293e-05}. Best is trial 12 with value: 0.8804942773232148.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:43:26,994] A new study created in memory with name: no-name-70262c27-308f-42f5-bd91-c02a6aa28f91
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:44:02,945] Trial 0 finished with value: 0.5838059758317421 and parameters: {'n_d': 22, 'n_a': 10, 'n_steps': 3, 'gamma': 1.7266588413744428, 'lambda_sparse': 1.0041982809541484e-05, 'lr': 0.00022410436398405208, 'weight_decay': 9.691790304081337e-05}. Best is trial 0 with value: 0.5838059758317421.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:45:30,443] Trial 1 finished with value: 0.8096268377951986 and parameters: {'n_d': 31, 'n_a': 23, 'n_steps': 9, 'gamma': 1.7463965916050581, 'lambda_sparse': 6.731162884774785e-05, 'lr': 0.005379579520236609, 'weight_decay': 1.350743864146762e-05}. Best is trial 1 with value: 0.8096268377951986.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:46:20,000] Trial 2 finished with value: 0.8712169927211079 and parameters: {'n_d': 28, 'n_a': 40, 'n_steps': 4, 'gamma': 1.2594195457689765, 'lambda_sparse': 1.5250010481581123e-05, 'lr': 0.01046362235823655, 'weight_decay': 0.0004698838136813901}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:47:02,988] Trial 3 finished with value: 0.8263769760288856 and parameters: {'n_d': 57, 'n_a': 46, 'n_steps': 9, 'gamma': 1.2632800231594232, 'lambda_sparse': 0.0007675723002040899, 'lr': 0.088317438165029, 'weight_decay': 0.000495815186828303}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:48:31,107] Trial 4 finished with value: 0.7668287303298691 and parameters: {'n_d': 12, 'n_a': 54, 'n_steps': 9, 'gamma': 1.8599484977902907, 'lambda_sparse': 0.0050805940178134295, 'lr': 0.0027567533199365185, 'weight_decay': 0.00031212466473555755}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:49:56,694] Trial 5 finished with value: -3.222716980490233 and parameters: {'n_d': 53, 'n_a': 29, 'n_steps': 9, 'gamma': 1.2510435182187911, 'lambda_sparse': 0.00041616869782447227, 'lr': 0.00014354581818851848, 'weight_decay': 0.000826146598331359}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:51:00,907] Trial 6 finished with value: 0.8402881349657938 and parameters: {'n_d': 11, 'n_a': 54, 'n_steps': 6, 'gamma': 1.8135541566376605, 'lambda_sparse': 1.765665418188368e-05, 'lr': 0.015225973110892002, 'weight_decay': 2.6401256892350053e-06}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:51:21,342] Trial 7 finished with value: 0.8459992329147741 and parameters: {'n_d': 15, 'n_a': 19, 'n_steps': 3, 'gamma': 1.638083467287066, 'lambda_sparse': 0.00016157112126653403, 'lr': 0.036395252714830635, 'weight_decay': 0.00023903183833654665}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:52:32,960] Trial 8 finished with value: -0.545361509642051 and parameters: {'n_d': 40, 'n_a': 11, 'n_steps': 8, 'gamma': 1.8044317312446705, 'lambda_sparse': 0.0011044798352981302, 'lr': 0.0005412795393486817, 'weight_decay': 7.383607493435968e-06}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:53:08,616] Trial 9 finished with value: 0.8357578502944493 and parameters: {'n_d': 40, 'n_a': 49, 'n_steps': 3, 'gamma': 1.7281708255080979, 'lambda_sparse': 0.008146929835704855, 'lr': 0.037051057120102315, 'weight_decay': 0.0005487312421076221}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:54:05,519] Trial 10 finished with value: 0.8602932482278789 and parameters: {'n_d': 28, 'n_a': 64, 'n_steps': 5, 'gamma': 1.0625062530028886, 'lambda_sparse': 4.0452275868289555e-05, 'lr': 0.0017416327884340734, 'weight_decay': 5.486407912636314e-05}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:55:02,961] Trial 11 finished with value: 0.8666089358343194 and parameters: {'n_d': 28, 'n_a': 38, 'n_steps': 5, 'gamma': 1.000179572226752, 'lambda_sparse': 3.7242022943932954e-05, 'lr': 0.0019709883821437736, 'weight_decay': 5.461101625990401e-05}. Best is trial 2 with value: 0.8712169927211079.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:55:56,668] Trial 12 finished with value: 0.8838560293897985 and parameters: {'n_d': 46, 'n_a': 39, 'n_steps': 5, 'gamma': 1.07082635416498, 'lambda_sparse': 3.896661101279003e-05, 'lr': 0.00743313064700156, 'weight_decay': 2.3607884970136522e-05}. Best is trial 12 with value: 0.8838560293897985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:56:32,387] Trial 13 finished with value: 0.852167437698779 and parameters: {'n_d': 48, 'n_a': 37, 'n_steps': 5, 'gamma': 1.326622799244667, 'lambda_sparse': 0.00013834401755593494, 'lr': 0.008687080257308206, 'weight_decay': 1.6937139017489002e-05}. Best is trial 12 with value: 0.8838560293897985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:57:44,441] Trial 14 finished with value: 0.8653070537864338 and parameters: {'n_d': 62, 'n_a': 31, 'n_steps': 7, 'gamma': 1.4463100858202615, 'lambda_sparse': 2.076898436115146e-05, 'lr': 0.015599862846058642, 'weight_decay': 0.00015279753817056772}. Best is trial 12 with value: 0.8838560293897985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:58:34,135] Trial 15 finished with value: 0.8381591661504755 and parameters: {'n_d': 44, 'n_a': 42, 'n_steps': 4, 'gamma': 1.129956137402229, 'lambda_sparse': 9.653254472793266e-05, 'lr': 0.0008218507151870748, 'weight_decay': 5.2254448372288114e-06}. Best is trial 12 with value: 0.8838560293897985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 01:59:32,604] Trial 16 finished with value: 0.8391687170555349 and parameters: {'n_d': 34, 'n_a': 32, 'n_steps': 6, 'gamma': 1.987720992145098, 'lambda_sparse': 1.0799275178642257e-05, 'lr': 0.0055326465302706915, 'weight_decay': 3.2082501782033664e-05}. Best is trial 12 with value: 0.8838560293897985.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:00:22,224] Trial 17 finished with value: 0.8870801487392567 and parameters: {'n_d': 49, 'n_a': 24, 'n_steps': 4, 'gamma': 1.1567397903574868, 'lambda_sparse': 3.679678482191886e-05, 'lr': 0.018115278754978013, 'weight_decay': 1.165904080021873e-06}. Best is trial 17 with value: 0.8870801487392567.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:01:27,195] Trial 18 finished with value: 0.8499634564808497 and parameters: {'n_d': 49, 'n_a': 21, 'n_steps': 7, 'gamma': 1.1413564546605819, 'lambda_sparse': 0.0002679134516323401, 'lr': 0.033718993666769156, 'weight_decay': 1.3562882021698208e-06}. Best is trial 17 with value: 0.8870801487392567.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:02:09,215] Trial 19 finished with value: 0.8725150679500673 and parameters: {'n_d': 63, 'n_a': 26, 'n_steps': 4, 'gamma': 1.441161294988789, 'lambda_sparse': 5.492832225881139e-05, 'lr': 0.08561732862388101, 'weight_decay': 1.1131281836158802e-06}. Best is trial 17 with value: 0.8870801487392567.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:03:23,123] A new study created in memory with name: no-name-595ada90-e243-4ad9-aaf3-e7e03bc01717
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:04:50,710] Trial 0 finished with value: 0.8405461342542117 and parameters: {'n_d': 57, 'n_a': 30, 'n_steps': 9, 'gamma': 1.9313068689748372, 'lambda_sparse': 2.294626906089746e-05, 'lr': 0.010252613194415049, 'weight_decay': 0.0004807448168719066}. Best is trial 0 with value: 0.8405461342542117.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:06:18,413] Trial 1 finished with value: -2.1441896624658683 and parameters: {'n_d': 45, 'n_a': 25, 'n_steps': 9, 'gamma': 1.042177455614845, 'lambda_sparse': 0.00010995000675000307, 'lr': 0.00024373747635159427, 'weight_decay': 1.4983958955024658e-05}. Best is trial 0 with value: 0.8405461342542117.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:06:54,034] Trial 2 finished with value: 0.8804674443445077 and parameters: {'n_d': 56, 'n_a': 43, 'n_steps': 3, 'gamma': 1.9643055581669269, 'lambda_sparse': 0.0011023479155064051, 'lr': 0.023679703627042907, 'weight_decay': 2.3631772207048636e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:07:26,051] Trial 3 finished with value: 0.851342867828705 and parameters: {'n_d': 12, 'n_a': 29, 'n_steps': 3, 'gamma': 1.9505781097463213, 'lambda_sparse': 0.0005102897118777455, 'lr': 0.0021004995949223276, 'weight_decay': 0.00042514308274177004}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:08:31,382] Trial 4 finished with value: 0.8367869912162826 and parameters: {'n_d': 30, 'n_a': 64, 'n_steps': 10, 'gamma': 1.0562884386767921, 'lambda_sparse': 0.009621912645301767, 'lr': 0.012852915626961841, 'weight_decay': 4.322109553685992e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:10:07,077] Trial 5 finished with value: 0.8401619131406731 and parameters: {'n_d': 63, 'n_a': 47, 'n_steps': 10, 'gamma': 1.8419582078715244, 'lambda_sparse': 0.0004699644842096775, 'lr': 0.014943285333322759, 'weight_decay': 0.0008649028226771788}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:11:29,746] Trial 6 finished with value: 0.14709605075752852 and parameters: {'n_d': 29, 'n_a': 8, 'n_steps': 9, 'gamma': 1.0037293525268092, 'lambda_sparse': 7.57073350245597e-05, 'lr': 0.0006086174548663209, 'weight_decay': 0.00024443474445138424}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:12:41,819] Trial 7 finished with value: 0.4118387563112984 and parameters: {'n_d': 26, 'n_a': 21, 'n_steps': 7, 'gamma': 1.9384466647698395, 'lambda_sparse': 0.00813061750317212, 'lr': 0.0008705630593916862, 'weight_decay': 0.0001407266873256298}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:14:06,888] Trial 8 finished with value: 0.82433527494099 and parameters: {'n_d': 9, 'n_a': 40, 'n_steps': 9, 'gamma': 1.2519663172780904, 'lambda_sparse': 0.00038478902948866603, 'lr': 0.0033761614550856353, 'weight_decay': 0.0004721643718633963}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:15:42,076] Trial 9 finished with value: 0.7486397523174252 and parameters: {'n_d': 43, 'n_a': 25, 'n_steps': 10, 'gamma': 1.542394726213123, 'lambda_sparse': 3.392228501406029e-05, 'lr': 0.002750909098997672, 'weight_decay': 2.5809790834512385e-05}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:16:14,895] Trial 10 finished with value: 0.8725812265020119 and parameters: {'n_d': 52, 'n_a': 54, 'n_steps': 3, 'gamma': 1.6769470301349445, 'lambda_sparse': 0.0020147023378871767, 'lr': 0.0681002536211153, 'weight_decay': 1.0914543302286137e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:16:47,163] Trial 11 finished with value: 0.8715640087550848 and parameters: {'n_d': 50, 'n_a': 54, 'n_steps': 3, 'gamma': 1.6830263704331383, 'lambda_sparse': 0.0020102893030206656, 'lr': 0.08703954884848196, 'weight_decay': 1.021961524677182e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:17:42,026] Trial 12 finished with value: 0.8668157589775949 and parameters: {'n_d': 54, 'n_a': 52, 'n_steps': 5, 'gamma': 1.7054456933781488, 'lambda_sparse': 0.001987970481174946, 'lr': 0.07190664739847813, 'weight_decay': 1.515087189286487e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:18:38,976] Trial 13 finished with value: 0.8593016276706125 and parameters: {'n_d': 64, 'n_a': 62, 'n_steps': 5, 'gamma': 1.419870513712394, 'lambda_sparse': 0.0017996857381642377, 'lr': 0.032852194166521985, 'weight_decay': 4.762395023973996e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:19:28,945] Trial 14 finished with value: 0.8668687316177267 and parameters: {'n_d': 38, 'n_a': 41, 'n_steps': 4, 'gamma': 1.7345742198849843, 'lambda_sparse': 0.0011356050137645945, 'lr': 0.03034349225887738, 'weight_decay': 3.214925861557173e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:20:06,451] Trial 15 finished with value: 0.8076643997611579 and parameters: {'n_d': 50, 'n_a': 54, 'n_steps': 6, 'gamma': 1.491566775548351, 'lambda_sparse': 0.0038767935987352674, 'lr': 0.03676600758883945, 'weight_decay': 1.0168481197027133e-05}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:20:56,005] Trial 16 finished with value: 0.8721516730303974 and parameters: {'n_d': 58, 'n_a': 47, 'n_steps': 4, 'gamma': 1.7995625388794891, 'lambda_sparse': 0.00017651488944427318, 'lr': 0.006190817341149633, 'weight_decay': 7.440708937940609e-05}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:21:45,116] Trial 17 finished with value: 0.8182256976768184 and parameters: {'n_d': 39, 'n_a': 36, 'n_steps': 7, 'gamma': 1.6021744251604735, 'lambda_sparse': 1.0291471596767993e-05, 'lr': 0.08866138891035082, 'weight_decay': 2.2392844396202825e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:22:14,601] Trial 18 finished with value: 0.8705577795176314 and parameters: {'n_d': 49, 'n_a': 57, 'n_steps': 3, 'gamma': 1.3265409524303637, 'lambda_sparse': 0.0009210253672904361, 'lr': 0.03208406919109294, 'weight_decay': 5.79009346583622e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:23:02,467] Trial 19 finished with value: 0.20958695281832385 and parameters: {'n_d': 18, 'n_a': 46, 'n_steps': 4, 'gamma': 1.8305927785958476, 'lambda_sparse': 0.0044091574347533795, 'lr': 0.00010063254019516328, 'weight_decay': 1.0627719793184803e-06}. Best is trial 2 with value: 0.8804674443445077.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:23:43,830] A new study created in memory with name: no-name-2618c1e0-c9a3-41da-8d81-fcb34f10be00
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:24:39,967] Trial 0 finished with value: 0.8864336281754386 and parameters: {'n_d': 62, 'n_a': 41, 'n_steps': 6, 'gamma': 1.0629274901858725, 'lambda_sparse': 1.3121371277335902e-05, 'lr': 0.056561640754354985, 'weight_decay': 3.093673589532337e-06}. Best is trial 0 with value: 0.8864336281754386.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:26:14,640] Trial 1 finished with value: 0.17083625311862205 and parameters: {'n_d': 15, 'n_a': 18, 'n_steps': 10, 'gamma': 1.3060568090439544, 'lambda_sparse': 1.0233995785241664e-05, 'lr': 0.0008150490648620445, 'weight_decay': 0.0005400131907910459}. Best is trial 0 with value: 0.8864336281754386.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:27:42,026] Trial 2 finished with value: -11.02829153623013 and parameters: {'n_d': 21, 'n_a': 38, 'n_steps': 9, 'gamma': 1.7801058269178933, 'lambda_sparse': 1.652679347401158e-05, 'lr': 0.00016911472827928643, 'weight_decay': 0.0006841552901539912}. Best is trial 0 with value: 0.8864336281754386.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:28:39,053] Trial 3 finished with value: -3.255828087450041 and parameters: {'n_d': 37, 'n_a': 8, 'n_steps': 5, 'gamma': 1.2141729002017718, 'lambda_sparse': 2.0076771051625362e-05, 'lr': 0.00011608314885504411, 'weight_decay': 0.0009749885682967725}. Best is trial 0 with value: 0.8864336281754386.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:30:14,196] Trial 4 finished with value: -2.8014187047044388 and parameters: {'n_d': 63, 'n_a': 11, 'n_steps': 10, 'gamma': 1.8436515142726435, 'lambda_sparse': 7.457588784013608e-05, 'lr': 0.0003087768997451833, 'weight_decay': 1.1593310073768953e-05}. Best is trial 0 with value: 0.8864336281754386.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:31:18,231] Trial 5 finished with value: 0.8674353368204661 and parameters: {'n_d': 56, 'n_a': 26, 'n_steps': 7, 'gamma': 1.1564072477032368, 'lambda_sparse': 4.79899407645576e-05, 'lr': 0.0407990580163983, 'weight_decay': 0.00010958251053168905}. Best is trial 0 with value: 0.8864336281754386.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:32:00,418] Trial 6 finished with value: 0.8913676852973011 and parameters: {'n_d': 54, 'n_a': 23, 'n_steps': 3, 'gamma': 1.37719160177214, 'lambda_sparse': 0.00020607278040492047, 'lr': 0.0023272776594750752, 'weight_decay': 0.0005132329267523726}. Best is trial 6 with value: 0.8913676852973011.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:32:35,199] Trial 7 finished with value: 0.8315507616397013 and parameters: {'n_d': 53, 'n_a': 56, 'n_steps': 5, 'gamma': 1.4264238599060426, 'lambda_sparse': 2.3092316516363576e-05, 'lr': 0.05019509595850523, 'weight_decay': 0.0007304655959273672}. Best is trial 6 with value: 0.8913676852973011.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:33:37,916] Trial 8 finished with value: -1.834167632898534 and parameters: {'n_d': 27, 'n_a': 27, 'n_steps': 7, 'gamma': 1.3714993202086958, 'lambda_sparse': 0.0003038575157857364, 'lr': 0.00010751995669123262, 'weight_decay': 8.755333618559509e-05}. Best is trial 6 with value: 0.8913676852973011.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:34:35,934] Trial 9 finished with value: 0.8656045566454846 and parameters: {'n_d': 44, 'n_a': 24, 'n_steps': 8, 'gamma': 1.1542328185907058, 'lambda_sparse': 0.0060456553104952845, 'lr': 0.06081595142245447, 'weight_decay': 4.3143645735274005e-05}. Best is trial 6 with value: 0.8913676852973011.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:35:14,616] Trial 10 finished with value: 0.9036052267113249 and parameters: {'n_d': 47, 'n_a': 50, 'n_steps': 3, 'gamma': 1.6100644202742778, 'lambda_sparse': 0.0031871361340264494, 'lr': 0.005356322555225445, 'weight_decay': 1.293198304683542e-06}. Best is trial 10 with value: 0.9036052267113249.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:35:55,977] Trial 11 finished with value: 0.9019992743131515 and parameters: {'n_d': 45, 'n_a': 51, 'n_steps': 3, 'gamma': 1.616989324121387, 'lambda_sparse': 0.003905876993945386, 'lr': 0.0061245226699920136, 'weight_decay': 4.56216449270452e-06}. Best is trial 10 with value: 0.9036052267113249.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:36:34,268] Trial 12 finished with value: 0.9123756514893149 and parameters: {'n_d': 41, 'n_a': 53, 'n_steps': 3, 'gamma': 1.6520377422244228, 'lambda_sparse': 0.003866832765080467, 'lr': 0.010303922213342342, 'weight_decay': 1.081193558785807e-06}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:37:23,673] Trial 13 finished with value: 0.9009998251599424 and parameters: {'n_d': 32, 'n_a': 64, 'n_steps': 4, 'gamma': 1.638878025030518, 'lambda_sparse': 0.0015146867984509578, 'lr': 0.008452727691188435, 'weight_decay': 1.1337312139763296e-06}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:38:05,026] Trial 14 finished with value: 0.8792478053781948 and parameters: {'n_d': 42, 'n_a': 48, 'n_steps': 4, 'gamma': 1.9695151296678364, 'lambda_sparse': 0.0012223604952775378, 'lr': 0.017291000445191055, 'weight_decay': 1.0477801010062023e-06}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:38:38,929] Trial 15 finished with value: 0.8913894230699095 and parameters: {'n_d': 48, 'n_a': 64, 'n_steps': 3, 'gamma': 1.5669176203988435, 'lambda_sparse': 0.0016386842303997686, 'lr': 0.0015456861822488665, 'weight_decay': 3.47909566433947e-06}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:39:19,428] Trial 16 finished with value: 0.85367352795501 and parameters: {'n_d': 36, 'n_a': 45, 'n_steps': 5, 'gamma': 1.7427066596656868, 'lambda_sparse': 0.007943624023899613, 'lr': 0.012930598757039922, 'weight_decay': 1.2526255823125052e-05}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:40:03,743] Trial 17 finished with value: 0.9027191823567486 and parameters: {'n_d': 27, 'n_a': 57, 'n_steps': 4, 'gamma': 1.5301583285752502, 'lambda_sparse': 0.0006747319232640258, 'lr': 0.004460405580500947, 'weight_decay': 2.2748869092608614e-06}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:41:03,306] Trial 18 finished with value: 0.8664348149534165 and parameters: {'n_d': 36, 'n_a': 34, 'n_steps': 6, 'gamma': 1.6971729408900869, 'lambda_sparse': 0.0036418147629463365, 'lr': 0.021056224725385497, 'weight_decay': 7.89697340220574e-06}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-06 02:41:35,675] Trial 19 finished with value: 0.8672912567945884 and parameters: {'n_d': 51, 'n_a': 55, 'n_steps': 3, 'gamma': 1.9207254973244976, 'lambda_sparse': 0.000614861822582388, 'lr': 0.0007773483070090959, 'weight_decay': 1.5637322715530956e-06}. Best is trial 12 with value: 0.9123756514893149.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-06 02:42:14 [INFO] TabNet →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/tabnet (mean R²=0.8917)
2025-08-06 02:42:14 [INFO] Ensemble weights: TabPFN=0.335, Tree=0.339, TabNet=0.326
2025-08-06 02:42:14 [INFO] Loading individual models into memory...
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-06 02:42:21 [INFO] Saved weighted ensemble to /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/final_model.pkl
2025-08-06 02:42:58 [INFO] Loading X_test (fold 11) from /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/superconductivity
2025-08-06 02:42:58 [INFO] Loading X_test for fold 11 of dataset: /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/superconductivity
2025-08-06 02:42:58 [INFO] Loaded full training data (8601 rows, 81 cols)
2025-08-06 02:42:58 [INFO] Loading ensemble from /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/final_model.pkl
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:3453: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-06 02:49:04 [INFO] Saving predictions to /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal-superconductivity/y_pred.csv
