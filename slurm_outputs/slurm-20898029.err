cpu-bind=MASK - dlcgpu25, task  0  0 [2030677]: mask 0xf0000000f0000 set
/var/spool/slurm/job20898029/slurm_script: line 11: module: command not found
2025-08-02 03:26:56 [INFO] Using device: cuda
2025-08-02 03:26:56 [INFO] Training TabPFN model...
[I 2025-08-02 03:26:56,696] A new study created in memory with name: no-name-85cb0aa1-c1f9-4995-866c-63d88c328a44
2025-08-02 03:26:56 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
2025-08-02 03:26:56 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-02 03:30:10,918] Trial 0 finished with value: 0.9260572256148073 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.9260572256148073.
2025-08-02 03:30:10 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
2025-08-02 03:30:10 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-02 03:33:47,738] Trial 1 finished with value: 0.9262889835026962 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 1 with value: 0.9262889835026962.
2025-08-02 03:33:47 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
2025-08-02 03:33:47 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-02 03:38:00,998] Trial 2 finished with value: 0.9240255091562499 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 1 with value: 0.9262889835026962.
2025-08-02 03:38:00 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
2025-08-02 03:38:01 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-02 03:40:15,233] Trial 3 finished with value: 0.9252326124326563 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 1 with value: 0.9262889835026962.
2025-08-02 03:40:15 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
2025-08-02 03:40:15 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
[I 2025-08-02 03:43:36,243] Trial 4 finished with value: 0.9259055239950397 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 1 with value: 0.9262889835026962.
2025-08-02 03:43:36 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
2025-08-02 03:43:36 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:44:45 [INFO] ⏸️ Pruned trial 5 at step 5 (R²=0.9252)
[I 2025-08-02 03:44:45,756] Trial 5 pruned. 
2025-08-02 03:44:45 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
2025-08-02 03:44:45 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:46:43 [INFO] ⏸️ Pruned trial 6 at step 5 (R²=0.9246)
[I 2025-08-02 03:46:43,359] Trial 6 pruned. 
2025-08-02 03:46:43 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
2025-08-02 03:46:43 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:48:39 [INFO] ⏸️ Pruned trial 7 at step 5 (R²=0.9246)
[I 2025-08-02 03:48:39,606] Trial 7 pruned. 
2025-08-02 03:48:39 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
2025-08-02 03:48:39 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:49:06 [INFO] ⏸️ Pruned trial 8 at step 1 (R²=0.9173)
[I 2025-08-02 03:49:06,530] Trial 8 pru ned. 
2025-08-02 03:49:06 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
2025-08-02 03:49:06 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:51:09 [INFO] ⏸️ Pruned trial 9 at step 5 (R²=0.9251)
[I 2025-08-02 03:51:09,607] Trial 9 pruned. 
2025-08-02 03:51:09 [INFO] 🔍 Trial 10: n_bootstrap=20, sample_frac=0.74
2025-08-02 03:51:09 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:51:35 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.9174)
[I 2025-08-02 03:51:35,897] Trial 10 pruned. 
2025-08-02 03:51:35 [INFO] 🔍 Trial 11: n_bootstrap=17, sample_frac=0.81
2025-08-02 03:51:35 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:51:48 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.9165)
[I 2025-08-02 03:51:48,451] Trial 11 pruned. 
2025-08-02 03:51:48 [INFO] 🔍 Trial 12: n_bootstrap=18, sample_frac=0.83
2025-08-02 03:51:48 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:52:01 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.9173)
[I 2025-08-02 03:52:01,238] Trial 12 pruned. 
2025-08-02 03:52:01 [INFO] 🔍 Trial 13: n_bootstrap=15, sample_frac=0.74
2025-08-02 03:52:01 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:52:27 [INFO] ⏸️ Pruned trial 13 at step 1 (R²=0.9171)
[I 2025-08-02 03:52:27,701] Trial 13 pruned. 
2025-08-02 03:52:27 [INFO] 🔍 Trial 14: n_bootstrap=16, sample_frac=0.60
2025-08-02 03:52:27 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:52:49 [INFO] ⏸️ Pruned trial 14 at step 1 (R²=0.9171)
[I 2025-08-02 03:52:49,082] Trial 14 pruned. 
2025-08-02 03:52:49 [INFO] 🔍 Trial 15: n_bootstrap=14, sample_frac=0.88
2025-08-02 03:52:49 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:53:44 [INFO] ⏸️ Pruned trial 15 at step 4 (R²=0.9234)
[I 2025-08-02 03:53:44,952] Trial 15 pruned. 
2025-08-02 03:53:44 [INFO] 🔍 Trial 16: n_bootstrap=18, sample_frac=0.78
2025-08-02 03:53:44 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:53:56 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.9169)
[I 2025-08-02 03:53:56,993] Trial 16 pruned. 
2025-08-02 03:53:57 [INFO] 🔍 Trial 17: n_bootstrap=20, sample_frac=0.84
2025-08-02 03:53:57 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:54:49 [INFO] ⏸️ Pruned trial 17 at step 4 (R²=0.9230)
[I 2025-08-02 03:54:49,370] Trial 17 pruned. 
2025-08-02 03:54:49 [INFO] 🔍 Trial 18: n_bootstrap=16, sample_frac=0.78
2025-08-02 03:54:49 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:55:01 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.9174)
[I 2025-08-02 03:55:01,325] Trial 18 pruned. 
2025-08-02 03:55:01 [INFO] 🔍 Trial 19: n_bootstrap=13, sample_frac=0.72
2025-08-02 03:55:01 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:57:08 [INFO] ⏸️ Pruned trial 19 at step 5 (R²=0.9251)
[I 2025-08-02 03:57:08,670] Trial 19 pruned. 
2025-08-02 03:57:08 [INFO] 🔍 Trial 20: n_bootstrap=18, sample_frac=0.86
2025-08-02 03:57:08 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:58:02 [INFO] ⏸️ Pruned trial 20 at step 4 (R²=0.9229)
[I 2025-08-02 03:58:02,482] Trial 20 pruned. 
2025-08-02 03:58:02 [INFO] 🔍 Trial 21: n_bootstrap=16, sample_frac=0.81
2025-08-02 03:58:02 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:58:14 [INFO] ⏸️ Pruned trial 21 at step 1 (R²=0.9167)
[I 2025-08-02 03:58:14,994] Trial 21 pruned. 
2025-08-02 03:58:15 [INFO] 🔍 Trial 22: n_bootstrap=15, sample_frac=0.83
2025-08-02 03:58:15 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:58:27 [INFO] ⏸️ Pruned trial 22 at step 1 (R²=0.9175)
[I 2025-08-02 03:58:27,894] Trial 22 pruned. 
2025-08-02 03:58:27 [INFO] 🔍 Trial 23: n_bootstrap=17, sample_frac=0.79
2025-08-02 03:58:27 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:58:40 [INFO] ⏸️ Pruned trial 23 at step 1 (R²=0.9168)
[I 2025-08-02 03:58:40,044] Trial 23 pruned. 
2025-08-02 03:58:40 [INFO] 🔍 Trial 24: n_bootstrap=17, sample_frac=0.90
2025-08-02 03:58:40 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:59:36 [INFO] ⏸️ Pruned trial 24 at step 4 (R²=0.9235)
[I 2025-08-02 03:59:36,844] Trial 24 pruned. 
2025-08-02 03:59:36 [INFO] 🔍 Trial 25: n_bootstrap=14, sample_frac=0.86
2025-08-02 03:59:36 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 03:59:50 [INFO] ⏸️ Pruned trial 25 at step 1 (R²=0.9170)
[I 2025-08-02 03:59:50,259] Trial 25 pruned. 
2025-08-02 03:59:50 [INFO] 🔍 Trial 26: n_bootstrap=15, sample_frac=0.81
2025-08-02 03:59:50 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 04:00:02 [INFO] ⏸️ Pruned trial 26 at step 1 (R²=0.9166)
[I 2025-08-02 04:00:02,643] Trial 26 pruned. 
2025-08-02 04:00:02 [INFO] 🔍 Trial 27: n_bootstrap=19, sample_frac=0.72
2025-08-02 04:00:02 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 04:02:09 [INFO] ⏸️ Pruned trial 27 at step 5 (R²=0.9250)
[I 2025-08-02 04:02:09,777] Trial 27 pruned. 
2025-08-02 04:02:09 [INFO] 🔍 Trial 28: n_bootstrap=13, sample_frac=0.76
2025-08-02 04:02:09 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 04:02:37 [INFO] ⏸️ Pruned trial 28 at step 1 (R²=0.9170)
[I 2025-08-02 04:02:37,253] Trial 28 pruned. 
2025-08-02 04:02:37 [INFO] 🔍 Trial 29: n_bootstrap=12, sample_frac=0.72
2025-08-02 04:02:37 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 04:03:02 [INFO] ⏸️ Pruned trial 29 at step 1 (R²=0.9175)
[I 2025-08-02 04:03:02,765] Trial 29 pruned. 
2025-08-02 04:03:02 [INFO] 🏆 Best Params: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}, R²=0.92629
2025-08-02 04:03:02 [INFO] Bootstrap training → dataset=exam_dataset, device=cuda
2025-08-02 04:03:02 [WARNING] y_test not found at /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/data/exam_dataset/1/y_test.parquet, returning empty DataFrame
2025-08-02 04:03:02 [INFO] [1/18] bootstrap sample size=9665
2025-08-02 04:03:15 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_1.pkl
2025-08-02 04:03:15 [INFO] [2/18] bootstrap sample size=9665
2025-08-02 04:03:27 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_2.pkl
2025-08-02 04:03:27 [INFO] [3/18] bootstrap sample size=9665
2025-08-02 04:03:39 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_3.pkl
2025-08-02 04:03:39 [INFO] [4/18] bootstrap sample size=9665
2025-08-02 04:03:51 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_4.pkl
2025-08-02 04:03:51 [INFO] [5/18] bootstrap sample size=9665
2025-08-02 04:04:04 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_5.pkl
2025-08-02 04:04:04 [INFO] [6/18] bootstrap sample size=9665
2025-08-02 04:04:16 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_6.pkl
2025-08-02 04:04:16 [INFO] [7/18] bootstrap sample size=9665
2025-08-02 04:04:29 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_7.pkl
2025-08-02 04:04:29 [INFO] [8/18] bootstrap sample size=9665
2025-08-02 04:04:41 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_8.pkl
2025-08-02 04:04:41 [INFO] [9/18] bootstrap sample size=9665
2025-08-02 04:04:53 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_9.pkl
2025-08-02 04:04:53 [INFO] [10/18] bootstrap sample size=9665
2025-08-02 04:05:05 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_10.pkl
2025-08-02 04:05:05 [INFO] [11/18] bootstrap sample size=9665
2025-08-02 04:05:17 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_11.pkl
2025-08-02 04:05:17 [INFO] [12/18] bootstrap sample size=9665
2025-08-02 04:05:29 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_12.pkl
2025-08-02 04:05:29 [INFO] [13/18] bootstrap sample size=9665
2025-08-02 04:05:41 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_13.pkl
2025-08-02 04:05:42 [INFO] [14/18] bootstrap sample size=9665
2025-08-02 04:05:54 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_14.pkl
2025-08-02 04:05:54 [INFO] [15/18] bootstrap sample size=9665
2025-08-02 04:06:06 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_15.pkl
2025-08-02 04:06:06 [INFO] [16/18] bootstrap sample size=9665
2025-08-02 04:06:18 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_16.pkl
2025-08-02 04:06:18 [INFO] [17/18] bootstrap sample size=9665
2025-08-02 04:06:30 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_17.pkl
2025-08-02 04:06:30 [INFO] [18/18] bootstrap sample size=9665
2025-08-02 04:06:42 [INFO] Saved model → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/bootstrap_18.pkl
2025-08-02 04:06:42 [INFO] 📊 Final OOB R² = 0.92629
2025-08-02 04:06:47 [INFO] Saved ensemble → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/ensemble.pkl
2025-08-02 04:06:47 [INFO] Total time: 225.2s
2025-08-02 04:06:47 [INFO] TabPFN →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/exam_dataset/ensemble.pkl (R²=0.9263)
2025-08-02 04:06:47 [INFO] Training tree-based model...
2025-08-02 04:06:47 [INFO] AutoML pipeline started
2025-08-02 04:06:47 [INFO] Output directory '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal' is ready and logging is configured.
2025-08-02 04:06:47 [INFO] Merged training data: 12398 rows
2025-08-02 04:06:47 [INFO] Split data into pool (11158 rows) and validation (1240 rows)
2025-08-02 04:06:48 [INFO] Feature engineering completed: 15 features
[I 2025-08-02 04:06:48,010] A new study created in memory with name: no-name-5b908502-5cd0-42e2-96e9-1b7c9dc7e104
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-02 04:15:10,811] Trial 0 finished with value: -0.9192681976555727 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.9192681976555727.
[I 2025-08-02 04:15:28,257] Trial 1 finished with value: -0.9248285114768328 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 1 with value: -0.9248285114768328.
[I 2025-08-02 04:18:05,439] Trial 2 finished with value: -0.9273848557532703 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 2 with value: -0.9273848557532703.
[I 2025-08-02 04:18:18,283] Trial 3 finished with value: -0.9375502497414795 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:18:48,280] Trial 4 finished with value: -0.9326797560095647 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:19:03,842] Trial 5 finished with value: -0.9369319804573402 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:22:41,760] Trial 6 finished with value: -0.921418961738998 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:22:54,431] Trial 7 finished with value: -0.9343409890451928 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:32:45,448] Trial 8 finished with value: -0.907989861192331 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:32:58,771] Trial 9 finished with value: -0.9239047139689794 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:33:08,782] Trial 10 finished with value: -0.9246820908637526 and parameters: {'learning_rate': 0.24893231508461813, 'depth': 7, 'l2_leaf_reg': 4.318558954489875, 'border_count': 36}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:33:24,400] Trial 11 finished with value: -0.9369454849160178 and parameters: {'learning_rate': 0.1634682281229447, 'depth': 6, 'l2_leaf_reg': 3.2989911288867892, 'border_count': 95}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:33:38,062] Trial 12 finished with value: -0.9347376779487853 and parameters: {'learning_rate': 0.2131295144154623, 'depth': 6, 'l2_leaf_reg': 2.7598418378945464, 'border_count': 63}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:33:57,266] Trial 13 finished with value: -0.9358140185351469 and parameters: {'learning_rate': 0.15105812997121756, 'depth': 7, 'l2_leaf_reg': 2.6405727171834563, 'border_count': 85}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:34:20,403] Trial 14 finished with value: -0.9256764147854911 and parameters: {'learning_rate': 0.13601968314420324, 'depth': 9, 'l2_leaf_reg': 5.383456459024634, 'border_count': 34}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:34:39,513] Trial 15 finished with value: -0.9373321061237677 and parameters: {'learning_rate': 0.1316823595028282, 'depth': 6, 'l2_leaf_reg': 4.022852934698015, 'border_count': 178}. Best is trial 3 with value: -0.9375502497414795.
[I 2025-08-02 04:35:00,073] Trial 16 finished with value: -0.938418379403486 and parameters: {'learning_rate': 0.1085680837914764, 'depth': 6, 'l2_leaf_reg': 4.2373103179548295, 'border_count': 182}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:35:24,658] Trial 17 finished with value: -0.9306891619997077 and parameters: {'learning_rate': 0.28261778375857405, 'depth': 8, 'l2_leaf_reg': 6.079330114147569, 'border_count': 190}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:35:47,730] Trial 18 finished with value: -0.9371579486679049 and parameters: {'learning_rate': 0.09943962462639522, 'depth': 7, 'l2_leaf_reg': 1.8684561477588453, 'border_count': 135}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:36:04,794] Trial 19 finished with value: -0.9343322149674816 and parameters: {'learning_rate': 0.05551943670494743, 'depth': 5, 'l2_leaf_reg': 8.687129358946713, 'border_count': 204}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:36:18,026] Trial 20 finished with value: -0.9378781225023185 and parameters: {'learning_rate': 0.1891602844552718, 'depth': 4, 'l2_leaf_reg': 4.7368595472697, 'border_count': 152}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:36:30,953] Trial 21 finished with value: -0.9362751352607365 and parameters: {'learning_rate': 0.19045655048354346, 'depth': 4, 'l2_leaf_reg': 4.870585477684502, 'border_count': 160}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:36:46,016] Trial 22 finished with value: -0.9374964725693271 and parameters: {'learning_rate': 0.09706723625469812, 'depth': 5, 'l2_leaf_reg': 4.552130737823427, 'border_count': 153}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:36:57,354] Trial 23 finished with value: -0.9344771410383729 and parameters: {'learning_rate': 0.2987409767905252, 'depth': 4, 'l2_leaf_reg': 5.726674906828739, 'border_count': 181}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:37:14,763] Trial 24 finished with value: -0.9366906968620123 and parameters: {'learning_rate': 0.11320014331059625, 'depth': 6, 'l2_leaf_reg': 2.007410550267633, 'border_count': 126}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:37:27,884] Trial 25 finished with value: -0.9371031088955859 and parameters: {'learning_rate': 0.18852344571118598, 'depth': 5, 'l2_leaf_reg': 3.529304028624873, 'border_count': 112}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:37:40,544] Trial 26 finished with value: -0.9274787820920655 and parameters: {'learning_rate': 0.05890970652502962, 'depth': 4, 'l2_leaf_reg': 5.2719468807529175, 'border_count': 55}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:38:02,670] Trial 27 finished with value: -0.9330442380119596 and parameters: {'learning_rate': 0.21042988873652194, 'depth': 7, 'l2_leaf_reg': 3.9886839747645344, 'border_count': 202}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:38:23,207] Trial 28 finished with value: -0.9371439502306508 and parameters: {'learning_rate': 0.1169400056864563, 'depth': 6, 'l2_leaf_reg': 2.4281139993700562, 'border_count': 233}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:38:38,431] Trial 29 finished with value: -0.9382732878332434 and parameters: {'learning_rate': 0.16212942052989116, 'depth': 5, 'l2_leaf_reg': 6.875962023752984, 'border_count': 166}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:39:45,723] Trial 30 finished with value: -0.9322323704605631 and parameters: {'learning_rate': 0.03888719446770967, 'depth': 9, 'l2_leaf_reg': 8.014853820805108, 'border_count': 171}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:40:01,572] Trial 31 finished with value: -0.9370652495784273 and parameters: {'learning_rate': 0.16109210128496648, 'depth': 5, 'l2_leaf_reg': 6.894362458310247, 'border_count': 164}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:40:14,154] Trial 32 finished with value: -0.935604351370467 and parameters: {'learning_rate': 0.23337526098534886, 'depth': 5, 'l2_leaf_reg': 8.059157393704988, 'border_count': 147}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:40:27,648] Trial 33 finished with value: -0.9361481472617531 and parameters: {'learning_rate': 0.16665126620327483, 'depth': 4, 'l2_leaf_reg': 6.069703041543002, 'border_count': 188}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:40:44,658] Trial 34 finished with value: -0.9362881714808823 and parameters: {'learning_rate': 0.08908723910095916, 'depth': 5, 'l2_leaf_reg': 1.2828943270983402, 'border_count': 226}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:41:01,027] Trial 35 finished with value: -0.9380926967629309 and parameters: {'learning_rate': 0.12053969073410714, 'depth': 6, 'l2_leaf_reg': 3.1891528043512585, 'border_count': 121}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:41:32,804] Trial 36 finished with value: -0.9359391482602091 and parameters: {'learning_rate': 0.06664890363495787, 'depth': 8, 'l2_leaf_reg': 4.970533378349469, 'border_count': 116}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:41:50,309] Trial 37 finished with value: -0.9367900709529037 and parameters: {'learning_rate': 0.12171840272734945, 'depth': 6, 'l2_leaf_reg': 3.406469367171943, 'border_count': 138}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:42:20,813] Trial 38 finished with value: -0.9382464890250841 and parameters: {'learning_rate': 0.10266814729179007, 'depth': 7, 'l2_leaf_reg': 6.856252518383914, 'border_count': 255}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:43:09,499] Trial 39 finished with value: -0.9346599479698359 and parameters: {'learning_rate': 0.06805708155290285, 'depth': 8, 'l2_leaf_reg': 7.371094645846609, 'border_count': 253}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:43:39,694] Trial 40 finished with value: -0.9378024375552808 and parameters: {'learning_rate': 0.08255550593688984, 'depth': 7, 'l2_leaf_reg': 6.639402717273303, 'border_count': 239}. Best is trial 16 with value: -0.938418379403486.
[I 2025-08-02 04:43:59,049] Trial 41 finished with value: -0.9385412818667795 and parameters: {'learning_rate': 0.09966484343265844, 'depth': 6, 'l2_leaf_reg': 7.82592987233913, 'border_count': 156}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:44:19,449] Trial 42 finished with value: -0.9376677153952062 and parameters: {'learning_rate': 0.10341879130725463, 'depth': 6, 'l2_leaf_reg': 7.789399790716478, 'border_count': 210}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:44:42,910] Trial 43 finished with value: -0.9346205363417065 and parameters: {'learning_rate': 0.04357485139378124, 'depth': 7, 'l2_leaf_reg': 8.80367531636246, 'border_count': 119}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:44:59,837] Trial 44 finished with value: -0.9371830197375292 and parameters: {'learning_rate': 0.14261645809605666, 'depth': 6, 'l2_leaf_reg': 8.5845331976665, 'border_count': 99}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:45:25,982] Trial 45 finished with value: -0.930450086510848 and parameters: {'learning_rate': 0.02880400661662094, 'depth': 7, 'l2_leaf_reg': 9.25693517020279, 'border_count': 167}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:45:47,015] Trial 46 finished with value: -0.9363214926402486 and parameters: {'learning_rate': 0.07118932583229345, 'depth': 6, 'l2_leaf_reg': 7.139996579963493, 'border_count': 198}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:46:31,209] Trial 47 finished with value: -0.9252038992775589 and parameters: {'learning_rate': 0.015732372759858473, 'depth': 8, 'l2_leaf_reg': 6.615714862725563, 'border_count': 218}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:52:44,995] Trial 48 finished with value: -0.9179759279212172 and parameters: {'learning_rate': 0.08822919482324126, 'depth': 12, 'l2_leaf_reg': 5.835190752638422, 'border_count': 142}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:53:00,308] Trial 49 finished with value: -0.9373566148498633 and parameters: {'learning_rate': 0.11366818609368329, 'depth': 5, 'l2_leaf_reg': 7.631204631254444, 'border_count': 104}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:53:19,967] Trial 50 finished with value: -0.9346072948130791 and parameters: {'learning_rate': 0.13077001417749595, 'depth': 7, 'l2_leaf_reg': 6.298801309072634, 'border_count': 85}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:53:35,011] Trial 51 finished with value: -0.9375667167568482 and parameters: {'learning_rate': 0.1948886799712879, 'depth': 5, 'l2_leaf_reg': 3.083038624923333, 'border_count': 155}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:53:47,134] Trial 52 finished with value: -0.936036608585022 and parameters: {'learning_rate': 0.2516028134611995, 'depth': 4, 'l2_leaf_reg': 3.9971384926660165, 'border_count': 175}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:54:04,227] Trial 53 finished with value: -0.9364158543690234 and parameters: {'learning_rate': 0.14930168355231085, 'depth': 6, 'l2_leaf_reg': 4.712350189221064, 'border_count': 146}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:54:19,900] Trial 54 finished with value: -0.9375014486331621 and parameters: {'learning_rate': 0.10180433331562902, 'depth': 5, 'l2_leaf_reg': 5.243605042928747, 'border_count': 131}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:54:37,400] Trial 55 finished with value: -0.9378585172770549 and parameters: {'learning_rate': 0.17181432025233387, 'depth': 6, 'l2_leaf_reg': 4.305350596738405, 'border_count': 187}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:54:50,569] Trial 56 finished with value: -0.9365190414555936 and parameters: {'learning_rate': 0.13021379138928144, 'depth': 4, 'l2_leaf_reg': 8.230022901814202, 'border_count': 158}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:55:14,466] Trial 57 finished with value: -0.9357889064825091 and parameters: {'learning_rate': 0.05952476712563157, 'depth': 7, 'l2_leaf_reg': 6.994559536402924, 'border_count': 126}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:55:30,509] Trial 58 finished with value: -0.9368527784997454 and parameters: {'learning_rate': 0.07984990519759441, 'depth': 5, 'l2_leaf_reg': 9.984552275494028, 'border_count': 151}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:55:50,717] Trial 59 finished with value: -0.9373430922570495 and parameters: {'learning_rate': 0.050628749400783414, 'depth': 6, 'l2_leaf_reg': 3.0628337072358467, 'border_count': 169}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:56:03,854] Trial 60 finished with value: -0.9358990224018151 and parameters: {'learning_rate': 0.10725958173424704, 'depth': 4, 'l2_leaf_reg': 5.568769271346332, 'border_count': 124}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:58:17,520] Trial 61 finished with value: -0.9209226323822803 and parameters: {'learning_rate': 0.17574326246053193, 'depth': 11, 'l2_leaf_reg': 4.322480937749144, 'border_count': 185}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:58:33,915] Trial 62 finished with value: -0.9371068437410554 and parameters: {'learning_rate': 0.21165021202823933, 'depth': 6, 'l2_leaf_reg': 3.74797421416304, 'border_count': 197}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:59:28,891] Trial 63 finished with value: -0.9297263612916585 and parameters: {'learning_rate': 0.1433341542766398, 'depth': 9, 'l2_leaf_reg': 4.323008774963503, 'border_count': 175}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 04:59:48,197] Trial 64 finished with value: -0.9370092813343276 and parameters: {'learning_rate': 0.18002857398240055, 'depth': 6, 'l2_leaf_reg': 5.062507199740571, 'border_count': 245}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:00:01,425] Trial 65 finished with value: -0.9352452200929302 and parameters: {'learning_rate': 0.25863071830700607, 'depth': 5, 'l2_leaf_reg': 3.7660707367017467, 'border_count': 161}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:00:26,920] Trial 66 finished with value: -0.9371052436165489 and parameters: {'learning_rate': 0.15682692880928073, 'depth': 7, 'l2_leaf_reg': 4.537187583776428, 'border_count': 190}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:00:45,125] Trial 67 finished with value: -0.9383537315463958 and parameters: {'learning_rate': 0.09512914641265853, 'depth': 6, 'l2_leaf_reg': 2.245575955596257, 'border_count': 138}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:01:05,189] Trial 68 finished with value: -0.9365408159576357 and parameters: {'learning_rate': 0.1232442611272404, 'depth': 7, 'l2_leaf_reg': 2.1981033987618743, 'border_count': 138}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:01:22,988] Trial 69 finished with value: -0.9382841393420376 and parameters: {'learning_rate': 0.09254377539938932, 'depth': 6, 'l2_leaf_reg': 1.5649590997654461, 'border_count': 110}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:01:40,116] Trial 70 finished with value: -0.9377100384224992 and parameters: {'learning_rate': 0.0907248745538042, 'depth': 6, 'l2_leaf_reg': 1.6716846328968769, 'border_count': 108}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:01:55,014] Trial 71 finished with value: -0.9378112026001191 and parameters: {'learning_rate': 0.09586673016797378, 'depth': 5, 'l2_leaf_reg': 1.226129212097328, 'border_count': 89}. Best is trial 41 with value: -0.9385412818667795.
[I 2025-08-02 05:02:13,915] Trial 72 finished with value: -0.9391822178977461 and parameters: {'learning_rate': 0.07767097690146949, 'depth': 6, 'l2_leaf_reg': 2.4987957265179297, 'border_count': 136}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:02:32,610] Trial 73 finished with value: -0.9386378916377609 and parameters: {'learning_rate': 0.0752237343653366, 'depth': 6, 'l2_leaf_reg': 2.40294333145309, 'border_count': 132}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:02:55,936] Trial 74 finished with value: -0.9375799054845673 and parameters: {'learning_rate': 0.07623917878394577, 'depth': 7, 'l2_leaf_reg': 1.5539925238626346, 'border_count': 136}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:03:12,995] Trial 75 finished with value: -0.9374170298234836 and parameters: {'learning_rate': 0.06546634076264694, 'depth': 6, 'l2_leaf_reg': 2.289561121640393, 'border_count': 74}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:03:32,337] Trial 76 finished with value: -0.9380967694516882 and parameters: {'learning_rate': 0.062272133050297676, 'depth': 6, 'l2_leaf_reg': 2.6190701059364256, 'border_count': 146}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:03:55,700] Trial 77 finished with value: -0.9382321642997101 and parameters: {'learning_rate': 0.08172081396058223, 'depth': 7, 'l2_leaf_reg': 2.097804961495467, 'border_count': 131}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:04:13,954] Trial 78 finished with value: -0.9378207119074531 and parameters: {'learning_rate': 0.07389793858965714, 'depth': 6, 'l2_leaf_reg': 1.8010837449447066, 'border_count': 110}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:04:38,929] Trial 79 finished with value: -0.9371572103309612 and parameters: {'learning_rate': 0.0515673540234278, 'depth': 7, 'l2_leaf_reg': 2.515215825653515, 'border_count': 143}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:04:53,625] Trial 80 finished with value: -0.9381676655673511 and parameters: {'learning_rate': 0.09130271465819129, 'depth': 5, 'l2_leaf_reg': 2.947497851126898, 'border_count': 115}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:05:23,204] Trial 81 finished with value: -0.935653414419346 and parameters: {'learning_rate': 0.08460232905741538, 'depth': 8, 'l2_leaf_reg': 2.1557830432962097, 'border_count': 131}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:05:45,893] Trial 82 finished with value: -0.9382883252342756 and parameters: {'learning_rate': 0.11005598419410544, 'depth': 7, 'l2_leaf_reg': 1.8734552458633158, 'border_count': 130}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:06:04,751] Trial 83 finished with value: -0.9384132280519677 and parameters: {'learning_rate': 0.10894671446565221, 'depth': 6, 'l2_leaf_reg': 1.1137637513636787, 'border_count': 152}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:06:22,589] Trial 84 finished with value: -0.9381561741976334 and parameters: {'learning_rate': 0.11127166459590321, 'depth': 6, 'l2_leaf_reg': 1.421897565293975, 'border_count': 152}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:06:41,160] Trial 85 finished with value: -0.9366090074097967 and parameters: {'learning_rate': 0.09527034858953576, 'depth': 6, 'l2_leaf_reg': 1.7434186323308667, 'border_count': 139}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:06:57,460] Trial 86 finished with value: -0.9373539631520469 and parameters: {'learning_rate': 0.07073614599652381, 'depth': 5, 'l2_leaf_reg': 1.9344668288197782, 'border_count': 162}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:07:14,159] Trial 87 finished with value: -0.9387525985649124 and parameters: {'learning_rate': 0.10865115787770659, 'depth': 6, 'l2_leaf_reg': 1.0625634255928442, 'border_count': 119}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:07:30,222] Trial 88 finished with value: -0.9381353506072155 and parameters: {'learning_rate': 0.1092596277920276, 'depth': 6, 'l2_leaf_reg': 1.0165634981091256, 'border_count': 119}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:07:48,826] Trial 89 finished with value: -0.9384164143235647 and parameters: {'learning_rate': 0.09875202817310187, 'depth': 6, 'l2_leaf_reg': 1.0774226996908436, 'border_count': 127}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:08:09,069] Trial 90 finished with value: -0.9346712496904456 and parameters: {'learning_rate': 0.12284132758210912, 'depth': 7, 'l2_leaf_reg': 1.3479069528945402, 'border_count': 125}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:08:25,717] Trial 91 finished with value: -0.9387593640545127 and parameters: {'learning_rate': 0.10018580126806922, 'depth': 6, 'l2_leaf_reg': 1.0251970964621808, 'border_count': 105}. Best is trial 72 with value: -0.9391822178977461.
[I 2025-08-02 05:08:43,282] Trial 92 finished with value: -0.9394716224439139 and parameters: {'learning_rate': 0.10044628640189242, 'depth': 6, 'l2_leaf_reg': 1.0093332239216544, 'border_count': 102}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:09:00,356] Trial 93 finished with value: -0.9377571564878814 and parameters: {'learning_rate': 0.100281331783565, 'depth': 6, 'l2_leaf_reg': 1.0245815445775406, 'border_count': 96}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:09:18,351] Trial 94 finished with value: -0.9381926143014083 and parameters: {'learning_rate': 0.08563560103705999, 'depth': 6, 'l2_leaf_reg': 1.2269611368655244, 'border_count': 102}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:09:34,910] Trial 95 finished with value: -0.9375841638090683 and parameters: {'learning_rate': 0.13207495676018519, 'depth': 6, 'l2_leaf_reg': 2.8106603805342627, 'border_count': 105}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:09:52,294] Trial 96 finished with value: -0.937920002400747 and parameters: {'learning_rate': 0.07479101783119586, 'depth': 6, 'l2_leaf_reg': 1.0200494053081308, 'border_count': 92}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:10:09,286] Trial 97 finished with value: -0.9380915577796725 and parameters: {'learning_rate': 0.11767763341205184, 'depth': 6, 'l2_leaf_reg': 1.6183974886013388, 'border_count': 120}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:10:24,472] Trial 98 finished with value: -0.9391761870461184 and parameters: {'learning_rate': 0.07920140023567318, 'depth': 5, 'l2_leaf_reg': 1.4420849316780773, 'border_count': 150}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:10:40,207] Trial 99 finished with value: -0.9370258887635045 and parameters: {'learning_rate': 0.07919860340417538, 'depth': 5, 'l2_leaf_reg': 1.3815090419658218, 'border_count': 149}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:10:55,065] Trial 100 finished with value: -0.9379744309834874 and parameters: {'learning_rate': 0.10487277834426932, 'depth': 5, 'l2_leaf_reg': 1.1734347749243896, 'border_count': 156}. Best is trial 92 with value: -0.9394716224439139.
[I 2025-08-02 05:11:13,863] Trial 101 finished with value: -0.9395739314090116 and parameters: {'learning_rate': 0.09556605999349545, 'depth': 6, 'l2_leaf_reg': 1.4493569813578686, 'border_count': 142}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:11:31,078] Trial 102 finished with value: -0.9382923537910786 and parameters: {'learning_rate': 0.08530310757267469, 'depth': 6, 'l2_leaf_reg': 1.450887065825646, 'border_count': 113}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:11:47,102] Trial 103 finished with value: -0.937737935524672 and parameters: {'learning_rate': 0.06381686531246204, 'depth': 5, 'l2_leaf_reg': 1.1801198545825518, 'border_count': 142}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:12:03,687] Trial 104 finished with value: -0.9381881017499988 and parameters: {'learning_rate': 0.13869752119464465, 'depth': 6, 'l2_leaf_reg': 1.7128211291869695, 'border_count': 126}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:12:22,704] Trial 105 finished with value: -0.9373424676657842 and parameters: {'learning_rate': 0.05556006624108182, 'depth': 6, 'l2_leaf_reg': 1.9907660553302156, 'border_count': 130}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:12:37,399] Trial 106 finished with value: -0.9374817957693171 and parameters: {'learning_rate': 0.09989029111583046, 'depth': 5, 'l2_leaf_reg': 1.478186102493966, 'border_count': 134}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:12:57,016] Trial 107 finished with value: -0.9385385574380231 and parameters: {'learning_rate': 0.0701426109016537, 'depth': 6, 'l2_leaf_reg': 2.4156541831158087, 'border_count': 148}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:13:11,782] Trial 108 finished with value: -0.9366929749537832 and parameters: {'learning_rate': 0.059202090186490336, 'depth': 5, 'l2_leaf_reg': 2.531874576001003, 'border_count': 99}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:13:34,915] Trial 109 finished with value: -0.9375424098353017 and parameters: {'learning_rate': 0.06995416768672016, 'depth': 7, 'l2_leaf_reg': 1.297111700992017, 'border_count': 120}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:13:53,105] Trial 110 finished with value: -0.9393289458918225 and parameters: {'learning_rate': 0.07826603213494392, 'depth': 6, 'l2_leaf_reg': 1.580708660225205, 'border_count': 158}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:14:12,164] Trial 111 finished with value: -0.9381561009324961 and parameters: {'learning_rate': 0.0821458163066234, 'depth': 6, 'l2_leaf_reg': 2.788062300246809, 'border_count': 159}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:14:31,304] Trial 112 finished with value: -0.9388032040373182 and parameters: {'learning_rate': 0.07431614829438807, 'depth': 6, 'l2_leaf_reg': 2.373142423688021, 'border_count': 165}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:14:51,635] Trial 113 finished with value: -0.938313452977727 and parameters: {'learning_rate': 0.07287742322911701, 'depth': 6, 'l2_leaf_reg': 2.3183725485266495, 'border_count': 181}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:15:18,368] Trial 114 finished with value: -0.938509278658623 and parameters: {'learning_rate': 0.06771240863718765, 'depth': 7, 'l2_leaf_reg': 2.4200355210980256, 'border_count': 173}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:15:43,307] Trial 115 finished with value: -0.935986259301196 and parameters: {'learning_rate': 0.04641499816650391, 'depth': 7, 'l2_leaf_reg': 3.3736844745047714, 'border_count': 146}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:16:09,473] Trial 116 finished with value: -0.9377727716833046 and parameters: {'learning_rate': 0.06545081007570201, 'depth': 7, 'l2_leaf_reg': 1.9492518223478212, 'border_count': 168}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:16:29,554] Trial 117 finished with value: -0.9392043942431076 and parameters: {'learning_rate': 0.07840193999366471, 'depth': 6, 'l2_leaf_reg': 2.385149586624652, 'border_count': 171}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:16:49,277] Trial 118 finished with value: -0.9381303066305839 and parameters: {'learning_rate': 0.07746807419228315, 'depth': 6, 'l2_leaf_reg': 1.760802214053606, 'border_count': 165}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:17:04,663] Trial 119 finished with value: -0.938589641030657 and parameters: {'learning_rate': 0.08875145546022674, 'depth': 5, 'l2_leaf_reg': 2.0961222091782017, 'border_count': 156}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:17:18,995] Trial 120 finished with value: -0.9375009427511808 and parameters: {'learning_rate': 0.08890812051482197, 'depth': 5, 'l2_leaf_reg': 2.0209678398702176, 'border_count': 81}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:17:35,056] Trial 121 finished with value: -0.937531624257623 and parameters: {'learning_rate': 0.07655995288716333, 'depth': 5, 'l2_leaf_reg': 2.3876379239620493, 'border_count': 163}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:17:54,547] Trial 122 finished with value: -0.9395342460632488 and parameters: {'learning_rate': 0.08621335070624937, 'depth': 6, 'l2_leaf_reg': 1.562291852344845, 'border_count': 158}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:18:13,699] Trial 123 finished with value: -0.9385834661004041 and parameters: {'learning_rate': 0.08873983301704852, 'depth': 6, 'l2_leaf_reg': 1.567756180141096, 'border_count': 156}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:18:33,077] Trial 124 finished with value: -0.9379118620948579 and parameters: {'learning_rate': 0.08847970840822726, 'depth': 6, 'l2_leaf_reg': 1.543037383377597, 'border_count': 177}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:18:49,177] Trial 125 finished with value: -0.9372476503143942 and parameters: {'learning_rate': 0.09247689066404262, 'depth': 5, 'l2_leaf_reg': 1.6457415139001341, 'border_count': 171}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:19:08,830] Trial 126 finished with value: -0.9394879960943145 and parameters: {'learning_rate': 0.082215479575997, 'depth': 6, 'l2_leaf_reg': 1.8372302204662354, 'border_count': 156}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:19:22,120] Trial 127 finished with value: -0.9362505063377926 and parameters: {'learning_rate': 0.08490982963354224, 'depth': 4, 'l2_leaf_reg': 2.1217022569032196, 'border_count': 142}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:19:37,878] Trial 128 finished with value: -0.9372118777393473 and parameters: {'learning_rate': 0.07981717831696489, 'depth': 5, 'l2_leaf_reg': 1.8320064054499088, 'border_count': 161}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:19:57,561] Trial 129 finished with value: -0.9384716717400875 and parameters: {'learning_rate': 0.059929584252821605, 'depth': 6, 'l2_leaf_reg': 2.646181529220992, 'border_count': 153}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:20:16,407] Trial 130 finished with value: -0.9389832502098195 and parameters: {'learning_rate': 0.0746117601399342, 'depth': 6, 'l2_leaf_reg': 1.3509175139624823, 'border_count': 135}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:20:35,108] Trial 131 finished with value: -0.9385255032899783 and parameters: {'learning_rate': 0.07428956488803484, 'depth': 6, 'l2_leaf_reg': 1.3615637998121335, 'border_count': 141}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:20:53,328] Trial 132 finished with value: -0.9375760201244314 and parameters: {'learning_rate': 0.05542697710291003, 'depth': 6, 'l2_leaf_reg': 1.2810541206365875, 'border_count': 134}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:22:44,948] Trial 133 finished with value: -0.9272021725498395 and parameters: {'learning_rate': 0.08039597276899053, 'depth': 10, 'l2_leaf_reg': 2.13438034161771, 'border_count': 166}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:23:03,189] Trial 134 finished with value: -0.9383436160842447 and parameters: {'learning_rate': 0.09526919675923609, 'depth': 6, 'l2_leaf_reg': 1.903900608515042, 'border_count': 148}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:23:22,859] Trial 135 finished with value: -0.9318230491991673 and parameters: {'learning_rate': 0.020823990418646472, 'depth': 6, 'l2_leaf_reg': 1.4505228383772124, 'border_count': 157}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:23:42,552] Trial 136 finished with value: -0.9388220429001823 and parameters: {'learning_rate': 0.06289353014492755, 'depth': 6, 'l2_leaf_reg': 1.76834541754356, 'border_count': 151}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:24:01,328] Trial 137 finished with value: -0.9381718000848671 and parameters: {'learning_rate': 0.06491649691146871, 'depth': 6, 'l2_leaf_reg': 1.7217868250043948, 'border_count': 134}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:24:19,204] Trial 138 finished with value: -0.9378292607729539 and parameters: {'learning_rate': 0.06850966116048844, 'depth': 6, 'l2_leaf_reg': 1.0075623948365975, 'border_count': 106}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:24:38,415] Trial 139 finished with value: -0.9379047885608288 and parameters: {'learning_rate': 0.07390994009386959, 'depth': 6, 'l2_leaf_reg': 1.2163909781853226, 'border_count': 145}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:24:53,518] Trial 140 finished with value: -0.934829208558679 and parameters: {'learning_rate': 0.08278762910030701, 'depth': 6, 'l2_leaf_reg': 1.4168190349728338, 'border_count': 55}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:25:12,370] Trial 141 finished with value: -0.9389663008249528 and parameters: {'learning_rate': 0.07734361925788148, 'depth': 6, 'l2_leaf_reg': 1.8375809471474982, 'border_count': 155}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:25:32,268] Trial 142 finished with value: -0.9389119468141982 and parameters: {'learning_rate': 0.06269405815091278, 'depth': 6, 'l2_leaf_reg': 1.6477681627984382, 'border_count': 163}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:25:51,953] Trial 143 finished with value: -0.9381752662131018 and parameters: {'learning_rate': 0.061582891035573885, 'depth': 6, 'l2_leaf_reg': 1.6505614579398689, 'border_count': 151}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:26:12,190] Trial 144 finished with value: -0.9386726632836953 and parameters: {'learning_rate': 0.05221139782318708, 'depth': 6, 'l2_leaf_reg': 1.8501781462815325, 'border_count': 170}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:26:31,646] Trial 145 finished with value: -0.9384974994412301 and parameters: {'learning_rate': 0.05711086429482708, 'depth': 6, 'l2_leaf_reg': 1.256948704268874, 'border_count': 159}. Best is trial 101 with value: -0.9395739314090116.
[I 2025-08-02 05:26:51,646] Trial 146 finished with value: -0.9396440352360842 and parameters: {'learning_rate': 0.06865223367879426, 'depth': 6, 'l2_leaf_reg': 1.5094953482937852, 'border_count': 164}. Best is trial 146 with value: -0.9396440352360842.
[I 2025-08-02 05:27:11,770] Trial 147 finished with value: -0.9381468657085545 and parameters: {'learning_rate': 0.06699312907406534, 'depth': 6, 'l2_leaf_reg': 1.5621110432855339, 'border_count': 178}. Best is trial 146 with value: -0.9396440352360842.
[I 2025-08-02 05:27:31,757] Trial 148 finished with value: -0.9215148485301868 and parameters: {'learning_rate': 0.011059815337064169, 'depth': 6, 'l2_leaf_reg': 1.852245219928599, 'border_count': 165}. Best is trial 146 with value: -0.9396440352360842.
[I 2025-08-02 05:27:57,337] Trial 149 finished with value: -0.9377300841048041 and parameters: {'learning_rate': 0.07013077184848979, 'depth': 7, 'l2_leaf_reg': 2.2538382324609714, 'border_count': 162}. Best is trial 146 with value: -0.9396440352360842.
[I 2025-08-02 05:28:17,030] Trial 150 finished with value: -0.9386363809134877 and parameters: {'learning_rate': 0.06198114033603266, 'depth': 6, 'l2_leaf_reg': 1.4057656402007814, 'border_count': 172}. Best is trial 146 with value: -0.9396440352360842.
[I 2025-08-02 05:28:35,777] Trial 151 finished with value: -0.9373132073739753 and parameters: {'learning_rate': 0.07945123820240725, 'depth': 6, 'l2_leaf_reg': 1.1931610103224948, 'border_count': 153}. Best is trial 146 with value: -0.9396440352360842.
[I 2025-08-02 05:28:54,156] Trial 152 finished with value: -0.9397420395974728 and parameters: {'learning_rate': 0.10467879609939032, 'depth': 6, 'l2_leaf_reg': 1.6876771506202624, 'border_count': 150}. Best is trial 152 with value: -0.9397420395974728.
[I 2025-08-02 05:29:11,845] Trial 153 finished with value: -0.9392769974556526 and parameters: {'learning_rate': 0.1024005682984541, 'depth': 6, 'l2_leaf_reg': 2.013094986925124, 'border_count': 150}. Best is trial 152 with value: -0.9397420395974728.
[I 2025-08-02 05:29:31,144] Trial 154 finished with value: -0.9381608223910519 and parameters: {'learning_rate': 0.07303960255235509, 'depth': 6, 'l2_leaf_reg': 1.695976614637045, 'border_count': 149}. Best is trial 152 with value: -0.9397420395974728.
[I 2025-08-02 05:29:50,685] Trial 155 finished with value: -0.9383830255705766 and parameters: {'learning_rate': 0.08261008686598711, 'depth': 6, 'l2_leaf_reg': 2.0180148640330833, 'border_count': 160}. Best is trial 152 with value: -0.9397420395974728.
[I 2025-08-02 05:30:14,701] Trial 156 finished with value: -0.9373830768351118 and parameters: {'learning_rate': 0.0926631557676219, 'depth': 7, 'l2_leaf_reg': 1.8215829219318338, 'border_count': 144}. Best is trial 152 with value: -0.9397420395974728.
[I 2025-08-02 05:30:34,183] Trial 157 finished with value: -0.9383763466285918 and parameters: {'learning_rate': 0.07744378506775049, 'depth': 6, 'l2_leaf_reg': 2.200469710541846, 'border_count': 167}. Best is trial 152 with value: -0.9397420395974728.
[I 2025-08-02 05:30:53,818] Trial 158 finished with value: -0.9402104811575211 and parameters: {'learning_rate': 0.06264197859819605, 'depth': 6, 'l2_leaf_reg': 1.5588985328339513, 'border_count': 154}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:31:13,307] Trial 159 finished with value: -0.9386609195025755 and parameters: {'learning_rate': 0.051026501484468946, 'depth': 6, 'l2_leaf_reg': 1.5589406159279067, 'border_count': 153}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:31:32,442] Trial 160 finished with value: -0.9385045719898398 and parameters: {'learning_rate': 0.06179781073969435, 'depth': 6, 'l2_leaf_reg': 1.974139338043361, 'border_count': 138}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:31:51,542] Trial 161 finished with value: -0.938770154210929 and parameters: {'learning_rate': 0.06701268288175923, 'depth': 6, 'l2_leaf_reg': 1.6907183510818902, 'border_count': 157}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:32:11,002] Trial 162 finished with value: -0.9385163866074926 and parameters: {'learning_rate': 0.07210378322006288, 'depth': 6, 'l2_leaf_reg': 1.4704667949401395, 'border_count': 147}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:32:29,101] Trial 163 finished with value: -0.938050141945713 and parameters: {'learning_rate': 0.10267991276138326, 'depth': 6, 'l2_leaf_reg': 2.000222771141341, 'border_count': 162}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:32:47,633] Trial 164 finished with value: -0.9387914564455572 and parameters: {'learning_rate': 0.08452915510266153, 'depth': 6, 'l2_leaf_reg': 1.8105422103342395, 'border_count': 150}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:33:08,312] Trial 165 finished with value: -0.9376577855408245 and parameters: {'learning_rate': 0.046793590755889077, 'depth': 6, 'l2_leaf_reg': 1.3462795502934777, 'border_count': 182}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:33:31,900] Trial 166 finished with value: -0.9385511172736705 and parameters: {'learning_rate': 0.11564797680453603, 'depth': 7, 'l2_leaf_reg': 1.5811324262941653, 'border_count': 155}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:33:52,081] Trial 167 finished with value: -0.9384747418848054 and parameters: {'learning_rate': 0.06508074761073722, 'depth': 6, 'l2_leaf_reg': 2.249101269889219, 'border_count': 168}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:34:11,424] Trial 168 finished with value: -0.9388389242650924 and parameters: {'learning_rate': 0.07723929140043298, 'depth': 6, 'l2_leaf_reg': 2.5993894170255896, 'border_count': 142}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:34:30,798] Trial 169 finished with value: -0.9386748421075561 and parameters: {'learning_rate': 0.05838706030156718, 'depth': 6, 'l2_leaf_reg': 2.8438751279472037, 'border_count': 140}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:34:49,748] Trial 170 finished with value: -0.9376885263600651 and parameters: {'learning_rate': 0.09365759638954364, 'depth': 6, 'l2_leaf_reg': 1.7466728521339046, 'border_count': 145}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:35:08,744] Trial 171 finished with value: -0.9389322717655058 and parameters: {'learning_rate': 0.07799825441608907, 'depth': 6, 'l2_leaf_reg': 2.5517449406919455, 'border_count': 159}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:35:28,067] Trial 172 finished with value: -0.9392074558465409 and parameters: {'learning_rate': 0.07674440842396403, 'depth': 6, 'l2_leaf_reg': 2.5334893528970026, 'border_count': 151}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:35:47,966] Trial 173 finished with value: -0.9381615281383013 and parameters: {'learning_rate': 0.07941142952327229, 'depth': 6, 'l2_leaf_reg': 2.5081397859748993, 'border_count': 159}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:36:03,011] Trial 174 finished with value: -0.9322357331459449 and parameters: {'learning_rate': 0.08478697956370747, 'depth': 6, 'l2_leaf_reg': 3.015499909137719, 'border_count': 41}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:36:22,607] Trial 175 finished with value: -0.939377354703383 and parameters: {'learning_rate': 0.07663220823362439, 'depth': 6, 'l2_leaf_reg': 2.529886260242051, 'border_count': 156}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:36:47,987] Trial 176 finished with value: -0.9377798475775532 and parameters: {'learning_rate': 0.07162279393829203, 'depth': 7, 'l2_leaf_reg': 2.6821941900549584, 'border_count': 154}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:37:04,126] Trial 177 finished with value: -0.9380498178866683 and parameters: {'learning_rate': 0.08607977459400361, 'depth': 5, 'l2_leaf_reg': 3.1674594933830695, 'border_count': 161}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:37:24,109] Trial 178 finished with value: -0.9379593396461574 and parameters: {'learning_rate': 0.09485100461753027, 'depth': 6, 'l2_leaf_reg': 2.073659302384761, 'border_count': 172}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:37:43,956] Trial 179 finished with value: -0.9386377014868362 and parameters: {'learning_rate': 0.06922334558518715, 'depth': 6, 'l2_leaf_reg': 1.3537313516896101, 'border_count': 156}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:38:03,555] Trial 180 finished with value: -0.9378617969005895 and parameters: {'learning_rate': 0.08799480056681987, 'depth': 6, 'l2_leaf_reg': 2.282409630857771, 'border_count': 164}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:38:22,807] Trial 181 finished with value: -0.938036813727568 and parameters: {'learning_rate': 0.07784142346727985, 'depth': 6, 'l2_leaf_reg': 2.6359079648293045, 'border_count': 148}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:38:42,018] Trial 182 finished with value: -0.9390272185846489 and parameters: {'learning_rate': 0.07659393415511764, 'depth': 6, 'l2_leaf_reg': 2.609622494167527, 'border_count': 143}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:39:37,870] Trial 183 finished with value: -0.932463046672564 and parameters: {'learning_rate': 0.10474829299861575, 'depth': 9, 'l2_leaf_reg': 2.4809491908013825, 'border_count': 150}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:39:55,956] Trial 184 finished with value: -0.9379494373597199 and parameters: {'learning_rate': 0.08184431166770119, 'depth': 6, 'l2_leaf_reg': 1.5079544205254054, 'border_count': 138}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:40:15,361] Trial 185 finished with value: -0.9396688981000846 and parameters: {'learning_rate': 0.07485541917297217, 'depth': 6, 'l2_leaf_reg': 2.0621833893512527, 'border_count': 158}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:40:30,729] Trial 186 finished with value: -0.9380828772174503 and parameters: {'learning_rate': 0.0738084547649998, 'depth': 5, 'l2_leaf_reg': 2.8819207328704564, 'border_count': 154}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:40:49,415] Trial 187 finished with value: -0.9371670823471684 and parameters: {'learning_rate': 0.09033716132139459, 'depth': 6, 'l2_leaf_reg': 2.1308628883632843, 'border_count': 144}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:41:07,883] Trial 188 finished with value: -0.9391361727655365 and parameters: {'learning_rate': 0.09985394143512208, 'depth': 6, 'l2_leaf_reg': 2.7222908189723154, 'border_count': 157}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:41:26,985] Trial 189 finished with value: -0.939253016692071 and parameters: {'learning_rate': 0.0968953071837954, 'depth': 6, 'l2_leaf_reg': 1.9545118836446864, 'border_count': 151}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:41:45,796] Trial 190 finished with value: -0.9391709893719474 and parameters: {'learning_rate': 0.09817783938086216, 'depth': 6, 'l2_leaf_reg': 2.3341865652213802, 'border_count': 150}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:42:03,906] Trial 191 finished with value: -0.9382471967311982 and parameters: {'learning_rate': 0.09756325366738876, 'depth': 6, 'l2_leaf_reg': 2.384284944111192, 'border_count': 148}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:42:23,172] Trial 192 finished with value: -0.9387951629949358 and parameters: {'learning_rate': 0.10705179027078135, 'depth': 6, 'l2_leaf_reg': 2.7493337713664743, 'border_count': 151}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:42:40,850] Trial 193 finished with value: -0.9373443597910761 and parameters: {'learning_rate': 0.1159948754983274, 'depth': 6, 'l2_leaf_reg': 1.972075128804353, 'border_count': 144}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:42:57,803] Trial 194 finished with value: -0.9370647201402895 and parameters: {'learning_rate': 0.12441821525614183, 'depth': 6, 'l2_leaf_reg': 2.281544738110227, 'border_count': 137}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:43:17,249] Trial 195 finished with value: -0.9401498713310066 and parameters: {'learning_rate': 0.09537461886986859, 'depth': 6, 'l2_leaf_reg': 2.1332464462359284, 'border_count': 156}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:43:36,381] Trial 196 finished with value: -0.939009969299562 and parameters: {'learning_rate': 0.0984055447482144, 'depth': 6, 'l2_leaf_reg': 2.1351917271043925, 'border_count': 157}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:43:54,312] Trial 197 finished with value: -0.9376653673081067 and parameters: {'learning_rate': 0.0988824105823868, 'depth': 6, 'l2_leaf_reg': 2.454840399774713, 'border_count': 152}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:44:12,941] Trial 198 finished with value: -0.9381472862796031 and parameters: {'learning_rate': 0.09145253813304043, 'depth': 6, 'l2_leaf_reg': 2.9546279590609004, 'border_count': 159}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:44:28,725] Trial 199 finished with value: -0.9375003258142521 and parameters: {'learning_rate': 0.10960306455102406, 'depth': 5, 'l2_leaf_reg': 1.970718894912627, 'border_count': 167}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:44:50,184] Trial 200 finished with value: -0.9377607234491835 and parameters: {'learning_rate': 0.10128474925628307, 'depth': 7, 'l2_leaf_reg': 2.269186975741395, 'border_count': 150}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:45:09,893] Trial 201 finished with value: -0.9387816613923767 and parameters: {'learning_rate': 0.09495750897299729, 'depth': 6, 'l2_leaf_reg': 2.005094764252937, 'border_count': 158}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:45:29,410] Trial 202 finished with value: -0.9390551276534328 and parameters: {'learning_rate': 0.10319082158566625, 'depth': 6, 'l2_leaf_reg': 2.2220396023626123, 'border_count': 157}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:45:47,477] Trial 203 finished with value: -0.9381372763329898 and parameters: {'learning_rate': 0.10650535399787664, 'depth': 6, 'l2_leaf_reg': 2.640361556126541, 'border_count': 147}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:46:06,128] Trial 204 finished with value: -0.9379291890266396 and parameters: {'learning_rate': 0.11611151901559254, 'depth': 6, 'l2_leaf_reg': 2.1925783210142433, 'border_count': 154}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:46:26,042] Trial 205 finished with value: -0.9380687200995524 and parameters: {'learning_rate': 0.08730384717510364, 'depth': 6, 'l2_leaf_reg': 2.3948131660938343, 'border_count': 163}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:46:45,248] Trial 206 finished with value: -0.9397323862455925 and parameters: {'learning_rate': 0.08417772917057066, 'depth': 6, 'l2_leaf_reg': 1.8753003359509894, 'border_count': 145}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:47:03,993] Trial 207 finished with value: -0.9384076449991304 and parameters: {'learning_rate': 0.08412247508488067, 'depth': 6, 'l2_leaf_reg': 1.88391035586478, 'border_count': 153}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:47:22,767] Trial 208 finished with value: -0.9386718909526721 and parameters: {'learning_rate': 0.10303606075320049, 'depth': 6, 'l2_leaf_reg': 1.7216927769805983, 'border_count': 162}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:49:03,600] Trial 209 finished with value: -0.9276802225630564 and parameters: {'learning_rate': 0.09065658723354522, 'depth': 10, 'l2_leaf_reg': 1.5748018826351657, 'border_count': 175}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:49:22,098] Trial 210 finished with value: -0.9391536911003473 and parameters: {'learning_rate': 0.0956320017950343, 'depth': 6, 'l2_leaf_reg': 2.1061670470420104, 'border_count': 148}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:49:41,266] Trial 211 finished with value: -0.9387061423646103 and parameters: {'learning_rate': 0.09744291726757572, 'depth': 6, 'l2_leaf_reg': 2.149741113054868, 'border_count': 146}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:50:00,077] Trial 212 finished with value: -0.9397638893658293 and parameters: {'learning_rate': 0.09144946196176745, 'depth': 6, 'l2_leaf_reg': 1.892898246442302, 'border_count': 156}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:50:19,635] Trial 213 finished with value: -0.9387247302192011 and parameters: {'learning_rate': 0.08402152863268969, 'depth': 6, 'l2_leaf_reg': 1.9007782218379012, 'border_count': 152}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:50:38,766] Trial 214 finished with value: -0.9394266412857275 and parameters: {'learning_rate': 0.09253813332622045, 'depth': 6, 'l2_leaf_reg': 1.6857105832977723, 'border_count': 148}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:50:56,460] Trial 215 finished with value: -0.937496582978957 and parameters: {'learning_rate': 0.09159757374456035, 'depth': 6, 'l2_leaf_reg': 1.6554492718066638, 'border_count': 141}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:51:15,593] Trial 216 finished with value: -0.9392657597287627 and parameters: {'learning_rate': 0.0862204119158551, 'depth': 6, 'l2_leaf_reg': 1.8247791611513209, 'border_count': 149}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:51:34,459] Trial 217 finished with value: -0.9396108442293797 and parameters: {'learning_rate': 0.08186021446093332, 'depth': 6, 'l2_leaf_reg': 1.4564143424929938, 'border_count': 147}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:56:41,329] Trial 218 finished with value: -0.9111722990031108 and parameters: {'learning_rate': 0.08222654165342895, 'depth': 12, 'l2_leaf_reg': 1.5154927173156023, 'border_count': 145}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:56:59,890] Trial 219 finished with value: -0.9393631973562084 and parameters: {'learning_rate': 0.08649174285240019, 'depth': 6, 'l2_leaf_reg': 1.2741764479570363, 'border_count': 141}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:57:19,090] Trial 220 finished with value: -0.9398754722532847 and parameters: {'learning_rate': 0.08714116701708317, 'depth': 6, 'l2_leaf_reg': 1.1495554883580903, 'border_count': 139}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:57:38,125] Trial 221 finished with value: -0.9387215068802705 and parameters: {'learning_rate': 0.08831747660771874, 'depth': 6, 'l2_leaf_reg': 1.2207293383013105, 'border_count': 140}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:57:57,325] Trial 222 finished with value: -0.9387021465139863 and parameters: {'learning_rate': 0.08606963820152823, 'depth': 6, 'l2_leaf_reg': 1.1492178310601635, 'border_count': 140}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:58:16,316] Trial 223 finished with value: -0.9392582329142324 and parameters: {'learning_rate': 0.08978249332413625, 'depth': 6, 'l2_leaf_reg': 1.328633962276852, 'border_count': 145}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:58:34,948] Trial 224 finished with value: -0.9397650719024718 and parameters: {'learning_rate': 0.09118645481041762, 'depth': 6, 'l2_leaf_reg': 1.3564432803468651, 'border_count': 147}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:58:54,238] Trial 225 finished with value: -0.9387074657633285 and parameters: {'learning_rate': 0.08967791758713362, 'depth': 6, 'l2_leaf_reg': 1.2869707594955058, 'border_count': 144}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:59:12,777] Trial 226 finished with value: -0.9392774147339152 and parameters: {'learning_rate': 0.09162526640843906, 'depth': 6, 'l2_leaf_reg': 1.005161318693493, 'border_count': 147}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:59:30,643] Trial 227 finished with value: -0.9380044868835945 and parameters: {'learning_rate': 0.09244551760324567, 'depth': 6, 'l2_leaf_reg': 1.0014063178634258, 'border_count': 147}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 05:59:49,179] Trial 228 finished with value: -0.9386542667385976 and parameters: {'learning_rate': 0.08564472571984358, 'depth': 6, 'l2_leaf_reg': 1.2085849484350224, 'border_count': 142}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:00:07,459] Trial 229 finished with value: -0.9385164183113133 and parameters: {'learning_rate': 0.09217252674358464, 'depth': 6, 'l2_leaf_reg': 1.3746198976912507, 'border_count': 155}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:00:26,017] Trial 230 finished with value: -0.9387197989543312 and parameters: {'learning_rate': 0.08474066982101175, 'depth': 6, 'l2_leaf_reg': 1.5146634524876286, 'border_count': 137}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:00:44,933] Trial 231 finished with value: -0.9387372810479754 and parameters: {'learning_rate': 0.09141393088047632, 'depth': 6, 'l2_leaf_reg': 1.1277188121962165, 'border_count': 150}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:01:04,552] Trial 232 finished with value: -0.9390069541403129 and parameters: {'learning_rate': 0.08084946603409433, 'depth': 6, 'l2_leaf_reg': 1.3967365245023355, 'border_count': 146}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:01:23,693] Trial 233 finished with value: -0.9387825414683972 and parameters: {'learning_rate': 0.10976902578768746, 'depth': 6, 'l2_leaf_reg': 1.675037435355394, 'border_count': 152}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:01:43,022] Trial 234 finished with value: -0.9384814936715583 and parameters: {'learning_rate': 0.08343648148449291, 'depth': 6, 'l2_leaf_reg': 1.2279092161177776, 'border_count': 153}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:02:00,472] Trial 235 finished with value: -0.9388909105361154 and parameters: {'learning_rate': 0.09407331468985862, 'depth': 6, 'l2_leaf_reg': 1.481271260789748, 'border_count': 148}. Best is trial 158 with value: -0.9402104811575211.
[I 2025-08-02 06:02:19,631] Trial 236 finished with value: -0.9412786767017213 and parameters: {'learning_rate': 0.1025246337934536, 'depth': 6, 'l2_leaf_reg': 1.773971571026084, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:02:39,257] Trial 237 finished with value: -0.939649638157805 and parameters: {'learning_rate': 0.10341484338391237, 'depth': 6, 'l2_leaf_reg': 1.6536246892336317, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:02:57,891] Trial 238 finished with value: -0.9382049929550226 and parameters: {'learning_rate': 0.10506509761912035, 'depth': 6, 'l2_leaf_reg': 1.6633156007492016, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:03:17,494] Trial 239 finished with value: -0.9391027317352985 and parameters: {'learning_rate': 0.10393203102072793, 'depth': 6, 'l2_leaf_reg': 1.787347193993675, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:03:37,127] Trial 240 finished with value: -0.9389469497986009 and parameters: {'learning_rate': 0.0870826406368553, 'depth': 6, 'l2_leaf_reg': 1.360592138670192, 'border_count': 165}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:03:55,639] Trial 241 finished with value: -0.9387160006795315 and parameters: {'learning_rate': 0.11216543481973039, 'depth': 6, 'l2_leaf_reg': 1.8175294079768198, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:04:13,896] Trial 242 finished with value: -0.9392922568105836 and parameters: {'learning_rate': 0.09877580283359887, 'depth': 6, 'l2_leaf_reg': 1.5651637448557973, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:04:32,989] Trial 243 finished with value: -0.9385873230888393 and parameters: {'learning_rate': 0.09758473943793433, 'depth': 6, 'l2_leaf_reg': 1.5441929010854367, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:04:49,514] Trial 244 finished with value: -0.9374414566872715 and parameters: {'learning_rate': 0.10092876391859194, 'depth': 6, 'l2_leaf_reg': 1.029508648274144, 'border_count': 64}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:05:08,430] Trial 245 finished with value: -0.9396055463452253 and parameters: {'learning_rate': 0.08959320552726438, 'depth': 6, 'l2_leaf_reg': 1.3941205245433907, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:05:26,907] Trial 246 finished with value: -0.9393670511807815 and parameters: {'learning_rate': 0.11280441398954254, 'depth': 6, 'l2_leaf_reg': 1.5604741368386474, 'border_count': 157}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:05:45,328] Trial 247 finished with value: -0.9376193800550183 and parameters: {'learning_rate': 0.11787660739046482, 'depth': 6, 'l2_leaf_reg': 1.5707950125984187, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:06:03,903] Trial 248 finished with value: -0.9382567743210537 and parameters: {'learning_rate': 0.10913674897213145, 'depth': 6, 'l2_leaf_reg': 1.2044006733313328, 'border_count': 163}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:06:23,753] Trial 249 finished with value: -0.9386937004970919 and parameters: {'learning_rate': 0.10026746792280425, 'depth': 6, 'l2_leaf_reg': 1.4438509530871957, 'border_count': 167}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:06:41,699] Trial 250 finished with value: -0.9377787102826965 and parameters: {'learning_rate': 0.11376122655680204, 'depth': 6, 'l2_leaf_reg': 1.6165882917833467, 'border_count': 158}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:06:59,228] Trial 251 finished with value: -0.9382113111962564 and parameters: {'learning_rate': 0.12653796197677392, 'depth': 6, 'l2_leaf_reg': 1.3373259290133477, 'border_count': 162}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:07:18,344] Trial 252 finished with value: -0.9391562034366726 and parameters: {'learning_rate': 0.10511406849103974, 'depth': 6, 'l2_leaf_reg': 1.678025177086577, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:07:37,303] Trial 253 finished with value: -0.9398281287875264 and parameters: {'learning_rate': 0.09575445601217199, 'depth': 6, 'l2_leaf_reg': 1.1870676446058521, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:07:57,241] Trial 254 finished with value: -0.9391589446834916 and parameters: {'learning_rate': 0.0820891392513839, 'depth': 6, 'l2_leaf_reg': 1.1238059849229385, 'border_count': 168}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:08:17,074] Trial 255 finished with value: -0.9386389244233849 and parameters: {'learning_rate': 0.09570490691718157, 'depth': 6, 'l2_leaf_reg': 1.435511257582529, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:11:12,844] Trial 256 finished with value: -0.9194774541530332 and parameters: {'learning_rate': 0.09290079278328006, 'depth': 11, 'l2_leaf_reg': 1.209809852671246, 'border_count': 164}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:11:32,449] Trial 257 finished with value: -0.9390155633115326 and parameters: {'learning_rate': 0.07092140387620126, 'depth': 6, 'l2_leaf_reg': 1.355669628421853, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:11:52,105] Trial 258 finished with value: -0.9392213387467602 and parameters: {'learning_rate': 0.08951382370040485, 'depth': 6, 'l2_leaf_reg': 1.6134559863610178, 'border_count': 158}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:12:10,712] Trial 259 finished with value: -0.9391780354829512 and parameters: {'learning_rate': 0.09587852549945065, 'depth': 6, 'l2_leaf_reg': 1.0251512927482367, 'border_count': 153}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:12:29,831] Trial 260 finished with value: -0.9386921812604265 and parameters: {'learning_rate': 0.08235419161823311, 'depth': 6, 'l2_leaf_reg': 1.520184203307227, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:12:47,678] Trial 261 finished with value: -0.9384323881357093 and parameters: {'learning_rate': 0.12037756555811388, 'depth': 6, 'l2_leaf_reg': 1.2382801583787555, 'border_count': 162}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:13:06,682] Trial 262 finished with value: -0.937802599337753 and parameters: {'learning_rate': 0.0800204122625871, 'depth': 6, 'l2_leaf_reg': 1.808133617019609, 'border_count': 153}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:13:24,837] Trial 263 finished with value: -0.9384208701406023 and parameters: {'learning_rate': 0.1083785719637819, 'depth': 6, 'l2_leaf_reg': 1.481676581284904, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:13:44,341] Trial 264 finished with value: -0.939235115931628 and parameters: {'learning_rate': 0.08908828598071196, 'depth': 6, 'l2_leaf_reg': 1.0006148954705063, 'border_count': 166}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:14:03,425] Trial 265 finished with value: -0.937343135591095 and parameters: {'learning_rate': 0.0733210106250208, 'depth': 6, 'l2_leaf_reg': 1.7440178849332018, 'border_count': 144}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:14:21,269] Trial 266 finished with value: -0.9387687743519157 and parameters: {'learning_rate': 0.09789295938374604, 'depth': 6, 'l2_leaf_reg': 1.3120805005592553, 'border_count': 161}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:14:40,561] Trial 267 finished with value: -0.9389051471479756 and parameters: {'learning_rate': 0.0872620967648909, 'depth': 6, 'l2_leaf_reg': 1.6662651193821716, 'border_count': 170}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:14:59,065] Trial 268 finished with value: -0.9402222265689036 and parameters: {'learning_rate': 0.10318286129129182, 'depth': 6, 'l2_leaf_reg': 1.186238503274638, 'border_count': 148}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:15:17,753] Trial 269 finished with value: -0.9383940693109623 and parameters: {'learning_rate': 0.10931689809625858, 'depth': 6, 'l2_leaf_reg': 1.470415678999579, 'border_count': 154}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:15:36,721] Trial 270 finished with value: -0.938145139054731 and parameters: {'learning_rate': 0.10131942306202028, 'depth': 6, 'l2_leaf_reg': 1.8302399123031834, 'border_count': 139}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:15:55,767] Trial 271 finished with value: -0.9385294212876657 and parameters: {'learning_rate': 0.11200091845337022, 'depth': 6, 'l2_leaf_reg': 1.2572398300158907, 'border_count': 150}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:16:15,348] Trial 272 finished with value: -0.9391261715699308 and parameters: {'learning_rate': 0.06722086945699504, 'depth': 6, 'l2_leaf_reg': 1.5591716812821927, 'border_count': 158}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:16:32,283] Trial 273 finished with value: -0.9376418052637825 and parameters: {'learning_rate': 0.07999772685001955, 'depth': 6, 'l2_leaf_reg': 1.390749737083354, 'border_count': 82}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:16:57,168] Trial 274 finished with value: -0.9378552675158907 and parameters: {'learning_rate': 0.10485440848289299, 'depth': 7, 'l2_leaf_reg': 1.7134478704917995, 'border_count': 166}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:17:16,465] Trial 275 finished with value: -0.9338835115278837 and parameters: {'learning_rate': 0.026044073740709682, 'depth': 6, 'l2_leaf_reg': 1.9190385939732528, 'border_count': 142}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:17:34,579] Trial 276 finished with value: -0.9387510135200602 and parameters: {'learning_rate': 0.09496344829686192, 'depth': 6, 'l2_leaf_reg': 1.2724612517876406, 'border_count': 150}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:17:53,452] Trial 277 finished with value: -0.9380256476377399 and parameters: {'learning_rate': 0.07439193791415581, 'depth': 6, 'l2_leaf_reg': 1.60461460809662, 'border_count': 131}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:18:10,825] Trial 278 finished with value: -0.9390018980081969 and parameters: {'learning_rate': 0.13325108436194436, 'depth': 6, 'l2_leaf_reg': 1.1963106264570789, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:18:35,847] Trial 279 finished with value: -0.9373461253360484 and parameters: {'learning_rate': 0.12200654540363405, 'depth': 7, 'l2_leaf_reg': 1.4492214029585928, 'border_count': 163}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:18:54,690] Trial 280 finished with value: -0.9396922378076444 and parameters: {'learning_rate': 0.08576637691309713, 'depth': 6, 'l2_leaf_reg': 1.8746697586681267, 'border_count': 146}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:19:13,459] Trial 281 finished with value: -0.9385213507838882 and parameters: {'learning_rate': 0.08461416936230814, 'depth': 6, 'l2_leaf_reg': 1.9216759666498928, 'border_count': 146}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:19:32,166] Trial 282 finished with value: -0.937955967604365 and parameters: {'learning_rate': 0.07922433532638562, 'depth': 6, 'l2_leaf_reg': 1.7292192013024812, 'border_count': 135}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:19:51,233] Trial 283 finished with value: -0.9394624426885153 and parameters: {'learning_rate': 0.06992113109616649, 'depth': 6, 'l2_leaf_reg': 1.9847475022305654, 'border_count': 141}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:20:10,459] Trial 284 finished with value: -0.9382634988128593 and parameters: {'learning_rate': 0.06993219361522882, 'depth': 6, 'l2_leaf_reg': 2.0002256044313906, 'border_count': 140}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:20:29,279] Trial 285 finished with value: -0.9386474808396609 and parameters: {'learning_rate': 0.08921851859997824, 'depth': 6, 'l2_leaf_reg': 1.8467853514370152, 'border_count': 135}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:20:48,759] Trial 286 finished with value: -0.9384641007772898 and parameters: {'learning_rate': 0.09378705547570457, 'depth': 6, 'l2_leaf_reg': 2.0648815460104863, 'border_count': 143}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:21:07,779] Trial 287 finished with value: -0.9397559244511281 and parameters: {'learning_rate': 0.08359811197264919, 'depth': 6, 'l2_leaf_reg': 1.8118077505751917, 'border_count': 148}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:21:27,188] Trial 288 finished with value: -0.938609420392791 and parameters: {'learning_rate': 0.06790911522306264, 'depth': 6, 'l2_leaf_reg': 1.9506943805498902, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:21:46,300] Trial 289 finished with value: -0.9386138321343164 and parameters: {'learning_rate': 0.07529754570113723, 'depth': 6, 'l2_leaf_reg': 1.7785669294844995, 'border_count': 151}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:22:01,981] Trial 290 finished with value: -0.935907377391228 and parameters: {'learning_rate': 0.08227494647726821, 'depth': 5, 'l2_leaf_reg': 9.112339815365909, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:22:20,997] Trial 291 finished with value: -0.9392388548641653 and parameters: {'learning_rate': 0.10411409863934463, 'depth': 6, 'l2_leaf_reg': 1.7635372170559693, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:22:39,837] Trial 292 finished with value: -0.9378683584264141 and parameters: {'learning_rate': 0.07176686383116435, 'depth': 6, 'l2_leaf_reg': 5.993681454874119, 'border_count': 145}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:22:58,294] Trial 293 finished with value: -0.9394456434926994 and parameters: {'learning_rate': 0.09320137519561952, 'depth': 6, 'l2_leaf_reg': 2.0164411616660263, 'border_count': 149}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:23:17,021] Trial 294 finished with value: -0.9378666103995325 and parameters: {'learning_rate': 0.09077552088338857, 'depth': 6, 'l2_leaf_reg': 2.08372098086539, 'border_count': 139}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:23:41,749] Trial 295 finished with value: -0.937092016457799 and parameters: {'learning_rate': 0.08342329809899447, 'depth': 7, 'l2_leaf_reg': 2.0075652381974596, 'border_count': 149}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:24:00,941] Trial 296 finished with value: -0.9389536591643135 and parameters: {'learning_rate': 0.0756988820582827, 'depth': 6, 'l2_leaf_reg': 1.8492325403722818, 'border_count': 145}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:24:19,876] Trial 297 finished with value: -0.9393383011419926 and parameters: {'learning_rate': 0.09746994246828372, 'depth': 6, 'l2_leaf_reg': 2.1423426691894307, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:24:39,095] Trial 298 finished with value: -0.9257841992151359 and parameters: {'learning_rate': 0.013558017143562104, 'depth': 6, 'l2_leaf_reg': 1.6868493791702182, 'border_count': 142}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:24:57,286] Trial 299 finished with value: -0.9386810391039221 and parameters: {'learning_rate': 0.08664306599260402, 'depth': 6, 'l2_leaf_reg': 1.96455817395978, 'border_count': 128}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:25:16,175] Trial 300 finished with value: -0.938691719427975 and parameters: {'learning_rate': 0.09305992256224672, 'depth': 6, 'l2_leaf_reg': 1.4204331615455712, 'border_count': 148}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:25:35,605] Trial 301 finished with value: -0.9400531357408908 and parameters: {'learning_rate': 0.06556323432856252, 'depth': 6, 'l2_leaf_reg': 1.8349564967731384, 'border_count': 154}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:25:53,295] Trial 302 finished with value: -0.939210382792442 and parameters: {'learning_rate': 0.061005458270866515, 'depth': 6, 'l2_leaf_reg': 1.7040053669634403, 'border_count': 90}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:26:09,084] Trial 303 finished with value: -0.9371381846891983 and parameters: {'learning_rate': 0.06413761192435757, 'depth': 5, 'l2_leaf_reg': 1.8301922178157555, 'border_count': 136}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:26:28,756] Trial 304 finished with value: -0.9400114638742818 and parameters: {'learning_rate': 0.054770268130909974, 'depth': 6, 'l2_leaf_reg': 1.1614826836258558, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:27:30,350] Trial 305 finished with value: -0.9331427841617673 and parameters: {'learning_rate': 0.04944465291244805, 'depth': 9, 'l2_leaf_reg': 1.124633572153275, 'border_count': 153}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:28:07,302] Trial 306 finished with value: -0.9357487765733374 and parameters: {'learning_rate': 0.05752410662690241, 'depth': 8, 'l2_leaf_reg': 1.1842813368884144, 'border_count': 163}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:28:26,746] Trial 307 finished with value: -0.9380867634426099 and parameters: {'learning_rate': 0.06900403507930461, 'depth': 6, 'l2_leaf_reg': 1.3892030058234868, 'border_count': 153}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:28:46,647] Trial 308 finished with value: -0.9402296610084583 and parameters: {'learning_rate': 0.06473591988931529, 'depth': 6, 'l2_leaf_reg': 1.084866130135833, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:29:06,342] Trial 309 finished with value: -0.93855253492873 and parameters: {'learning_rate': 0.054903122368578305, 'depth': 6, 'l2_leaf_reg': 1.110174112756043, 'border_count': 158}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:29:26,333] Trial 310 finished with value: -0.9384854916616198 and parameters: {'learning_rate': 0.05389174135480566, 'depth': 6, 'l2_leaf_reg': 1.0353395716234004, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:29:46,131] Trial 311 finished with value: -0.9391684302686603 and parameters: {'learning_rate': 0.06086334019525111, 'depth': 6, 'l2_leaf_reg': 1.2991601521986367, 'border_count': 172}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:30:06,327] Trial 312 finished with value: -0.9366884652148252 and parameters: {'learning_rate': 0.04244391306871108, 'depth': 6, 'l2_leaf_reg': 1.1604186958487641, 'border_count': 169}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:30:26,182] Trial 313 finished with value: -0.9390446444247333 and parameters: {'learning_rate': 0.06446711966975219, 'depth': 6, 'l2_leaf_reg': 1.4629677605942448, 'border_count': 163}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:30:45,899] Trial 314 finished with value: -0.9394236885689324 and parameters: {'learning_rate': 0.05798529413922446, 'depth': 6, 'l2_leaf_reg': 1.0107291323263812, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:31:02,754] Trial 315 finished with value: -0.9384604869363736 and parameters: {'learning_rate': 0.06473868321834336, 'depth': 6, 'l2_leaf_reg': 1.33259727651205, 'border_count': 76}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:31:28,522] Trial 316 finished with value: -0.9384578271499736 and parameters: {'learning_rate': 0.07009469678826538, 'depth': 7, 'l2_leaf_reg': 1.5666348247708106, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:31:48,044] Trial 317 finished with value: -0.9389775001963359 and parameters: {'learning_rate': 0.05732805573751512, 'depth': 6, 'l2_leaf_reg': 1.1708649984759507, 'border_count': 143}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:32:04,093] Trial 318 finished with value: -0.9325296164613222 and parameters: {'learning_rate': 0.06426721458180722, 'depth': 6, 'l2_leaf_reg': 1.3860369532263874, 'border_count': 43}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:32:23,002] Trial 319 finished with value: -0.9400286802761116 and parameters: {'learning_rate': 0.07103193507941115, 'depth': 6, 'l2_leaf_reg': 1.538916926281395, 'border_count': 151}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:32:47,270] Trial 320 finished with value: -0.9373432051696445 and parameters: {'learning_rate': 0.07996773213408954, 'depth': 7, 'l2_leaf_reg': 1.4993245611351103, 'border_count': 153}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:33:08,068] Trial 321 finished with value: -0.9398849907852475 and parameters: {'learning_rate': 0.1020985211085654, 'depth': 6, 'l2_leaf_reg': 1.3330487861718232, 'border_count': 207}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:33:27,302] Trial 322 finished with value: -0.9394379129391403 and parameters: {'learning_rate': 0.07359911149737584, 'depth': 6, 'l2_leaf_reg': 1.578178154936456, 'border_count': 148}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:33:43,052] Trial 323 finished with value: -0.9367020380835658 and parameters: {'learning_rate': 0.060596454292231566, 'depth': 5, 'l2_leaf_reg': 1.3049485429484817, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:34:04,100] Trial 324 finished with value: -0.9377624444741886 and parameters: {'learning_rate': 0.053641664125196685, 'depth': 6, 'l2_leaf_reg': 1.4936311585473203, 'border_count': 194}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:34:26,448] Trial 325 finished with value: -0.9390738937025671 and parameters: {'learning_rate': 0.10358917169353293, 'depth': 6, 'l2_leaf_reg': 1.666633777494711, 'border_count': 247}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:34:48,402] Trial 326 finished with value: -0.9383877692298473 and parameters: {'learning_rate': 0.08006567859604667, 'depth': 6, 'l2_leaf_reg': 1.326842979361246, 'border_count': 226}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:35:10,267] Trial 327 finished with value: -0.9385269664239437 and parameters: {'learning_rate': 0.08607021675859343, 'depth': 6, 'l2_leaf_reg': 1.6134399588348716, 'border_count': 234}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:35:29,513] Trial 328 finished with value: -0.9388974995181246 and parameters: {'learning_rate': 0.065924621415285, 'depth': 6, 'l2_leaf_reg': 1.2014077179190068, 'border_count': 157}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:35:45,446] Trial 329 finished with value: -0.9347420988018489 and parameters: {'learning_rate': 0.033667908235053175, 'depth': 5, 'l2_leaf_reg': 1.4729620214153445, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:36:04,999] Trial 330 finished with value: -0.9385575717172834 and parameters: {'learning_rate': 0.07436919339059171, 'depth': 6, 'l2_leaf_reg': 1.765222283516163, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:36:23,431] Trial 331 finished with value: -0.9397089264989418 and parameters: {'learning_rate': 0.10194518832744097, 'depth': 6, 'l2_leaf_reg': 1.3397639144739562, 'border_count': 151}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:36:42,398] Trial 332 finished with value: -0.9371748308673794 and parameters: {'learning_rate': 0.11229654318532643, 'depth': 6, 'l2_leaf_reg': 7.27204420850906, 'border_count': 144}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:37:00,670] Trial 333 finished with value: -0.9396182594317785 and parameters: {'learning_rate': 0.10046936986038417, 'depth': 6, 'l2_leaf_reg': 1.2442082447627671, 'border_count': 151}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:37:18,185] Trial 334 finished with value: -0.9390098977996847 and parameters: {'learning_rate': 0.10536225229523855, 'depth': 6, 'l2_leaf_reg': 1.1948580780831097, 'border_count': 137}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:37:38,164] Trial 335 finished with value: -0.9400236843037398 and parameters: {'learning_rate': 0.11817207938996674, 'depth': 6, 'l2_leaf_reg': 1.322155833095084, 'border_count': 213}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:37:58,465] Trial 336 finished with value: -0.9386353424057208 and parameters: {'learning_rate': 0.12608984433002873, 'depth': 6, 'l2_leaf_reg': 1.173361535545554, 'border_count': 214}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:38:18,416] Trial 337 finished with value: -0.9370614724644494 and parameters: {'learning_rate': 0.12028373935653913, 'depth': 6, 'l2_leaf_reg': 1.3395478734934407, 'border_count': 201}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:38:38,947] Trial 338 finished with value: -0.937050996531443 and parameters: {'learning_rate': 0.1139950771890361, 'depth': 6, 'l2_leaf_reg': 5.390043155764673, 'border_count': 206}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:39:00,226] Trial 339 finished with value: -0.93929029381905 and parameters: {'learning_rate': 0.10610212813471274, 'depth': 6, 'l2_leaf_reg': 1.0346491863992373, 'border_count': 241}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:39:16,632] Trial 340 finished with value: -0.9378044336800833 and parameters: {'learning_rate': 0.10043707742640778, 'depth': 5, 'l2_leaf_reg': 1.3767422083988148, 'border_count': 210}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:39:35,587] Trial 341 finished with value: -0.93897984726198 and parameters: {'learning_rate': 0.1360805047174401, 'depth': 6, 'l2_leaf_reg': 1.275825455216241, 'border_count': 207}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:40:03,241] Trial 342 finished with value: -0.9387489104077524 and parameters: {'learning_rate': 0.11309409643161014, 'depth': 7, 'l2_leaf_reg': 1.1670029370319832, 'border_count': 220}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:40:20,841] Trial 343 finished with value: -0.9385818643867322 and parameters: {'learning_rate': 0.11844100493902546, 'depth': 6, 'l2_leaf_reg': 1.4214211966838088, 'border_count': 150}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:40:39,953] Trial 344 finished with value: -0.9392246785362588 and parameters: {'learning_rate': 0.10096676696960541, 'depth': 6, 'l2_leaf_reg': 1.5735254216770573, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:41:00,341] Trial 345 finished with value: -0.9392148081224153 and parameters: {'learning_rate': 0.11005254107163044, 'depth': 6, 'l2_leaf_reg': 3.892272915746333, 'border_count': 214}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:41:19,406] Trial 346 finished with value: -0.9391801931755293 and parameters: {'learning_rate': 0.09999653904541973, 'depth': 6, 'l2_leaf_reg': 1.0164287450820022, 'border_count': 149}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:41:47,065] Trial 347 finished with value: -0.9371242291828766 and parameters: {'learning_rate': 0.049098045450435134, 'depth': 7, 'l2_leaf_reg': 1.2809659158341464, 'border_count': 192}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:42:08,320] Trial 348 finished with value: -0.9372946647433157 and parameters: {'learning_rate': 0.10469830035383576, 'depth': 6, 'l2_leaf_reg': 1.466360026849626, 'border_count': 222}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:42:25,346] Trial 349 finished with value: -0.9385283286532252 and parameters: {'learning_rate': 0.09585591973661717, 'depth': 6, 'l2_leaf_reg': 1.7247167642358758, 'border_count': 144}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:42:45,103] Trial 350 finished with value: -0.9396289716420714 and parameters: {'learning_rate': 0.0673103767315803, 'depth': 6, 'l2_leaf_reg': 1.1991827319094248, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:43:06,627] Trial 351 finished with value: -0.9376821747560868 and parameters: {'learning_rate': 0.06772711082410406, 'depth': 6, 'l2_leaf_reg': 1.2089640360162737, 'border_count': 218}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:43:27,883] Trial 352 finished with value: -0.9377477675839675 and parameters: {'learning_rate': 0.05957752040515933, 'depth': 6, 'l2_leaf_reg': 3.539310748545241, 'border_count': 199}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:43:47,115] Trial 353 finished with value: -0.9380344162711258 and parameters: {'learning_rate': 0.06096167618201755, 'depth': 6, 'l2_leaf_reg': 1.0122902480567078, 'border_count': 153}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:44:05,992] Trial 354 finished with value: -0.9382966937991045 and parameters: {'learning_rate': 0.06639938965631167, 'depth': 6, 'l2_leaf_reg': 1.257245747594134, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:44:25,588] Trial 355 finished with value: -0.9396029291056944 and parameters: {'learning_rate': 0.07069072088252161, 'depth': 6, 'l2_leaf_reg': 1.5736226430800455, 'border_count': 154}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:44:46,133] Trial 356 finished with value: -0.9387401366948205 and parameters: {'learning_rate': 0.06405581042270382, 'depth': 6, 'l2_leaf_reg': 1.1555548885320253, 'border_count': 185}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:45:02,523] Trial 357 finished with value: -0.9371463836643114 and parameters: {'learning_rate': 0.05667754779395124, 'depth': 5, 'l2_leaf_reg': 1.424806882039398, 'border_count': 165}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:45:21,674] Trial 358 finished with value: -0.9383072122457429 and parameters: {'learning_rate': 0.11750731019975365, 'depth': 6, 'l2_leaf_reg': 1.821973110489357, 'border_count': 210}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:45:42,276] Trial 359 finished with value: -0.9374062006439025 and parameters: {'learning_rate': 0.1280465936238816, 'depth': 6, 'l2_leaf_reg': 1.0017461310754194, 'border_count': 225}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:46:01,582] Trial 360 finished with value: -0.9381875098768322 and parameters: {'learning_rate': 0.07268943591931848, 'depth': 6, 'l2_leaf_reg': 4.710781837170298, 'border_count': 139}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:46:19,766] Trial 361 finished with value: -0.9394593268584354 and parameters: {'learning_rate': 0.10751485011439371, 'depth': 6, 'l2_leaf_reg': 1.6481982129722201, 'border_count': 149}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:46:38,224] Trial 362 finished with value: -0.9391729914378958 and parameters: {'learning_rate': 0.07734122816480037, 'depth': 6, 'l2_leaf_reg': 1.3705043851178649, 'border_count': 132}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:46:57,369] Trial 363 finished with value: -0.9375634009059982 and parameters: {'learning_rate': 0.09710381439679323, 'depth': 6, 'l2_leaf_reg': 1.867415316593657, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:47:11,083] Trial 364 finished with value: -0.9329913989038242 and parameters: {'learning_rate': 0.05251492404250702, 'depth': 4, 'l2_leaf_reg': 6.6121538639008275, 'border_count': 154}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:47:36,035] Trial 365 finished with value: -0.9355181805349648 and parameters: {'learning_rate': 0.06362700985458514, 'depth': 7, 'l2_leaf_reg': 8.336600276814812, 'border_count': 144}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:47:55,158] Trial 366 finished with value: -0.9393872706119935 and parameters: {'learning_rate': 0.06689020144878664, 'depth': 6, 'l2_leaf_reg': 1.5790471586081707, 'border_count': 150}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:48:16,121] Trial 367 finished with value: -0.9382895864091079 and parameters: {'learning_rate': 0.09134273088495144, 'depth': 6, 'l2_leaf_reg': 1.259558286171101, 'border_count': 233}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:48:36,001] Trial 368 finished with value: -0.9369365859279875 and parameters: {'learning_rate': 0.10061481744709112, 'depth': 6, 'l2_leaf_reg': 9.937178010942414, 'border_count': 161}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:48:55,809] Trial 369 finished with value: -0.9400491205041329 and parameters: {'learning_rate': 0.07217254645574953, 'depth': 6, 'l2_leaf_reg': 1.7197704315293567, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:49:15,740] Trial 370 finished with value: -0.9375306301674071 and parameters: {'learning_rate': 0.07317450388777572, 'depth': 6, 'l2_leaf_reg': 2.085348244141623, 'border_count': 166}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:49:34,997] Trial 371 finished with value: -0.9386279241283854 and parameters: {'learning_rate': 0.06880450701197201, 'depth': 6, 'l2_leaf_reg': 1.8048705825896973, 'border_count': 157}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:49:54,729] Trial 372 finished with value: -0.9395964246548361 and parameters: {'learning_rate': 0.06229442458326712, 'depth': 6, 'l2_leaf_reg': 1.6808821587141245, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:50:13,906] Trial 373 finished with value: -0.9380515174678267 and parameters: {'learning_rate': 0.11027704352030518, 'depth': 6, 'l2_leaf_reg': 1.9167988888610128, 'border_count': 163}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:50:50,447] Trial 374 finished with value: -0.9363809907675669 and parameters: {'learning_rate': 0.05768318407666329, 'depth': 8, 'l2_leaf_reg': 2.18597789392371, 'border_count': 158}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:51:10,055] Trial 375 finished with value: -0.9318362406570383 and parameters: {'learning_rate': 0.020313497379792437, 'depth': 6, 'l2_leaf_reg': 1.4866609509306798, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:51:26,064] Trial 376 finished with value: -0.9372285711385941 and parameters: {'learning_rate': 0.06959358624894395, 'depth': 5, 'l2_leaf_reg': 1.152982925489388, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:51:47,855] Trial 377 finished with value: -0.9385981653449054 and parameters: {'learning_rate': 0.07666593580096262, 'depth': 6, 'l2_leaf_reg': 1.6868817864143828, 'border_count': 216}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:52:06,289] Trial 378 finished with value: -0.9396914854346367 and parameters: {'learning_rate': 0.11743117497680947, 'depth': 6, 'l2_leaf_reg': 1.314525415548768, 'border_count': 151}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:52:23,101] Trial 379 finished with value: -0.9357911488466318 and parameters: {'learning_rate': 0.1295961640233708, 'depth': 6, 'l2_leaf_reg': 1.9203327316938095, 'border_count': 144}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:52:40,792] Trial 380 finished with value: -0.9371766286475324 and parameters: {'learning_rate': 0.13902466789288315, 'depth': 6, 'l2_leaf_reg': 1.4925041748331926, 'border_count': 169}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:52:57,903] Trial 381 finished with value: -0.93864777686686 and parameters: {'learning_rate': 0.12576068333467566, 'depth': 6, 'l2_leaf_reg': 1.705748036250294, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:53:12,047] Trial 382 finished with value: -0.9371120484312037 and parameters: {'learning_rate': 0.14915274156886907, 'depth': 5, 'l2_leaf_reg': 1.3812141771031385, 'border_count': 162}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:53:31,312] Trial 383 finished with value: -0.9390013429993425 and parameters: {'learning_rate': 0.11467170818625268, 'depth': 6, 'l2_leaf_reg': 1.5826938905259051, 'border_count': 176}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:53:53,202] Trial 384 finished with value: -0.9374153881930537 and parameters: {'learning_rate': 0.11844393659707471, 'depth': 7, 'l2_leaf_reg': 1.8580003424619116, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:54:06,061] Trial 385 finished with value: -0.9320632873532699 and parameters: {'learning_rate': 0.2847970047874826, 'depth': 6, 'l2_leaf_reg': 1.121340644148554, 'border_count': 140}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:54:25,382] Trial 386 finished with value: -0.9385933177684657 and parameters: {'learning_rate': 0.060981673795961366, 'depth': 6, 'l2_leaf_reg': 4.115599527123337, 'border_count': 151}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:54:44,118] Trial 387 finished with value: -0.9385027968705841 and parameters: {'learning_rate': 0.10732000285700577, 'depth': 6, 'l2_leaf_reg': 5.7175955118098605, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:55:03,731] Trial 388 finished with value: -0.9388117276116897 and parameters: {'learning_rate': 0.06555988488304584, 'depth': 6, 'l2_leaf_reg': 2.1342793400809286, 'border_count': 164}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:55:22,912] Trial 389 finished with value: -0.9386753410891148 and parameters: {'learning_rate': 0.07157706477760581, 'depth': 6, 'l2_leaf_reg': 1.2950352766842133, 'border_count': 146}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:59:40,047] Trial 390 finished with value: -0.9223522254184099 and parameters: {'learning_rate': 0.08611046659831885, 'depth': 11, 'l2_leaf_reg': 1.4644438880718975, 'border_count': 251}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 06:59:59,954] Trial 391 finished with value: -0.9367613480047117 and parameters: {'learning_rate': 0.12085454318246638, 'depth': 6, 'l2_leaf_reg': 1.0004082547652382, 'border_count': 204}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:00:24,604] Trial 392 finished with value: -0.938084268912493 and parameters: {'learning_rate': 0.0775369267916027, 'depth': 7, 'l2_leaf_reg': 1.6804208117323642, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:00:43,313] Trial 393 finished with value: -0.938965827846643 and parameters: {'learning_rate': 0.09521168680541538, 'depth': 6, 'l2_leaf_reg': 2.0116100216826815, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:01:01,527] Trial 394 finished with value: -0.9379608987296315 and parameters: {'learning_rate': 0.10929803391334436, 'depth': 6, 'l2_leaf_reg': 1.3062978155310276, 'border_count': 149}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:01:19,764] Trial 395 finished with value: -0.938596880305942 and parameters: {'learning_rate': 0.0823585625167435, 'depth': 6, 'l2_leaf_reg': 1.802323497101214, 'border_count': 142}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:01:35,582] Trial 396 finished with value: -0.9363184070568973 and parameters: {'learning_rate': 0.07321386542515887, 'depth': 5, 'l2_leaf_reg': 1.594534390506518, 'border_count': 136}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:01:54,885] Trial 397 finished with value: -0.937098517699226 and parameters: {'learning_rate': 0.08925037449385866, 'depth': 6, 'l2_leaf_reg': 7.6104605815751025, 'border_count': 157}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:02:15,157] Trial 398 finished with value: -0.9386886289652142 and parameters: {'learning_rate': 0.06781180541532808, 'depth': 6, 'l2_leaf_reg': 1.1846485430493352, 'border_count': 168}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:02:34,625] Trial 399 finished with value: -0.939024645163759 and parameters: {'learning_rate': 0.10380200214351751, 'depth': 6, 'l2_leaf_reg': 1.3982447170787524, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:02:53,582] Trial 400 finished with value: -0.9387480264608735 and parameters: {'learning_rate': 0.09470891958439831, 'depth': 6, 'l2_leaf_reg': 1.8668918589654697, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:03:13,602] Trial 401 finished with value: -0.9380189044051003 and parameters: {'learning_rate': 0.05447579646121765, 'depth': 6, 'l2_leaf_reg': 2.240769848675021, 'border_count': 162}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:03:33,297] Trial 402 finished with value: -0.9382080121898143 and parameters: {'learning_rate': 0.060964568373521044, 'depth': 6, 'l2_leaf_reg': 1.573649633071165, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:03:52,557] Trial 403 finished with value: -0.9396177444908802 and parameters: {'learning_rate': 0.08079188476585845, 'depth': 6, 'l2_leaf_reg': 1.1468361982754458, 'border_count': 143}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:04:40,037] Trial 404 finished with value: -0.9298560391504903 and parameters: {'learning_rate': 0.11535384826566551, 'depth': 9, 'l2_leaf_reg': 1.337291142701267, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:04:58,991] Trial 405 finished with value: -0.9389834893906667 and parameters: {'learning_rate': 0.08618461820075957, 'depth': 6, 'l2_leaf_reg': 1.720928035203236, 'border_count': 149}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:05:17,725] Trial 406 finished with value: -0.9389197380564727 and parameters: {'learning_rate': 0.09720045176159633, 'depth': 6, 'l2_leaf_reg': 2.020980789068189, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:12:44,300] Trial 407 finished with value: -0.9124718519381916 and parameters: {'learning_rate': 0.04531218630884642, 'depth': 12, 'l2_leaf_reg': 1.0063283551684656, 'border_count': 165}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:13:09,163] Trial 408 finished with value: -0.9366958826868926 and parameters: {'learning_rate': 0.07659004220513968, 'depth': 7, 'l2_leaf_reg': 1.4416525345027558, 'border_count': 139}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:13:30,341] Trial 409 finished with value: -0.9379276418407146 and parameters: {'learning_rate': 0.10511778929936821, 'depth': 6, 'l2_leaf_reg': 1.2727806077405095, 'border_count': 210}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:13:49,602] Trial 410 finished with value: -0.9381273424583512 and parameters: {'learning_rate': 0.065492379003387, 'depth': 6, 'l2_leaf_reg': 1.5651316205520607, 'border_count': 146}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:14:09,589] Trial 411 finished with value: -0.9386875957771575 and parameters: {'learning_rate': 0.05698497447080447, 'depth': 6, 'l2_leaf_reg': 1.7256404456312726, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:14:25,317] Trial 412 finished with value: -0.9379163216823613 and parameters: {'learning_rate': 0.09041652761246607, 'depth': 5, 'l2_leaf_reg': 1.9879050634472684, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:14:43,917] Trial 413 finished with value: -0.938500453067094 and parameters: {'learning_rate': 0.12370131321492368, 'depth': 6, 'l2_leaf_reg': 5.078769044472672, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:15:03,881] Trial 414 finished with value: -0.9378644759066899 and parameters: {'learning_rate': 0.07235870489074941, 'depth': 6, 'l2_leaf_reg': 1.4474176682238211, 'border_count': 172}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:15:22,884] Trial 415 finished with value: -0.9392212622040357 and parameters: {'learning_rate': 0.10094397007465916, 'depth': 6, 'l2_leaf_reg': 1.1848560145250295, 'border_count': 150}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:17:04,184] Trial 416 finished with value: -0.9275543870281394 and parameters: {'learning_rate': 0.08196035009928496, 'depth': 10, 'l2_leaf_reg': 1.8527032061958584, 'border_count': 143}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:17:24,093] Trial 417 finished with value: -0.9380756177368816 and parameters: {'learning_rate': 0.050760879243172984, 'depth': 6, 'l2_leaf_reg': 1.3386767629151102, 'border_count': 162}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:17:41,851] Trial 418 finished with value: -0.938456769514043 and parameters: {'learning_rate': 0.11168727003156115, 'depth': 6, 'l2_leaf_reg': 1.5651232603602119, 'border_count': 132}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:18:01,452] Trial 419 finished with value: -0.939042824671125 and parameters: {'learning_rate': 0.069124961945407, 'depth': 6, 'l2_leaf_reg': 2.2793263529559296, 'border_count': 154}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:18:24,262] Trial 420 finished with value: -0.9376131738912996 and parameters: {'learning_rate': 0.09015865694473632, 'depth': 7, 'l2_leaf_reg': 1.0052913683225242, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:18:43,812] Trial 421 finished with value: -0.9391826995817956 and parameters: {'learning_rate': 0.06293049969530222, 'depth': 6, 'l2_leaf_reg': 1.7161434762945378, 'border_count': 158}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:19:02,940] Trial 422 finished with value: -0.9388120520845636 and parameters: {'learning_rate': 0.09471378504382542, 'depth': 6, 'l2_leaf_reg': 1.2084240061848504, 'border_count': 167}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:19:22,213] Trial 423 finished with value: -0.9376622151496068 and parameters: {'learning_rate': 0.07478284543636785, 'depth': 6, 'l2_leaf_reg': 2.0962958688830824, 'border_count': 138}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:19:40,189] Trial 424 finished with value: -0.9383559107556029 and parameters: {'learning_rate': 0.10496523404338466, 'depth': 6, 'l2_leaf_reg': 1.4784878864117832, 'border_count': 152}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:19:59,313] Trial 425 finished with value: -0.9387089853411819 and parameters: {'learning_rate': 0.08591062010025775, 'depth': 6, 'l2_leaf_reg': 1.856414802627628, 'border_count': 147}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:20:19,194] Trial 426 finished with value: -0.9395062220925678 and parameters: {'learning_rate': 0.07910998911011864, 'depth': 6, 'l2_leaf_reg': 1.3525357750059255, 'border_count': 157}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:20:34,453] Trial 427 finished with value: -0.9380321490393485 and parameters: {'learning_rate': 0.11878037889776705, 'depth': 5, 'l2_leaf_reg': 6.192260396185834, 'border_count': 142}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:20:53,715] Trial 428 finished with value: -0.9394913187685291 and parameters: {'learning_rate': 0.06707717659786784, 'depth': 6, 'l2_leaf_reg': 1.6302283711229915, 'border_count': 150}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:21:13,223] Trial 429 finished with value: -0.9391650890889492 and parameters: {'learning_rate': 0.09854159081340293, 'depth': 6, 'l2_leaf_reg': 1.13187447798028, 'border_count': 162}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:21:31,451] Trial 430 finished with value: -0.938988059189177 and parameters: {'learning_rate': 0.13186824608778505, 'depth': 6, 'l2_leaf_reg': 1.4972015684928217, 'border_count': 155}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:21:48,837] Trial 431 finished with value: -0.9385242120535415 and parameters: {'learning_rate': 0.10943470627457104, 'depth': 6, 'l2_leaf_reg': 1.9024605281210396, 'border_count': 145}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:22:07,212] Trial 432 finished with value: -0.9396043210569204 and parameters: {'learning_rate': 0.08706356594854837, 'depth': 6, 'l2_leaf_reg': 1.2876422050958496, 'border_count': 165}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:22:26,459] Trial 433 finished with value: -0.9389671161231881 and parameters: {'learning_rate': 0.059287786448313305, 'depth': 6, 'l2_leaf_reg': 1.6837391647114495, 'border_count': 151}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:22:50,924] Trial 434 finished with value: -0.9391861770540019 and parameters: {'learning_rate': 0.09629799286396942, 'depth': 7, 'l2_leaf_reg': 2.1849311421603863, 'border_count': 159}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:23:09,686] Trial 435 finished with value: -0.9383079392084599 and parameters: {'learning_rate': 0.07061120412517095, 'depth': 6, 'l2_leaf_reg': 1.1534368067114533, 'border_count': 136}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:23:29,180] Trial 436 finished with value: -0.9392744262527295 and parameters: {'learning_rate': 0.07795120309474132, 'depth': 6, 'l2_leaf_reg': 1.4320829163358058, 'border_count': 153}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:23:48,371] Trial 437 finished with value: -0.9387696180429139 and parameters: {'learning_rate': 0.06318290600772242, 'depth': 6, 'l2_leaf_reg': 1.7911627239345562, 'border_count': 141}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:24:05,673] Trial 438 finished with value: -0.9371339487480443 and parameters: {'learning_rate': 0.10244012173354607, 'depth': 6, 'l2_leaf_reg': 1.5881954938893739, 'border_count': 125}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:24:20,979] Trial 439 finished with value: -0.9376196395791843 and parameters: {'learning_rate': 0.08374843655282227, 'depth': 5, 'l2_leaf_reg': 1.001478223419972, 'border_count': 146}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:24:40,791] Trial 440 finished with value: -0.939460286094686 and parameters: {'learning_rate': 0.09364365046056318, 'depth': 6, 'l2_leaf_reg': 1.3287532314045294, 'border_count': 160}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:25:00,191] Trial 441 finished with value: -0.9389906579786355 and parameters: {'learning_rate': 0.1078680196880366, 'depth': 6, 'l2_leaf_reg': 2.0139300785055867, 'border_count': 179}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:25:19,815] Trial 442 finished with value: -0.9391518477835433 and parameters: {'learning_rate': 0.05404849773522731, 'depth': 6, 'l2_leaf_reg': 1.5473134552131749, 'border_count': 150}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:25:39,646] Trial 443 finished with value: -0.9385636510453229 and parameters: {'learning_rate': 0.07383102308468359, 'depth': 6, 'l2_leaf_reg': 1.2337447424423815, 'border_count': 156}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:26:01,506] Trial 444 finished with value: -0.9389002054611304 and parameters: {'learning_rate': 0.08965060791435453, 'depth': 6, 'l2_leaf_reg': 1.747669234829392, 'border_count': 223}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:26:21,737] Trial 445 finished with value: -0.9384846851199504 and parameters: {'learning_rate': 0.06526016451754958, 'depth': 6, 'l2_leaf_reg': 1.9050000778461003, 'border_count': 169}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:26:40,276] Trial 446 finished with value: -0.9379564808076654 and parameters: {'learning_rate': 0.11848288139017908, 'depth': 6, 'l2_leaf_reg': 1.4201529669652375, 'border_count': 164}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:26:56,077] Trial 447 finished with value: -0.937961703127903 and parameters: {'learning_rate': 0.08102908206444334, 'depth': 5, 'l2_leaf_reg': 1.1861977170742932, 'border_count': 154}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:27:14,187] Trial 448 finished with value: -0.9390633722038939 and parameters: {'learning_rate': 0.10236498733546613, 'depth': 6, 'l2_leaf_reg': 1.6289767562179014, 'border_count': 149}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:27:36,439] Trial 449 finished with value: -0.9377263417341267 and parameters: {'learning_rate': 0.058729206766610254, 'depth': 6, 'l2_leaf_reg': 1.3635702733893373, 'border_count': 229}. Best is trial 236 with value: -0.9412786767017213.
[I 2025-08-02 07:27:37,769] A new study created in memory with name: no-name-4bf5b223-2d20-457c-bc4f-b0ec6ce908ff
[I 2025-08-02 07:27:50,551] Trial 0 finished with value: -0.9296489422415345 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:27:54,237] Trial 1 finished with value: -0.9192499746440662 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:28:05,309] Trial 2 finished with value: -0.9295953871349146 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:28:11,244] Trial 3 finished with value: -0.9260232770070455 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:28:27,982] Trial 4 finished with value: -0.9185732217319685 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:28:31,468] Trial 5 finished with value: -0.8979919569394438 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:28:43,133] Trial 6 finished with value: -0.9262905149296325 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:28:46,772] Trial 7 finished with value: -0.9021307709766746 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:28:50,996] Trial 8 finished with value: -0.9174576483649517 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:29:06,388] Trial 9 finished with value: -0.9167334161621988 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 0 with value: -0.9296489422415345.
[I 2025-08-02 07:29:10,154] Trial 10 finished with value: -0.9333108588669554 and parameters: {'learning_rate': 0.1461184609693756, 'num_leaves': 9, 'max_depth': 11, 'min_child_samples': 11, 'feature_fraction': 0.5076838686640521, 'bagging_fraction': 0.7190404637309149, 'reg_alpha': 1.3686680646913219e-08, 'reg_lambda': 6.0990065353308305}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:29:13,671] Trial 11 finished with value: -0.9323497596144095 and parameters: {'learning_rate': 0.17061837680423544, 'num_leaves': 9, 'max_depth': 11, 'min_child_samples': 11, 'feature_fraction': 0.5123526693065024, 'bagging_fraction': 0.7171781358782056, 'reg_alpha': 1.4232159661562427e-08, 'reg_lambda': 5.19864215740603}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:29:16,799] Trial 12 finished with value: -0.9305170751645307 and parameters: {'learning_rate': 0.18413559883361694, 'num_leaves': 9, 'max_depth': 10, 'min_child_samples': 10, 'feature_fraction': 0.5225230855336822, 'bagging_fraction': 0.7351309251739944, 'reg_alpha': 2.0458168147483614e-08, 'reg_lambda': 0.055485863009831396}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:29:20,428] Trial 13 finished with value: -0.9291335986108306 and parameters: {'learning_rate': 0.19416552625841807, 'num_leaves': 16, 'max_depth': 9, 'min_child_samples': 11, 'feature_fraction': 0.5937663157166836, 'bagging_fraction': 0.7184628468385728, 'reg_alpha': 9.86874546485378, 'reg_lambda': 0.026273305371297274}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:29:29,709] Trial 14 finished with value: -0.9300932236811763 and parameters: {'learning_rate': 0.10632746242224578, 'num_leaves': 68, 'max_depth': 11, 'min_child_samples': 26, 'feature_fraction': 0.5065701578589041, 'bagging_fraction': 0.8130884565089302, 'reg_alpha': 2.3502902430317068e-07, 'reg_lambda': 9.207736961357908}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:29:37,575] Trial 15 finished with value: -0.9305399431579624 and parameters: {'learning_rate': 0.10468345169209065, 'num_leaves': 80, 'max_depth': 7, 'min_child_samples': 25, 'feature_fraction': 0.7261631564388041, 'bagging_fraction': 0.6924745509172271, 'reg_alpha': 6.561131700458375e-05, 'reg_lambda': 0.011357974415609666}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:29:47,769] Trial 16 finished with value: -0.9293463136021513 and parameters: {'learning_rate': 0.10696355595474458, 'num_leaves': 100, 'max_depth': 13, 'min_child_samples': 21, 'feature_fraction': 0.5707921208261755, 'bagging_fraction': 0.8100308334813918, 'reg_alpha': 1.103217333805366e-08, 'reg_lambda': 0.2818936773599525}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:29:55,326] Trial 17 finished with value: -0.9321681477356224 and parameters: {'learning_rate': 0.07657581103832431, 'num_leaves': 32, 'max_depth': 7, 'min_child_samples': 44, 'feature_fraction': 0.6553447098489982, 'bagging_fraction': 0.6707750474677461, 'reg_alpha': 3.7174233531789037e-07, 'reg_lambda': 0.002493260173300581}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:01,749] Trial 18 finished with value: -0.9296631836163839 and parameters: {'learning_rate': 0.14584365323126963, 'num_leaves': 38, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.7733205230569608, 'bagging_fraction': 0.8794818816915129, 'reg_alpha': 6.075545401373081e-07, 'reg_lambda': 9.69811869743224}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:09,062] Trial 19 finished with value: -0.9284562933240957 and parameters: {'learning_rate': 0.13940127601485913, 'num_leaves': 101, 'max_depth': 10, 'min_child_samples': 30, 'feature_fraction': 0.5049516018861933, 'bagging_fraction': 0.7507285077111834, 'reg_alpha': 9.91997817811405e-08, 'reg_lambda': 0.18915362097264535}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:13,083] Trial 20 finished with value: -0.9289815250500574 and parameters: {'learning_rate': 0.06827853812991018, 'num_leaves': 8, 'max_depth': 14, 'min_child_samples': 47, 'feature_fraction': 0.6092798302198211, 'bagging_fraction': 0.7737053867811918, 'reg_alpha': 0.00010396761370918967, 'reg_lambda': 1.5622348472380745}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:20,338] Trial 21 finished with value: -0.9306571991479969 and parameters: {'learning_rate': 0.08234375007768877, 'num_leaves': 34, 'max_depth': 7, 'min_child_samples': 45, 'feature_fraction': 0.6642431482973057, 'bagging_fraction': 0.663476297802019, 'reg_alpha': 7.263526411707138e-07, 'reg_lambda': 0.0017047827275227234}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:25,685] Trial 22 finished with value: -0.9286390168946034 and parameters: {'learning_rate': 0.13810695545699023, 'num_leaves': 32, 'max_depth': 6, 'min_child_samples': 17, 'feature_fraction': 0.5515685574879525, 'bagging_fraction': 0.6719619733911685, 'reg_alpha': 6.918619980122821e-08, 'reg_lambda': 1.3317066373504764e-08}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:33,096] Trial 23 finished with value: -0.9292734064803017 and parameters: {'learning_rate': 0.08611953811044991, 'num_leaves': 40, 'max_depth': 9, 'min_child_samples': 66, 'feature_fraction': 0.713422276360528, 'bagging_fraction': 0.6282221555974891, 'reg_alpha': 1.0155443877159402e-07, 'reg_lambda': 0.0060139232659868}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:39,637] Trial 24 finished with value: -0.9276480161865385 and parameters: {'learning_rate': 0.1502089207538033, 'num_leaves': 88, 'max_depth': 11, 'min_child_samples': 32, 'feature_fraction': 0.6251025611328982, 'bagging_fraction': 0.6834169718623797, 'reg_alpha': 2.397985700339648e-06, 'reg_lambda': 0.09015118712751347}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:45,898] Trial 25 finished with value: -0.9324749283730415 and parameters: {'learning_rate': 0.07889506653661935, 'num_leaves': 23, 'max_depth': 8, 'min_child_samples': 49, 'feature_fraction': 0.5662348501366643, 'bagging_fraction': 0.7779795372994887, 'reg_alpha': 1.606457901282244e-08, 'reg_lambda': 1.885598894628672}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:53,537] Trial 26 finished with value: -0.9306290383019967 and parameters: {'learning_rate': 0.11974037695176143, 'num_leaves': 55, 'max_depth': 10, 'min_child_samples': 55, 'feature_fraction': 0.5633313176279902, 'bagging_fraction': 0.8726160779551502, 'reg_alpha': 1.3569320422559495e-08, 'reg_lambda': 2.0912929933195845}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:30:58,108] Trial 27 finished with value: -0.9305480384308631 and parameters: {'learning_rate': 0.17923841769606658, 'num_leaves': 20, 'max_depth': 9, 'min_child_samples': 18, 'feature_fraction': 0.5001980968325078, 'bagging_fraction': 0.8571032942159467, 'reg_alpha': 1.9839923440674837e-06, 'reg_lambda': 8.774052901447902}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:31:10,058] Trial 28 finished with value: -0.9291743843087118 and parameters: {'learning_rate': 0.09086578665927474, 'num_leaves': 115, 'max_depth': 11, 'min_child_samples': 11, 'feature_fraction': 0.5452863102587361, 'bagging_fraction': 0.7771431587433939, 'reg_alpha': 1.053171303044327e-08, 'reg_lambda': 0.6499624054252254}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:31:20,769] Trial 29 finished with value: -0.9300454403183481 and parameters: {'learning_rate': 0.04336916626266124, 'num_leaves': 68, 'max_depth': 12, 'min_child_samples': 63, 'feature_fraction': 0.5848998037048261, 'bagging_fraction': 0.910799742594645, 'reg_alpha': 5.8385313652180363e-08, 'reg_lambda': 0.5885761266835914}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:31:31,730] Trial 30 finished with value: -0.9313927337476642 and parameters: {'learning_rate': 0.05311286445389737, 'num_leaves': 159, 'max_depth': 8, 'min_child_samples': 27, 'feature_fraction': 0.849546226415591, 'bagging_fraction': 0.7109837975668049, 'reg_alpha': 4.6471906398086107e-08, 'reg_lambda': 3.118648918080539}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:31:38,710] Trial 31 finished with value: -0.9311944282186259 and parameters: {'learning_rate': 0.07788540751343033, 'num_leaves': 25, 'max_depth': 7, 'min_child_samples': 45, 'feature_fraction': 0.665659688610648, 'bagging_fraction': 0.7739919359371534, 'reg_alpha': 2.0058942552472675e-07, 'reg_lambda': 0.0028310960808078903}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:31:46,634] Trial 32 finished with value: -0.9313914091796157 and parameters: {'learning_rate': 0.06967890649270342, 'num_leaves': 49, 'max_depth': 8, 'min_child_samples': 53, 'feature_fraction': 0.591709019546871, 'bagging_fraction': 0.6107919941624335, 'reg_alpha': 3.432248430496115e-08, 'reg_lambda': 0.20219686166307155}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:31:52,831] Trial 33 finished with value: -0.9311413783778008 and parameters: {'learning_rate': 0.03350620453241364, 'num_leaves': 19, 'max_depth': 6, 'min_child_samples': 38, 'feature_fraction': 0.5399075735061328, 'bagging_fraction': 0.6545408632692329, 'reg_alpha': 3.3816935289760113e-07, 'reg_lambda': 0.6990995044804889}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:31:59,214] Trial 34 finished with value: -0.9308442483458088 and parameters: {'learning_rate': 0.05975660131373902, 'num_leaves': 32, 'max_depth': 6, 'min_child_samples': 65, 'feature_fraction': 0.6340718683619792, 'bagging_fraction': 0.7477528131142287, 'reg_alpha': 8.528605170509435e-07, 'reg_lambda': 9.110272512812378e-06}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:05,963] Trial 35 finished with value: -0.9266630116387101 and parameters: {'learning_rate': 0.16308733916834112, 'num_leaves': 71, 'max_depth': 12, 'min_child_samples': 50, 'feature_fraction': 0.5729309221891542, 'bagging_fraction': 0.5909831373194376, 'reg_alpha': 2.8924504618759768e-08, 'reg_lambda': 9.395516318534388e-05}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:13,434] Trial 36 finished with value: -0.9294032129387174 and parameters: {'learning_rate': 0.09603957668562564, 'num_leaves': 46, 'max_depth': 8, 'min_child_samples': 35, 'feature_fraction': 0.6842900064402708, 'bagging_fraction': 0.6972468151400346, 'reg_alpha': 1.333405411396594e-05, 'reg_lambda': 0.027710704613742528}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:18,125] Trial 37 finished with value: -0.9304369298737571 and parameters: {'learning_rate': 0.11927712326601288, 'num_leaves': 255, 'max_depth': 5, 'min_child_samples': 60, 'feature_fraction': 0.5285725924044746, 'bagging_fraction': 0.8017267130410887, 'reg_alpha': 2.1900667591541745e-07, 'reg_lambda': 3.399714940817894}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:22,150] Trial 38 finished with value: -0.9316754828633775 and parameters: {'learning_rate': 0.11791904259576616, 'num_leaves': 9, 'max_depth': 10, 'min_child_samples': 42, 'feature_fraction': 0.6092709337190011, 'bagging_fraction': 0.5013339806386407, 'reg_alpha': 0.0010438560409938528, 'reg_lambda': 0.0012616393080595186}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:30,113] Trial 39 finished with value: -0.9238509610173263 and parameters: {'learning_rate': 0.02695393258989714, 'num_leaves': 25, 'max_depth': 8, 'min_child_samples': 73, 'feature_fraction': 0.9899226356996809, 'bagging_fraction': 0.5715921050932261, 'reg_alpha': 1.3315926275093543e-06, 'reg_lambda': 4.3553404595663186e-06}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:40,815] Trial 40 finished with value: -0.927187247706921 and parameters: {'learning_rate': 0.06980526747211349, 'num_leaves': 181, 'max_depth': 13, 'min_child_samples': 96, 'feature_fraction': 0.7522840397955358, 'bagging_fraction': 0.7341443659315855, 'reg_alpha': 5.119245142855714e-06, 'reg_lambda': 0.00014218375931406368}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:44,452] Trial 41 finished with value: -0.9323872556104909 and parameters: {'learning_rate': 0.12846776628968218, 'num_leaves': 8, 'max_depth': 10, 'min_child_samples': 39, 'feature_fraction': 0.6085989410162765, 'bagging_fraction': 0.5503916288348017, 'reg_alpha': 0.0009341844388050163, 'reg_lambda': 0.0006803055651312175}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:49,867] Trial 42 finished with value: -0.9297200940851115 and parameters: {'learning_rate': 0.16977961038176928, 'num_leaves': 25, 'max_depth': 9, 'min_child_samples': 22, 'feature_fraction': 0.6401709119154068, 'bagging_fraction': 0.638962886072237, 'reg_alpha': 0.014035332290804428, 'reg_lambda': 0.00048619339133572435}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:32:53,869] Trial 43 finished with value: -0.9307671798524845 and parameters: {'learning_rate': 0.13515456003842757, 'num_leaves': 9, 'max_depth': 11, 'min_child_samples': 41, 'feature_fraction': 0.6096587258068511, 'bagging_fraction': 0.5492903046147741, 'reg_alpha': 0.00034537699025849575, 'reg_lambda': 1.2218002429594095}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:04,817] Trial 44 finished with value: -0.930665933415148 and parameters: {'learning_rate': 0.01869296065815932, 'num_leaves': 45, 'max_depth': 10, 'min_child_samples': 34, 'feature_fraction': 0.5240730701367702, 'bagging_fraction': 0.7132910687014743, 'reg_alpha': 0.007810786186498372, 'reg_lambda': 0.000476608710759108}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:10,251] Trial 45 finished with value: -0.9234748991792066 and parameters: {'learning_rate': 0.19874869046307966, 'num_leaves': 60, 'max_depth': 11, 'min_child_samples': 14, 'feature_fraction': 0.5602948356372489, 'bagging_fraction': 0.6157830697437754, 'reg_alpha': 0.0008130750827894251, 'reg_lambda': 4.245995695690757e-05}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:16,258] Trial 46 finished with value: -0.9321140397134456 and parameters: {'learning_rate': 0.12440607301910313, 'num_leaves': 23, 'max_depth': 9, 'min_child_samples': 58, 'feature_fraction': 0.5195913015912941, 'bagging_fraction': 0.75869865307179, 'reg_alpha': 4.714772432088224e-05, 'reg_lambda': 0.008382763940749943}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:21,320] Trial 47 finished with value: -0.9281885790400721 and parameters: {'learning_rate': 0.16642578581187267, 'num_leaves': 32, 'max_depth': 7, 'min_child_samples': 50, 'feature_fraction': 0.5841476440258551, 'bagging_fraction': 0.8388009650452389, 'reg_alpha': 0.07861606957207275, 'reg_lambda': 0.07615874347489797}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:30,115] Trial 48 finished with value: -0.9299011799191761 and parameters: {'learning_rate': 0.09903780569741977, 'num_leaves': 223, 'max_depth': 10, 'min_child_samples': 70, 'feature_fraction': 0.6819478747503419, 'bagging_fraction': 0.7965949702350477, 'reg_alpha': 2.938748607512436e-08, 'reg_lambda': 4.0180453370148}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:35,070] Trial 49 finished with value: -0.9318900663564776 and parameters: {'learning_rate': 0.049743632407101404, 'num_leaves': 14, 'max_depth': 5, 'min_child_samples': 29, 'feature_fraction': 0.5497806604297668, 'bagging_fraction': 0.5889027656925213, 'reg_alpha': 1.2609838739849926, 'reg_lambda': 0.017463223713896484}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:41,156] Trial 50 finished with value: -0.9268789220500262 and parameters: {'learning_rate': 0.15653032929941985, 'num_leaves': 61, 'max_depth': 14, 'min_child_samples': 23, 'feature_fraction': 0.6084324705356249, 'bagging_fraction': 0.7290272303678572, 'reg_alpha': 1.315210303834104e-07, 'reg_lambda': 0.26800841488536487}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:47,081] Trial 51 finished with value: -0.9319919221548265 and parameters: {'learning_rate': 0.12177115663578728, 'num_leaves': 22, 'max_depth': 9, 'min_child_samples': 58, 'feature_fraction': 0.5161755519012073, 'bagging_fraction': 0.7603749955938752, 'reg_alpha': 4.534822515957619e-05, 'reg_lambda': 0.006388787278980237}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:53,092] Trial 52 finished with value: -0.9295094950149184 and parameters: {'learning_rate': 0.13217966353067537, 'num_leaves': 40, 'max_depth': 8, 'min_child_samples': 52, 'feature_fraction': 0.525150823560518, 'bagging_fraction': 0.829599849898257, 'reg_alpha': 0.00016922393666744971, 'reg_lambda': 0.0012202697297700002}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:33:58,097] Trial 53 finished with value: -0.9328677348584554 and parameters: {'learning_rate': 0.1098132890694061, 'num_leaves': 17, 'max_depth': 9, 'min_child_samples': 48, 'feature_fraction': 0.5574412315808621, 'bagging_fraction': 0.6985050927321629, 'reg_alpha': 2.4165197781258144e-05, 'reg_lambda': 0.002885172900106696}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:34:01,971] Trial 54 finished with value: -0.9312376581612145 and parameters: {'learning_rate': 0.1058186202335369, 'num_leaves': 8, 'max_depth': 10, 'min_child_samples': 48, 'feature_fraction': 0.5677770185950425, 'bagging_fraction': 0.6871414595932286, 'reg_alpha': 1.3675008407893251e-05, 'reg_lambda': 0.00016144814753450657}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:34:10,064] Trial 55 finished with value: -0.9315403878653382 and parameters: {'learning_rate': 0.07895983475010092, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 44, 'feature_fraction': 0.6566752505486512, 'bagging_fraction': 0.656294874495644, 'reg_alpha': 1.5570426166432696e-08, 'reg_lambda': 4.491485992747816e-05}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:34:15,905] Trial 56 finished with value: -0.9332438974805527 and parameters: {'learning_rate': 0.06303908454203042, 'num_leaves': 17, 'max_depth': 11, 'min_child_samples': 15, 'feature_fraction': 0.5493853406639586, 'bagging_fraction': 0.7022952444225543, 'reg_alpha': 0.002085827457369907, 'reg_lambda': 0.002654994829991085}. Best is trial 10 with value: -0.9333108588669554.
[I 2025-08-02 07:34:21,447] Trial 57 finished with value: -0.9337006142352033 and parameters: {'learning_rate': 0.08945745047418373, 'num_leaves': 16, 'max_depth': 11, 'min_child_samples': 14, 'feature_fraction': 0.5455834195255317, 'bagging_fraction': 0.7024880422446701, 'reg_alpha': 0.004766827261699702, 'reg_lambda': 5.904496364887742}. Best is trial 57 with value: -0.9337006142352033.
[I 2025-08-02 07:34:27,202] Trial 58 finished with value: -0.9331456589406116 and parameters: {'learning_rate': 0.060641365791799684, 'num_leaves': 18, 'max_depth': 11, 'min_child_samples': 13, 'feature_fraction': 0.5450942960693608, 'bagging_fraction': 0.7079082310897166, 'reg_alpha': 0.004779671543076755, 'reg_lambda': 2.1832156423799984e-06}. Best is trial 57 with value: -0.9337006142352033.
[I 2025-08-02 07:34:37,187] Trial 59 finished with value: -0.9334514128327497 and parameters: {'learning_rate': 0.06507287016384954, 'num_leaves': 51, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.5418993332069405, 'bagging_fraction': 0.7035363969065569, 'reg_alpha': 0.045356094240842464, 'reg_lambda': 1.6757897262321857e-07}. Best is trial 57 with value: -0.9337006142352033.
[I 2025-08-02 07:34:47,403] Trial 60 finished with value: -0.9329186830933877 and parameters: {'learning_rate': 0.06209485820035861, 'num_leaves': 47, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.5430927555914983, 'bagging_fraction': 0.6931919139260518, 'reg_alpha': 0.08630931535354239, 'reg_lambda': 2.039244892800112e-07}. Best is trial 57 with value: -0.9337006142352033.
[I 2025-08-02 07:34:57,570] Trial 61 finished with value: -0.9327019424126445 and parameters: {'learning_rate': 0.05832451582350545, 'num_leaves': 50, 'max_depth': 13, 'min_child_samples': 15, 'feature_fraction': 0.5393746090439141, 'bagging_fraction': 0.699596924014826, 'reg_alpha': 0.05537361088072747, 'reg_lambda': 1.7458559314829724e-07}. Best is trial 57 with value: -0.9337006142352033.
[I 2025-08-02 07:35:09,207] Trial 62 finished with value: -0.9313163727929418 and parameters: {'learning_rate': 0.03877086386261361, 'num_leaves': 41, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.930305570741614, 'bagging_fraction': 0.6724089388395463, 'reg_alpha': 0.00529396952789135, 'reg_lambda': 4.0421852650194874e-08}. Best is trial 57 with value: -0.9337006142352033.
[I 2025-08-02 07:35:22,550] Trial 63 finished with value: -0.931558082867321 and parameters: {'learning_rate': 0.06369267749350549, 'num_leaves': 80, 'max_depth': 12, 'min_child_samples': 14, 'feature_fraction': 0.5070587568226921, 'bagging_fraction': 0.7252132324666245, 'reg_alpha': 0.0400551400641819, 'reg_lambda': 1.4406358962458572e-06}. Best is trial 57 with value: -0.9337006142352033.
[I 2025-08-02 07:35:28,928] Trial 64 finished with value: -0.9353443311960399 and parameters: {'learning_rate': 0.04770014065085033, 'num_leaves': 20, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5558905850865983, 'bagging_fraction': 0.7058700900835913, 'reg_alpha': 0.15437876544549645, 'reg_lambda': 4.322106610278296e-08}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:35:40,662] Trial 65 finished with value: -0.9336072381513211 and parameters: {'learning_rate': 0.05007299061141174, 'num_leaves': 55, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5399979984452932, 'bagging_fraction': 0.6489200549740443, 'reg_alpha': 0.5494853675026371, 'reg_lambda': 5.1043986630383134e-08}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:35:59,588] Trial 66 finished with value: -0.9314225989382385 and parameters: {'learning_rate': 0.04426013758839648, 'num_leaves': 89, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.8196683814223185, 'bagging_fraction': 0.6521690133153343, 'reg_alpha': 0.6658134407474071, 'reg_lambda': 2.498092658310597e-08}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:36:14,504] Trial 67 finished with value: -0.9308699611090407 and parameters: {'learning_rate': 0.05252451113715267, 'num_leaves': 110, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5814368827305821, 'bagging_fraction': 0.6364784660724696, 'reg_alpha': 3.5802309481472214, 'reg_lambda': 6.15759807935164e-07}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:36:24,653] Trial 68 finished with value: -0.9339281809461749 and parameters: {'learning_rate': 0.03938110938298564, 'num_leaves': 36, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5975104850682096, 'bagging_fraction': 0.7421446474836196, 'reg_alpha': 0.25284857603538746, 'reg_lambda': 6.011138144589783e-08}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:36:38,255] Trial 69 finished with value: -0.932063458008545 and parameters: {'learning_rate': 0.03770642269092415, 'num_leaves': 66, 'max_depth': 14, 'min_child_samples': 24, 'feature_fraction': 0.5941308433911613, 'bagging_fraction': 0.7417778901839397, 'reg_alpha': 0.22391313035783544, 'reg_lambda': 6.200312364692529e-08}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:36:50,281] Trial 70 finished with value: -0.9323213883043164 and parameters: {'learning_rate': 0.047907058201695475, 'num_leaves': 55, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.5033621649741468, 'bagging_fraction': 0.6732613889034926, 'reg_alpha': 0.20254501117503576, 'reg_lambda': 1.0803020131219274e-07}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:36:56,083] Trial 71 finished with value: -0.9339134500765706 and parameters: {'learning_rate': 0.056369961599718015, 'num_leaves': 17, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5321259759194982, 'bagging_fraction': 0.7120204743302782, 'reg_alpha': 0.01673078841604108, 'reg_lambda': 2.051574719593008e-08}. Best is trial 64 with value: -0.9353443311960399.
[I 2025-08-02 07:37:05,517] Trial 72 finished with value: -0.9357034107499388 and parameters: {'learning_rate': 0.03361872638425765, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5303982973843946, 'bagging_fraction': 0.7200416425253419, 'reg_alpha': 0.02282848904653063, 'reg_lambda': 1.1828247148356493e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:37:15,567] Trial 73 finished with value: -0.9350855438809512 and parameters: {'learning_rate': 0.03333979607915114, 'num_leaves': 36, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5276513370070162, 'bagging_fraction': 0.7221375896101694, 'reg_alpha': 0.46473394274682, 'reg_lambda': 1.1231420682872289e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:37:25,861] Trial 74 finished with value: -0.9355535211071563 and parameters: {'learning_rate': 0.03314380308023537, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5302712773385204, 'bagging_fraction': 0.7225003419803352, 'reg_alpha': 0.02396731827901039, 'reg_lambda': 1.3134315305726621e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:37:35,999] Trial 75 finished with value: -0.9355130699089825 and parameters: {'learning_rate': 0.030724994871208104, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.533096650455574, 'bagging_fraction': 0.7533265452968452, 'reg_alpha': 0.020428419804002555, 'reg_lambda': 1.1228696004822665e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:37:46,168] Trial 76 finished with value: -0.9355638332025189 and parameters: {'learning_rate': 0.03035429104340565, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5265267269873769, 'bagging_fraction': 0.7606501128433887, 'reg_alpha': 0.02126882226300248, 'reg_lambda': 1.1554875993386883e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:37:56,588] Trial 77 finished with value: -0.9353182566734073 and parameters: {'learning_rate': 0.030420552085476643, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5256245515706366, 'bagging_fraction': 0.7619390317303875, 'reg_alpha': 0.020381125930820976, 'reg_lambda': 1.0273969465655201e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:38:06,858] Trial 78 finished with value: -0.9332797377323561 and parameters: {'learning_rate': 0.029690179310168208, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5180859500999795, 'bagging_fraction': 0.794077889166318, 'reg_alpha': 0.15188467704220734, 'reg_lambda': 1.236259702055338e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:38:16,285] Trial 79 finished with value: -0.9344734902013128 and parameters: {'learning_rate': 0.022345905985675905, 'num_leaves': 29, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5705843640934196, 'bagging_fraction': 0.7650021470973747, 'reg_alpha': 0.4209537728644218, 'reg_lambda': 1.0006439775475848e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:38:33,632] Trial 80 finished with value: -0.9345933474096122 and parameters: {'learning_rate': 0.020888828363195326, 'num_leaves': 73, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5651078944484683, 'bagging_fraction': 0.7604067617878145, 'reg_alpha': 0.02044750349938947, 'reg_lambda': 1.0003439831169785e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:38:42,730] Trial 81 finished with value: -0.933912299364965 and parameters: {'learning_rate': 0.022504098740745795, 'num_leaves': 28, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.576537241580171, 'bagging_fraction': 0.7867425196169083, 'reg_alpha': 0.028867185715290563, 'reg_lambda': 1.1247932469532302e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:38:54,472] Trial 82 finished with value: -0.9324987263494761 and parameters: {'learning_rate': 0.020955621975378702, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.5629991365810633, 'bagging_fraction': 0.7625375796438942, 'reg_alpha': 0.019889446617321473, 'reg_lambda': 2.3483726878236935e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:39:08,751] Trial 83 finished with value: -0.9332681742570539 and parameters: {'learning_rate': 0.032341560386765035, 'num_leaves': 61, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5306661422073784, 'bagging_fraction': 0.7669530445905245, 'reg_alpha': 0.49682015427861276, 'reg_lambda': 1.9814344447281692e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:39:27,215] Trial 84 finished with value: -0.9339711883563512 and parameters: {'learning_rate': 0.02696662880151852, 'num_leaves': 80, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5145169335780737, 'bagging_fraction': 0.748381350581825, 'reg_alpha': 0.009965930467181186, 'reg_lambda': 3.243783451882464e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:39:36,721] Trial 85 finished with value: -0.9307089917162841 and parameters: {'learning_rate': 0.01681586461667131, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5700270345386897, 'bagging_fraction': 0.8113524169995258, 'reg_alpha': 1.180774859076738, 'reg_lambda': 8.136778801199256e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:39:54,554] Trial 86 finished with value: -0.931760441688651 and parameters: {'learning_rate': 0.03453465669961791, 'num_leaves': 126, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.5003111305431043, 'bagging_fraction': 0.7836598848889909, 'reg_alpha': 0.10381184347549124, 'reg_lambda': 1.4420078840598636e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:40:11,544] Trial 87 finished with value: -0.9345912418940034 and parameters: {'learning_rate': 0.02889762876363115, 'num_leaves': 75, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5582008664493309, 'bagging_fraction': 0.7249184276415027, 'reg_alpha': 0.022072571006949135, 'reg_lambda': 1.0221423231013511e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:40:28,210] Trial 88 finished with value: -0.9317745046988279 and parameters: {'learning_rate': 0.029718060447960597, 'num_leaves': 93, 'max_depth': 15, 'min_child_samples': 26, 'feature_fraction': 0.5561561997060489, 'bagging_fraction': 0.7294845728766095, 'reg_alpha': 0.0021690218515448773, 'reg_lambda': 3.3605832929400983e-07}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:40:44,950] Trial 89 finished with value: -0.9336381871796838 and parameters: {'learning_rate': 0.025457373324007826, 'num_leaves': 73, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5316093199381351, 'bagging_fraction': 0.7365985049642159, 'reg_alpha': 0.029219843810234274, 'reg_lambda': 4.324244769594925e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:41:00,617] Trial 90 finished with value: -0.9328660159070133 and parameters: {'learning_rate': 0.03634535628672877, 'num_leaves': 75, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5242411967016375, 'bagging_fraction': 0.7532614616277737, 'reg_alpha': 0.010581723230798088, 'reg_lambda': 3.333583181876047e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:41:11,599] Trial 91 finished with value: -0.9344236296986702 and parameters: {'learning_rate': 0.028498260423372557, 'num_leaves': 38, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5753748727365741, 'bagging_fraction': 0.7216522381577156, 'reg_alpha': 0.02549505091212407, 'reg_lambda': 1.5353863961069416e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:41:24,026] Trial 92 finished with value: -0.933891111542426 and parameters: {'learning_rate': 0.023196223123727492, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.6265685290642299, 'bagging_fraction': 0.772303802100202, 'reg_alpha': 0.06144815419016135, 'reg_lambda': 1.1835766038570382e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:41:47,098] Trial 93 finished with value: -0.9330797400217848 and parameters: {'learning_rate': 0.03178279577809656, 'num_leaves': 142, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5548620973244069, 'bagging_fraction': 0.9818752497240795, 'reg_alpha': 0.11895057677493752, 'reg_lambda': 1.0254369903435487e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:41:55,764] Trial 94 finished with value: -0.9315621214304346 and parameters: {'learning_rate': 0.019260718350233887, 'num_leaves': 28, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5163933749661468, 'bagging_fraction': 0.8228703781514353, 'reg_alpha': 1.5375145849623189, 'reg_lambda': 8.719551802162522e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:42:06,269] Trial 95 finished with value: -0.9335733822055066 and parameters: {'learning_rate': 0.02500604849194345, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5860212270571246, 'bagging_fraction': 0.6846933701225069, 'reg_alpha': 0.43871896995095516, 'reg_lambda': 2.7020212724417164e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:42:19,714] Trial 96 finished with value: -0.9333424202977897 and parameters: {'learning_rate': 0.04174029554330873, 'num_leaves': 65, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.5618653661964468, 'bagging_fraction': 0.7470123010854623, 'reg_alpha': 3.46723237245388, 'reg_lambda': 1.905812663423917e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:42:32,153] Trial 97 finished with value: -0.9339783499183516 and parameters: {'learning_rate': 0.03405041129529997, 'num_leaves': 49, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.600527356428551, 'bagging_fraction': 0.7168391529314724, 'reg_alpha': 0.35228955024827446, 'reg_lambda': 3.61363877639342e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:42:46,364] Trial 98 finished with value: -0.9331249820037988 and parameters: {'learning_rate': 0.027225795129307933, 'num_leaves': 58, 'max_depth': 13, 'min_child_samples': 22, 'feature_fraction': 0.5330258528719211, 'bagging_fraction': 0.7571045377160968, 'reg_alpha': 0.003202102816172962, 'reg_lambda': 1.789156581842499e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:42:54,273] Trial 99 finished with value: -0.9332547531489406 and parameters: {'learning_rate': 0.03545181453309846, 'num_leaves': 26, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5133251185561472, 'bagging_fraction': 0.73525651133375, 'reg_alpha': 0.15928106420272428, 'reg_lambda': 1.0539794756856504e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:43:06,057] Trial 100 finished with value: -0.9328813612653873 and parameters: {'learning_rate': 0.015515809777751232, 'num_leaves': 42, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5571137601102009, 'bagging_fraction': 0.8013139941300575, 'reg_alpha': 0.008172934811293954, 'reg_lambda': 1.3237270146829957e-07}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:43:16,866] Trial 101 finished with value: -0.9272763607509795 and parameters: {'learning_rate': 0.02941424067076034, 'num_leaves': 38, 'max_depth': 14, 'min_child_samples': 87, 'feature_fraction': 0.5709271944412774, 'bagging_fraction': 0.7222697952043088, 'reg_alpha': 0.023484599197442668, 'reg_lambda': 1.7098211167294092e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:43:44,445] Trial 102 finished with value: -0.9310403227601676 and parameters: {'learning_rate': 0.028389051104731947, 'num_leaves': 170, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.6197573168506063, 'bagging_fraction': 0.7220431551987205, 'reg_alpha': 0.04095845147181189, 'reg_lambda': 7.199356692528539e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:43:54,272] Trial 103 finished with value: -0.9341985813160858 and parameters: {'learning_rate': 0.021476911065702303, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5712242301332827, 'bagging_fraction': 0.782532410258633, 'reg_alpha': 0.8577347186691383, 'reg_lambda': 1.0003598814068469e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:44:06,992] Trial 104 finished with value: -0.9336427418771058 and parameters: {'learning_rate': 0.03153991179993799, 'num_leaves': 50, 'max_depth': 13, 'min_child_samples': 15, 'feature_fraction': 0.5320631411887152, 'bagging_fraction': 0.7642410679161484, 'reg_alpha': 0.012892184501761772, 'reg_lambda': 2.9807148544885017e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:44:17,144] Trial 105 finished with value: -0.9342979201420469 and parameters: {'learning_rate': 0.024690566292838837, 'num_leaves': 36, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5521921136637065, 'bagging_fraction': 0.7324105088405166, 'reg_alpha': 0.03315654833553609, 'reg_lambda': 4.6731134966152646e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:44:22,564] Trial 106 finished with value: -0.9312475725754513 and parameters: {'learning_rate': 0.04085368896236204, 'num_leaves': 13, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5825096612790723, 'bagging_fraction': 0.6810398572749535, 'reg_alpha': 0.07011560675399081, 'reg_lambda': 2.626019653840691e-07}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:44:30,005] Trial 107 finished with value: -0.9334336462606138 and parameters: {'learning_rate': 0.02787581203732869, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5234406783705652, 'bagging_fraction': 0.771240076285611, 'reg_alpha': 2.300373408134729, 'reg_lambda': 1.645791605071033e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:44:41,509] Trial 108 finished with value: -0.9330555186945895 and parameters: {'learning_rate': 0.020381109825519966, 'num_leaves': 42, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5088159237522022, 'bagging_fraction': 0.7548753333578053, 'reg_alpha': 0.0061632943462790095, 'reg_lambda': 2.443905611391476e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:44:54,506] Trial 109 finished with value: -0.9336269445273759 and parameters: {'learning_rate': 0.046812506743719784, 'num_leaves': 53, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.7091301857472234, 'bagging_fraction': 0.7903896308280696, 'reg_alpha': 0.02125328526476022, 'reg_lambda': 4.985410700963701e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:45:16,698] Trial 110 finished with value: -0.9328168266876266 and parameters: {'learning_rate': 0.025565206756196127, 'num_leaves': 98, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.7443074468862783, 'bagging_fraction': 0.7409651455290587, 'reg_alpha': 0.003500658347574573, 'reg_lambda': 1.1284768317372792e-07}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:45:26,996] Trial 111 finished with value: -0.9337428235303522 and parameters: {'learning_rate': 0.024062283386178305, 'num_leaves': 35, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5503435850093316, 'bagging_fraction': 0.7275728591352147, 'reg_alpha': 0.034573739737922764, 'reg_lambda': 1.602981489998179e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:45:37,651] Trial 112 finished with value: -0.9323335614456479 and parameters: {'learning_rate': 0.017738487626326273, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5395291390216717, 'bagging_fraction': 0.7156512899046718, 'reg_alpha': 0.0015066333015749985, 'reg_lambda': 4.4408698845354446e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:45:44,986] Trial 113 finished with value: -0.9339138622979768 and parameters: {'learning_rate': 0.033065123815958414, 'num_leaves': 23, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.5491002749625724, 'bagging_fraction': 0.7349420805767847, 'reg_alpha': 0.013332021861472976, 'reg_lambda': 2.7597694743565634e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:45:56,804] Trial 114 finished with value: -0.9342239997731411 and parameters: {'learning_rate': 0.030806377102716172, 'num_leaves': 46, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5652827824549443, 'bagging_fraction': 0.7489183258041344, 'reg_alpha': 0.12483806203047022, 'reg_lambda': 6.10667315843383e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:46:06,100] Trial 115 finished with value: -0.9343530500616186 and parameters: {'learning_rate': 0.025755893140536248, 'num_leaves': 31, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5378756980797632, 'bagging_fraction': 0.7095742154964363, 'reg_alpha': 0.07655007123166933, 'reg_lambda': 1.6075025516340576e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:46:11,481] Trial 116 finished with value: -0.9295647015937074 and parameters: {'learning_rate': 0.02257659690412277, 'num_leaves': 13, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5252651181095869, 'bagging_fraction': 0.6897952170752155, 'reg_alpha': 0.06076184215139147, 'reg_lambda': 1.671443543249083e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:46:20,192] Trial 117 finished with value: -0.9351789363553681 and parameters: {'learning_rate': 0.03695310128370291, 'num_leaves': 28, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5773937306180306, 'bagging_fraction': 0.7106111987351897, 'reg_alpha': 9.345131152866932, 'reg_lambda': 1.1002024068184529e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:46:27,134] Trial 118 finished with value: -0.9329567425584755 and parameters: {'learning_rate': 0.036944248245698086, 'num_leaves': 20, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5924031117718135, 'bagging_fraction': 0.6632448929818545, 'reg_alpha': 0.007619701747267994, 'reg_lambda': 1.1040015690661487e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:46:38,579] Trial 119 finished with value: -0.9334596155285129 and parameters: {'learning_rate': 0.042315116748377395, 'num_leaves': 46, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5765676509108464, 'bagging_fraction': 0.7201513954540687, 'reg_alpha': 0.017842340396873484, 'reg_lambda': 2.6961346973826275e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:47:01,909] Trial 120 finished with value: -0.9299366005471548 and parameters: {'learning_rate': 0.013305097937893475, 'num_leaves': 114, 'max_depth': 15, 'min_child_samples': 21, 'feature_fraction': 0.6411272783649768, 'bagging_fraction': 0.7694379849766814, 'reg_alpha': 9.094429810340532, 'reg_lambda': 1.0150761882717353e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:47:11,033] Trial 121 finished with value: -0.9348149962988043 and parameters: {'learning_rate': 0.026469851653499514, 'num_leaves': 31, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5408958351738514, 'bagging_fraction': 0.7098562342862357, 'reg_alpha': 0.34149286556918246, 'reg_lambda': 1.6189243873218238e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:47:19,460] Trial 122 finished with value: -0.9345677938497414 and parameters: {'learning_rate': 0.030291336801964164, 'num_leaves': 28, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5594510876681894, 'bagging_fraction': 0.7440505020007707, 'reg_alpha': 0.26099341843868445, 'reg_lambda': 2.358809056728857e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:47:27,613] Trial 123 finished with value: -0.9341986309935593 and parameters: {'learning_rate': 0.03431655429129841, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5000703164400692, 'bagging_fraction': 0.7427466927818144, 'reg_alpha': 0.2566979736804918, 'reg_lambda': 3.2805675891866145e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:47:36,419] Trial 124 finished with value: -0.9333696784572453 and parameters: {'learning_rate': 0.03007135954666778, 'num_leaves': 30, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5150189161105465, 'bagging_fraction': 0.695959989717138, 'reg_alpha': 0.327836818021014, 'reg_lambda': 2.4215286055221576e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:47:41,262] Trial 125 finished with value: -0.9297351013054288 and parameters: {'learning_rate': 0.03235478847341779, 'num_leaves': 21, 'max_depth': 4, 'min_child_samples': 12, 'feature_fraction': 0.5401542591541535, 'bagging_fraction': 0.7077723348459289, 'reg_alpha': 6.8637905126857035, 'reg_lambda': 4.001461697850847e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:47:46,582] Trial 126 finished with value: -0.932304682482209 and parameters: {'learning_rate': 0.03916903321172181, 'num_leaves': 14, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5602143758741258, 'bagging_fraction': 0.7781977195377148, 'reg_alpha': 0.8143167999300236, 'reg_lambda': 2.042869707198053e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:48:11,008] Trial 127 finished with value: -0.9320209360222627 and parameters: {'learning_rate': 0.03606094872455797, 'num_leaves': 198, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5253379498590213, 'bagging_fraction': 0.7559503084013192, 'reg_alpha': 1.9670564563589534, 'reg_lambda': 9.624622513785347e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:48:31,716] Trial 128 finished with value: -0.931923684527549 and parameters: {'learning_rate': 0.02670428055675507, 'num_leaves': 126, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.5465288166258012, 'bagging_fraction': 0.6760105809581495, 'reg_alpha': 0.16618106667795418, 'reg_lambda': 1.5644523150223572e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:48:40,020] Trial 129 finished with value: -0.9346786338779209 and parameters: {'learning_rate': 0.04509604114515249, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5847968064091077, 'bagging_fraction': 0.732255443615054, 'reg_alpha': 0.0004416579435412258, 'reg_lambda': 1.0064445265405698e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:48:51,935] Trial 130 finished with value: -0.929926754079347 and parameters: {'learning_rate': 0.0102934672512002, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.534406127781492, 'bagging_fraction': 0.727184843334288, 'reg_alpha': 0.00045952851954413006, 'reg_lambda': 7.11872853809785e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:48:59,943] Trial 131 finished with value: -0.9338710148405706 and parameters: {'learning_rate': 0.04456846260464244, 'num_leaves': 26, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.6028719085156975, 'bagging_fraction': 0.7521346750944649, 'reg_alpha': 0.10791063202670605, 'reg_lambda': 1.1470838937188471e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:49:09,469] Trial 132 finished with value: -0.9345305202974747 and parameters: {'learning_rate': 0.03099707723713746, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5851111577075048, 'bagging_fraction': 0.7387447848554485, 'reg_alpha': 0.41431835385932464, 'reg_lambda': 1.000860617523253e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:49:19,642] Trial 133 finished with value: -0.9339982399021776 and parameters: {'learning_rate': 0.030816156745445616, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.584004512406183, 'bagging_fraction': 0.7408861989911151, 'reg_alpha': 0.04665150609750545, 'reg_lambda': 2.9120455412820844e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:49:27,183] Trial 134 finished with value: -0.9318571081036989 and parameters: {'learning_rate': 0.037832300525555446, 'num_leaves': 20, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.8745847317337323, 'bagging_fraction': 0.7066416459125685, 'reg_alpha': 0.8883992927520135, 'reg_lambda': 1.9761538636246267e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:49:36,289] Trial 135 finished with value: -0.935509608136489 and parameters: {'learning_rate': 0.03418433012317206, 'num_leaves': 32, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5580519080360942, 'bagging_fraction': 0.692032146771822, 'reg_alpha': 0.19538746922549236, 'reg_lambda': 1.007825791216275e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:49:48,254] Trial 136 finished with value: -0.9288140774294543 and parameters: {'learning_rate': 0.03397778192660832, 'num_leaves': 53, 'max_depth': 15, 'min_child_samples': 78, 'feature_fraction': 0.5550766545511682, 'bagging_fraction': 0.6951717087786, 'reg_alpha': 0.017345593965277996, 'reg_lambda': 3.818894172468236e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:49:59,553] Trial 137 finished with value: -0.9339980348578136 and parameters: {'learning_rate': 0.03990820359500861, 'num_leaves': 40, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.7873922111393914, 'bagging_fraction': 0.7150958393208733, 'reg_alpha': 0.2155670618148775, 'reg_lambda': 1.5816566793995436e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:50:07,375] Trial 138 finished with value: -0.9330144434744346 and parameters: {'learning_rate': 0.029039145965788177, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5126336790016361, 'bagging_fraction': 0.6848977556325097, 'reg_alpha': 0.00011059502349678478, 'reg_lambda': 5.8349529272664685e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:50:20,101] Trial 139 finished with value: -0.9336599597825723 and parameters: {'learning_rate': 0.04694599527945201, 'num_leaves': 59, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5652779783735998, 'bagging_fraction': 0.7286601403706181, 'reg_alpha': 0.010480577448083103, 'reg_lambda': 2.536936308791857e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:50:25,467] Trial 140 finished with value: -0.9312978258625846 and parameters: {'learning_rate': 0.032936258743317036, 'num_leaves': 14, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.546015366653692, 'bagging_fraction': 0.663866445625776, 'reg_alpha': 0.09056394594335439, 'reg_lambda': 1.541369064496106e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:50:35,258] Trial 141 finished with value: -0.934590208073501 and parameters: {'learning_rate': 0.030775167520558023, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5883238121259782, 'bagging_fraction': 0.7022419475970418, 'reg_alpha': 0.4770860457069242, 'reg_lambda': 1.13370234550429e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:50:59,947] Trial 142 finished with value: -0.9324373230564731 and parameters: {'learning_rate': 0.03593033697715388, 'num_leaves': 152, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5255153439266944, 'bagging_fraction': 0.7045365651978044, 'reg_alpha': 0.047888941951699265, 'reg_lambda': 2.128079748961677e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:51:10,304] Trial 143 finished with value: -0.9340337477956331 and parameters: {'learning_rate': 0.027364255893806425, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.6137881204802126, 'bagging_fraction': 0.7192225804277668, 'reg_alpha': 0.25609034353088067, 'reg_lambda': 1.0177737814210315e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:51:20,534] Trial 144 finished with value: -0.9339088454767975 and parameters: {'learning_rate': 0.05425500710261129, 'num_leaves': 47, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5584043870866875, 'bagging_fraction': 0.692737615981848, 'reg_alpha': 0.7450996060434839, 'reg_lambda': 3.8079233765154294e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:51:29,689] Trial 145 finished with value: -0.935441368674661 and parameters: {'learning_rate': 0.03485171430470013, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5415280831953062, 'bagging_fraction': 0.7025659325828006, 'reg_alpha': 0.13703843481875505, 'reg_lambda': 1.5167313233987766e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:51:39,718] Trial 146 finished with value: -0.9332595837643013 and parameters: {'learning_rate': 0.041660357184796125, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5390026938228182, 'bagging_fraction': 0.680399457024062, 'reg_alpha': 5.137431306373857, 'reg_lambda': 1.3490944545788016e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:51:48,747] Trial 147 finished with value: -0.9350682463655519 and parameters: {'learning_rate': 0.035101738681317815, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5197226938346206, 'bagging_fraction': 0.7018636769525273, 'reg_alpha': 0.1328604333794691, 'reg_lambda': 1.0139700039119765e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:51:55,440] Trial 148 finished with value: -0.9326315553943954 and parameters: {'learning_rate': 0.037736809746336676, 'num_leaves': 21, 'max_depth': 15, 'min_child_samples': 19, 'feature_fraction': 0.519733826740964, 'bagging_fraction': 0.710416420519546, 'reg_alpha': 0.12949711876913478, 'reg_lambda': 1.8976738527399368e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:52:09,151] Trial 149 finished with value: -0.9337987606248637 and parameters: {'learning_rate': 0.03522890063183127, 'num_leaves': 63, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5096373181161137, 'bagging_fraction': 0.690188485419328, 'reg_alpha': 0.026301717097714315, 'reg_lambda': 3.534470450537588e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:52:19,755] Trial 150 finished with value: -0.9338432455041087 and parameters: {'learning_rate': 0.04486624681851092, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5305321773348466, 'bagging_fraction': 0.7272538556774151, 'reg_alpha': 0.05999743992826266, 'reg_lambda': 5.5221217728447476e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:52:28,926] Trial 151 finished with value: -0.9352713862382843 and parameters: {'learning_rate': 0.032365884613366425, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5478110344183514, 'bagging_fraction': 0.7007131426859439, 'reg_alpha': 0.5368983328387323, 'reg_lambda': 1.009567928452642e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:52:37,863] Trial 152 finished with value: -0.9356345680753154 and parameters: {'learning_rate': 0.0329796512547903, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5451680589227571, 'bagging_fraction': 0.7144698319060061, 'reg_alpha': 1.2981584553664098, 'reg_lambda': 1.5711323391672797e-08}. Best is trial 72 with value: -0.9357034107499388.
[I 2025-08-02 07:52:46,883] Trial 153 finished with value: -0.9358298611898934 and parameters: {'learning_rate': 0.03304259918932675, 'num_leaves': 32, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5346045937636675, 'bagging_fraction': 0.7016665668282873, 'reg_alpha': 3.1808172799406558, 'reg_lambda': 1.5218930136157965e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:52:56,075] Trial 154 finished with value: -0.9351541238678656 and parameters: {'learning_rate': 0.03256937247823459, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5336409127423329, 'bagging_fraction': 0.6938846560958506, 'reg_alpha': 2.7809352469198947, 'reg_lambda': 1.755118647992016e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:53:05,341] Trial 155 finished with value: -0.9337059957052797 and parameters: {'learning_rate': 0.033052747605995206, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5307203080230822, 'bagging_fraction': 0.6673835615624892, 'reg_alpha': 2.6093331201514967, 'reg_lambda': 2.1374404825599973e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:53:15,568] Trial 156 finished with value: -0.9352712980739227 and parameters: {'learning_rate': 0.034852031922646375, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5221341738742702, 'bagging_fraction': 0.6753723299146261, 'reg_alpha': 1.853161455691551, 'reg_lambda': 3.0625064250566704e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:53:25,369] Trial 157 finished with value: -0.9344134929926357 and parameters: {'learning_rate': 0.034889955062619125, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5201731671217991, 'bagging_fraction': 0.6748754346201451, 'reg_alpha': 1.3619017987929347, 'reg_lambda': 3.018198460825512e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:53:37,500] Trial 158 finished with value: -0.93331565261091 and parameters: {'learning_rate': 0.03763998326381661, 'num_leaves': 50, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5061929540222416, 'bagging_fraction': 0.656859240889936, 'reg_alpha': 5.810049073963327, 'reg_lambda': 4.826084997315247e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:53:48,216] Trial 159 finished with value: -0.9352932742893098 and parameters: {'learning_rate': 0.03259329037949777, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5191235919278656, 'bagging_fraction': 0.6850837536081872, 'reg_alpha': 3.557839930825824, 'reg_lambda': 9.274172556942301e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:53:58,376] Trial 160 finished with value: -0.9340209139450157 and parameters: {'learning_rate': 0.032632797416076186, 'num_leaves': 40, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5322539565805693, 'bagging_fraction': 0.6836542393490207, 'reg_alpha': 3.3603564910271944, 'reg_lambda': 8.6758309643072e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:54:09,695] Trial 161 finished with value: -0.9349253786208964 and parameters: {'learning_rate': 0.035073526743121086, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5195472429270224, 'bagging_fraction': 0.6980238124085532, 'reg_alpha': 4.329877688980668, 'reg_lambda': 1.6494284740355735e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:54:16,998] Trial 162 finished with value: -0.933182774831084 and parameters: {'learning_rate': 0.039775703942336864, 'num_leaves': 24, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5114336534277384, 'bagging_fraction': 0.6878081098802477, 'reg_alpha': 9.659879915634708, 'reg_lambda': 2.6668268732747974e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:54:27,276] Trial 163 finished with value: -0.9346122861823608 and parameters: {'learning_rate': 0.03267059605844641, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5468460647806076, 'bagging_fraction': 0.6432409401840931, 'reg_alpha': 1.7058588180547603, 'reg_lambda': 1.5612051006789334e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:54:36,514] Trial 164 finished with value: -0.9275762660776465 and parameters: {'learning_rate': 0.03699621984310909, 'num_leaves': 30, 'max_depth': 15, 'min_child_samples': 100, 'feature_fraction': 0.537542046931521, 'bagging_fraction': 0.6973579385336856, 'reg_alpha': 2.9259632651219554, 'reg_lambda': 1.335104316862013e-07}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:54:48,600] Trial 165 finished with value: -0.9347917635614131 and parameters: {'learning_rate': 0.028528398630516878, 'num_leaves': 47, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.501325452554933, 'bagging_fraction': 0.6719243269520888, 'reg_alpha': 1.8607311595594158, 'reg_lambda': 3.9218752200435076e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:54:54,884] Trial 166 finished with value: -0.9326613318740252 and parameters: {'learning_rate': 0.03136491857164602, 'num_leaves': 18, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5227642695843381, 'bagging_fraction': 0.7134059223596517, 'reg_alpha': 6.982817477883682, 'reg_lambda': 2.483577230713411e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:55:04,420] Trial 167 finished with value: -0.9357277072398383 and parameters: {'learning_rate': 0.033925670795968615, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5470512390722901, 'bagging_fraction': 0.6286075233079996, 'reg_alpha': 1.2257032810017086, 'reg_lambda': 5.165815423788978e-07}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:55:14,966] Trial 168 finished with value: -0.9340933428927178 and parameters: {'learning_rate': 0.03317355005539217, 'num_leaves': 40, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5506628308874718, 'bagging_fraction': 0.6014048340395847, 'reg_alpha': 1.4060942124597267, 'reg_lambda': 9.225892895599193e-06}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:55:22,763] Trial 169 finished with value: -0.933164215203228 and parameters: {'learning_rate': 0.029068550658471987, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5324560471526852, 'bagging_fraction': 0.6600420655156576, 'reg_alpha': 0.9295757029991557, 'reg_lambda': 8.757931884367016e-07}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:55:37,622] Trial 170 finished with value: -0.9330001113930287 and parameters: {'learning_rate': 0.03185040245066909, 'num_leaves': 55, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.9373836115120877, 'bagging_fraction': 0.6822728735178764, 'reg_alpha': 2.5709825449471166, 'reg_lambda': 1.7854500641495497e-07}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:55:46,872] Trial 171 finished with value: -0.9352370953101452 and parameters: {'learning_rate': 0.035135206240501336, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5432841287682667, 'bagging_fraction': 0.6228446194441297, 'reg_alpha': 3.767073919544106, 'reg_lambda': 1.5722270317286e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:55:56,409] Trial 172 finished with value: -0.9339313820531447 and parameters: {'learning_rate': 0.03705895663397553, 'num_leaves': 36, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5474012389301592, 'bagging_fraction': 0.5758743484121026, 'reg_alpha': 4.726229408592821, 'reg_lambda': 1.7357214259446367e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:56:04,396] Trial 173 finished with value: -0.9342941012192884 and parameters: {'learning_rate': 0.03968112085145565, 'num_leaves': 28, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5408826547504543, 'bagging_fraction': 0.6239337656508216, 'reg_alpha': 0.5905410347146438, 'reg_lambda': 5.645055720939328e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:56:34,971] Trial 174 finished with value: -0.9324794658615687 and parameters: {'learning_rate': 0.03454209499401368, 'num_leaves': 238, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5322746353234962, 'bagging_fraction': 0.6244803716973832, 'reg_alpha': 1.170835174198781, 'reg_lambda': 3.037335377066019e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:56:46,449] Trial 175 finished with value: -0.9349523790468662 and parameters: {'learning_rate': 0.0298752377818464, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5534938518068931, 'bagging_fraction': 0.6040185496806969, 'reg_alpha': 3.9999686568424515, 'reg_lambda': 1.5170440686194815e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:56:56,193] Trial 176 finished with value: -0.9336498080949379 and parameters: {'learning_rate': 0.033347339844381534, 'num_leaves': 36, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.5261796564328022, 'bagging_fraction': 0.561576017416619, 'reg_alpha': 1.7883223857114745, 'reg_lambda': 2.3205561679846234e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:57:03,127] Trial 177 finished with value: -0.9347620486287076 and parameters: {'learning_rate': 0.031283780141962654, 'num_leaves': 21, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.542373873748493, 'bagging_fraction': 0.5884343119151151, 'reg_alpha': 2.6712196409142104, 'reg_lambda': 4.587194860669586e-07}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:57:11,517] Trial 178 finished with value: -0.934136473898 and parameters: {'learning_rate': 0.03606915092412474, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5106988206794496, 'bagging_fraction': 0.6147373220063912, 'reg_alpha': 0.6959341285682731, 'reg_lambda': 3.5007290917103023e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:57:21,207] Trial 179 finished with value: -0.9336798580631015 and parameters: {'learning_rate': 0.028100782342010563, 'num_leaves': 32, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5680126467586561, 'bagging_fraction': 0.7190113494058328, 'reg_alpha': 5.912800421862881, 'reg_lambda': 1.4579714936154255e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:57:31,590] Trial 180 finished with value: -0.9348445198657348 and parameters: {'learning_rate': 0.03881600315943087, 'num_leaves': 41, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5502267715742355, 'bagging_fraction': 0.6343525681440836, 'reg_alpha': 1.1167109229459526, 'reg_lambda': 6.859301145517953e-08}. Best is trial 153 with value: -0.9358298611898934.
[I 2025-08-02 07:57:40,871] Trial 181 finished with value: -0.9360705907673996 and parameters: {'learning_rate': 0.03428390132778631, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5167317316643383, 'bagging_fraction': 0.7012104426133072, 'reg_alpha': 9.946848288734214, 'reg_lambda': 1.0149182725275904e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:57:50,205] Trial 182 finished with value: -0.9333529701922955 and parameters: {'learning_rate': 0.03182765966198504, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5266032723806706, 'bagging_fraction': 0.6952779269603142, 'reg_alpha': 9.118986608630715, 'reg_lambda': 2.0639245275396218e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:57:57,803] Trial 183 finished with value: -0.9353252148585439 and parameters: {'learning_rate': 0.03443048285788272, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5150765022408474, 'bagging_fraction': 0.7078339693905232, 'reg_alpha': 4.76690507052742, 'reg_lambda': 1.4366313392522739e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:58:05,401] Trial 184 finished with value: -0.9342725743404666 and parameters: {'learning_rate': 0.03476263335643082, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5144914875445119, 'bagging_fraction': 0.7041284455354292, 'reg_alpha': 3.3284350889641843, 'reg_lambda': 1.3864952826093588e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:58:11,760] Trial 185 finished with value: -0.9336844521803261 and parameters: {'learning_rate': 0.040904233582286585, 'num_leaves': 19, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5366093900044184, 'bagging_fraction': 0.6499852324699446, 'reg_alpha': 5.852190740699685, 'reg_lambda': 2.268321971750365e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:58:16,703] Trial 186 finished with value: -0.9314757052856972 and parameters: {'learning_rate': 0.029872951061403395, 'num_leaves': 12, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5008338105219996, 'bagging_fraction': 0.6893747732329316, 'reg_alpha': 3.901699789640517, 'reg_lambda': 4.0289185617735385e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:58:25,163] Trial 187 finished with value: -0.9352297564927224 and parameters: {'learning_rate': 0.036450395463377756, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5177512130595614, 'bagging_fraction': 0.7111358540760918, 'reg_alpha': 9.651151442140266, 'reg_lambda': 1.468794493278703e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:58:32,786] Trial 188 finished with value: -0.9333597385355255 and parameters: {'learning_rate': 0.03730120299212558, 'num_leaves': 25, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.5155473484540091, 'bagging_fraction': 0.7070185087471398, 'reg_alpha': 8.908258956749258, 'reg_lambda': 1.3884463457889045e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:58:44,436] Trial 189 finished with value: -0.9339766539807264 and parameters: {'learning_rate': 0.042090401986481916, 'num_leaves': 49, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5217288737462803, 'bagging_fraction': 0.6759635520778967, 'reg_alpha': 6.217351987164664, 'reg_lambda': 1.0279560577056442e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:58:54,879] Trial 190 finished with value: -0.9331207512442241 and parameters: {'learning_rate': 0.036284287434254194, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 32, 'feature_fraction': 0.5082923482883489, 'bagging_fraction': 0.7115518391379823, 'reg_alpha': 2.067215610924686, 'reg_lambda': 3.0634504192580306e-06}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:59:03,413] Trial 191 finished with value: -0.9346326238685503 and parameters: {'learning_rate': 0.03276414770052275, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5377848438600612, 'bagging_fraction': 0.6963928779957994, 'reg_alpha': 9.777581771919424, 'reg_lambda': 2.0491726458039956e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:59:12,531] Trial 192 finished with value: -0.935760434675958 and parameters: {'learning_rate': 0.03443541045978789, 'num_leaves': 32, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5292896439186329, 'bagging_fraction': 0.9238170881655938, 'reg_alpha': 4.232439799740176, 'reg_lambda': 1.5461796613316166e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:59:19,612] Trial 193 finished with value: -0.9346710553995218 and parameters: {'learning_rate': 0.03447606767304995, 'num_leaves': 22, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5232512525373239, 'bagging_fraction': 0.8462145605736469, 'reg_alpha': 4.372691410616323, 'reg_lambda': 2.9100143439212333e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:59:29,695] Trial 194 finished with value: -0.9351615269345145 and parameters: {'learning_rate': 0.030123177520323237, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5459674826985637, 'bagging_fraction': 0.8605886207338499, 'reg_alpha': 5.431257420020553, 'reg_lambda': 1.0089660193364526e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:59:38,495] Trial 195 finished with value: -0.9341783317507405 and parameters: {'learning_rate': 0.03841762093653119, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5579004517086213, 'bagging_fraction': 0.8977954901187861, 'reg_alpha': 1.9678286334044224, 'reg_lambda': 1.615783569530868e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:59:49,363] Trial 196 finished with value: -0.9339678940262325 and parameters: {'learning_rate': 0.03543067692349756, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5145290072048797, 'bagging_fraction': 0.7194177767611972, 'reg_alpha': 4.0046408069576085, 'reg_lambda': 2.6014561101857903e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 07:59:57,651] Trial 197 finished with value: -0.9346030352917502 and parameters: {'learning_rate': 0.031112879426371712, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.530188421815321, 'bagging_fraction': 0.9356052893587504, 'reg_alpha': 6.466565235559564, 'reg_lambda': 1.4313871961263417e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:00:07,594] Trial 198 finished with value: -0.9359858091389576 and parameters: {'learning_rate': 0.03390904294295416, 'num_leaves': 36, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5432189004782323, 'bagging_fraction': 0.9596435529187335, 'reg_alpha': 1.4052755385889844, 'reg_lambda': 1.0002236851034973e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:00:17,797] Trial 199 finished with value: -0.9357230287678283 and parameters: {'learning_rate': 0.033914817435385006, 'num_leaves': 37, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5423524525361852, 'bagging_fraction': 0.9229372443107665, 'reg_alpha': 2.290289122523194, 'reg_lambda': 4.4279852807196924e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:00:29,776] Trial 200 finished with value: -0.9353575669661566 and parameters: {'learning_rate': 0.02773734394298706, 'num_leaves': 46, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5444007823656233, 'bagging_fraction': 0.9835920925279238, 'reg_alpha': 1.297532306488641, 'reg_lambda': 4.8073246443026483e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:00:40,391] Trial 201 finished with value: -0.9347559566208752 and parameters: {'learning_rate': 0.027957360598960205, 'num_leaves': 39, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5446415771586711, 'bagging_fraction': 0.9719253753221275, 'reg_alpha': 1.2145965240647951, 'reg_lambda': 7.781962715034553e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:00:51,671] Trial 202 finished with value: -0.934850927805407 and parameters: {'learning_rate': 0.03317352742757713, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.538861666857773, 'bagging_fraction': 0.992882698165787, 'reg_alpha': 1.6970808759014626, 'reg_lambda': 4.879447103940488e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:01:01,373] Trial 203 finished with value: -0.9345708844689377 and parameters: {'learning_rate': 0.030885981771989746, 'num_leaves': 35, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5565179111244556, 'bagging_fraction': 0.9199918517982799, 'reg_alpha': 0.6766090615116547, 'reg_lambda': 3.403307225456969e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:01:13,903] Trial 204 finished with value: -0.9343547301187584 and parameters: {'learning_rate': 0.026432529462486188, 'num_leaves': 49, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5296818807018012, 'bagging_fraction': 0.96629153786049, 'reg_alpha': 2.32794779947995, 'reg_lambda': 1.1336799140129926e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:01:24,054] Trial 205 finished with value: -0.9344656141696437 and parameters: {'learning_rate': 0.033798985830615025, 'num_leaves': 37, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5494735850480678, 'bagging_fraction': 0.8965020962765471, 'reg_alpha': 1.2986193394877055, 'reg_lambda': 2.2406113635945516e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:01:35,705] Trial 206 finished with value: -0.9349093242819891 and parameters: {'learning_rate': 0.029803461482525148, 'num_leaves': 45, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5403055881135679, 'bagging_fraction': 0.9293352146095755, 'reg_alpha': 0.9883249062535273, 'reg_lambda': 5.4224014866610215e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:01:45,019] Trial 207 finished with value: -0.934228752160303 and parameters: {'learning_rate': 0.03189327002420298, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5265272595676239, 'bagging_fraction': 0.9674619962381839, 'reg_alpha': 2.3442293938690972, 'reg_lambda': 3.413340062822703e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:01:56,135] Trial 208 finished with value: -0.9338896816206669 and parameters: {'learning_rate': 0.028515877167469592, 'num_leaves': 41, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5643287595028774, 'bagging_fraction': 0.9950140634203832, 'reg_alpha': 3.5685688184344726, 'reg_lambda': 1.0213173250137646e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:02:10,082] Trial 209 finished with value: -0.9331878639461738 and parameters: {'learning_rate': 0.033994418582661154, 'num_leaves': 52, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.8160822949972002, 'bagging_fraction': 0.9548012584741101, 'reg_alpha': 0.5483014123297563, 'reg_lambda': 1.976614697479947e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:02:19,643] Trial 210 finished with value: -0.9340005916958141 and parameters: {'learning_rate': 0.031350109237123586, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5478572253677153, 'bagging_fraction': 0.9445568968273267, 'reg_alpha': 1.5994243317528378, 'reg_lambda': 2.4432604234839477e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:02:28,099] Trial 211 finished with value: -0.934798484615848 and parameters: {'learning_rate': 0.03602635768943169, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5191520502532805, 'bagging_fraction': 0.9767450169120715, 'reg_alpha': 2.8435598451347386, 'reg_lambda': 1.5367941278613614e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:02:36,668] Trial 212 finished with value: -0.9350536155065275 and parameters: {'learning_rate': 0.034383744550267846, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5334607761932573, 'bagging_fraction': 0.9837837627116363, 'reg_alpha': 4.153556106775343, 'reg_lambda': 1.5245321618283314e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:02:44,014] Trial 213 finished with value: -0.9347133466068798 and parameters: {'learning_rate': 0.0388828835537423, 'num_leaves': 24, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5002057378083555, 'bagging_fraction': 0.5140025668360881, 'reg_alpha': 0.9897077659056205, 'reg_lambda': 2.2605586162146562e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:02:47,485] Trial 214 finished with value: -0.9233888922695933 and parameters: {'learning_rate': 0.03616725273436032, 'num_leaves': 40, 'max_depth': 3, 'min_child_samples': 12, 'feature_fraction': 0.5158679105630822, 'bagging_fraction': 0.9556959259000118, 'reg_alpha': 2.255425222581096, 'reg_lambda': 1.392856360066829e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:02:53,544] Trial 215 finished with value: -0.9323937165207301 and parameters: {'learning_rate': 0.03249066727832315, 'num_leaves': 17, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5246517592752933, 'bagging_fraction': 0.9604015960642281, 'reg_alpha': 0.033554643233855444, 'reg_lambda': 2.914944962404831e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:03:04,340] Trial 216 finished with value: -0.9297725749413487 and parameters: {'learning_rate': 0.02954110669400786, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 69, 'feature_fraction': 0.5382159249200698, 'bagging_fraction': 0.9126124169432548, 'reg_alpha': 1.4931707278074124, 'reg_lambda': 1.0016834524525725e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:03:13,973] Trial 217 finished with value: -0.9277441421590011 and parameters: {'learning_rate': 0.034168675123239414, 'num_leaves': 32, 'max_depth': 15, 'min_child_samples': 87, 'feature_fraction': 0.5080329147268341, 'bagging_fraction': 0.8939265198242937, 'reg_alpha': 0.013484372919673256, 'reg_lambda': 4.267730207189557e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:03:25,855] Trial 218 finished with value: -0.935098902392887 and parameters: {'learning_rate': 0.03181800026397823, 'num_leaves': 45, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5550963985422456, 'bagging_fraction': 0.7046554470553575, 'reg_alpha': 6.258434076443374, 'reg_lambda': 1.9003640006254538e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:03:33,220] Trial 219 finished with value: -0.9340824409402523 and parameters: {'learning_rate': 0.038099961792970066, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.532713640784208, 'bagging_fraction': 0.9330213833822951, 'reg_alpha': 3.477712847788355, 'reg_lambda': 1.005489018175896e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:03:42,778] Trial 220 finished with value: -0.9347520897640019 and parameters: {'learning_rate': 0.035705720047006104, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5438540429340132, 'bagging_fraction': 0.6879616830867522, 'reg_alpha': 0.6249570105695513, 'reg_lambda': 2.4771043070536296e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:03:50,714] Trial 221 finished with value: -0.9346531752084862 and parameters: {'learning_rate': 0.037073195840033955, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5518370957435996, 'bagging_fraction': 0.7157752001605746, 'reg_alpha': 9.581285912732486, 'reg_lambda': 1.570639259825133e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:03:59,802] Trial 222 finished with value: -0.9343698484984778 and parameters: {'learning_rate': 0.033204076395911206, 'num_leaves': 30, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5684841292632886, 'bagging_fraction': 0.8806328863423806, 'reg_alpha': 7.196600459661852, 'reg_lambda': 1.4791754656231509e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:04:09,420] Trial 223 finished with value: -0.9346636189718907 and parameters: {'learning_rate': 0.03466876291040253, 'num_leaves': 36, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5230090479728475, 'bagging_fraction': 0.707088106370053, 'reg_alpha': 4.809513574075728, 'reg_lambda': 1.4189003157645802e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:04:17,286] Trial 224 finished with value: -0.9335078535672936 and parameters: {'learning_rate': 0.04078536134128025, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5365026945499501, 'bagging_fraction': 0.7238500709739726, 'reg_alpha': 2.4567291523174033, 'reg_lambda': 2.4536829032846398e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:04:28,113] Trial 225 finished with value: -0.9356642265834965 and parameters: {'learning_rate': 0.03063757415704411, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5129155402103971, 'bagging_fraction': 0.7013763984209751, 'reg_alpha': 0.1882247301000811, 'reg_lambda': 1.0501976543102591e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:04:39,311] Trial 226 finished with value: -0.9348475882163128 and parameters: {'learning_rate': 0.02801398405547095, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.515050228762792, 'bagging_fraction': 0.9864531008411054, 'reg_alpha': 0.22624931331179565, 'reg_lambda': 3.797606809070775e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:04:51,473] Trial 227 finished with value: -0.9344178868498368 and parameters: {'learning_rate': 0.03022073431979904, 'num_leaves': 47, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5110147787645484, 'bagging_fraction': 0.6977741216815385, 'reg_alpha': 0.33409298658570924, 'reg_lambda': 2.1546697922685732e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:05:01,986] Trial 228 finished with value: -0.9355387651512918 and parameters: {'learning_rate': 0.03156377691662361, 'num_leaves': 41, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5253010112763535, 'bagging_fraction': 0.9474036964956896, 'reg_alpha': 0.07722511523335554, 'reg_lambda': 1.0281259775424032e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:05:13,449] Trial 229 finished with value: -0.9342867445098383 and parameters: {'learning_rate': 0.02659683952976094, 'num_leaves': 43, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5275440791831784, 'bagging_fraction': 0.9259736820848723, 'reg_alpha': 0.15757375572303353, 'reg_lambda': 3.5376170234601834e-05}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:05:24,005] Trial 230 finished with value: -0.9345926586540273 and parameters: {'learning_rate': 0.02934225467873361, 'num_leaves': 38, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5432956096693798, 'bagging_fraction': 0.9468921345192781, 'reg_alpha': 0.07194396678922754, 'reg_lambda': 1.0470062437456934e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:05:33,094] Trial 231 finished with value: -0.9342236077699487 and parameters: {'learning_rate': 0.04970857353094288, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5216612583162388, 'bagging_fraction': 0.6991204213720618, 'reg_alpha': 0.17236973328709979, 'reg_lambda': 1.0204206771305903e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:05:41,684] Trial 232 finished with value: -0.9342374831127841 and parameters: {'learning_rate': 0.03185903785123841, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5310021977075972, 'bagging_fraction': 0.9374899999385419, 'reg_alpha': 0.049295051801434904, 'reg_lambda': 1.5912125533806523e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:05:52,130] Trial 233 finished with value: -0.9345817033451974 and parameters: {'learning_rate': 0.03308222780492875, 'num_leaves': 41, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5080849630108293, 'bagging_fraction': 0.6848822564254529, 'reg_alpha': 0.10418853277474129, 'reg_lambda': 1.004089748366275e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:06:01,681] Trial 234 finished with value: -0.9348024503671096 and parameters: {'learning_rate': 0.030501033079370733, 'num_leaves': 33, 'max_depth': 12, 'min_child_samples': 10, 'feature_fraction': 0.5193237962248048, 'bagging_fraction': 0.6308922360705478, 'reg_alpha': 0.026738835709926072, 'reg_lambda': 2.0152921932993173e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:06:13,176] Trial 235 finished with value: -0.9339094622334225 and parameters: {'learning_rate': 0.03412292182560381, 'num_leaves': 46, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.535953353323628, 'bagging_fraction': 0.9457765674103467, 'reg_alpha': 0.07918195986649491, 'reg_lambda': 1.4946696432437273e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:06:23,576] Trial 236 finished with value: -0.9345479147279891 and parameters: {'learning_rate': 0.031402112945969694, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5245937610556398, 'bagging_fraction': 0.7132473891008713, 'reg_alpha': 0.37560037777774596, 'reg_lambda': 3.304864612973939e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:06:30,774] Trial 237 finished with value: -0.9345011991992447 and parameters: {'learning_rate': 0.03590817974329428, 'num_leaves': 22, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.544378071690422, 'bagging_fraction': 0.7329717216207993, 'reg_alpha': 0.9782101732331077, 'reg_lambda': 2.0744802973347078e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:06:41,660] Trial 238 finished with value: -0.9338644203078478 and parameters: {'learning_rate': 0.028817997031133743, 'num_leaves': 41, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5093073011589927, 'bagging_fraction': 0.6771770651111009, 'reg_alpha': 0.01657409081203601, 'reg_lambda': 1.5305656338450752e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:06:50,762] Trial 239 finished with value: -0.9349247509548545 and parameters: {'learning_rate': 0.03264440871036663, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5309613740163301, 'bagging_fraction': 0.6909641783034589, 'reg_alpha': 0.20161758216472986, 'reg_lambda': 2.9949770916213436e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:07:03,599] Trial 240 finished with value: -0.9346962166914317 and parameters: {'learning_rate': 0.03054573969498087, 'num_leaves': 50, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5560831945033557, 'bagging_fraction': 0.7047093217339316, 'reg_alpha': 0.04084909539791284, 'reg_lambda': 5.818953721071943e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:07:11,746] Trial 241 finished with value: -0.935680745814532 and parameters: {'learning_rate': 0.03688966651507873, 'num_leaves': 28, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5481436979598361, 'bagging_fraction': 0.7158329913177818, 'reg_alpha': 9.667181185584687, 'reg_lambda': 1.0459882121896e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:07:19,989] Trial 242 finished with value: -0.9349529302457037 and parameters: {'learning_rate': 0.0344475875903893, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5419572680261955, 'bagging_fraction': 0.7214017611378468, 'reg_alpha': 4.934180898630112, 'reg_lambda': 1.4192120692954273e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:07:29,343] Trial 243 finished with value: -0.9348017517029649 and parameters: {'learning_rate': 0.03599627162248749, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5345139844471254, 'bagging_fraction': 0.9157566961621266, 'reg_alpha': 3.142472159926702, 'reg_lambda': 1.3882188853961737e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:07:39,891] Trial 244 finished with value: -0.9354714950704177 and parameters: {'learning_rate': 0.03287014313440146, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.552576753241244, 'bagging_fraction': 0.7095146092556087, 'reg_alpha': 5.658758763620974, 'reg_lambda': 1.0184344161461742e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:07:50,028] Trial 245 finished with value: -0.9343041943341339 and parameters: {'learning_rate': 0.032422413882180846, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5607336342137387, 'bagging_fraction': 0.700054756431259, 'reg_alpha': 1.4108043314336451, 'reg_lambda': 1.0658486010739092e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:08:01,316] Trial 246 finished with value: -0.9350228326540436 and parameters: {'learning_rate': 0.03340044194654466, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5494588172324048, 'bagging_fraction': 0.7308792899545319, 'reg_alpha': 1.8187955012049644, 'reg_lambda': 2.0982173017033265e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:08:11,568] Trial 247 finished with value: -0.9344327116985508 and parameters: {'learning_rate': 0.03101196218353476, 'num_leaves': 38, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5493923614590595, 'bagging_fraction': 0.6109033058273321, 'reg_alpha': 4.3727129598854475, 'reg_lambda': 1.0036948672462768e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:08:21,288] Trial 248 finished with value: -0.9350561440241615 and parameters: {'learning_rate': 0.02830631701015889, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5409195474232934, 'bagging_fraction': 0.713323865521528, 'reg_alpha': 0.0076943440614775475, 'reg_lambda': 2.120823649737768e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:08:32,928] Trial 249 finished with value: -0.9345530010361593 and parameters: {'learning_rate': 0.0380620402877764, 'num_leaves': 47, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5625957062521075, 'bagging_fraction': 0.6880658742169659, 'reg_alpha': 0.11505480452846856, 'reg_lambda': 1.4523827602227812e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:08:40,494] Trial 250 finished with value: -0.9353339546627859 and parameters: {'learning_rate': 0.034070004629815326, 'num_leaves': 24, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.553264141596064, 'bagging_fraction': 0.7012607532390284, 'reg_alpha': 3.1306996559237867, 'reg_lambda': 2.786276544576838e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:08:47,066] Trial 251 finished with value: -0.9314881176848504 and parameters: {'learning_rate': 0.031883675363357, 'num_leaves': 19, 'max_depth': 15, 'min_child_samples': 37, 'feature_fraction': 0.5556760703122867, 'bagging_fraction': 0.7033869718391925, 'reg_alpha': 2.310958889287485, 'reg_lambda': 2.861763786636455e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:08:55,798] Trial 252 finished with value: -0.9342738827477125 and parameters: {'learning_rate': 0.029599265555785036, 'num_leaves': 26, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.6741366439476525, 'bagging_fraction': 0.7199329912789285, 'reg_alpha': 2.8800247691129592, 'reg_lambda': 1.004328322456708e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:09:03,314] Trial 253 finished with value: -0.9333057127826143 and parameters: {'learning_rate': 0.03357062915973797, 'num_leaves': 22, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5726427545029604, 'bagging_fraction': 0.6932990863148731, 'reg_alpha': 6.073369048591868, 'reg_lambda': 3.387768300714311e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:09:14,402] Trial 254 finished with value: -0.9352809862236715 and parameters: {'learning_rate': 0.0309402553851828, 'num_leaves': 42, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5284304792420751, 'bagging_fraction': 0.9583502847973068, 'reg_alpha': 0.795498643925352, 'reg_lambda': 4.655677257121956e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:09:23,276] Trial 255 finished with value: -0.9338242847148613 and parameters: {'learning_rate': 0.027220621541841898, 'num_leaves': 30, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5306454892091303, 'bagging_fraction': 0.941371761696768, 'reg_alpha': 0.7657300489894212, 'reg_lambda': 6.414025316764787e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:09:34,699] Trial 256 finished with value: -0.934976936605405 and parameters: {'learning_rate': 0.029710650389908097, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5519355989523708, 'bagging_fraction': 0.9600264888890532, 'reg_alpha': 0.46640543355367725, 'reg_lambda': 2.187453523741831e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:09:48,044] Trial 257 finished with value: -0.9344726157919874 and parameters: {'learning_rate': 0.031841891529299254, 'num_leaves': 55, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.5374627521288033, 'bagging_fraction': 0.9771947832951832, 'reg_alpha': 0.30160661738835753, 'reg_lambda': 1.0186472925254351e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:09:55,576] Trial 258 finished with value: -0.9338389808415749 and parameters: {'learning_rate': 0.030677046570462302, 'num_leaves': 24, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5632457205458381, 'bagging_fraction': 0.955221911928692, 'reg_alpha': 1.0423906852428646, 'reg_lambda': 4.755382099603229e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:10:01,455] Trial 259 finished with value: -0.9342127132706189 and parameters: {'learning_rate': 0.03371417395653794, 'num_leaves': 16, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.524211155134917, 'bagging_fraction': 0.9715745681920921, 'reg_alpha': 0.019314443946592076, 'reg_lambda': 0.00019377321174529066}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:10:13,447] Trial 260 finished with value: -0.9337469689114738 and parameters: {'learning_rate': 0.02741304820543073, 'num_leaves': 40, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.7515788028430298, 'bagging_fraction': 0.7439928151407351, 'reg_alpha': 0.14829028164834537, 'reg_lambda': 1.1608814113491618e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:10:22,889] Trial 261 finished with value: -0.9338448660235756 and parameters: {'learning_rate': 0.03161132403954165, 'num_leaves': 33, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5457391672491072, 'bagging_fraction': 0.7268776191421427, 'reg_alpha': 0.6292924280007154, 'reg_lambda': 2.0197087586177696e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:10:35,649] Trial 262 finished with value: -0.935333188698227 and parameters: {'learning_rate': 0.028861659763022813, 'num_leaves': 50, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5328601046779928, 'bagging_fraction': 0.7106750625838227, 'reg_alpha': 0.010359707253266091, 'reg_lambda': 1.566436782867583e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:10:48,350] Trial 263 finished with value: -0.934081014019203 and parameters: {'learning_rate': 0.02455718863415568, 'num_leaves': 49, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5165053109110638, 'bagging_fraction': 0.7181367150393644, 'reg_alpha': 0.010898790874195022, 'reg_lambda': 1.0112747939008116e-06}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:11:00,281] Trial 264 finished with value: -0.9353606537173975 and parameters: {'learning_rate': 0.026149088358904993, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5302938821994978, 'bagging_fraction': 0.7597624322191845, 'reg_alpha': 0.02462192257863383, 'reg_lambda': 4.35020859126135e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:11:09,265] Trial 265 finished with value: -0.9329559089946037 and parameters: {'learning_rate': 0.026617444632712796, 'num_leaves': 52, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.5355836753698162, 'bagging_fraction': 0.7781574871237763, 'reg_alpha': 0.031654430064272966, 'reg_lambda': 1.7285319573425405e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:11:21,299] Trial 266 finished with value: -0.9341357551613402 and parameters: {'learning_rate': 0.028386899674878712, 'num_leaves': 46, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5082097917832862, 'bagging_fraction': 0.7630089417758505, 'reg_alpha': 0.012219171039938045, 'reg_lambda': 8.104054671460167e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:11:32,068] Trial 267 finished with value: -0.9349752616122449 and parameters: {'learning_rate': 0.02518972665504398, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5288146149460715, 'bagging_fraction': 0.7480515631039505, 'reg_alpha': 0.030856115399609547, 'reg_lambda': 2.8642004844845608e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:11:40,660] Trial 268 finished with value: -0.9329449499772042 and parameters: {'learning_rate': 0.023580115332956144, 'num_leaves': 28, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5191162499062184, 'bagging_fraction': 0.7559904979106485, 'reg_alpha': 0.01937335816021572, 'reg_lambda': 1.8050588166095304e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:11:51,996] Trial 269 finished with value: -0.9347070624070359 and parameters: {'learning_rate': 0.02901444563197935, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5001747661530888, 'bagging_fraction': 0.5386828846772131, 'reg_alpha': 0.004808112293715585, 'reg_lambda': 1.4563535406669286e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:12:05,707] Trial 270 finished with value: -0.9339318058813556 and parameters: {'learning_rate': 0.025895193694001572, 'num_leaves': 56, 'max_depth': 13, 'min_child_samples': 15, 'feature_fraction': 0.5562404228717447, 'bagging_fraction': 0.9043104419472348, 'reg_alpha': 0.053044095399353, 'reg_lambda': 2.6266819168790437e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:12:15,617] Trial 271 finished with value: -0.93445123239759 and parameters: {'learning_rate': 0.043172422665619985, 'num_leaves': 36, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5396516009174713, 'bagging_fraction': 0.7345646135236118, 'reg_alpha': 0.020309769466464112, 'reg_lambda': 4.1455205387328896e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:12:40,312] Trial 272 finished with value: -0.9314107717096529 and parameters: {'learning_rate': 0.03805868209611795, 'num_leaves': 206, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5297958457918016, 'bagging_fraction': 0.7064376530539811, 'reg_alpha': 0.07629198001442931, 'reg_lambda': 1.0158671592279256e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:12:47,236] Trial 273 finished with value: -0.9312413357560321 and parameters: {'learning_rate': 0.035364429655634674, 'num_leaves': 20, 'max_depth': 15, 'min_child_samples': 62, 'feature_fraction': 0.5453454783142114, 'bagging_fraction': 0.7137970473262878, 'reg_alpha': 0.030803336768182386, 'reg_lambda': 1.95462728722034e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:12:59,690] Trial 274 finished with value: -0.9338574869322648 and parameters: {'learning_rate': 0.033149628973386844, 'num_leaves': 50, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5193006994819442, 'bagging_fraction': 0.7698883527365437, 'reg_alpha': 6.7801714744790225, 'reg_lambda': 1.5883805169326468e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:13:08,712] Trial 275 finished with value: -0.9351528203168424 and parameters: {'learning_rate': 0.029353276010245854, 'num_leaves': 30, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5354472122035902, 'bagging_fraction': 0.736031357097603, 'reg_alpha': 0.013358742203428422, 'reg_lambda': 2.9112649765244132e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:13:31,855] Trial 276 finished with value: -0.9322183661109733 and parameters: {'learning_rate': 0.036903557036191866, 'num_leaves': 186, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5734359835088177, 'bagging_fraction': 0.7086075228914782, 'reg_alpha': 0.03833640749164244, 'reg_lambda': 1.0008695281140819e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:13:36,885] Trial 277 finished with value: -0.9299713543843289 and parameters: {'learning_rate': 0.0274052084675501, 'num_leaves': 12, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5528309798173225, 'bagging_fraction': 0.7273880719936636, 'reg_alpha': 5.316362619866866, 'reg_lambda': 5.042850879129594e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:13:44,841] Trial 278 finished with value: -0.9352475361866723 and parameters: {'learning_rate': 0.034643251127225716, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5122608941429965, 'bagging_fraction': 0.6972156356501109, 'reg_alpha': 0.007252871181874284, 'reg_lambda': 1.5166600172077487e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:13:56,345] Trial 279 finished with value: -0.9336344853510037 and parameters: {'learning_rate': 0.029994945675250476, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.7122465412391006, 'bagging_fraction': 0.9970868104383408, 'reg_alpha': 0.05061067498591407, 'reg_lambda': 2.4579499080418213e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:14:06,965] Trial 280 finished with value: -0.9286499647766918 and parameters: {'learning_rate': 0.03256156908737188, 'num_leaves': 34, 'max_depth': 14, 'min_child_samples': 54, 'feature_fraction': 0.7326124193772204, 'bagging_fraction': 0.7534768752550847, 'reg_alpha': 3.548851161107044, 'reg_lambda': 1.4955206209787866e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:14:18,314] Trial 281 finished with value: -0.9335644263163912 and parameters: {'learning_rate': 0.033972434838955096, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5394060201134484, 'bagging_fraction': 0.7163471214934833, 'reg_alpha': 0.02452427945526799, 'reg_lambda': 3.284440534181453e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:14:26,796] Trial 282 finished with value: -0.9346613481674185 and parameters: {'learning_rate': 0.04024719483529845, 'num_leaves': 30, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.525916451049473, 'bagging_fraction': 0.6882290275270596, 'reg_alpha': 0.09571810481702703, 'reg_lambda': 2.1699735964737748e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:14:36,999] Trial 283 finished with value: -0.9342445924749022 and parameters: {'learning_rate': 0.031124504311692135, 'num_leaves': 37, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5601729186310009, 'bagging_fraction': 0.7006833294795894, 'reg_alpha': 7.4418687616480845, 'reg_lambda': 1.4529091123476962e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:14:48,313] Trial 284 finished with value: -0.933382592135302 and parameters: {'learning_rate': 0.046849513336169, 'num_leaves': 48, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5466985990247536, 'bagging_fraction': 0.7403523653555162, 'reg_alpha': 0.013178630005891052, 'reg_lambda': 6.815893379710688e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:14:56,487] Trial 285 finished with value: -0.9355692409044762 and parameters: {'learning_rate': 0.03666411678575174, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5185592952700177, 'bagging_fraction': 0.8192626841874138, 'reg_alpha': 2.9653244413296136, 'reg_lambda': 4.458113464503802e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:02,570] Trial 286 finished with value: -0.9324714206350052 and parameters: {'learning_rate': 0.03936506564636037, 'num_leaves': 17, 'max_depth': 15, 'min_child_samples': 28, 'feature_fraction': 0.5333387544787931, 'bagging_fraction': 0.7961299695476829, 'reg_alpha': 8.281924676602834e-06, 'reg_lambda': 4.391452520500876e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:09,883] Trial 287 finished with value: -0.9348945056390986 and parameters: {'learning_rate': 0.037139706440076956, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5115861481981867, 'bagging_fraction': 0.7657195175451589, 'reg_alpha': 2.0926634461406968, 'reg_lambda': 1.3656484445470734e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:17,883] Trial 288 finished with value: -0.9344812667016859 and parameters: {'learning_rate': 0.0354934499707507, 'num_leaves': 28, 'max_depth': 7, 'min_child_samples': 13, 'feature_fraction': 0.5262028038331628, 'bagging_fraction': 0.9210645038886472, 'reg_alpha': 0.022019057624913338, 'reg_lambda': 1.0127393316930157e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:22,694] Trial 289 finished with value: -0.9338588130816933 and parameters: {'learning_rate': 0.05145645692146509, 'num_leaves': 26, 'max_depth': 4, 'min_child_samples': 10, 'feature_fraction': 0.5663455470224414, 'bagging_fraction': 0.8445755702478437, 'reg_alpha': 4.2992710157136, 'reg_lambda': 2.1288919353356103e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:32,356] Trial 290 finished with value: -0.9330736400583852 and parameters: {'learning_rate': 0.027983651032514687, 'num_leaves': 34, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.5410699697808051, 'bagging_fraction': 0.7258719929552702, 'reg_alpha': 9.939289635685922, 'reg_lambda': 3.1928603464218256e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:39,299] Trial 291 finished with value: -0.9341501988051141 and parameters: {'learning_rate': 0.037136042296353505, 'num_leaves': 21, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5518410224160261, 'bagging_fraction': 0.8141950784450489, 'reg_alpha': 0.009076225223181793, 'reg_lambda': 1.4250303391509121e-05}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:48,181] Trial 292 finished with value: -0.9354205871459259 and parameters: {'learning_rate': 0.03431055718096152, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5205130948717493, 'bagging_fraction': 0.8289496282794384, 'reg_alpha': 0.06849367018260376, 'reg_lambda': 0.11866658098050434}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:15:55,261] Trial 293 finished with value: -0.9331684906414512 and parameters: {'learning_rate': 0.039838596710000174, 'num_leaves': 17, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.8486197238097275, 'bagging_fraction': 0.8287356463192651, 'reg_alpha': 0.126368996481799, 'reg_lambda': 1.2852731192024782}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:16:04,192] Trial 294 finished with value: -0.9347428390605027 and parameters: {'learning_rate': 0.035142406352774894, 'num_leaves': 30, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5089204895091026, 'bagging_fraction': 0.8752034014472768, 'reg_alpha': 0.06294308372651866, 'reg_lambda': 0.0035342180625885394}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:16:12,012] Trial 295 finished with value: -0.9343804900078851 and parameters: {'learning_rate': 0.033560656358109904, 'num_leaves': 25, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.5198415816663507, 'bagging_fraction': 0.8890585884744133, 'reg_alpha': 0.045780300330687744, 'reg_lambda': 0.001552419782433976}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:16:16,131] Trial 296 finished with value: -0.932208430715029 and parameters: {'learning_rate': 0.04263866741947575, 'num_leaves': 9, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.535529719316993, 'bagging_fraction': 0.8086975211851527, 'reg_alpha': 0.16796285421037152, 'reg_lambda': 0.0004394444373911328}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:16:25,166] Trial 297 finished with value: -0.9338187224479014 and parameters: {'learning_rate': 0.03698039020573676, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5257361267657352, 'bagging_fraction': 0.7121146892741982, 'reg_alpha': 0.10325628248864129, 'reg_lambda': 2.185053796752961e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:16:34,977] Trial 298 finished with value: -0.9351536299537384 and parameters: {'learning_rate': 0.03473727618572206, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5011638495144503, 'bagging_fraction': 0.7849306266145286, 'reg_alpha': 0.24024022973132533, 'reg_lambda': 6.699955479703171e-05}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:16:42,982] Trial 299 finished with value: -0.9359048657772621 and parameters: {'learning_rate': 0.03218586159590649, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5482188171211143, 'bagging_fraction': 0.8619656024628073, 'reg_alpha': 2.9150828943036933, 'reg_lambda': 0.01104296594489997}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:16:53,571] Trial 300 finished with value: -0.9338346204439223 and parameters: {'learning_rate': 0.031593875964473384, 'num_leaves': 39, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.5610823331452932, 'bagging_fraction': 0.8505333255172902, 'reg_alpha': 1.7854700025682861, 'reg_lambda': 0.2357652118029625}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:17:00,836] Trial 301 finished with value: -0.9337658077507032 and parameters: {'learning_rate': 0.029823421929076412, 'num_leaves': 21, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5506491359614124, 'bagging_fraction': 0.8630763439443387, 'reg_alpha': 2.882380517475616, 'reg_lambda': 0.06327625944254092}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:17:10,407] Trial 302 finished with value: -0.9340161338383195 and parameters: {'learning_rate': 0.02596261255834411, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.6946440643880389, 'bagging_fraction': 0.8211033265584696, 'reg_alpha': 1.3918461120626875, 'reg_lambda': 0.49502733848992886}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:17:20,631] Trial 303 finished with value: -0.9273982081100463 and parameters: {'learning_rate': 0.032924475612583, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 93, 'feature_fraction': 0.5436088360205532, 'bagging_fraction': 0.906319434605594, 'reg_alpha': 0.06678460797725132, 'reg_lambda': 0.04593844269920941}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:17:50,818] Trial 304 finished with value: -0.9304079322597363 and parameters: {'learning_rate': 0.030860449840367194, 'num_leaves': 225, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5696682408961649, 'bagging_fraction': 0.8658499334016976, 'reg_alpha': 2.4273499634533797, 'reg_lambda': 0.14093748977301576}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:18:01,823] Trial 305 finished with value: -0.9334728664114195 and parameters: {'learning_rate': 0.038101937951034885, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5538781119208879, 'bagging_fraction': 0.931266496409202, 'reg_alpha': 5.885648837650715, 'reg_lambda': 0.009210165722611257}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:18:25,449] Trial 306 finished with value: -0.9333959033768356 and parameters: {'learning_rate': 0.028927200651491847, 'num_leaves': 131, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.536799238760446, 'bagging_fraction': 0.9473659528499518, 'reg_alpha': 1.409000698887873, 'reg_lambda': 0.018044032071060253}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:18:36,227] Trial 307 finished with value: -0.9348650005863328 and parameters: {'learning_rate': 0.03270302470301375, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5773271442428012, 'bagging_fraction': 0.722283653271552, 'reg_alpha': 0.038179120261507674, 'reg_lambda': 0.015423662456663592}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:18:43,684] Trial 308 finished with value: -0.933903265227421 and parameters: {'learning_rate': 0.05586291371792497, 'num_leaves': 28, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5447341289952212, 'bagging_fraction': 0.7443249234372714, 'reg_alpha': 0.09305302104015833, 'reg_lambda': 0.15585608211473026}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:18:51,145] Trial 309 finished with value: -0.9328803106105332 and parameters: {'learning_rate': 0.03586989338629297, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5614364292034485, 'bagging_fraction': 0.8235470710551983, 'reg_alpha': 2.7068033243899454, 'reg_lambda': 0.04187278563024462}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:19:03,447] Trial 310 finished with value: -0.934318051848718 and parameters: {'learning_rate': 0.024514512062333123, 'num_leaves': 46, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5302343583769046, 'bagging_fraction': 0.7049147713806102, 'reg_alpha': 0.18021502898709085, 'reg_lambda': 0.11246219708446271}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:19:09,086] Trial 311 finished with value: -0.9314404912407496 and parameters: {'learning_rate': 0.03159201157955805, 'num_leaves': 15, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.551066467300124, 'bagging_fraction': 0.9851069491564468, 'reg_alpha': 4.204457628326442, 'reg_lambda': 7.665985040059756e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:19:20,418] Trial 312 finished with value: -0.9279690334872707 and parameters: {'learning_rate': 0.027831667620277237, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 42, 'feature_fraction': 0.9675444483651551, 'bagging_fraction': 0.8320030231320538, 'reg_alpha': 6.912199042313216, 'reg_lambda': 4.232680945901276e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:19:31,250] Trial 313 finished with value: -0.9298171830955275 and parameters: {'learning_rate': 0.03430875747685143, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 74, 'feature_fraction': 0.5365573005247015, 'bagging_fraction': 0.719941856409588, 'reg_alpha': 1.785465137335309, 'reg_lambda': 0.00472332832789443}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:19:43,961] Trial 314 finished with value: -0.9340022588849046 and parameters: {'learning_rate': 0.03874488931880396, 'num_leaves': 53, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5264039664805019, 'bagging_fraction': 0.9692052287274981, 'reg_alpha': 0.00018738054923740147, 'reg_lambda': 1.0108676231516054e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:19:55,888] Trial 315 finished with value: -0.9342983978688 and parameters: {'learning_rate': 0.02961468289884127, 'num_leaves': 42, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5437296123488514, 'bagging_fraction': 0.8349642179636803, 'reg_alpha': 0.06469488518817006, 'reg_lambda': 2.769953465656393}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:20:10,878] Trial 316 finished with value: -0.9302365823397926 and parameters: {'learning_rate': 0.03298168313008221, 'num_leaves': 157, 'max_depth': 15, 'min_child_samples': 57, 'feature_fraction': 0.5175995044072295, 'bagging_fraction': 0.7328744414037652, 'reg_alpha': 0.3089152168512264, 'reg_lambda': 3.596901526619423e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:20:31,623] Trial 317 finished with value: -0.9330323074491708 and parameters: {'learning_rate': 0.031246797157640484, 'num_leaves': 107, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5546284112917987, 'bagging_fraction': 0.7908088375914485, 'reg_alpha': 9.772023671204542, 'reg_lambda': 0.0009117704186247194}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:20:40,281] Trial 318 finished with value: -0.9347657132627027 and parameters: {'learning_rate': 0.03640075299258105, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5348529591773451, 'bagging_fraction': 0.8813468299831709, 'reg_alpha': 0.02889374190462604, 'reg_lambda': 0.027915336640908422}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:20:47,400] Trial 319 finished with value: -0.9339335182344256 and parameters: {'learning_rate': 0.034246432480780506, 'num_leaves': 20, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5674262532998178, 'bagging_fraction': 0.925658419404483, 'reg_alpha': 3.3704130261981335, 'reg_lambda': 1.815195428895901e-06}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:20:57,407] Trial 320 finished with value: -0.9340350758759942 and parameters: {'learning_rate': 0.030281740492834375, 'num_leaves': 37, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.5430802008316558, 'bagging_fraction': 0.8034665516706827, 'reg_alpha': 1.0977862110697, 'reg_lambda': 2.216834951120243e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:21:05,756] Trial 321 finished with value: -0.9340429005800224 and parameters: {'learning_rate': 0.044851290362843674, 'num_leaves': 28, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.526175742491279, 'bagging_fraction': 0.850615674742131, 'reg_alpha': 0.018219285133219625, 'reg_lambda': 3.526901350719398e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:21:17,921] Trial 322 finished with value: -0.935225328318444 and parameters: {'learning_rate': 0.026322105745031663, 'num_leaves': 46, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5166453817990831, 'bagging_fraction': 0.6925816623348559, 'reg_alpha': 5.231505298748336, 'reg_lambda': 4.20701269028245e-06}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:21:26,918] Trial 323 finished with value: -0.9339871695495157 and parameters: {'learning_rate': 0.04022870484544494, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5587361085909331, 'bagging_fraction': 0.7131144129460145, 'reg_alpha': 0.12129781723517703, 'reg_lambda': 1.5645253617586158e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:21:40,822] Trial 324 finished with value: -0.9350628925475544 and parameters: {'learning_rate': 0.03257824515146592, 'num_leaves': 58, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5333682184105679, 'bagging_fraction': 0.6970408665829465, 'reg_alpha': 2.7150004324716153, 'reg_lambda': 1.5550042134368682e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:21:51,600] Trial 325 finished with value: -0.9335668300900664 and parameters: {'learning_rate': 0.03547940504027687, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5483847617929983, 'bagging_fraction': 0.6817293489730599, 'reg_alpha': 0.2162188313266267, 'reg_lambda': 2.6062803845013035e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:22:00,782] Trial 326 finished with value: -0.9330979286680099 and parameters: {'learning_rate': 0.02930019797110608, 'num_leaves': 26, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.7770014408491741, 'bagging_fraction': 0.7273555276546776, 'reg_alpha': 0.04602996762539998, 'reg_lambda': 1.4236793453718858e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:22:10,213] Trial 327 finished with value: -0.9350147343615879 and parameters: {'learning_rate': 0.03291567012801528, 'num_leaves': 35, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5239548445878994, 'bagging_fraction': 0.7546981318411966, 'reg_alpha': 1.4225571194627722, 'reg_lambda': 5.517982297579119e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:22:17,800] Trial 328 finished with value: -0.9321089768109897 and parameters: {'learning_rate': 0.037603601836982976, 'num_leaves': 24, 'max_depth': 15, 'min_child_samples': 46, 'feature_fraction': 0.5393593707710242, 'bagging_fraction': 0.6662376256444218, 'reg_alpha': 0.0808934157352033, 'reg_lambda': 1.8214800291795016e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:22:37,836] Trial 329 finished with value: -0.9324087998536458 and parameters: {'learning_rate': 0.028228484769836595, 'num_leaves': 87, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.6475563023858051, 'bagging_fraction': 0.7033194487219115, 'reg_alpha': 2.0454190391966285, 'reg_lambda': 3.0164388591451544e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:22:48,539] Trial 330 finished with value: -0.9350858629656489 and parameters: {'learning_rate': 0.0349267063809249, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5091053188615628, 'bagging_fraction': 0.9388095789596012, 'reg_alpha': 3.023158102369422e-06, 'reg_lambda': 1.012067281146304e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:22:59,696] Trial 331 finished with value: -0.9337427554362916 and parameters: {'learning_rate': 0.0487204866546698, 'num_leaves': 49, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5319052317097549, 'bagging_fraction': 0.7144689172640283, 'reg_alpha': 6.569692688707443, 'reg_lambda': 2.0047467541884452e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:23:08,673] Trial 332 finished with value: -0.9350419530644071 and parameters: {'learning_rate': 0.03168648913303551, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5501818719131314, 'bagging_fraction': 0.7753101656129959, 'reg_alpha': 3.851911368146875, 'reg_lambda': 1.0116280302506601e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:23:14,648] Trial 333 finished with value: -0.9323947738068145 and parameters: {'learning_rate': 0.03056266620182367, 'num_leaves': 16, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5194035864157567, 'bagging_fraction': 0.9519696035689236, 'reg_alpha': 0.013450808768825383, 'reg_lambda': 1.0092314657295732e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:23:26,461] Trial 334 finished with value: -0.9333941081154653 and parameters: {'learning_rate': 0.03628564764895437, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.9026387156630395, 'bagging_fraction': 0.739127031309841, 'reg_alpha': 0.029883981704124783, 'reg_lambda': 0.3283795337701029}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:23:34,157] Trial 335 finished with value: -0.9342113718115314 and parameters: {'learning_rate': 0.04163877639466628, 'num_leaves': 26, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5611388193699263, 'bagging_fraction': 0.9122749176783852, 'reg_alpha': 0.4299345446626765, 'reg_lambda': 1.4741670502924404e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:23:43,686] Trial 336 finished with value: -0.9343540074125529 and parameters: {'learning_rate': 0.03338372174199792, 'num_leaves': 33, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5406110198420682, 'bagging_fraction': 0.7057626448988392, 'reg_alpha': 0.8837630673278096, 'reg_lambda': 4.459515454120826e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:23:55,434] Trial 337 finished with value: -0.9334913532707282 and parameters: {'learning_rate': 0.028316927719653554, 'num_leaves': 45, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.5286818220639141, 'bagging_fraction': 0.9659168014978334, 'reg_alpha': 3.0434117533171916, 'reg_lambda': 2.6401527015424376e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:24:03,073] Trial 338 finished with value: -0.9288979342106302 and parameters: {'learning_rate': 0.03859787150539895, 'num_leaves': 21, 'max_depth': 15, 'min_child_samples': 84, 'feature_fraction': 0.5743550063409903, 'bagging_fraction': 0.7220987953669854, 'reg_alpha': 0.15668880819780354, 'reg_lambda': 1.675306000171287e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:24:11,868] Trial 339 finished with value: -0.9352489504954801 and parameters: {'learning_rate': 0.02680775409198673, 'num_leaves': 29, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5140713496840518, 'bagging_fraction': 0.6944206380288741, 'reg_alpha': 0.0035296889577904915, 'reg_lambda': 1.4160819172913781e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:24:22,519] Trial 340 finished with value: -0.9338426713234598 and parameters: {'learning_rate': 0.034164991833001146, 'num_leaves': 40, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5523158363502618, 'bagging_fraction': 0.8404270032146559, 'reg_alpha': 5.122876752011478, 'reg_lambda': 3.652167928727078e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:24:32,355] Trial 341 finished with value: -0.9337659107660256 and parameters: {'learning_rate': 0.031320983291517744, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5372386439747223, 'bagging_fraction': 0.9798215737587797, 'reg_alpha': 2.0805607599316223, 'reg_lambda': 2.0717492867348312e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:24:40,062] Trial 342 finished with value: -0.9346150460711756 and parameters: {'learning_rate': 0.03592727415615284, 'num_leaves': 25, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.504963921816397, 'bagging_fraction': 0.7138022774147207, 'reg_alpha': 0.021678221623825118, 'reg_lambda': 5.9322540855877685e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:24:53,046] Trial 343 finished with value: -0.9350692593282981 and parameters: {'learning_rate': 0.029696158669300407, 'num_leaves': 51, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5254674862080125, 'bagging_fraction': 0.6783320265844804, 'reg_alpha': 0.044299919394655794, 'reg_lambda': 1.0137064446820936e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:25:04,328] Trial 344 finished with value: -0.9335444604983846 and parameters: {'learning_rate': 0.03294303827294482, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5434347726326781, 'bagging_fraction': 0.8183485773261456, 'reg_alpha': 1.170574482622891, 'reg_lambda': 2.4299878472484444e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:25:09,398] Trial 345 finished with value: -0.929415094365012 and parameters: {'learning_rate': 0.02509993996236277, 'num_leaves': 12, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5640427860797126, 'bagging_fraction': 0.7480837608372458, 'reg_alpha': 7.232654047102121, 'reg_lambda': 1.4674493522364978e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:25:18,226] Trial 346 finished with value: -0.9340535680162534 and parameters: {'learning_rate': 0.032042117829978345, 'num_leaves': 31, 'max_depth': 9, 'min_child_samples': 14, 'feature_fraction': 0.5333070113757039, 'bagging_fraction': 0.7313191278029095, 'reg_alpha': 0.009591048008588943, 'reg_lambda': 1.0026563089781483e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:25:28,045] Trial 347 finished with value: -0.9356564266777585 and parameters: {'learning_rate': 0.0347230425760724, 'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 10, 'feature_fraction': 0.519598419115705, 'bagging_fraction': 0.7014157807886576, 'reg_alpha': 0.2826205691537494, 'reg_lambda': 3.000996095131942e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:25:37,783] Trial 348 finished with value: -0.9343827792540433 and parameters: {'learning_rate': 0.03816521873828392, 'num_leaves': 36, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.5150264236863236, 'bagging_fraction': 0.68966245593997, 'reg_alpha': 0.2383564440987531, 'reg_lambda': 7.372684387466549e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:25:44,304] Trial 349 finished with value: -0.9326236056243722 and parameters: {'learning_rate': 0.0354256581999025, 'num_leaves': 19, 'max_depth': 10, 'min_child_samples': 32, 'feature_fraction': 0.5024348055981406, 'bagging_fraction': 0.6998696103737406, 'reg_alpha': 0.4563491032926512, 'reg_lambda': 3.928937186456089e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:25:52,839] Trial 350 finished with value: -0.9351140851656529 and parameters: {'learning_rate': 0.03395131148173137, 'num_leaves': 29, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5210929025340737, 'bagging_fraction': 0.6818902594861632, 'reg_alpha': 0.11654939697586786, 'reg_lambda': 2.867445671440408e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:26:02,661] Trial 351 finished with value: -0.9346133016383592 and parameters: {'learning_rate': 0.03755123875156415, 'num_leaves': 39, 'max_depth': 8, 'min_child_samples': 12, 'feature_fraction': 0.5465871703552613, 'bagging_fraction': 0.7645637526686552, 'reg_alpha': 0.28338232926992174, 'reg_lambda': 5.1089801273009964e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:26:11,774] Trial 352 finished with value: -0.9338191449815073 and parameters: {'learning_rate': 0.04174503587741354, 'num_leaves': 33, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5125947514018969, 'bagging_fraction': 0.9986550023481243, 'reg_alpha': 0.2048733751012715, 'reg_lambda': 2.2634306500099218e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:26:19,453] Trial 353 finished with value: -0.9352407372392921 and parameters: {'learning_rate': 0.03547058316310249, 'num_leaves': 27, 'max_depth': 6, 'min_child_samples': 10, 'feature_fraction': 0.5582599605429858, 'bagging_fraction': 0.9036319588968226, 'reg_alpha': 0.6492585584351308, 'reg_lambda': 0.6966656568244839}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:26:29,347] Trial 354 finished with value: -0.9334760751727943 and parameters: {'learning_rate': 0.03200259660046511, 'num_leaves': 36, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.5223490803244538, 'bagging_fraction': 0.7236239283806749, 'reg_alpha': 0.09631921916478678, 'reg_lambda': 3.433775652073336e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:26:36,590] Trial 355 finished with value: -0.931886022244764 and parameters: {'learning_rate': 0.03385483405267865, 'num_leaves': 22, 'max_depth': 11, 'min_child_samples': 50, 'feature_fraction': 0.5436381237832005, 'bagging_fraction': 0.7001954993073924, 'reg_alpha': 0.15579634965163952, 'reg_lambda': 0.00020981157856227636}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:26:54,401] Trial 356 finished with value: -0.9331238657541242 and parameters: {'learning_rate': 0.0370231891402912, 'num_leaves': 252, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.5299764235523889, 'bagging_fraction': 0.5945252499227304, 'reg_alpha': 3.1043018534178164, 'reg_lambda': 9.589693581976569e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:27:16,537] Trial 357 finished with value: -0.9326246288860173 and parameters: {'learning_rate': 0.03071851956470277, 'num_leaves': 125, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5502618062369556, 'bagging_fraction': 0.8681019992095581, 'reg_alpha': 0.315128687588648, 'reg_lambda': 1.9611168875044724e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:27:23,417] Trial 358 finished with value: -0.9325188849944731 and parameters: {'learning_rate': 0.039586380312160885, 'num_leaves': 41, 'max_depth': 5, 'min_child_samples': 12, 'feature_fraction': 0.580190837455008, 'bagging_fraction': 0.8539784237320686, 'reg_alpha': 1.8369300191311608, 'reg_lambda': 1.4143849529449311e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:27:31,873] Trial 359 finished with value: -0.9352031386317987 and parameters: {'learning_rate': 0.03406230880117837, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5095046053653457, 'bagging_fraction': 0.7054741914188777, 'reg_alpha': 5.125940488565301, 'reg_lambda': 2.7630668343583468e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:27:59,326] Trial 360 finished with value: -0.9319346788736652 and parameters: {'learning_rate': 0.03230584488258912, 'num_leaves': 167, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5235191722413222, 'bagging_fraction': 0.8895685477911588, 'reg_alpha': 1.5225042070425514, 'reg_lambda': 2.0871746543947997e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:28:08,704] Trial 361 finished with value: -0.93384489252296 and parameters: {'learning_rate': 0.035982420434879724, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5377679520587366, 'bagging_fraction': 0.6927036038781976, 'reg_alpha': 0.07936349299092701, 'reg_lambda': 6.361655334294426e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:28:16,061] Trial 362 finished with value: -0.9327607557405584 and parameters: {'learning_rate': 0.03021869894037935, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5541695132738128, 'bagging_fraction': 0.9407227170476059, 'reg_alpha': 0.7653849211542437, 'reg_lambda': 1.6308663786122612e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:28:28,362] Trial 363 finished with value: -0.9322714974073929 and parameters: {'learning_rate': 0.03382597798680227, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5685653934959143, 'bagging_fraction': 0.6701921632117048, 'reg_alpha': 3.483583346818012, 'reg_lambda': 5.2953270721464305}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:28:33,490] Trial 364 finished with value: -0.9275196792461339 and parameters: {'learning_rate': 0.180770817720604, 'num_leaves': 37, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5302098577467107, 'bagging_fraction': 0.7994470633628478, 'reg_alpha': 0.0013387849570501984, 'reg_lambda': 4.3411340881652904e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:28:41,621] Trial 365 finished with value: -0.9336216841473206 and parameters: {'learning_rate': 0.04353845704481347, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5162200213070592, 'bagging_fraction': 0.716766414575788, 'reg_alpha': 1.1663844817650395, 'reg_lambda': 1.4200647044837255e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:28:47,856] Trial 366 finished with value: -0.9338786382740097 and parameters: {'learning_rate': 0.03935610125423217, 'num_leaves': 18, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.543226912785232, 'bagging_fraction': 0.5604908156974968, 'reg_alpha': 9.715085900884452, 'reg_lambda': 2.3202383235042763e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:28:56,252] Trial 367 finished with value: -0.9341689790882831 and parameters: {'learning_rate': 0.02314546320474304, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5357337618938537, 'bagging_fraction': 0.7385532249971717, 'reg_alpha': 0.14480330012255024, 'reg_lambda': 6.51478689934708e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:29:08,197] Trial 368 finished with value: -0.928840948808202 and parameters: {'learning_rate': 0.01119960443718916, 'num_leaves': 42, 'max_depth': 15, 'min_child_samples': 25, 'feature_fraction': 0.5007049461071801, 'bagging_fraction': 0.7070229854132869, 'reg_alpha': 4.546073066022824, 'reg_lambda': 1.405276395004342e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:29:17,979] Trial 369 finished with value: -0.9339984166750825 and parameters: {'learning_rate': 0.03173778906939721, 'num_leaves': 36, 'max_depth': 13, 'min_child_samples': 13, 'feature_fraction': 0.5570104335267236, 'bagging_fraction': 0.9204781569183011, 'reg_alpha': 0.058980585304013095, 'reg_lambda': 1.0357621771455464e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:29:28,224] Trial 370 finished with value: -0.934044370602946 and parameters: {'learning_rate': 0.036496793475789685, 'num_leaves': 32, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.845530951785933, 'bagging_fraction': 0.9614908286672855, 'reg_alpha': 2.614145104761496, 'reg_lambda': 1.3101730272506917e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:29:36,288] Trial 371 finished with value: -0.9310523987863537 and parameters: {'learning_rate': 0.03413504636771158, 'num_leaves': 25, 'max_depth': 15, 'min_child_samples': 68, 'feature_fraction': 0.5227390374822818, 'bagging_fraction': 0.772360932840885, 'reg_alpha': 6.421544188868267, 'reg_lambda': 3.396813864883995e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:29:47,067] Trial 372 finished with value: -0.9337826738044777 and parameters: {'learning_rate': 0.027339332597837444, 'num_leaves': 40, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5435002535078755, 'bagging_fraction': 0.6924722602294883, 'reg_alpha': 0.38197390800545034, 'reg_lambda': 1.0061135901589992e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:29:59,111] Trial 373 finished with value: -0.9351997823105083 and parameters: {'learning_rate': 0.03088405598503441, 'num_leaves': 47, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5296448823618068, 'bagging_fraction': 0.7223177279868452, 'reg_alpha': 2.034463999581128, 'reg_lambda': 2.0035622236302694e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:30:08,115] Trial 374 finished with value: -0.9341153738333081 and parameters: {'learning_rate': 0.029222776855130903, 'num_leaves': 31, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5134832878959511, 'bagging_fraction': 0.7829713645065239, 'reg_alpha': 0.21851420456289578, 'reg_lambda': 0.0020171388222713126}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:30:18,255] Trial 375 finished with value: -0.9352986017357824 and parameters: {'learning_rate': 0.03276804659307682, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.566192362077949, 'bagging_fraction': 0.9873859326546701, 'reg_alpha': 3.6535739984018107, 'reg_lambda': 2.4643851884998636e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:30:23,622] Trial 376 finished with value: -0.9328171779048844 and parameters: {'learning_rate': 0.03545582185953788, 'num_leaves': 14, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5525589176859863, 'bagging_fraction': 0.9492173413650298, 'reg_alpha': 1.070251346992128e-06, 'reg_lambda': 3.034759837652441e-05}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:30:29,711] Trial 377 finished with value: -0.933658914720258 and parameters: {'learning_rate': 0.07317408318991814, 'num_leaves': 21, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.5377430846019787, 'bagging_fraction': 0.7528493723276777, 'reg_alpha': 0.10873508692657137, 'reg_lambda': 4.806213907908786e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:30:37,479] Trial 378 finished with value: -0.935112711260049 and parameters: {'learning_rate': 0.04685605092604728, 'num_leaves': 27, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5300002265540275, 'bagging_fraction': 0.7334211744955942, 'reg_alpha': 0.9852697044442731, 'reg_lambda': 1.0119152040092723e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:30:48,544] Trial 379 finished with value: -0.9335404078870871 and parameters: {'learning_rate': 0.0391505225420526, 'num_leaves': 46, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5177560087804208, 'bagging_fraction': 0.6823085428770631, 'reg_alpha': 0.5500249982172756, 'reg_lambda': 1.7358008269061698e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:30:57,945] Trial 380 finished with value: -0.9345401066841398 and parameters: {'learning_rate': 0.0325520514628177, 'num_leaves': 34, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.5494690820348413, 'bagging_fraction': 0.7088714431731322, 'reg_alpha': 0.0006325557913465118, 'reg_lambda': 3.299667155891934e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:31:06,621] Trial 381 finished with value: -0.9325910636242478 and parameters: {'learning_rate': 0.03690125188006528, 'num_leaves': 41, 'max_depth': 8, 'min_child_samples': 39, 'feature_fraction': 0.523775606453543, 'bagging_fraction': 0.6412165250201057, 'reg_alpha': 6.841091895804474, 'reg_lambda': 0.006409046456702721}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:31:15,414] Trial 382 finished with value: -0.9340971691236172 and parameters: {'learning_rate': 0.030318870388413282, 'num_leaves': 30, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.5415031365736581, 'bagging_fraction': 0.9314592013492192, 'reg_alpha': 2.39391561881625, 'reg_lambda': 0.39832500306134866}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:31:24,961] Trial 383 finished with value: -0.9335435930964145 and parameters: {'learning_rate': 0.053137441237707465, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5084731433238544, 'bagging_fraction': 0.6968428306130386, 'reg_alpha': 1.5009275613794564, 'reg_lambda': 1.9402502096011894e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:31:32,612] Trial 384 finished with value: -0.9352152097763147 and parameters: {'learning_rate': 0.033909493172438576, 'num_leaves': 24, 'max_depth': 10, 'min_child_samples': 10, 'feature_fraction': 0.5603803506788494, 'bagging_fraction': 0.9758251366204945, 'reg_alpha': 0.05602091009317069, 'reg_lambda': 0.08884137654398278}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:31:46,142] Trial 385 finished with value: -0.9349643236325254 and parameters: {'learning_rate': 0.028098139440680556, 'num_leaves': 54, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5356700747254081, 'bagging_fraction': 0.8090309950018484, 'reg_alpha': 3.9772618123921553, 'reg_lambda': 7.762774458256978e-06}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:31:52,834] Trial 386 finished with value: -0.9320007473012772 and parameters: {'learning_rate': 0.03506457336910498, 'num_leaves': 18, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5716785727189736, 'bagging_fraction': 0.760492186418765, 'reg_alpha': 0.17895823354863385, 'reg_lambda': 1.3847966337409197e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:31:56,766] Trial 387 finished with value: -0.9275723302517128 and parameters: {'learning_rate': 0.03201201387714779, 'num_leaves': 8, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5236125542441061, 'bagging_fraction': 0.7165477267729521, 'reg_alpha': 9.449641151391292, 'reg_lambda': 7.620395218433616e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:32:21,353] Trial 388 finished with value: -0.932738336152896 and parameters: {'learning_rate': 0.030240298873487836, 'num_leaves': 142, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5490409493718486, 'bagging_fraction': 0.7437401464757675, 'reg_alpha': 0.0845605240792392, 'reg_lambda': 2.7382568654543144e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:32:32,518] Trial 389 finished with value: -0.9336740299631824 and parameters: {'learning_rate': 0.0377595886121572, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.5322442139960477, 'bagging_fraction': 0.7015850622101766, 'reg_alpha': 0.027086263732571086, 'reg_lambda': 1.4597678954976915e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:32:41,716] Trial 390 finished with value: -0.9354795420878248 and parameters: {'learning_rate': 0.040945664230660046, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5085674822527382, 'bagging_fraction': 0.7251385159085906, 'reg_alpha': 5.824979038332017e-07, 'reg_lambda': 5.05447973235246e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:32:50,913] Trial 391 finished with value: -0.9342303780611734 and parameters: {'learning_rate': 0.04228296284996741, 'num_leaves': 34, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5004220234325342, 'bagging_fraction': 0.7334333581109943, 'reg_alpha': 4.0686113128199236e-07, 'reg_lambda': 5.483096247320008e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:33:01,020] Trial 392 finished with value: -0.9337326584783392 and parameters: {'learning_rate': 0.04434657621185627, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5108891136957157, 'bagging_fraction': 0.7258626968990544, 'reg_alpha': 0.3074372481706778, 'reg_lambda': 1.1625513617922322e-07}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:33:12,152] Trial 393 finished with value: -0.9334541099977767 and parameters: {'learning_rate': 0.04084977604271473, 'num_leaves': 46, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5086775731526946, 'bagging_fraction': 0.7166048879394165, 'reg_alpha': 3.7024684410386465e-08, 'reg_lambda': 1.0071211719367209e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:33:21,154] Trial 394 finished with value: -0.9332990876249335 and parameters: {'learning_rate': 0.039992457573702955, 'num_leaves': 32, 'max_depth': 11, 'min_child_samples': 35, 'feature_fraction': 0.5139639909489498, 'bagging_fraction': 0.7468416659756483, 'reg_alpha': 0.034915390148331685, 'reg_lambda': 4.0610592573456685e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:33:31,076] Trial 395 finished with value: -0.9342736152402991 and parameters: {'learning_rate': 0.03764478472912983, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5213305419775276, 'bagging_fraction': 0.7249504033950317, 'reg_alpha': 7.138900518566318e-07, 'reg_lambda': 1.898278335930951e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:33:39,596] Trial 396 finished with value: -0.9346974419239403 and parameters: {'learning_rate': 0.03587143101662313, 'num_leaves': 29, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.519159112675442, 'bagging_fraction': 0.8814199839239952, 'reg_alpha': 0.12285953105482425, 'reg_lambda': 7.82548059759266e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:33:49,902] Trial 397 finished with value: -0.933714853316669 and parameters: {'learning_rate': 0.03928804366736452, 'num_leaves': 41, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.5015865205954569, 'bagging_fraction': 0.7137709595934815, 'reg_alpha': 0.7963662454640967, 'reg_lambda': 1.4797008175405468e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:34:00,428] Trial 398 finished with value: -0.9341858349293195 and parameters: {'learning_rate': 0.03603183454712878, 'num_leaves': 49, 'max_depth': 7, 'min_child_samples': 12, 'feature_fraction': 0.5267356879253496, 'bagging_fraction': 0.7350588211954666, 'reg_alpha': 7.822720071716406e-05, 'reg_lambda': 3.5544702937978586e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:34:11,221] Trial 399 finished with value: -0.932432858060775 and parameters: {'learning_rate': 0.02577653882916634, 'num_leaves': 33, 'max_depth': 15, 'min_child_samples': 18, 'feature_fraction': 0.8019115263740495, 'bagging_fraction': 0.9557800331801241, 'reg_alpha': 9.234550387977957e-06, 'reg_lambda': 1.0193202608591858e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:34:21,344] Trial 400 finished with value: -0.9347921155151169 and parameters: {'learning_rate': 0.03289102269716738, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5358629404138064, 'bagging_fraction': 0.9144582436692772, 'reg_alpha': 2.3126452225371234e-05, 'reg_lambda': 2.2499197176876125e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:34:36,301] Trial 401 finished with value: -0.9344310605897604 and parameters: {'learning_rate': 0.0292439843953037, 'num_leaves': 62, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.512872665296452, 'bagging_fraction': 0.7568542110293548, 'reg_alpha': 1.532472198378147e-06, 'reg_lambda': 4.8726120873484834e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:34:44,755] Trial 402 finished with value: -0.9352767855719165 and parameters: {'learning_rate': 0.04127005744805488, 'num_leaves': 29, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5419005803564547, 'bagging_fraction': 0.7249924212491513, 'reg_alpha': 2.418644772558974e-07, 'reg_lambda': 1.0991493757635753}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:34:55,831] Trial 403 finished with value: -0.9337516969640326 and parameters: {'learning_rate': 0.031427855603742186, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.5267577816410774, 'bagging_fraction': 0.6566938601732184, 'reg_alpha': 0.00027284529521490354, 'reg_lambda': 8.021855826302895e-05}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:35:05,265] Trial 404 finished with value: -0.9349148604628527 and parameters: {'learning_rate': 0.03467225432012673, 'num_leaves': 35, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5181940483807876, 'bagging_fraction': 0.7093772765145138, 'reg_alpha': 0.05962082918016947, 'reg_lambda': 1.886013010323613e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:35:13,199] Trial 405 finished with value: -0.9345165631372576 and parameters: {'learning_rate': 0.037324570900444824, 'num_leaves': 26, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.5331308533328746, 'bagging_fraction': 0.9690675481141908, 'reg_alpha': 6.685481596251013e-08, 'reg_lambda': 1.404376273877979e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:35:17,013] Trial 406 finished with value: -0.9178224527233182 and parameters: {'learning_rate': 0.02755485069096977, 'num_leaves': 46, 'max_depth': 3, 'min_child_samples': 14, 'feature_fraction': 0.7629056587931022, 'bagging_fraction': 0.8338456029775586, 'reg_alpha': 0.39172945190962627, 'reg_lambda': 2.577287725633135e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:35:26,080] Trial 407 finished with value: -0.9356151771857526 and parameters: {'learning_rate': 0.03324692329721099, 'num_leaves': 32, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5440175694816254, 'bagging_fraction': 0.6877522469802343, 'reg_alpha': 0.1618494954933504, 'reg_lambda': 1.015243156284634e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:35:36,376] Trial 408 finished with value: -0.9309877672653648 and parameters: {'learning_rate': 0.0334892659878912, 'num_leaves': 39, 'max_depth': 13, 'min_child_samples': 60, 'feature_fraction': 0.5407897254629283, 'bagging_fraction': 0.6862528284640187, 'reg_alpha': 0.0391127816554276, 'reg_lambda': 1.4091417241870755e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:35:45,299] Trial 409 finished with value: -0.9357356189271216 and parameters: {'learning_rate': 0.031137725994128975, 'num_leaves': 31, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5085887220556273, 'bagging_fraction': 0.6797495058478815, 'reg_alpha': 0.22552319534600102, 'reg_lambda': 1.0286597957303298e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:35:54,102] Trial 410 finished with value: -0.9343432586287482 and parameters: {'learning_rate': 0.032557904007602334, 'num_leaves': 31, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.5021527686452083, 'bagging_fraction': 0.6822187996854132, 'reg_alpha': 0.20570162110018655, 'reg_lambda': 1.0172379973016907e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:36:03,165] Trial 411 finished with value: -0.9359881568747102 and parameters: {'learning_rate': 0.034663980822129604, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 10, 'feature_fraction': 0.5163573720597748, 'bagging_fraction': 0.6714471862630282, 'reg_alpha': 3.6114491302739364e-05, 'reg_lambda': 1.0424826604690184e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:36:10,932] Trial 412 finished with value: -0.9346673870807914 and parameters: {'learning_rate': 0.03617972321136133, 'num_leaves': 27, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.5074933378046588, 'bagging_fraction': 0.6678128838092862, 'reg_alpha': 0.28595929083166755, 'reg_lambda': 1.3897584069376691e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:36:19,892] Trial 413 finished with value: -0.9343267207117303 and parameters: {'learning_rate': 0.0344380115262465, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 14, 'feature_fraction': 0.5004299251093093, 'bagging_fraction': 0.6766681985907873, 'reg_alpha': 0.11968522359733924, 'reg_lambda': 1.0236704132258108e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:36:27,453] Trial 414 finished with value: -0.9338921038902428 and parameters: {'learning_rate': 0.03157296054625528, 'num_leaves': 24, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5119385119407711, 'bagging_fraction': 0.6656840636592387, 'reg_alpha': 0.17028652449075501, 'reg_lambda': 1.4007873861953689e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:36:36,616] Trial 415 finished with value: -0.9336949553615652 and parameters: {'learning_rate': 0.03804337157463374, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 16, 'feature_fraction': 0.5180192175535603, 'bagging_fraction': 0.6511281761827876, 'reg_alpha': 0.25735065040291155, 'reg_lambda': 1.0300967021108043e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:36:44,832] Trial 416 finished with value: -0.9349393202051278 and parameters: {'learning_rate': 0.034475217549555764, 'num_leaves': 27, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5094926091296559, 'bagging_fraction': 0.6744840796093642, 'reg_alpha': 1.0102837599145918e-07, 'reg_lambda': 1.8256590776025157e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:36:54,380] Trial 417 finished with value: -0.9340566281652862 and parameters: {'learning_rate': 0.031726730604797374, 'num_leaves': 34, 'max_depth': 12, 'min_child_samples': 13, 'feature_fraction': 0.5173621476784801, 'bagging_fraction': 0.6868290153995515, 'reg_alpha': 1.0617605941502673e-08, 'reg_lambda': 1.488531092025043e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:37:03,289] Trial 418 finished with value: -0.934650085971671 and parameters: {'learning_rate': 0.035542668596837634, 'num_leaves': 31, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.5226905124527708, 'bagging_fraction': 0.6929139236581044, 'reg_alpha': 4.193538148533371e-06, 'reg_lambda': 1.8437690923941444e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:37:26,421] Trial 419 finished with value: -0.9326523405941481 and parameters: {'learning_rate': 0.03357806156983707, 'num_leaves': 191, 'max_depth': 11, 'min_child_samples': 10, 'feature_fraction': 0.5243118447635041, 'bagging_fraction': 0.6714352840650153, 'reg_alpha': 1.305885403015484e-05, 'reg_lambda': 1.397504497578156e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:37:36,353] Trial 420 finished with value: -0.9343875125801806 and parameters: {'learning_rate': 0.03063601815710611, 'num_leaves': 36, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.5141628500779108, 'bagging_fraction': 0.6904260112689624, 'reg_alpha': 4.217163813517944e-05, 'reg_lambda': 1.068009717920522e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:37:43,393] Trial 421 finished with value: -0.9333400178149008 and parameters: {'learning_rate': 0.03886787516173366, 'num_leaves': 22, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.5087557478484109, 'bagging_fraction': 0.663094098964855, 'reg_alpha': 2.035378586929329e-08, 'reg_lambda': 1.9368241936575645e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:37:51,817] Trial 422 finished with value: -0.9353486238498383 and parameters: {'learning_rate': 0.0363366966460137, 'num_leaves': 28, 'max_depth': 11, 'min_child_samples': 10, 'feature_fraction': 0.527633150794136, 'bagging_fraction': 0.6818953334369428, 'reg_alpha': 0.0021328341884683014, 'reg_lambda': 1.0010637895057634e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:38:01,949] Trial 423 finished with value: -0.934061146260651 and parameters: {'learning_rate': 0.03302125838375444, 'num_leaves': 38, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.5324546645067196, 'bagging_fraction': 0.7018741416196154, 'reg_alpha': 0.000122184122824179, 'reg_lambda': 2.3424518994300486e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:38:10,793] Trial 424 finished with value: -0.9339155562391134 and parameters: {'learning_rate': 0.031391884801584946, 'num_leaves': 31, 'max_depth': 10, 'min_child_samples': 16, 'feature_fraction': 0.5207704218112665, 'bagging_fraction': 0.6973486980070248, 'reg_alpha': 0.09031714923495725, 'reg_lambda': 1.4292119208079609e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:38:18,156] Trial 425 finished with value: -0.9346846529263819 and parameters: {'learning_rate': 0.03511288816475047, 'num_leaves': 23, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5001799374318863, 'bagging_fraction': 0.6766722853361149, 'reg_alpha': 5.9503357995878945, 'reg_lambda': 2.0328296133697987e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:38:28,505] Trial 426 finished with value: -0.9346081657203164 and parameters: {'learning_rate': 0.02977551567072845, 'num_leaves': 39, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.5376144771237926, 'bagging_fraction': 0.6892533743085663, 'reg_alpha': 0.48266932418973435, 'reg_lambda': 1.474559555722905e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:38:36,880] Trial 427 finished with value: -0.9346450245087742 and parameters: {'learning_rate': 0.03730447423743364, 'num_leaves': 29, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.51104922732864, 'bagging_fraction': 0.7087241031070486, 'reg_alpha': 6.433288522193741, 'reg_lambda': 1.0063266801143611e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:38:46,659] Trial 428 finished with value: -0.9354568465928025 and parameters: {'learning_rate': 0.032976601862896394, 'num_leaves': 35, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5265718402744449, 'bagging_fraction': 0.696199554351255, 'reg_alpha': 9.51894806850716, 'reg_lambda': 1.0070508272679057e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:38:56,397] Trial 429 finished with value: -0.9343472633767665 and parameters: {'learning_rate': 0.032626726035369834, 'num_leaves': 36, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.5485056860759225, 'bagging_fraction': 0.6992590622758539, 'reg_alpha': 1.7191109861797525e-07, 'reg_lambda': 2.0219509583286876e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:39:07,081] Trial 430 finished with value: -0.9349319940584174 and parameters: {'learning_rate': 0.03029760990643282, 'num_leaves': 41, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5313344295928575, 'bagging_fraction': 0.6868768638905021, 'reg_alpha': 7.5889545380888235, 'reg_lambda': 1.0171002866848366e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:39:16,623] Trial 431 finished with value: -0.9341790256262813 and parameters: {'learning_rate': 0.0328913495362416, 'num_leaves': 35, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.542242603966482, 'bagging_fraction': 0.6471504806364365, 'reg_alpha': 9.905146754485914, 'reg_lambda': 1.017159285195735e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:39:25,464] Trial 432 finished with value: -0.9334940508084515 and parameters: {'learning_rate': 0.03124634708502666, 'num_leaves': 26, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.7251465204611236, 'bagging_fraction': 0.7068633411297418, 'reg_alpha': 4.286476616089278, 'reg_lambda': 2.6624945229874615e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:39:36,900] Trial 433 finished with value: -0.9348373006339199 and parameters: {'learning_rate': 0.036212147872692904, 'num_leaves': 41, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.6607155089608678, 'bagging_fraction': 0.694773382901374, 'reg_alpha': 9.261869414783988, 'reg_lambda': 1.5941448562678217e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:39:47,559] Trial 434 finished with value: -0.9336274863225695 and parameters: {'learning_rate': 0.03375934392118497, 'num_leaves': 34, 'max_depth': 12, 'min_child_samples': 13, 'feature_fraction': 0.8301798733444219, 'bagging_fraction': 0.715827319666777, 'reg_alpha': 6.3077078189379225, 'reg_lambda': 1.770133594915857e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:39:54,130] Trial 435 finished with value: -0.9332469403550101 and parameters: {'learning_rate': 0.029552137216465924, 'num_leaves': 19, 'max_depth': 13, 'min_child_samples': 11, 'feature_fraction': 0.52829664939754, 'bagging_fraction': 0.6798641758332676, 'reg_alpha': 0.005572577354183976, 'reg_lambda': 2.7984800740537564e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:40:02,663] Trial 436 finished with value: -0.9335020380120672 and parameters: {'learning_rate': 0.03955880605210279, 'num_leaves': 31, 'max_depth': 11, 'min_child_samples': 15, 'feature_fraction': 0.556807598619474, 'bagging_fraction': 0.6602519298813373, 'reg_alpha': 5.250790100006003, 'reg_lambda': 1.0079892122143878e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:40:12,762] Trial 437 finished with value: -0.9350708523405423 and parameters: {'learning_rate': 0.03480674786914679, 'num_leaves': 39, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5198579774766624, 'bagging_fraction': 0.6181998795427038, 'reg_alpha': 3.995453037763546, 'reg_lambda': 1.5323973005548278e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:40:20,744] Trial 438 finished with value: -0.9341946739240878 and parameters: {'learning_rate': 0.03189896485090942, 'num_leaves': 26, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.5381874775441575, 'bagging_fraction': 0.7008048267260895, 'reg_alpha': 2.671480841187635, 'reg_lambda': 1.2012697249462994e-06}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:40:31,507] Trial 439 finished with value: -0.9335061405216495 and parameters: {'learning_rate': 0.03733935892908327, 'num_leaves': 35, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.8735722090200773, 'bagging_fraction': 0.7191208991057099, 'reg_alpha': 4.459960684148825, 'reg_lambda': 2.37645207639355e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:40:42,996] Trial 440 finished with value: -0.933764008516038 and parameters: {'learning_rate': 0.03317334207476547, 'num_leaves': 43, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.6290985890389585, 'bagging_fraction': 0.6918516058415627, 'reg_alpha': 0.44801795880877293, 'reg_lambda': 1.0021419998833031e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:40:51,577] Trial 441 finished with value: -0.9351375520634124 and parameters: {'learning_rate': 0.029222825335072863, 'num_leaves': 29, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.5462735197383293, 'bagging_fraction': 0.6715728767996635, 'reg_alpha': 1.9328547811745798, 'reg_lambda': 1.6329401160062207e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:41:08,187] Trial 442 finished with value: -0.9338693803927212 and parameters: {'learning_rate': 0.03483773109306458, 'num_leaves': 81, 'max_depth': 15, 'min_child_samples': 12, 'feature_fraction': 0.5092359969259068, 'bagging_fraction': 0.707560798522934, 'reg_alpha': 9.653991902921883, 'reg_lambda': 1.4560122204325687e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:41:13,297] Trial 443 finished with value: -0.9308854531082544 and parameters: {'learning_rate': 0.14584203433903992, 'num_leaves': 21, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.9844151563594756, 'bagging_fraction': 0.9380720336689587, 'reg_alpha': 0.2239926213070778, 'reg_lambda': 2.7000063191903084e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:41:24,028] Trial 444 finished with value: -0.9347561323728335 and parameters: {'learning_rate': 0.03142709533234531, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 11, 'feature_fraction': 0.6912640654689164, 'bagging_fraction': 0.730685091303467, 'reg_alpha': 3.073287428410267, 'reg_lambda': 1.9899705873587127e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:41:36,139] Trial 445 finished with value: -0.9343880989263503 and parameters: {'learning_rate': 0.037328388767096474, 'num_leaves': 50, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.5276188011009226, 'bagging_fraction': 0.6834674833838922, 'reg_alpha': 5.812861232382854, 'reg_lambda': 1.442942428170748e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:41:44,831] Trial 446 finished with value: -0.9353104404103284 and parameters: {'learning_rate': 0.04133164455228897, 'num_leaves': 32, 'max_depth': 15, 'min_child_samples': 10, 'feature_fraction': 0.5364516689139082, 'bagging_fraction': 0.7127623455017682, 'reg_alpha': 0.15759345607851205, 'reg_lambda': 1.006013176022759e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:41:56,357] Trial 447 finished with value: -0.9342712179976991 and parameters: {'learning_rate': 0.03358145180823663, 'num_leaves': 44, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.517861904804926, 'bagging_fraction': 0.6987952697549762, 'reg_alpha': 0.6812934958510817, 'reg_lambda': 2.7188543850775353e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:42:04,027] Trial 448 finished with value: -0.9331896234151362 and parameters: {'learning_rate': 0.030802046158552258, 'num_leaves': 24, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.5596886158197418, 'bagging_fraction': 0.7214742280799291, 'reg_alpha': 4.346587448105853e-05, 'reg_lambda': 1.4281464907244846e-08}. Best is trial 181 with value: -0.9360705907673996.
[I 2025-08-02 08:42:33,442] Trial 449 finished with value: -0.932693677290763 and parameters: {'learning_rate': 0.03494717539674085, 'num_leaves': 222, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.5449057503101347, 'bagging_fraction': 0.7060768188597033, 'reg_alpha': 1.2249703277111743, 'reg_lambda': 0.0003568570671668123}. Best is trial 181 with value: -0.9360705907673996.
2025-08-02 08:42:34 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.9189381278326872, 'val_lightgbm': 0.9091975695613692, 'val_ensemble': 0.9162272836680849}
2025-08-02 08:42:34 [INFO] Selected best model 'catboost' with validation R²=0.9189
2025-08-02 08:42:34 [INFO] Retraining best model 'catboost' on full dataset
2025-08-02 08:42:35 [INFO] Retraining completed
2025-08-02 08:42:35 [INFO] Saved final model to '/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/final_catboost.pkl'
2025-08-02 08:42:35 [INFO] Tree-based → /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/final_catboost.pkl (R²=0.9189)
2025-08-02 08:42:35 [INFO] Training TabNet model...
[I 2025-08-02 08:42:35,815] A new study created in memory with name: no-name-76b01d1b-ee62-4272-9da1-9196e593531a
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:44:04,144] Trial 0 finished with value: 0.890462800366633 and parameters: {'n_d': 55, 'n_a': 28, 'n_steps': 6, 'gamma': 1.0535193921183756, 'lambda_sparse': 0.004365959304313505, 'lr': 0.010867293039830622, 'weight_decay': 0.0002870535542419275}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:45:17,550] Trial 1 finished with value: 0.8386443157536523 and parameters: {'n_d': 59, 'n_a': 55, 'n_steps': 4, 'gamma': 1.5670439830053198, 'lambda_sparse': 0.0001106350025813826, 'lr': 0.00039704363233317034, 'weight_decay': 0.0005068741414542507}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:45:36,422] Trial 2 finished with value: 0.09443493545348625 and parameters: {'n_d': 9, 'n_a': 19, 'n_steps': 3, 'gamma': 1.5552980006577681, 'lambda_sparse': 0.0007590294841871854, 'lr': 0.021789876456540673, 'weight_decay': 0.00018358557292376588}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:46:58,127] Trial 3 finished with value: 0.7982619418784813 and parameters: {'n_d': 26, 'n_a': 21, 'n_steps': 4, 'gamma': 1.657255091053313, 'lambda_sparse': 0.00032209629894428834, 'lr': 0.000523364644579955, 'weight_decay': 1.0599473361155201e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:48:59,096] Trial 4 finished with value: 0.8855870662572365 and parameters: {'n_d': 9, 'n_a': 19, 'n_steps': 10, 'gamma': 1.398125307748648, 'lambda_sparse': 0.0015453855195293315, 'lr': 0.04778312102907919, 'weight_decay': 2.113149439789945e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:50:51,087] Trial 5 finished with value: 0.8687102534910784 and parameters: {'n_d': 52, 'n_a': 53, 'n_steps': 8, 'gamma': 1.686424803378976, 'lambda_sparse': 0.007061972047273277, 'lr': 0.011750952656607838, 'weight_decay': 1.6401811988746448e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:52:12,245] Trial 6 finished with value: 0.698340955698964 and parameters: {'n_d': 43, 'n_a': 19, 'n_steps': 5, 'gamma': 1.7579661421231934, 'lambda_sparse': 1.8842714927724572e-05, 'lr': 0.0003292369203825682, 'weight_decay': 2.1177272166187213e-06}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:54:15,182] Trial 7 finished with value: 0.8858409220415981 and parameters: {'n_d': 39, 'n_a': 8, 'n_steps': 9, 'gamma': 1.0238539637689672, 'lambda_sparse': 0.003037296120636304, 'lr': 0.04168194768457274, 'weight_decay': 0.0002725670925342879}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:56:20,074] Trial 8 finished with value: 0.6424406606127067 and parameters: {'n_d': 58, 'n_a': 15, 'n_steps': 9, 'gamma': 1.2175434674563061, 'lambda_sparse': 0.004384880127224968, 'lr': 0.00041160762594192403, 'weight_decay': 2.6705829951146647e-06}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:56:56,074] Trial 9 finished with value: 0.37450209835165194 and parameters: {'n_d': 45, 'n_a': 58, 'n_steps': 5, 'gamma': 1.8534744880308867, 'lambda_sparse': 0.0016355576889977468, 'lr': 0.01591601596297381, 'weight_decay': 8.504654761263757e-06}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 08:58:37,959] Trial 10 finished with value: 0.8900302838779486 and parameters: {'n_d': 26, 'n_a': 37, 'n_steps': 7, 'gamma': 1.018915598746713, 'lambda_sparse': 9.271545998294172e-05, 'lr': 0.0024893659140139343, 'weight_decay': 6.395701931496705e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:00:20,200] Trial 11 finished with value: 0.8846756926514772 and parameters: {'n_d': 28, 'n_a': 36, 'n_steps': 7, 'gamma': 1.0032517983188967, 'lambda_sparse': 6.568313212793273e-05, 'lr': 0.0040380061926853965, 'weight_decay': 8.298105719099799e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:01:51,823] Trial 12 finished with value: 0.8903988339144459 and parameters: {'n_d': 24, 'n_a': 35, 'n_steps': 6, 'gamma': 1.2321188223425485, 'lambda_sparse': 8.863484651716811e-05, 'lr': 0.0021391997282025964, 'weight_decay': 7.517898786292653e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:03:23,462] Trial 13 finished with value: 0.8825838320367739 and parameters: {'n_d': 19, 'n_a': 34, 'n_steps': 6, 'gamma': 1.274896918034776, 'lambda_sparse': 1.5880120956628035e-05, 'lr': 0.0021508865777235633, 'weight_decay': 0.0007108344211814063}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:04:41,406] Trial 14 finished with value: 0.8875951957130279 and parameters: {'n_d': 33, 'n_a': 44, 'n_steps': 6, 'gamma': 1.2618513134142595, 'lambda_sparse': 0.00033362777655066993, 'lr': 0.005735207849737437, 'weight_decay': 7.747428506484426e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:05:44,676] Trial 15 finished with value: 0.8613449639344428 and parameters: {'n_d': 19, 'n_a': 28, 'n_steps': 5, 'gamma': 1.173844454919416, 'lambda_sparse': 4.350551871812507e-05, 'lr': 0.00109617861109499, 'weight_decay': 0.00020025686110645383}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:07:09,885] Trial 16 finished with value: 0.8728454188002307 and parameters: {'n_d': 49, 'n_a': 45, 'n_steps': 7, 'gamma': 1.4006769744047254, 'lambda_sparse': 0.00019308430512308012, 'lr': 0.007414001801804082, 'weight_decay': 4.43617823877515e-05}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:09:00,267] Trial 17 finished with value: 0.49987887341085147 and parameters: {'n_d': 62, 'n_a': 29, 'n_steps': 8, 'gamma': 1.1430282534691427, 'lambda_sparse': 0.0006399573169222393, 'lr': 0.00016967147261325822, 'weight_decay': 0.0003722769712128708}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:10:31,641] Trial 18 finished with value: 0.8626000275651876 and parameters: {'n_d': 18, 'n_a': 44, 'n_steps': 6, 'gamma': 1.375094293566823, 'lambda_sparse': 3.193203602554306e-05, 'lr': 0.0014015223777829788, 'weight_decay': 0.0009597981452003075}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:10:56,064] Trial 19 finished with value: 0.2040544311898861 and parameters: {'n_d': 35, 'n_a': 28, 'n_steps': 3, 'gamma': 1.1004623949149461, 'lambda_sparse': 0.008662513647512905, 'lr': 0.0935980627226121, 'weight_decay': 0.0001318315404529128}. Best is trial 0 with value: 0.890462800366633.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:12:56,240] A new study created in memory with name: no-name-5095421c-5243-4e29-93f5-a8cab73d82fa
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:13:41,988] Trial 0 finished with value: 0.90008920721527 and parameters: {'n_d': 22, 'n_a': 12, 'n_steps': 3, 'gamma': 1.964079579216877, 'lambda_sparse': 0.002430778185479248, 'lr': 0.001340402371541086, 'weight_decay': 0.0008522368124644633}. Best is trial 0 with value: 0.90008920721527.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:14:45,327] Trial 1 finished with value: 0.8656730060208118 and parameters: {'n_d': 41, 'n_a': 36, 'n_steps': 5, 'gamma': 1.6181547132162257, 'lambda_sparse': 0.0038528427999005785, 'lr': 0.0015132260721097512, 'weight_decay': 1.2055319332371614e-06}. Best is trial 0 with value: 0.90008920721527.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:16:55,098] Trial 2 finished with value: 0.8676240052339853 and parameters: {'n_d': 53, 'n_a': 12, 'n_steps': 10, 'gamma': 1.928561631664854, 'lambda_sparse': 0.0010183343795909273, 'lr': 0.006616831012622286, 'weight_decay': 2.3565228370709017e-05}. Best is trial 0 with value: 0.90008920721527.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:18:04,283] Trial 3 finished with value: 0.8489360481068905 and parameters: {'n_d': 19, 'n_a': 53, 'n_steps': 3, 'gamma': 1.2747329185142626, 'lambda_sparse': 6.497126216317912e-05, 'lr': 0.0006529286496643541, 'weight_decay': 1.2948275206584666e-06}. Best is trial 0 with value: 0.90008920721527.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:20:04,029] Trial 4 finished with value: 0.9089154977859929 and parameters: {'n_d': 60, 'n_a': 32, 'n_steps': 9, 'gamma': 1.8604156680483315, 'lambda_sparse': 0.008690498013801217, 'lr': 0.09253162265033373, 'weight_decay': 1.1401403761577792e-06}. Best is trial 4 with value: 0.9089154977859929.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:22:06,213] Trial 5 finished with value: 0.9143711720732661 and parameters: {'n_d': 37, 'n_a': 50, 'n_steps': 9, 'gamma': 1.0943713038565037, 'lambda_sparse': 0.00012110943139416614, 'lr': 0.036302036872617405, 'weight_decay': 6.0318185119074225e-06}. Best is trial 5 with value: 0.9143711720732661.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:23:05,557] Trial 6 finished with value: 0.7985534534678453 and parameters: {'n_d': 20, 'n_a': 16, 'n_steps': 3, 'gamma': 1.7637095049867324, 'lambda_sparse': 0.0001467615259544588, 'lr': 0.0003669747146992638, 'weight_decay': 0.00020258873937284677}. Best is trial 5 with value: 0.9143711720732661.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:24:28,729] Trial 7 finished with value: 0.611090668320042 and parameters: {'n_d': 25, 'n_a': 26, 'n_steps': 4, 'gamma': 1.8755407842388587, 'lambda_sparse': 0.00010665246363154542, 'lr': 0.00011280971981133785, 'weight_decay': 8.73918729393784e-06}. Best is trial 5 with value: 0.9143711720732661.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:25:59,773] Trial 8 finished with value: 0.650910422813584 and parameters: {'n_d': 49, 'n_a': 10, 'n_steps': 6, 'gamma': 1.864151538060115, 'lambda_sparse': 0.00015838196632529596, 'lr': 0.00025810128737569524, 'weight_decay': 6.2395342508938684e-06}. Best is trial 5 with value: 0.9143711720732661.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:27:24,196] Trial 9 finished with value: 0.8958564540112008 and parameters: {'n_d': 57, 'n_a': 60, 'n_steps': 6, 'gamma': 1.4470017460735343, 'lambda_sparse': 0.004850669789261087, 'lr': 0.009197909290885709, 'weight_decay': 0.0005162234166075719}. Best is trial 5 with value: 0.9143711720732661.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:29:05,467] Trial 10 finished with value: 0.9069826288938646 and parameters: {'n_d': 32, 'n_a': 48, 'n_steps': 8, 'gamma': 1.008973572514132, 'lambda_sparse': 1.2520315935536056e-05, 'lr': 0.06335554701164611, 'weight_decay': 8.430743405050683e-05}. Best is trial 5 with value: 0.9143711720732661.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:30:56,465] Trial 11 finished with value: 0.91714038480926 and parameters: {'n_d': 64, 'n_a': 37, 'n_steps': 9, 'gamma': 1.0120611720477999, 'lambda_sparse': 0.0005927168917605332, 'lr': 0.08506833090336449, 'weight_decay': 4.084802937634756e-06}. Best is trial 11 with value: 0.91714038480926.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:32:28,204] Trial 12 finished with value: 0.9227521985241768 and parameters: {'n_d': 42, 'n_a': 43, 'n_steps': 8, 'gamma': 1.056591575222996, 'lambda_sparse': 0.0007033610052869428, 'lr': 0.02716709833236461, 'weight_decay': 6.287224510455807e-06}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:34:13,797] Trial 13 finished with value: 0.9069033556073359 and parameters: {'n_d': 64, 'n_a': 43, 'n_steps': 8, 'gamma': 1.185564050480315, 'lambda_sparse': 0.0009369745225288719, 'lr': 0.018271931617437207, 'weight_decay': 1.843263882396032e-05}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:35:54,776] Trial 14 finished with value: 0.9084721357660421 and parameters: {'n_d': 47, 'n_a': 26, 'n_steps': 8, 'gamma': 1.3381414514658085, 'lambda_sparse': 0.0005593462978105021, 'lr': 0.026570594721975954, 'weight_decay': 4.1584220452555025e-06}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:38:09,403] Trial 15 finished with value: 0.9213749018175796 and parameters: {'n_d': 8, 'n_a': 42, 'n_steps': 10, 'gamma': 1.004236563519836, 'lambda_sparse': 0.00038193389916915476, 'lr': 0.009859170354899317, 'weight_decay': 3.2090803581141386e-06}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:40:25,246] Trial 16 finished with value: 0.8945687426583112 and parameters: {'n_d': 9, 'n_a': 64, 'n_steps': 10, 'gamma': 1.1739564781422702, 'lambda_sparse': 3.240469843618021e-05, 'lr': 0.004756578559988278, 'weight_decay': 5.071425739587991e-05}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:42:07,191] Trial 17 finished with value: 0.8858327321084274 and parameters: {'n_d': 9, 'n_a': 42, 'n_steps': 7, 'gamma': 1.4535327756425904, 'lambda_sparse': 0.00027857678018081833, 'lr': 0.012425654707459738, 'weight_decay': 2.480835789190365e-06}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:44:08,594] Trial 18 finished with value: 0.8221529542913247 and parameters: {'n_d': 28, 'n_a': 56, 'n_steps': 10, 'gamma': 1.3272878893113615, 'lambda_sparse': 0.001758188611474564, 'lr': 0.0021239042270154093, 'weight_decay': 1.4917946425786086e-05}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:45:32,305] Trial 19 finished with value: 0.8985842461607504 and parameters: {'n_d': 40, 'n_a': 43, 'n_steps': 7, 'gamma': 1.6046060427761706, 'lambda_sparse': 0.0002797325987336648, 'lr': 0.003702159395024117, 'weight_decay': 1.1253991411725382e-05}. Best is trial 12 with value: 0.9227521985241768.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:48:07,547] A new study created in memory with name: no-name-fe20615e-13e3-495b-ac94-25dfd2a68bc8
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:49:12,287] Trial 0 finished with value: 0.9032367014216188 and parameters: {'n_d': 43, 'n_a': 43, 'n_steps': 3, 'gamma': 1.6143540319019731, 'lambda_sparse': 0.0013888453373967552, 'lr': 0.0009059105853097147, 'weight_decay': 0.00041367215194917993}. Best is trial 0 with value: 0.9032367014216188.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:50:50,783] Trial 1 finished with value: 0.9140837738125898 and parameters: {'n_d': 45, 'n_a': 24, 'n_steps': 7, 'gamma': 1.5739980278345513, 'lambda_sparse': 0.0057056548216166585, 'lr': 0.02436490636336461, 'weight_decay': 1.4176872376900408e-05}. Best is trial 1 with value: 0.9140837738125898.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:52:06,314] Trial 2 finished with value: 0.9116477840982171 and parameters: {'n_d': 28, 'n_a': 10, 'n_steps': 6, 'gamma': 1.7980015644938054, 'lambda_sparse': 0.00011683885372216597, 'lr': 0.008311224464003385, 'weight_decay': 0.0008433591669753732}. Best is trial 1 with value: 0.9140837738125898.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:52:35,705] Trial 3 finished with value: 0.519952642135804 and parameters: {'n_d': 27, 'n_a': 40, 'n_steps': 6, 'gamma': 1.9203162954287485, 'lambda_sparse': 0.0001383768472449373, 'lr': 0.03483737523757996, 'weight_decay': 4.606209174848403e-06}. Best is trial 1 with value: 0.9140837738125898.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:53:24,911] Trial 4 finished with value: 0.9331139968419675 and parameters: {'n_d': 57, 'n_a': 37, 'n_steps': 3, 'gamma': 1.667940923574327, 'lambda_sparse': 0.003967697986222571, 'lr': 0.062466455177163926, 'weight_decay': 4.921924752652182e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:55:21,900] Trial 5 finished with value: 0.8802426134729939 and parameters: {'n_d': 25, 'n_a': 43, 'n_steps': 9, 'gamma': 1.528455473403549, 'lambda_sparse': 0.0030434450557287776, 'lr': 0.00533019283085098, 'weight_decay': 2.750749992150578e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:56:45,837] Trial 6 finished with value: 0.5891126909211618 and parameters: {'n_d': 24, 'n_a': 53, 'n_steps': 6, 'gamma': 1.6352848931804131, 'lambda_sparse': 0.0016457412413236122, 'lr': 0.00014145099907104627, 'weight_decay': 5.351345939952537e-05}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:58:05,700] Trial 7 finished with value: 0.8986363456398262 and parameters: {'n_d': 18, 'n_a': 37, 'n_steps': 4, 'gamma': 1.1750498020860758, 'lambda_sparse': 0.00026895639821212874, 'lr': 0.051568569098645455, 'weight_decay': 0.0006121055043729364}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 09:58:37,493] Trial 8 finished with value: 0.48390099263146824 and parameters: {'n_d': 42, 'n_a': 43, 'n_steps': 8, 'gamma': 1.364565089578115, 'lambda_sparse': 0.0009347125374495584, 'lr': 0.0770729604763843, 'weight_decay': 0.000633841721133651}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:00:27,455] Trial 9 finished with value: 0.8955446255468301 and parameters: {'n_d': 52, 'n_a': 12, 'n_steps': 9, 'gamma': 1.8993514535550275, 'lambda_sparse': 2.3495160061993453e-05, 'lr': 0.014301463710271254, 'weight_decay': 3.36074779089102e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:01:33,197] Trial 10 finished with value: 0.9146944234148155 and parameters: {'n_d': 64, 'n_a': 63, 'n_steps': 4, 'gamma': 1.066181717920622, 'lambda_sparse': 0.009927424558904444, 'lr': 0.0010575548632735941, 'weight_decay': 1.0815628819408133e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:02:29,275] Trial 11 finished with value: 0.8950816003242771 and parameters: {'n_d': 62, 'n_a': 61, 'n_steps': 4, 'gamma': 1.065485704281394, 'lambda_sparse': 0.009426656206942918, 'lr': 0.0010543438682404588, 'weight_decay': 1.1320976074320351e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:03:13,912] Trial 12 finished with value: 0.8756169388930848 and parameters: {'n_d': 61, 'n_a': 25, 'n_steps': 3, 'gamma': 1.3570613311308088, 'lambda_sparse': 0.009850048130810765, 'lr': 0.0013094756886854492, 'weight_decay': 1.5454615793512737e-05}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:04:07,992] Trial 13 finished with value: 0.8379175120847421 and parameters: {'n_d': 53, 'n_a': 64, 'n_steps': 4, 'gamma': 1.3320442407606161, 'lambda_sparse': 0.0006239497985497238, 'lr': 0.0002314879602341597, 'weight_decay': 1.1838799720659656e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:05:11,611] Trial 14 finished with value: 0.9098517316585377 and parameters: {'n_d': 55, 'n_a': 52, 'n_steps': 5, 'gamma': 1.0042969152487102, 'lambda_sparse': 0.003063649928143152, 'lr': 0.0026694994669211876, 'weight_decay': 7.630127509169774e-05}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:06:01,129] Trial 15 finished with value: 0.8961198725689599 and parameters: {'n_d': 64, 'n_a': 28, 'n_steps': 3, 'gamma': 1.7145409553761266, 'lambda_sparse': 0.0036992940477280313, 'lr': 0.0003989868059458184, 'weight_decay': 1.0405440703431789e-05}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:07:06,072] Trial 16 finished with value: 0.9199178664536454 and parameters: {'n_d': 9, 'n_a': 54, 'n_steps': 5, 'gamma': 1.1795556332314365, 'lambda_sparse': 1.1047069477855824e-05, 'lr': 0.0018381216217596215, 'weight_decay': 4.935073453946761e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:08:27,596] Trial 17 finished with value: 0.912011032746077 and parameters: {'n_d': 10, 'n_a': 52, 'n_steps': 5, 'gamma': 1.438015560781273, 'lambda_sparse': 1.3013232963413016e-05, 'lr': 0.0035919496067856353, 'weight_decay': 6.913219829295035e-06}. Best is trial 4 with value: 0.9331139968419675.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:09:43,667] Trial 18 finished with value: 0.9334840928031197 and parameters: {'n_d': 8, 'n_a': 32, 'n_steps': 5, 'gamma': 1.2266674300556708, 'lambda_sparse': 3.956576678219114e-05, 'lr': 0.013384072427089395, 'weight_decay': 2.9264914982700805e-05}. Best is trial 18 with value: 0.9334840928031197.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:10:59,032] Trial 19 finished with value: 0.5695408801844986 and parameters: {'n_d': 35, 'n_a': 32, 'n_steps': 10, 'gamma': 1.2685893396734313, 'lambda_sparse': 4.6737818708808115e-05, 'lr': 0.09716309572265319, 'weight_decay': 0.00012222295523293183}. Best is trial 18 with value: 0.9334840928031197.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:12:26,980] A new study created in memory with name: no-name-cc77ea43-c1d3-46a2-8d8f-ab31d5409e51
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:13:36,653] Trial 0 finished with value: 0.9223263988670138 and parameters: {'n_d': 23, 'n_a': 61, 'n_steps': 3, 'gamma': 1.6407249110760724, 'lambda_sparse': 1.0087026495614673e-05, 'lr': 0.0073196803275837035, 'weight_decay': 2.5359928215656246e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:13:58,427] Trial 1 finished with value: -0.8171598028934424 and parameters: {'n_d': 63, 'n_a': 43, 'n_steps': 4, 'gamma': 1.6884695432710957, 'lambda_sparse': 7.677162499121673e-05, 'lr': 0.033098373804208124, 'weight_decay': 1.68370353352753e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:15:09,587] Trial 2 finished with value: 0.9040447355554726 and parameters: {'n_d': 8, 'n_a': 21, 'n_steps': 3, 'gamma': 1.6202932555543563, 'lambda_sparse': 3.4111446204884814e-05, 'lr': 0.07029324333641396, 'weight_decay': 0.00045921280151467247}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:16:28,779] Trial 3 finished with value: 0.9196993574942331 and parameters: {'n_d': 47, 'n_a': 57, 'n_steps': 4, 'gamma': 1.4560521921385257, 'lambda_sparse': 1.2183347607931499e-05, 'lr': 0.015085926457865427, 'weight_decay': 8.92812324493397e-06}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:18:42,947] Trial 4 finished with value: -5.509135914135812 and parameters: {'n_d': 55, 'n_a': 51, 'n_steps': 10, 'gamma': 1.5740540763659459, 'lambda_sparse': 0.0006289154933534196, 'lr': 0.00019385171658583444, 'weight_decay': 0.00045123278839784476}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:19:59,767] Trial 5 finished with value: 0.9170634250881019 and parameters: {'n_d': 19, 'n_a': 35, 'n_steps': 4, 'gamma': 1.568167641605196, 'lambda_sparse': 0.005225484852685419, 'lr': 0.015556467644724766, 'weight_decay': 3.8327886963481944e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:22:06,452] Trial 6 finished with value: 0.8887130614419477 and parameters: {'n_d': 25, 'n_a': 59, 'n_steps': 9, 'gamma': 1.0098318125302368, 'lambda_sparse': 0.006249999840117619, 'lr': 0.0007260441852764065, 'weight_decay': 0.0002465383131526269}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:23:01,179] Trial 7 finished with value: 0.8242016763537908 and parameters: {'n_d': 31, 'n_a': 35, 'n_steps': 4, 'gamma': 1.6292387676871738, 'lambda_sparse': 0.00012712594183239787, 'lr': 0.00020178408477578998, 'weight_decay': 0.0005484114652803163}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:24:53,994] Trial 8 finished with value: 0.8909627073547933 and parameters: {'n_d': 24, 'n_a': 45, 'n_steps': 9, 'gamma': 1.3232907623134724, 'lambda_sparse': 5.467123351395792e-05, 'lr': 0.004897230251117678, 'weight_decay': 0.00022877717535275808}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:26:08,049] Trial 9 finished with value: 0.8860855387571687 and parameters: {'n_d': 16, 'n_a': 52, 'n_steps': 4, 'gamma': 1.2335860498525877, 'lambda_sparse': 0.0014473325471121624, 'lr': 0.0935979056602437, 'weight_decay': 0.00040739430817645093}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:27:33,356] Trial 10 finished with value: 0.8471496358662752 and parameters: {'n_d': 40, 'n_a': 8, 'n_steps': 6, 'gamma': 1.9562325815879242, 'lambda_sparse': 1.4296295820016945e-05, 'lr': 0.0017809776353200112, 'weight_decay': 1.732593392803176e-06}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:29:02,009] Trial 11 finished with value: 0.9105408785082398 and parameters: {'n_d': 43, 'n_a': 62, 'n_steps': 6, 'gamma': 1.8453863437548534, 'lambda_sparse': 1.0404695784733567e-05, 'lr': 0.007242508630272818, 'weight_decay': 9.356528856819674e-06}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:30:11,649] Trial 12 finished with value: 0.9071121777194062 and parameters: {'n_d': 48, 'n_a': 60, 'n_steps': 3, 'gamma': 1.3740430497137905, 'lambda_sparse': 2.3440674174386208e-05, 'lr': 0.012316257359365507, 'weight_decay': 3.276529771084195e-06}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:31:34,197] Trial 13 finished with value: 0.8967743514959736 and parameters: {'n_d': 34, 'n_a': 64, 'n_steps': 5, 'gamma': 1.420734289576128, 'lambda_sparse': 0.00014891625393471591, 'lr': 0.002590969309627411, 'weight_decay': 5.521245149430769e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:32:25,392] Trial 14 finished with value: 0.6615598954870643 and parameters: {'n_d': 52, 'n_a': 52, 'n_steps': 7, 'gamma': 1.795867031688506, 'lambda_sparse': 0.00033347878585073595, 'lr': 0.025914722992854806, 'weight_decay': 9.328850247656095e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:34:10,191] Trial 15 finished with value: 0.8557436410892248 and parameters: {'n_d': 64, 'n_a': 29, 'n_steps': 7, 'gamma': 1.2192172066744917, 'lambda_sparse': 1.1078247521824897e-05, 'lr': 0.0009338345804682357, 'weight_decay': 5.192701711312523e-06}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:34:34,807] Trial 16 finished with value: -2.3086565988386663 and parameters: {'n_d': 30, 'n_a': 45, 'n_steps': 3, 'gamma': 1.7534597097093305, 'lambda_sparse': 3.302517174334413e-05, 'lr': 0.007271779902038346, 'weight_decay': 1.6770814946279503e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:35:57,013] Trial 17 finished with value: 0.9121895645816464 and parameters: {'n_d': 40, 'n_a': 54, 'n_steps': 5, 'gamma': 1.4764831664059554, 'lambda_sparse': 2.379161564686993e-05, 'lr': 0.03837599609992898, 'weight_decay': 1.2108857643394183e-06}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:37:19,149] Trial 18 finished with value: 0.9167010869912524 and parameters: {'n_d': 10, 'n_a': 25, 'n_steps': 5, 'gamma': 1.9445388833279291, 'lambda_sparse': 0.00146217712807717, 'lr': 0.013883209223120304, 'weight_decay': 1.2673619503856765e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:38:28,750] Trial 19 finished with value: 0.911979999656143 and parameters: {'n_d': 46, 'n_a': 57, 'n_steps': 3, 'gamma': 1.085253869301829, 'lambda_sparse': 7.72719725665358e-05, 'lr': 0.0014005314295089423, 'weight_decay': 8.337961294893933e-05}. Best is trial 0 with value: 0.9223263988670138.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:39:54,237] A new study created in memory with name: no-name-2fed4c5a-2597-41b5-8b18-b2b6fce8725e
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:40:08,167] Trial 0 finished with value: -161.17163922909594 and parameters: {'n_d': 23, 'n_a': 23, 'n_steps': 3, 'gamma': 1.9806827287289854, 'lambda_sparse': 0.002289351962597124, 'lr': 0.03804802314516856, 'weight_decay': 1.2280163647578682e-05}. Best is trial 0 with value: -161.17163922909594.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:41:19,541] Trial 1 finished with value: 0.8355482442807961 and parameters: {'n_d': 37, 'n_a': 46, 'n_steps': 3, 'gamma': 1.5561373348238563, 'lambda_sparse': 0.0021377667491707113, 'lr': 0.00023795450784999835, 'weight_decay': 0.00034415016880428017}. Best is trial 1 with value: 0.8355482442807961.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:43:35,145] Trial 2 finished with value: 0.7950673010379042 and parameters: {'n_d': 34, 'n_a': 55, 'n_steps': 10, 'gamma': 1.2997365257854965, 'lambda_sparse': 0.0022974499509437313, 'lr': 0.0005133432056260329, 'weight_decay': 2.4923594091536364e-05}. Best is trial 1 with value: 0.8355482442807961.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:44:45,376] Trial 3 finished with value: 0.802129219006973 and parameters: {'n_d': 52, 'n_a': 27, 'n_steps': 4, 'gamma': 1.9181511759090777, 'lambda_sparse': 0.00023483647997443648, 'lr': 0.0002598315277556697, 'weight_decay': 1.8268162136089902e-05}. Best is trial 1 with value: 0.8355482442807961.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:46:39,229] Trial 4 finished with value: 0.3960866371470454 and parameters: {'n_d': 17, 'n_a': 63, 'n_steps': 8, 'gamma': 1.6266740836488451, 'lambda_sparse': 0.0012454932023560849, 'lr': 0.00020067739769146718, 'weight_decay': 5.06469649500125e-05}. Best is trial 1 with value: 0.8355482442807961.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:47:20,259] Trial 5 finished with value: 0.4327138202701649 and parameters: {'n_d': 53, 'n_a': 12, 'n_steps': 8, 'gamma': 1.8807244313502764, 'lambda_sparse': 3.968682481878048e-05, 'lr': 0.03930981092825061, 'weight_decay': 1.0146395867616747e-05}. Best is trial 1 with value: 0.8355482442807961.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:49:33,374] Trial 6 finished with value: 0.5466770084959396 and parameters: {'n_d': 45, 'n_a': 58, 'n_steps': 10, 'gamma': 1.611787287977592, 'lambda_sparse': 0.0001309941929775339, 'lr': 0.0002788156895347271, 'weight_decay': 1.227544963440347e-05}. Best is trial 1 with value: 0.8355482442807961.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:51:39,157] Trial 7 finished with value: 0.741783935906483 and parameters: {'n_d': 21, 'n_a': 57, 'n_steps': 9, 'gamma': 1.8736922605293433, 'lambda_sparse': 0.00011233077646688869, 'lr': 0.0012286876623710335, 'weight_decay': 1.1401909517049492e-05}. Best is trial 1 with value: 0.8355482442807961.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:53:07,985] Trial 8 finished with value: 0.9028445946063897 and parameters: {'n_d': 59, 'n_a': 31, 'n_steps': 6, 'gamma': 1.9669179895776008, 'lambda_sparse': 0.005896493657723416, 'lr': 0.01908573978238541, 'weight_decay': 4.596353951831041e-06}. Best is trial 8 with value: 0.9028445946063897.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:54:17,808] Trial 9 finished with value: 0.9050150114612174 and parameters: {'n_d': 32, 'n_a': 31, 'n_steps': 3, 'gamma': 1.9961305012758008, 'lambda_sparse': 1.4606630981276338e-05, 'lr': 0.0036289885683066427, 'weight_decay': 1.4134571705641656e-06}. Best is trial 9 with value: 0.9050150114612174.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:55:30,674] Trial 10 finished with value: 0.9191779374200522 and parameters: {'n_d': 8, 'n_a': 41, 'n_steps': 5, 'gamma': 1.0696728302215266, 'lambda_sparse': 1.1895043206111954e-05, 'lr': 0.005368873737628293, 'weight_decay': 1.6795703920899807e-06}. Best is trial 10 with value: 0.9191779374200522.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:56:34,220] Trial 11 finished with value: 0.9202003067214005 and parameters: {'n_d': 8, 'n_a': 41, 'n_steps': 5, 'gamma': 1.0256599096023264, 'lambda_sparse': 1.1897794447353982e-05, 'lr': 0.005640169133657342, 'weight_decay': 1.306915079184448e-06}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:57:51,530] Trial 12 finished with value: 0.9117649480053959 and parameters: {'n_d': 8, 'n_a': 43, 'n_steps': 5, 'gamma': 1.0349954999264848, 'lambda_sparse': 1.0431484971565731e-05, 'lr': 0.004971923370334265, 'weight_decay': 1.0912736927349778e-06}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 10:59:22,604] Trial 13 finished with value: 0.9144539855014246 and parameters: {'n_d': 8, 'n_a': 42, 'n_steps': 6, 'gamma': 1.0221744759984928, 'lambda_sparse': 3.419383690549593e-05, 'lr': 0.010304369538941083, 'weight_decay': 2.382617438573182e-06}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:00:43,651] Trial 14 finished with value: 0.9029973079100015 and parameters: {'n_d': 15, 'n_a': 48, 'n_steps': 5, 'gamma': 1.2182570221989275, 'lambda_sparse': 3.182644226158927e-05, 'lr': 0.0015324923257367094, 'weight_decay': 9.393476079579625e-05}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:02:05,263] Trial 15 finished with value: 0.9124610508014195 and parameters: {'n_d': 27, 'n_a': 38, 'n_steps': 5, 'gamma': 1.2134153105837497, 'lambda_sparse': 6.22938518140974e-05, 'lr': 0.008155274566587068, 'weight_decay': 3.7038064113470426e-06}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:03:47,980] Trial 16 finished with value: 0.8314157512815583 and parameters: {'n_d': 15, 'n_a': 17, 'n_steps': 7, 'gamma': 1.4037700057564897, 'lambda_sparse': 0.0005496310434136864, 'lr': 0.001515094175249638, 'weight_decay': 4.545201571626929e-06}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:04:21,430] Trial 17 finished with value: 0.57181941182911 and parameters: {'n_d': 9, 'n_a': 50, 'n_steps': 4, 'gamma': 1.136324422421073, 'lambda_sparse': 1.756158978347753e-05, 'lr': 0.09453149138104174, 'weight_decay': 1.0273499257259547e-06}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:06:03,931] Trial 18 finished with value: 0.9045726010596414 and parameters: {'n_d': 27, 'n_a': 36, 'n_steps': 7, 'gamma': 1.4115538179430602, 'lambda_sparse': 1.030096916449666e-05, 'lr': 0.01456043729875625, 'weight_decay': 0.00022406621146135586}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:07:11,142] Trial 19 finished with value: 0.9103767847832211 and parameters: {'n_d': 40, 'n_a': 37, 'n_steps': 4, 'gamma': 1.1169734317873197, 'lambda_sparse': 7.276940156474473e-05, 'lr': 0.002275567599253901, 'weight_decay': 0.0008107246628415442}. Best is trial 11 with value: 0.9202003067214005.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:09:08,681] A new study created in memory with name: no-name-4c86f68d-0a71-4979-a3c2-4444238afe69
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:10:12,447] Trial 0 finished with value: 0.8927163154416411 and parameters: {'n_d': 46, 'n_a': 45, 'n_steps': 4, 'gamma': 1.8017354232557516, 'lambda_sparse': 0.0004553224584817182, 'lr': 0.0018822267054406168, 'weight_decay': 0.0003695948795738744}. Best is trial 0 with value: 0.8927163154416411.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:12:03,445] Trial 1 finished with value: 0.9170425909464318 and parameters: {'n_d': 34, 'n_a': 11, 'n_steps': 9, 'gamma': 1.2441227345274315, 'lambda_sparse': 0.0002488108891080168, 'lr': 0.021858977206667015, 'weight_decay': 4.995310697072421e-05}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:13:59,577] Trial 2 finished with value: 0.8640256723042967 and parameters: {'n_d': 42, 'n_a': 43, 'n_steps': 8, 'gamma': 1.1789613460090544, 'lambda_sparse': 0.0010581232459557707, 'lr': 0.0007723182042220058, 'weight_decay': 5.772923426863337e-05}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:16:06,729] Trial 3 finished with value: 0.9060286874428475 and parameters: {'n_d': 52, 'n_a': 27, 'n_steps': 9, 'gamma': 1.9508937163546918, 'lambda_sparse': 0.0010073864097807591, 'lr': 0.03592864905685955, 'weight_decay': 8.347465416480412e-06}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:17:25,473] Trial 4 finished with value: 0.9122840138564288 and parameters: {'n_d': 60, 'n_a': 36, 'n_steps': 5, 'gamma': 1.6888414222961954, 'lambda_sparse': 1.4978033591286207e-05, 'lr': 0.005214245978407997, 'weight_decay': 0.0003597698436648161}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:18:46,773] Trial 5 finished with value: 0.8902398907252307 and parameters: {'n_d': 20, 'n_a': 48, 'n_steps': 4, 'gamma': 1.4023350855879528, 'lambda_sparse': 0.0003167039567141836, 'lr': 0.0013838354101446562, 'weight_decay': 8.023087570043222e-05}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:19:30,335] Trial 6 finished with value: 0.5742639528638125 and parameters: {'n_d': 43, 'n_a': 37, 'n_steps': 7, 'gamma': 1.89016598844785, 'lambda_sparse': 0.0008678357635250585, 'lr': 0.021018568194247345, 'weight_decay': 0.0002106478347917027}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:21:48,773] Trial 7 finished with value: 0.8720306559987446 and parameters: {'n_d': 53, 'n_a': 34, 'n_steps': 10, 'gamma': 1.7525243058905717, 'lambda_sparse': 0.000492342364965068, 'lr': 0.010727541210575963, 'weight_decay': 5.415380393483294e-05}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:22:59,684] Trial 8 finished with value: 0.9089893518852338 and parameters: {'n_d': 35, 'n_a': 31, 'n_steps': 3, 'gamma': 1.771385229427007, 'lambda_sparse': 0.0005240514040000991, 'lr': 0.007200297651588942, 'weight_decay': 0.0005662353627751833}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:24:11,651] Trial 9 finished with value: 0.8397077760932866 and parameters: {'n_d': 53, 'n_a': 44, 'n_steps': 3, 'gamma': 1.28706146811747, 'lambda_sparse': 0.00019592734465503128, 'lr': 0.00017649694538916634, 'weight_decay': 3.0573895876770662e-06}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:26:21,868] Trial 10 finished with value: 0.8848304767400799 and parameters: {'n_d': 9, 'n_a': 13, 'n_steps': 10, 'gamma': 1.110789250035596, 'lambda_sparse': 0.009761097439166887, 'lr': 0.09840501751316806, 'weight_decay': 1.3659221629476816e-05}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:27:49,946] Trial 11 finished with value: 0.9014624828447168 and parameters: {'n_d': 64, 'n_a': 61, 'n_steps': 6, 'gamma': 1.5670207015816742, 'lambda_sparse': 1.0417499665281461e-05, 'lr': 0.004918619105205724, 'weight_decay': 0.0008894534947484442}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:29:22,619] Trial 12 finished with value: 0.9089987777098315 and parameters: {'n_d': 29, 'n_a': 9, 'n_steps': 6, 'gamma': 1.5521519785652995, 'lambda_sparse': 1.681193842212166e-05, 'lr': 0.0321233622435928, 'weight_decay': 0.0001415507660272284}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:30:36,522] Trial 13 finished with value: 0.8782680723787485 and parameters: {'n_d': 27, 'n_a': 19, 'n_steps': 5, 'gamma': 1.0026642191204274, 'lambda_sparse': 5.1553678767779395e-05, 'lr': 0.0005702468579207911, 'weight_decay': 1.1622097415028065e-06}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:31:14,129] Trial 14 finished with value: 0.541048605264842 and parameters: {'n_d': 64, 'n_a': 21, 'n_steps': 8, 'gamma': 1.37986752557136, 'lambda_sparse': 7.524134839487329e-05, 'lr': 0.08283488698186119, 'weight_decay': 2.107161269165526e-05}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:32:40,068] Trial 15 finished with value: 0.9008902475602129 and parameters: {'n_d': 19, 'n_a': 62, 'n_steps': 7, 'gamma': 1.5755092576100131, 'lambda_sparse': 0.003269419601562686, 'lr': 0.012677652469180902, 'weight_decay': 0.00017954604754618467}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:34:03,605] Trial 16 finished with value: 0.8943090247865116 and parameters: {'n_d': 34, 'n_a': 53, 'n_steps': 5, 'gamma': 1.664714653242971, 'lambda_sparse': 4.3245346357978306e-05, 'lr': 0.0037696786732746594, 'weight_decay': 7.086338187575608e-06}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:36:06,292] Trial 17 finished with value: 0.8544279282132672 and parameters: {'n_d': 59, 'n_a': 22, 'n_steps': 9, 'gamma': 1.4326628490672488, 'lambda_sparse': 0.00010985199109004261, 'lr': 0.002584554290378706, 'weight_decay': 2.8269990533731054e-05}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:37:09,766] Trial 18 finished with value: 0.9115727143037688 and parameters: {'n_d': 40, 'n_a': 10, 'n_steps': 5, 'gamma': 1.2109773546828053, 'lambda_sparse': 2.7874550919800015e-05, 'lr': 0.01809569474561255, 'weight_decay': 0.0003409992530286085}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:38:41,698] Trial 19 finished with value: 0.4240489852045848 and parameters: {'n_d': 25, 'n_a': 16, 'n_steps': 8, 'gamma': 1.3147533375319425, 'lambda_sparse': 0.0028326830381284894, 'lr': 0.00021612925286713282, 'weight_decay': 0.00010180545467846676}. Best is trial 1 with value: 0.9170425909464318.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:41:07,846] A new study created in memory with name: no-name-ea562d35-6a93-4c79-b7b0-4a726d48c330
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:42:48,275] Trial 0 finished with value: 0.5996216972645569 and parameters: {'n_d': 27, 'n_a': 28, 'n_steps': 7, 'gamma': 1.1534979875715128, 'lambda_sparse': 0.0009827251203204706, 'lr': 0.00015184080196176765, 'weight_decay': 7.017041178905075e-06}. Best is trial 0 with value: 0.5996216972645569.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:44:51,871] Trial 1 finished with value: 0.7472975333061879 and parameters: {'n_d': 50, 'n_a': 24, 'n_steps': 9, 'gamma': 1.3332701545537928, 'lambda_sparse': 0.0021517537311871895, 'lr': 0.0005697783121166452, 'weight_decay': 2.0930153467418415e-05}. Best is trial 1 with value: 0.7472975333061879.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:46:32,665] Trial 2 finished with value: 0.7358927260169668 and parameters: {'n_d': 22, 'n_a': 18, 'n_steps': 7, 'gamma': 1.6496431237222824, 'lambda_sparse': 0.00023409170546177409, 'lr': 0.000931782633887606, 'weight_decay': 1.269511364761359e-06}. Best is trial 1 with value: 0.7472975333061879.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:48:49,469] Trial 3 finished with value: 0.9234548597537999 and parameters: {'n_d': 32, 'n_a': 25, 'n_steps': 10, 'gamma': 1.189246401124155, 'lambda_sparse': 0.003928397375614644, 'lr': 0.025833172630135535, 'weight_decay': 0.00028289531368032176}. Best is trial 3 with value: 0.9234548597537999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:49:11,982] Trial 4 finished with value: 0.2855015604055182 and parameters: {'n_d': 59, 'n_a': 44, 'n_steps': 4, 'gamma': 1.1389950624807212, 'lambda_sparse': 1.5086544820761012e-05, 'lr': 0.035407842870191344, 'weight_decay': 6.229441013422885e-05}. Best is trial 3 with value: 0.9234548597537999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:51:12,040] Trial 5 finished with value: 0.7724363671916201 and parameters: {'n_d': 35, 'n_a': 58, 'n_steps': 9, 'gamma': 1.6131887771000994, 'lambda_sparse': 0.00022715920172294192, 'lr': 0.0010960827469961437, 'weight_decay': 0.00011893624031156122}. Best is trial 3 with value: 0.9234548597537999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:52:34,224] Trial 6 finished with value: 0.9115034681178096 and parameters: {'n_d': 55, 'n_a': 56, 'n_steps': 7, 'gamma': 1.2167040766888513, 'lambda_sparse': 0.00012935721761249747, 'lr': 0.08083038640416768, 'weight_decay': 0.0002518035955592769}. Best is trial 3 with value: 0.9234548597537999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:54:35,301] Trial 7 finished with value: 0.8453817611741546 and parameters: {'n_d': 63, 'n_a': 17, 'n_steps': 9, 'gamma': 1.3404927503392725, 'lambda_sparse': 0.0003440863598127652, 'lr': 0.003920219016232759, 'weight_decay': 6.5707165978262734e-06}. Best is trial 3 with value: 0.9234548597537999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:56:26,013] Trial 8 finished with value: 0.8361678079403486 and parameters: {'n_d': 53, 'n_a': 11, 'n_steps': 8, 'gamma': 1.7997912074518978, 'lambda_sparse': 0.004324648701186798, 'lr': 0.002448694432043464, 'weight_decay': 8.473141665363686e-05}. Best is trial 3 with value: 0.9234548597537999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:57:11,460] Trial 9 finished with value: -3.5594458121814405 and parameters: {'n_d': 43, 'n_a': 8, 'n_steps': 9, 'gamma': 1.8280194110545742, 'lambda_sparse': 1.6627758140866884e-05, 'lr': 0.0258029111469955, 'weight_decay': 0.00023640002844135122}. Best is trial 3 with value: 0.9234548597537999.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:58:27,032] Trial 10 finished with value: 0.9281318050788326 and parameters: {'n_d': 9, 'n_a': 38, 'n_steps': 4, 'gamma': 1.025298981847253, 'lambda_sparse': 0.007761527919351624, 'lr': 0.008864367727253908, 'weight_decay': 0.0008010636564578424}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 11:59:36,530] Trial 11 finished with value: 0.9191154495659548 and parameters: {'n_d': 10, 'n_a': 41, 'n_steps': 3, 'gamma': 1.0207060816207267, 'lambda_sparse': 0.008991956086386957, 'lr': 0.01056453713131804, 'weight_decay': 0.000959746160757339}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:00:55,522] Trial 12 finished with value: 0.9273630576324716 and parameters: {'n_d': 10, 'n_a': 35, 'n_steps': 5, 'gamma': 1.0065384609849441, 'lambda_sparse': 0.009267445637395205, 'lr': 0.011137005960140629, 'weight_decay': 0.0007934946646618804}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:02:17,208] Trial 13 finished with value: 0.9236677988549002 and parameters: {'n_d': 13, 'n_a': 36, 'n_steps': 5, 'gamma': 1.0504001841807282, 'lambda_sparse': 0.009221888223515442, 'lr': 0.00709013777940113, 'weight_decay': 0.0006715635086095912}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:03:40,471] Trial 14 finished with value: 0.9182651856185519 and parameters: {'n_d': 18, 'n_a': 50, 'n_steps': 5, 'gamma': 1.402693470475659, 'lambda_sparse': 0.0010759460010845716, 'lr': 0.010799682922253426, 'weight_decay': 0.0005320516549743032}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:05:03,429] Trial 15 finished with value: 0.9190555227575362 and parameters: {'n_d': 9, 'n_a': 34, 'n_steps': 5, 'gamma': 1.007184368506056, 'lambda_sparse': 0.0014040373393332099, 'lr': 0.0032822168577487597, 'weight_decay': 2.536665634699405e-05}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:05:57,971] Trial 16 finished with value: 0.8927403752273143 and parameters: {'n_d': 18, 'n_a': 45, 'n_steps': 3, 'gamma': 1.9721103005551415, 'lambda_sparse': 6.091265381978345e-05, 'lr': 0.06246301546666506, 'weight_decay': 0.0009973011913540553}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:07:15,834] Trial 17 finished with value: 0.9204488489601301 and parameters: {'n_d': 28, 'n_a': 31, 'n_steps': 4, 'gamma': 1.4358727012126073, 'lambda_sparse': 0.00404457523798199, 'lr': 0.014681281067820339, 'weight_decay': 0.00035238757215472715}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:08:42,790] Trial 18 finished with value: 0.9235746320914799 and parameters: {'n_d': 17, 'n_a': 64, 'n_steps': 6, 'gamma': 1.265236020160293, 'lambda_sparse': 0.0005685307583358953, 'lr': 0.005489927665816887, 'weight_decay': 0.00013296832142614332}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:10:00,171] Trial 19 finished with value: 0.9143421936689372 and parameters: {'n_d': 43, 'n_a': 40, 'n_steps': 4, 'gamma': 1.5568975659810325, 'lambda_sparse': 0.002454812422828497, 'lr': 0.00233764726277146, 'weight_decay': 4.746469764141165e-05}. Best is trial 10 with value: 0.9281318050788326.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:11:58,101] A new study created in memory with name: no-name-7b5ae6b8-f660-43dd-9ca4-5aa328aab81f
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:13:41,113] Trial 0 finished with value: 0.9161314358507919 and parameters: {'n_d': 64, 'n_a': 27, 'n_steps': 7, 'gamma': 1.3868251072231224, 'lambda_sparse': 0.0015901010499982402, 'lr': 0.04231405663180669, 'weight_decay': 8.938318212155011e-05}. Best is trial 0 with value: 0.9161314358507919.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:14:56,219] Trial 1 finished with value: 0.9190015002389531 and parameters: {'n_d': 52, 'n_a': 63, 'n_steps': 4, 'gamma': 1.0069441700548034, 'lambda_sparse': 5.307719224578655e-05, 'lr': 0.004062478984849044, 'weight_decay': 3.902526396365931e-05}. Best is trial 1 with value: 0.9190015002389531.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:16:54,317] Trial 2 finished with value: 0.8802134766889259 and parameters: {'n_d': 60, 'n_a': 58, 'n_steps': 10, 'gamma': 1.0956650812685733, 'lambda_sparse': 0.006586925694973885, 'lr': 0.000797317707882286, 'weight_decay': 1.3777215904307506e-05}. Best is trial 1 with value: 0.9190015002389531.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:18:46,536] Trial 3 finished with value: 0.7621065771126427 and parameters: {'n_d': 44, 'n_a': 58, 'n_steps': 8, 'gamma': 1.626716204588194, 'lambda_sparse': 2.9425131550604615e-05, 'lr': 0.00045888826113169446, 'weight_decay': 7.619942899996892e-06}. Best is trial 1 with value: 0.9190015002389531.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:20:41,730] Trial 4 finished with value: 0.9212969806035667 and parameters: {'n_d': 11, 'n_a': 64, 'n_steps': 8, 'gamma': 1.0559203345014052, 'lambda_sparse': 2.3961103453618993e-05, 'lr': 0.04177882381017636, 'weight_decay': 5.3587735424100395e-05}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:22:01,903] Trial 5 finished with value: 0.888018103018976 and parameters: {'n_d': 11, 'n_a': 63, 'n_steps': 5, 'gamma': 1.2368014452065113, 'lambda_sparse': 1.3215603779055517e-05, 'lr': 0.0006482858055939065, 'weight_decay': 2.114378484914818e-05}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:22:48,917] Trial 6 finished with value: 0.5460725114368774 and parameters: {'n_d': 62, 'n_a': 56, 'n_steps': 8, 'gamma': 1.801146839011094, 'lambda_sparse': 3.768841610433343e-05, 'lr': 0.028956705996558568, 'weight_decay': 6.69661153430329e-05}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:23:30,128] Trial 7 finished with value: 0.6214862169649147 and parameters: {'n_d': 45, 'n_a': 9, 'n_steps': 8, 'gamma': 1.2860772635270625, 'lambda_sparse': 0.005375375807134938, 'lr': 0.07423829935860211, 'weight_decay': 0.0005604815843783275}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:25:03,441] Trial 8 finished with value: 0.5092729679917493 and parameters: {'n_d': 29, 'n_a': 21, 'n_steps': 7, 'gamma': 1.3451851090276352, 'lambda_sparse': 2.3050799660412494e-05, 'lr': 0.0001690103726494545, 'weight_decay': 1.5903665424458573e-05}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:26:33,570] Trial 9 finished with value: 0.9048955641342687 and parameters: {'n_d': 22, 'n_a': 54, 'n_steps': 6, 'gamma': 1.680417237345878, 'lambda_sparse': 0.0007021776275550834, 'lr': 0.003027490566611676, 'weight_decay': 0.00038108880611946347}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:28:49,235] Trial 10 finished with value: 0.8905388078900361 and parameters: {'n_d': 8, 'n_a': 44, 'n_steps': 10, 'gamma': 1.5227062744493474, 'lambda_sparse': 0.00015038973038954538, 'lr': 0.010327466970448614, 'weight_decay': 2.3050448804888e-06}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:29:58,872] Trial 11 finished with value: 0.9202804895404989 and parameters: {'n_d': 49, 'n_a': 42, 'n_steps': 3, 'gamma': 1.0060235273173241, 'lambda_sparse': 9.9826990429018e-05, 'lr': 0.00613986444865207, 'weight_decay': 0.00013559251049827164}. Best is trial 4 with value: 0.9212969806035667.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:31:08,513] Trial 12 finished with value: 0.9303368826611063 and parameters: {'n_d': 33, 'n_a': 44, 'n_steps': 3, 'gamma': 1.1334009664732887, 'lambda_sparse': 0.00015119918186529051, 'lr': 0.010862718477674768, 'weight_decay': 0.00016902276238760724}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:32:18,318] Trial 13 finished with value: 0.9297840006640544 and parameters: {'n_d': 19, 'n_a': 46, 'n_steps': 3, 'gamma': 1.1510477544525732, 'lambda_sparse': 0.00030227917935390496, 'lr': 0.016252755547353268, 'weight_decay': 0.00020345046531907774}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:32:46,971] Trial 14 finished with value: 0.048505534565858155 and parameters: {'n_d': 30, 'n_a': 45, 'n_steps': 3, 'gamma': 1.9641349182378867, 'lambda_sparse': 0.00035229132508845005, 'lr': 0.016510641805113524, 'weight_decay': 0.0002447045644245955}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:34:06,107] Trial 15 finished with value: 0.8951850259168832 and parameters: {'n_d': 21, 'n_a': 31, 'n_steps': 4, 'gamma': 1.1862606357682832, 'lambda_sparse': 0.00029884336154084996, 'lr': 0.0019473486026443947, 'weight_decay': 0.0009364437785963458}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:35:28,420] Trial 16 finished with value: 0.9283655926420132 and parameters: {'n_d': 35, 'n_a': 38, 'n_steps': 4, 'gamma': 1.4431223904741446, 'lambda_sparse': 0.0013662394647057702, 'lr': 0.010569611055733466, 'weight_decay': 0.0001858447362667135}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:36:49,903] Trial 17 finished with value: 0.9172746004784713 and parameters: {'n_d': 23, 'n_a': 50, 'n_steps': 5, 'gamma': 1.1674750369502112, 'lambda_sparse': 0.00010248846446188951, 'lr': 0.0020012530929495818, 'weight_decay': 0.0003892265893562014}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:37:39,684] Trial 18 finished with value: 0.9211036849366991 and parameters: {'n_d': 17, 'n_a': 35, 'n_steps': 3, 'gamma': 1.1452973987769275, 'lambda_sparse': 0.0002966690853925526, 'lr': 0.01995820736237855, 'weight_decay': 0.0001295584399377479}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:38:00,190] Trial 19 finished with value: 0.32270798029176717 and parameters: {'n_d': 37, 'n_a': 49, 'n_steps': 5, 'gamma': 1.5121319932689432, 'lambda_sparse': 0.0024659694032096954, 'lr': 0.08852067628665036, 'weight_decay': 1.0053867674691441e-06}. Best is trial 12 with value: 0.9303368826611063.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:38:58,077] A new study created in memory with name: no-name-a53f13c7-948b-47af-a556-8c17502e9cc9
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:39:13,673] Trial 0 finished with value: 0.16522480074260315 and parameters: {'n_d': 55, 'n_a': 22, 'n_steps': 3, 'gamma': 1.7171809079437867, 'lambda_sparse': 0.0018937835168749795, 'lr': 0.00934223584716681, 'weight_decay': 4.7077520402343997e-05}. Best is trial 0 with value: 0.16522480074260315.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:40:55,582] Trial 1 finished with value: 0.8521474043087762 and parameters: {'n_d': 28, 'n_a': 21, 'n_steps': 9, 'gamma': 1.3181930792087877, 'lambda_sparse': 6.591216685816664e-05, 'lr': 0.004031379011404625, 'weight_decay': 0.00013260315822535005}. Best is trial 1 with value: 0.8521474043087762.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:42:31,482] Trial 2 finished with value: 0.8833846992804951 and parameters: {'n_d': 41, 'n_a': 18, 'n_steps': 8, 'gamma': 1.543777015677774, 'lambda_sparse': 0.004032933684950389, 'lr': 0.013236943155365133, 'weight_decay': 0.0001361078026536087}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:44:03,397] Trial 3 finished with value: 0.7976838903951343 and parameters: {'n_d': 36, 'n_a': 55, 'n_steps': 6, 'gamma': 1.1501158680817722, 'lambda_sparse': 1.8786363163143986e-05, 'lr': 0.00033502916248714736, 'weight_decay': 5.1559627142034526e-06}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:45:45,831] Trial 4 finished with value: 0.6647149275302903 and parameters: {'n_d': 13, 'n_a': 18, 'n_steps': 7, 'gamma': 1.3007000104497488, 'lambda_sparse': 1.2414550352697372e-05, 'lr': 0.00027202979540563157, 'weight_decay': 6.61339727608614e-06}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:46:18,014] Trial 5 finished with value: 0.2736310701173956 and parameters: {'n_d': 23, 'n_a': 47, 'n_steps': 4, 'gamma': 1.9470145134598478, 'lambda_sparse': 0.008533405388519304, 'lr': 0.012951562232423887, 'weight_decay': 2.981356267803465e-05}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:47:24,260] Trial 6 finished with value: 0.8525995938962859 and parameters: {'n_d': 34, 'n_a': 41, 'n_steps': 3, 'gamma': 1.498004534411121, 'lambda_sparse': 1.043656373003562e-05, 'lr': 0.00037079653260215027, 'weight_decay': 0.00029847144707367156}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:49:20,311] Trial 7 finished with value: 0.4250421371198656 and parameters: {'n_d': 49, 'n_a': 22, 'n_steps': 8, 'gamma': 1.9773592675680234, 'lambda_sparse': 0.002417430285643871, 'lr': 0.0001781203319401934, 'weight_decay': 1.319315445781072e-06}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:51:03,692] Trial 8 finished with value: 0.8057081289613566 and parameters: {'n_d': 8, 'n_a': 62, 'n_steps': 7, 'gamma': 1.8935489025527625, 'lambda_sparse': 0.000713668268341896, 'lr': 0.001913169222902624, 'weight_decay': 7.672912707175162e-06}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:52:36,124] Trial 9 finished with value: 0.778721226180304 and parameters: {'n_d': 32, 'n_a': 24, 'n_steps': 6, 'gamma': 1.1543172208556338, 'lambda_sparse': 0.0005435089560305311, 'lr': 0.0003496459952847438, 'weight_decay': 2.3064126197828653e-06}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:53:23,889] Trial 10 finished with value: 0.5103708197601925 and parameters: {'n_d': 46, 'n_a': 9, 'n_steps': 10, 'gamma': 1.6195901692818941, 'lambda_sparse': 0.00013872896986083158, 'lr': 0.09615829676218997, 'weight_decay': 0.0009718193803116077}. Best is trial 2 with value: 0.8833846992804951.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:54:46,043] Trial 11 finished with value: 0.8903289568676466 and parameters: {'n_d': 63, 'n_a': 37, 'n_steps': 5, 'gamma': 1.508813904532052, 'lambda_sparse': 0.007124084880101631, 'lr': 0.04941010441586865, 'weight_decay': 0.00045381516706972903}. Best is trial 11 with value: 0.8903289568676466.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:55:26,170] Trial 12 finished with value: 0.6399381625693559 and parameters: {'n_d': 64, 'n_a': 36, 'n_steps': 5, 'gamma': 1.4828638659369393, 'lambda_sparse': 0.00844097335201651, 'lr': 0.06166482019808524, 'weight_decay': 0.0005143051646331358}. Best is trial 11 with value: 0.8903289568676466.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:57:18,966] Trial 13 finished with value: 0.8798557669683443 and parameters: {'n_d': 64, 'n_a': 33, 'n_steps': 8, 'gamma': 1.6969026473453697, 'lambda_sparse': 0.00291270737464022, 'lr': 0.029460157622648676, 'weight_decay': 0.00012139012178863997}. Best is trial 11 with value: 0.8903289568676466.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:58:37,984] Trial 14 finished with value: 0.9048206117813853 and parameters: {'n_d': 44, 'n_a': 8, 'n_steps': 5, 'gamma': 1.3286444152164534, 'lambda_sparse': 0.0011501532670021315, 'lr': 0.027153275592138, 'weight_decay': 0.00019034469565003465}. Best is trial 14 with value: 0.9048206117813853.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 12:59:49,421] Trial 15 finished with value: 0.8861733830208963 and parameters: {'n_d': 53, 'n_a': 9, 'n_steps': 5, 'gamma': 1.344711321786165, 'lambda_sparse': 0.0009752862268334442, 'lr': 0.037165477369838704, 'weight_decay': 3.957842658704353e-05}. Best is trial 14 with value: 0.9048206117813853.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:01:02,108] Trial 16 finished with value: 0.9019298494854137 and parameters: {'n_d': 58, 'n_a': 31, 'n_steps': 5, 'gamma': 1.3707580072773973, 'lambda_sparse': 0.00023453913221580425, 'lr': 0.0018127545724824883, 'weight_decay': 0.0005073656660444741}. Best is trial 14 with value: 0.9048206117813853.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:02:26,248] Trial 17 finished with value: 0.8669487708359036 and parameters: {'n_d': 56, 'n_a': 31, 'n_steps': 4, 'gamma': 1.0882058799136927, 'lambda_sparse': 0.00022620896422432065, 'lr': 0.001307333780557599, 'weight_decay': 0.00028131401545570514}. Best is trial 14 with value: 0.9048206117813853.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:03:50,830] Trial 18 finished with value: 0.8859116181578569 and parameters: {'n_d': 45, 'n_a': 46, 'n_steps': 4, 'gamma': 1.0064792934763507, 'lambda_sparse': 7.02445700926634e-05, 'lr': 0.0009059598605713454, 'weight_decay': 0.0008427929389414153}. Best is trial 14 with value: 0.9048206117813853.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:05:23,693] Trial 19 finished with value: 0.9030684118326651 and parameters: {'n_d': 42, 'n_a': 13, 'n_steps': 6, 'gamma': 1.377684782642336, 'lambda_sparse': 0.0003832413956403683, 'lr': 0.006940564912188924, 'weight_decay': 7.220418253743489e-05}. Best is trial 14 with value: 0.9048206117813853.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:07:07,732] A new study created in memory with name: no-name-fac420f8-33e4-4383-9a58-a1c5d8ea018b
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:08:23,503] Trial 0 finished with value: 0.7847028413922328 and parameters: {'n_d': 44, 'n_a': 53, 'n_steps': 5, 'gamma': 1.723147620795397, 'lambda_sparse': 8.731846454203402e-05, 'lr': 0.0002527674012587426, 'weight_decay': 0.0009435942680680407}. Best is trial 0 with value: 0.7847028413922328.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:10:17,654] Trial 1 finished with value: 0.8574163768135364 and parameters: {'n_d': 30, 'n_a': 34, 'n_steps': 8, 'gamma': 1.530630382559536, 'lambda_sparse': 0.007791147504446974, 'lr': 0.015952321073374538, 'weight_decay': 1.2191383567963962e-06}. Best is trial 1 with value: 0.8574163768135364.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:12:24,275] Trial 2 finished with value: 0.8815160506758836 and parameters: {'n_d': 31, 'n_a': 39, 'n_steps': 9, 'gamma': 1.1210547894092928, 'lambda_sparse': 3.7497831821287845e-05, 'lr': 0.061053514935359744, 'weight_decay': 0.00019240648985950845}. Best is trial 2 with value: 0.8815160506758836.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:13:50,470] Trial 3 finished with value: 0.871821905307381 and parameters: {'n_d': 9, 'n_a': 53, 'n_steps': 6, 'gamma': 1.605320674543824, 'lambda_sparse': 3.8038654415087635e-05, 'lr': 0.0027549194169828456, 'weight_decay': 6.40099665900774e-05}. Best is trial 2 with value: 0.8815160506758836.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:14:55,620] Trial 4 finished with value: 0.8863077439838414 and parameters: {'n_d': 40, 'n_a': 40, 'n_steps': 3, 'gamma': 1.5156983983055234, 'lambda_sparse': 0.00012048902817378407, 'lr': 0.007272344509194928, 'weight_decay': 4.640282045313482e-06}. Best is trial 4 with value: 0.8863077439838414.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:15:24,925] Trial 5 finished with value: 0.6258074552560571 and parameters: {'n_d': 11, 'n_a': 40, 'n_steps': 5, 'gamma': 1.2624022859889839, 'lambda_sparse': 0.00793002742022023, 'lr': 0.09460524805183605, 'weight_decay': 0.0001494475303934716}. Best is trial 4 with value: 0.8863077439838414.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:17:17,703] Trial 6 finished with value: 0.8075456189273664 and parameters: {'n_d': 8, 'n_a': 48, 'n_steps': 8, 'gamma': 1.025185883636283, 'lambda_sparse': 0.0031770436806456102, 'lr': 0.0003980798944486999, 'weight_decay': 0.0003939394997656405}. Best is trial 4 with value: 0.8863077439838414.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:18:49,841] Trial 7 finished with value: 0.7062881072306004 and parameters: {'n_d': 21, 'n_a': 51, 'n_steps': 6, 'gamma': 1.2253356656110954, 'lambda_sparse': 0.00412279826104725, 'lr': 0.00013452885311647161, 'weight_decay': 1.1892631793334924e-05}. Best is trial 4 with value: 0.8863077439838414.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:21:04,315] Trial 8 finished with value: 0.7444434482485089 and parameters: {'n_d': 35, 'n_a': 13, 'n_steps': 10, 'gamma': 1.833458222548717, 'lambda_sparse': 0.000576511484804243, 'lr': 0.002135653939564149, 'weight_decay': 1.4482557254242275e-06}. Best is trial 4 with value: 0.8863077439838414.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:23:08,477] Trial 9 finished with value: 0.7602915323262638 and parameters: {'n_d': 35, 'n_a': 11, 'n_steps': 9, 'gamma': 1.0569536167016165, 'lambda_sparse': 0.0007698127052339371, 'lr': 0.0003625374063284404, 'weight_decay': 7.981768750251902e-05}. Best is trial 4 with value: 0.8863077439838414.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:24:17,902] Trial 10 finished with value: 0.9023119586712344 and parameters: {'n_d': 59, 'n_a': 28, 'n_steps': 3, 'gamma': 1.3896861905003615, 'lambda_sparse': 1.2385250731720158e-05, 'lr': 0.012376475630312654, 'weight_decay': 8.740301969890314e-06}. Best is trial 10 with value: 0.9023119586712344.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:25:25,871] Trial 11 finished with value: 0.8877684258955543 and parameters: {'n_d': 61, 'n_a': 26, 'n_steps': 3, 'gamma': 1.4305145265677597, 'lambda_sparse': 1.587672670392579e-05, 'lr': 0.012561271376833688, 'weight_decay': 8.227056124811717e-06}. Best is trial 10 with value: 0.9023119586712344.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:26:10,320] Trial 12 finished with value: 0.8967623425586942 and parameters: {'n_d': 64, 'n_a': 25, 'n_steps': 3, 'gamma': 1.358240391215067, 'lambda_sparse': 1.257570181581113e-05, 'lr': 0.016860911691477517, 'weight_decay': 1.3397571886491699e-05}. Best is trial 10 with value: 0.9023119586712344.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:26:30,403] Trial 13 finished with value: 0.6404530963004941 and parameters: {'n_d': 62, 'n_a': 22, 'n_steps': 4, 'gamma': 1.3490320653893162, 'lambda_sparse': 1.2922629840006199e-05, 'lr': 0.03217264478166226, 'weight_decay': 2.7840546965406962e-05}. Best is trial 10 with value: 0.9023119586712344.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:27:48,897] Trial 14 finished with value: 0.8699684840254474 and parameters: {'n_d': 51, 'n_a': 24, 'n_steps': 4, 'gamma': 1.9537230998436945, 'lambda_sparse': 1.084402916795123e-05, 'lr': 0.005965574705215886, 'weight_decay': 2.5339768463224267e-05}. Best is trial 10 with value: 0.9023119586712344.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:28:48,890] Trial 15 finished with value: 0.8803239077230239 and parameters: {'n_d': 50, 'n_a': 30, 'n_steps': 3, 'gamma': 1.3361317640336166, 'lambda_sparse': 4.8406521543039106e-05, 'lr': 0.0015852316918525693, 'weight_decay': 3.4338210123664028e-06}. Best is trial 10 with value: 0.9023119586712344.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:29:44,725] Trial 16 finished with value: 0.8956025519237315 and parameters: {'n_d': 55, 'n_a': 16, 'n_steps': 4, 'gamma': 1.6908955537151147, 'lambda_sparse': 0.00015390497939983793, 'lr': 0.02902276283590663, 'weight_decay': 1.4443069188921816e-05}. Best is trial 10 with value: 0.9023119586712344.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:31:00,542] Trial 17 finished with value: 0.9065205873392087 and parameters: {'n_d': 57, 'n_a': 64, 'n_steps': 5, 'gamma': 1.190745021888818, 'lambda_sparse': 0.0003106811974529849, 'lr': 0.007068220768347114, 'weight_decay': 4.068791294812078e-06}. Best is trial 17 with value: 0.9065205873392087.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:32:22,391] Trial 18 finished with value: 0.8718774034141601 and parameters: {'n_d': 54, 'n_a': 59, 'n_steps': 5, 'gamma': 1.1779151033068342, 'lambda_sparse': 0.001148377510158428, 'lr': 0.0010365240560964697, 'weight_decay': 3.3183684334192585e-06}. Best is trial 17 with value: 0.9065205873392087.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-02 13:34:05,224] Trial 19 finished with value: 0.8772230825496978 and parameters: {'n_d': 46, 'n_a': 64, 'n_steps': 7, 'gamma': 1.4413257209557002, 'lambda_sparse': 0.000283146022170816, 'lr': 0.006195320400587989, 'weight_decay': 6.761203311662475e-06}. Best is trial 17 with value: 0.9065205873392087.
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-02 13:35:44 [INFO] TabNet →      /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/tabnet (mean R²=0.9212)
2025-08-02 13:35:44 [INFO] Ensemble weights: TabPFN=0.335, Tree=0.332, TabNet=0.333
2025-08-02 13:35:44 [INFO] Loading individual models into memory...
/work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-02 13:35:49 [INFO] Saved weighted ensemble to /work/dlclarge2/alidemaa-dl_lab/automl/automl-exam-ss25-tabular-freiburg-template/modelsFinal/final_model.pkl
