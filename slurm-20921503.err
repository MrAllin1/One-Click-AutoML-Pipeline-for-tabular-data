cpu-bind=MASK - dlcgpu02, task  0  0 [1930271]: mask 0x32200000322000 set
/var/spool/slurm/job20921503/slurm_script: line 11: module: command not found
2025-08-05 01:17:48 [INFO] Using device: cuda
2025-08-05 01:17:48 [INFO] Training TabPFN model...
[I 2025-08-05 01:17:48,731] A new study created in memory with name: no-name-3dff552b-a32b-4b2c-91e3-578d3f09ce6b
2025-08-05 01:17:48 [INFO] 🔍 Trial 0: n_bootstrap=14, sample_frac=0.89
[I 2025-08-05 01:20:43,579] Trial 0 finished with value: 0.9407270398052201 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8852142919229748}. Best is trial 0 with value: 0.9407270398052201.
2025-08-05 01:20:43 [INFO] 🔍 Trial 1: n_bootstrap=18, sample_frac=0.78
[I 2025-08-05 01:22:29,485] Trial 1 finished with value: 0.9415474303403686 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.779597545259111}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 01:22:29 [INFO] 🔍 Trial 2: n_bootstrap=11, sample_frac=0.65
[I 2025-08-05 01:23:27,723] Trial 2 finished with value: 0.939915931530898 and parameters: {'n_bootstrap': 11, 'sample_frac': 0.6467983561008608}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 01:23:27 [INFO] 🔍 Trial 3: n_bootstrap=10, sample_frac=0.86
[I 2025-08-05 01:24:36,056] Trial 3 finished with value: 0.9403807173408154 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8598528437324806}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 01:24:36 [INFO] 🔍 Trial 4: n_bootstrap=16, sample_frac=0.81
[I 2025-08-05 01:26:19,030] Trial 4 finished with value: 0.941036618937641 and parameters: {'n_bootstrap': 16, 'sample_frac': 0.8124217733388137}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 01:26:19 [INFO] 🔍 Trial 5: n_bootstrap=10, sample_frac=0.89
[I 2025-08-05 01:27:29,024] Trial 5 finished with value: 0.9405680591660275 and parameters: {'n_bootstrap': 10, 'sample_frac': 0.8909729556485984}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 01:27:29 [INFO] 🔍 Trial 6: n_bootstrap=19, sample_frac=0.66
2025-08-05 01:27:34 [INFO] ⏸️ Pruned trial 6 at step 1 (R²=0.9303)
[I 2025-08-05 01:27:34,529] Trial 6 pruned. 
2025-08-05 01:27:34 [INFO] 🔍 Trial 7: n_bootstrap=12, sample_frac=0.66
2025-08-05 01:27:41 [INFO] ⏸️ Pruned trial 7 at step 1 (R²=0.9304)
[I 2025-08-05 01:27:41,539] Trial 7 pruned. 
2025-08-05 01:27:41 [INFO] 🔍 Trial 8: n_bootstrap=13, sample_frac=0.76
2025-08-05 01:27:47 [INFO] ⏸️ Pruned trial 8 at step 1 (R²=0.9319)
[I 2025-08-05 01:27:47,250] Trial 8 pruned. 
2025-08-05 01:27:47 [INFO] 🔍 Trial 9: n_bootstrap=14, sample_frac=0.69
2025-08-05 01:27:52 [INFO] ⏸️ Pruned trial 9 at step 1 (R²=0.9309)
[I 2025-08-05 01:27:52,930] Trial 9 pruned. 
2025-08-05 01:27:52 [INFO] 🔍 Trial 10: n_bootstrap=20, sample_frac=0.74
2025-08-05 01:28:01 [INFO] ⏸️ Pruned trial 10 at step 1 (R²=0.9311)
[I 2025-08-05 01:28:01,581] Trial 10 pruned. 
2025-08-05 01:28:01 [INFO] 🔍 Trial 11: n_bootstrap=17, sample_frac=0.81
2025-08-05 01:28:08 [INFO] ⏸️ Pruned trial 11 at step 1 (R²=0.9326)
[I 2025-08-05 01:28:08,276] Trial 11 pruned. 
2025-08-05 01:28:08 [INFO] 🔍 Trial 12: n_bootstrap=17, sample_frac=0.81
2025-08-05 01:28:17 [INFO] ⏸️ Pruned trial 12 at step 1 (R²=0.9327)
[I 2025-08-05 01:28:17,492] Trial 12 pruned. 
2025-08-05 01:28:17 [INFO] 🔍 Trial 13: n_bootstrap=17, sample_frac=0.79
2025-08-05 01:28:23 [INFO] ⏸️ Pruned trial 13 at step 1 (R²=0.9333)
[I 2025-08-05 01:28:23,685] Trial 13 pruned. 
2025-08-05 01:28:23 [INFO] 🔍 Trial 14: n_bootstrap=16, sample_frac=0.71
2025-08-05 01:28:29 [INFO] ⏸️ Pruned trial 14 at step 1 (R²=0.9308)
[I 2025-08-05 01:28:29,462] Trial 14 pruned. 
2025-08-05 01:28:29 [INFO] 🔍 Trial 15: n_bootstrap=19, sample_frac=0.83
2025-08-05 01:28:36 [INFO] ⏸️ Pruned trial 15 at step 1 (R²=0.9323)
[I 2025-08-05 01:28:36,979] Trial 15 pruned. 
2025-08-05 01:28:36 [INFO] 🔍 Trial 16: n_bootstrap=15, sample_frac=0.76
2025-08-05 01:28:42 [INFO] ⏸️ Pruned trial 16 at step 1 (R²=0.9322)
[I 2025-08-05 01:28:42,940] Trial 16 pruned. 
2025-08-05 01:28:42 [INFO] 🔍 Trial 17: n_bootstrap=18, sample_frac=0.84
2025-08-05 01:28:50 [INFO] ⏸️ Pruned trial 17 at step 1 (R²=0.9327)
[I 2025-08-05 01:28:50,410] Trial 17 pruned. 
2025-08-05 01:28:50 [INFO] 🔍 Trial 18: n_bootstrap=16, sample_frac=0.78
2025-08-05 01:28:58 [INFO] ⏸️ Pruned trial 18 at step 1 (R²=0.9338)
[I 2025-08-05 01:28:58,342] Trial 18 pruned. 
2025-08-05 01:28:58 [INFO] 🔍 Trial 19: n_bootstrap=19, sample_frac=0.72
2025-08-05 01:29:06 [INFO] ⏸️ Pruned trial 19 at step 1 (R²=0.9308)
[I 2025-08-05 01:29:06,277] Trial 19 pruned. 
2025-08-05 01:29:06 [INFO] 🔍 Trial 20: n_bootstrap=15, sample_frac=0.61
2025-08-05 01:29:11 [INFO] ⏸️ Pruned trial 20 at step 1 (R²=0.9313)
[I 2025-08-05 01:29:11,635] Trial 20 pruned. 
2025-08-05 01:29:11 [INFO] 🔍 Trial 21: n_bootstrap=14, sample_frac=0.88
[I 2025-08-05 01:30:51,780] Trial 21 finished with value: 0.9407565058034427 and parameters: {'n_bootstrap': 14, 'sample_frac': 0.8841404752206518}. Best is trial 1 with value: 0.9415474303403686.
2025-08-05 01:30:51 [INFO] 🔍 Trial 22: n_bootstrap=13, sample_frac=0.86
2025-08-05 01:30:58 [INFO] ⏸️ Pruned trial 22 at step 1 (R²=0.9339)
[I 2025-08-05 01:30:58,917] Trial 22 pruned. 
2025-08-05 01:30:58 [INFO] 🔍 Trial 23: n_bootstrap=16, sample_frac=0.84
2025-08-05 01:31:07 [INFO] ⏸️ Pruned trial 23 at step 1 (R²=0.9327)
[I 2025-08-05 01:31:07,195] Trial 23 pruned. 
2025-08-05 01:31:07 [INFO] 🔍 Trial 24: n_bootstrap=18, sample_frac=0.79
2025-08-05 01:31:13 [INFO] ⏸️ Pruned trial 24 at step 1 (R²=0.9336)
[I 2025-08-05 01:31:13,172] Trial 24 pruned. 
2025-08-05 01:31:13 [INFO] 🔍 Trial 25: n_bootstrap=14, sample_frac=0.82
2025-08-05 01:31:22 [INFO] ⏸️ Pruned trial 25 at step 1 (R²=0.9317)
[I 2025-08-05 01:31:22,573] Trial 25 pruned. 
2025-08-05 01:31:22 [INFO] 🔍 Trial 26: n_bootstrap=18, sample_frac=0.87
[I 2025-08-05 01:33:34,449] Trial 26 finished with value: 0.9415544920301624 and parameters: {'n_bootstrap': 18, 'sample_frac': 0.8713581762004475}. Best is trial 26 with value: 0.9415544920301624.
2025-08-05 01:33:34 [INFO] 🔍 Trial 27: n_bootstrap=20, sample_frac=0.86
2025-08-05 01:33:44 [INFO] ⏸️ Pruned trial 27 at step 1 (R²=0.9340)
[I 2025-08-05 01:33:44,503] Trial 27 pruned. 
2025-08-05 01:33:44 [INFO] 🔍 Trial 28: n_bootstrap=18, sample_frac=0.74
2025-08-05 01:33:51 [INFO] ⏸️ Pruned trial 28 at step 1 (R²=0.9311)
[I 2025-08-05 01:33:51,392] Trial 28 pruned. 
2025-08-05 01:33:51 [INFO] 🔍 Trial 29: n_bootstrap=17, sample_frac=0.90
[I 2025-08-05 01:35:57,950] Trial 29 finished with value: 0.9417814033337457 and parameters: {'n_bootstrap': 17, 'sample_frac': 0.8995784440661511}. Best is trial 29 with value: 0.9417814033337457.
2025-08-05 01:35:57 [INFO] 🏆 Best Params: {'n_bootstrap': 17, 'sample_frac': 0.8995784440661511}, R²=0.94178
2025-08-05 01:35:57 [INFO] Bootstrap training → dataset=bike_sharing_demand, device=cuda
2025-08-05 01:35:58 [INFO] [1/17] bootstrap sample size=6329
2025-08-05 01:36:14 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_1.pkl
2025-08-05 01:36:15 [INFO] [2/17] bootstrap sample size=6329
2025-08-05 01:36:23 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_2.pkl
2025-08-05 01:36:23 [INFO] [3/17] bootstrap sample size=6329
2025-08-05 01:36:34 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_3.pkl
2025-08-05 01:36:34 [INFO] [4/17] bootstrap sample size=6329
2025-08-05 01:36:48 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_4.pkl
2025-08-05 01:36:48 [INFO] [5/17] bootstrap sample size=6329
2025-08-05 01:36:57 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_5.pkl
2025-08-05 01:36:58 [INFO] [6/17] bootstrap sample size=6329
2025-08-05 01:37:08 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_6.pkl
2025-08-05 01:37:09 [INFO] [7/17] bootstrap sample size=6329
2025-08-05 01:37:15 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_7.pkl
2025-08-05 01:37:15 [INFO] [8/17] bootstrap sample size=6329
2025-08-05 01:37:24 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_8.pkl
2025-08-05 01:37:24 [INFO] [9/17] bootstrap sample size=6329
2025-08-05 01:37:40 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_9.pkl
2025-08-05 01:37:41 [INFO] [10/17] bootstrap sample size=6329
2025-08-05 01:37:49 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_10.pkl
2025-08-05 01:37:49 [INFO] [11/17] bootstrap sample size=6329
2025-08-05 01:37:59 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_11.pkl
2025-08-05 01:37:59 [INFO] [12/17] bootstrap sample size=6329
2025-08-05 01:38:10 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_12.pkl
2025-08-05 01:38:11 [INFO] [13/17] bootstrap sample size=6329
2025-08-05 01:38:18 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_13.pkl
2025-08-05 01:38:18 [INFO] [14/17] bootstrap sample size=6329
2025-08-05 01:38:26 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_14.pkl
2025-08-05 01:38:27 [INFO] [15/17] bootstrap sample size=6329
2025-08-05 01:38:38 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_15.pkl
2025-08-05 01:38:38 [INFO] [16/17] bootstrap sample size=6329
2025-08-05 01:38:50 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_16.pkl
2025-08-05 01:38:50 [INFO] [17/17] bootstrap sample size=6329
2025-08-05 01:39:02 [INFO] Saved model → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/bootstrap_17.pkl
2025-08-05 01:39:03 [INFO] 📊 Final OOB R² = 0.94178
2025-08-05 01:39:25 [INFO] Saved ensemble → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/ensemble.pkl
2025-08-05 01:39:25 [WARNING] get_test_data failed or unavailable; skipping test R² logging
2025-08-05 01:39:25 [INFO] Total time: 208.0s
2025-08-05 01:39:26 [INFO] TabPFN →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/bike_sharing_demand/ensemble.pkl (R²=0.9418)
2025-08-05 01:39:26 [INFO] Training tree-based model...
2025-08-05 01:39:26 [INFO] AutoML pipeline started
2025-08-05 01:39:26 [INFO] Output directory '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand' is ready and logging is configured.
2025-08-05 01:39:26 [INFO] Merged training data: 7036 rows
2025-08-05 01:39:26 [INFO] Split data into pool (6332 rows) and validation (704 rows)
2025-08-05 01:39:26 [INFO] Feature engineering completed: 11 features
[I 2025-08-05 01:39:26,244] A new study created in memory with name: no-name-8044e36e-01f7-440c-a17f-c27926dde198
TBB Warning: The number of workers is currently limited to 7. The request for 63 workers is ignored. Further requests for more workers will be silently ignored until the limit changes.

[I 2025-08-05 01:41:00,270] Trial 0 finished with value: -0.9420850310429097 and parameters: {'learning_rate': 0.03574712922600244, 'depth': 12, 'l2_leaf_reg': 7.587945476302646, 'border_count': 166}. Best is trial 0 with value: -0.9420850310429097.
[I 2025-08-05 01:41:11,800] Trial 1 finished with value: -0.919482120906484 and parameters: {'learning_rate': 0.01700037298921102, 'depth': 5, 'l2_leaf_reg': 1.5227525095137953, 'border_count': 226}. Best is trial 0 with value: -0.9420850310429097.
[I 2025-08-05 01:41:26,036] Trial 2 finished with value: -0.942145085000307 and parameters: {'learning_rate': 0.07725378389307355, 'depth': 10, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 01:41:34,881] Trial 3 finished with value: -0.9360381967367711 and parameters: {'learning_rate': 0.16967533607196555, 'depth': 5, 'l2_leaf_reg': 2.636424704863906, 'border_count': 73}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 01:41:53,956] Trial 4 finished with value: -0.9406664018245173 and parameters: {'learning_rate': 0.028145092716060652, 'depth': 8, 'l2_leaf_reg': 4.887505167779041, 'border_count': 97}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 01:42:05,466] Trial 5 finished with value: -0.93596421448217 and parameters: {'learning_rate': 0.08012737503998542, 'depth': 5, 'l2_leaf_reg': 3.629301836816963, 'border_count': 114}. Best is trial 2 with value: -0.942145085000307.
[I 2025-08-05 01:42:44,456] Trial 6 finished with value: -0.9429075764821212 and parameters: {'learning_rate': 0.04717052037625178, 'depth': 11, 'l2_leaf_reg': 2.7970640394252375, 'border_count': 147}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 01:42:54,359] Trial 7 finished with value: -0.9256462632126544 and parameters: {'learning_rate': 0.07500118950416987, 'depth': 4, 'l2_leaf_reg': 6.467903667112945, 'border_count': 70}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 01:44:23,152] Trial 8 finished with value: -0.9374041351458068 and parameters: {'learning_rate': 0.012476394272569451, 'depth': 12, 'l2_leaf_reg': 9.690688297671034, 'border_count': 213}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 01:44:33,409] Trial 9 finished with value: -0.9097722005501373 and parameters: {'learning_rate': 0.028180680291847244, 'depth': 4, 'l2_leaf_reg': 7.158097238609412, 'border_count': 130}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 01:44:42,183] Trial 10 finished with value: -0.941098586670725 and parameters: {'learning_rate': 0.24893231508461813, 'depth': 9, 'l2_leaf_reg': 4.318558954489875, 'border_count': 175}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 01:44:52,892] Trial 11 finished with value: -0.9418322571451027 and parameters: {'learning_rate': 0.11386552028513468, 'depth': 10, 'l2_leaf_reg': 1.0763393887328419, 'border_count': 250}. Best is trial 6 with value: -0.9429075764821212.
[I 2025-08-05 01:45:08,180] Trial 12 finished with value: -0.942942808864033 and parameters: {'learning_rate': 0.05033186585861864, 'depth': 10, 'l2_leaf_reg': 2.53256400708008, 'border_count': 41}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 01:45:30,806] Trial 13 finished with value: -0.9421694183584254 and parameters: {'learning_rate': 0.04666176218448525, 'depth': 11, 'l2_leaf_reg': 2.880463341431277, 'border_count': 36}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 01:45:48,545] Trial 14 finished with value: -0.9427043615322919 and parameters: {'learning_rate': 0.051527024214005596, 'depth': 8, 'l2_leaf_reg': 2.8449544909574693, 'border_count': 160}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 01:46:04,434] Trial 15 finished with value: -0.9350196331040646 and parameters: {'learning_rate': 0.020546790816083238, 'depth': 7, 'l2_leaf_reg': 5.531162329838407, 'border_count': 195}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 01:46:10,742] Trial 16 finished with value: -0.9407859730704597 and parameters: {'learning_rate': 0.13811007646509937, 'depth': 10, 'l2_leaf_reg': 2.340481892680636, 'border_count': 36}. Best is trial 12 with value: -0.942942808864033.
[I 2025-08-05 01:46:48,594] Trial 17 finished with value: -0.943125410298701 and parameters: {'learning_rate': 0.04071611822052514, 'depth': 11, 'l2_leaf_reg': 3.894752015334281, 'border_count': 141}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:47:12,233] Trial 18 finished with value: -0.9361762970415135 and parameters: {'learning_rate': 0.010907863682082639, 'depth': 9, 'l2_leaf_reg': 3.8101144232990465, 'border_count': 67}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:47:55,703] Trial 19 finished with value: -0.9426848044377918 and parameters: {'learning_rate': 0.03305323034166552, 'depth': 11, 'l2_leaf_reg': 5.608041644328219, 'border_count': 92}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:48:11,589] Trial 20 finished with value: -0.9336406907434831 and parameters: {'learning_rate': 0.020201780497292713, 'depth': 7, 'l2_leaf_reg': 8.675815964448498, 'border_count': 121}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:48:44,241] Trial 21 finished with value: -0.9424345943142839 and parameters: {'learning_rate': 0.0442622424134713, 'depth': 11, 'l2_leaf_reg': 2.0275635855984584, 'border_count': 145}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:49:32,994] Trial 22 finished with value: -0.9411996136795251 and parameters: {'learning_rate': 0.07002993047047383, 'depth': 12, 'l2_leaf_reg': 3.402133768679974, 'border_count': 142}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:49:54,103] Trial 23 finished with value: -0.9429587898588239 and parameters: {'learning_rate': 0.057871436385387075, 'depth': 9, 'l2_leaf_reg': 4.805133980122038, 'border_count': 201}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:50:08,878] Trial 24 finished with value: -0.9426676012168915 and parameters: {'learning_rate': 0.09788764905810535, 'depth': 9, 'l2_leaf_reg': 4.5230067577948505, 'border_count': 200}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:50:30,846] Trial 25 finished with value: -0.9428900225562865 and parameters: {'learning_rate': 0.06016763329060489, 'depth': 10, 'l2_leaf_reg': 4.849869867931115, 'border_count': 182}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:50:46,346] Trial 26 finished with value: -0.9397905891839471 and parameters: {'learning_rate': 0.03738730947894328, 'depth': 7, 'l2_leaf_reg': 5.889228002920342, 'border_count': 54}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:51:06,023] Trial 27 finished with value: -0.9429396323223255 and parameters: {'learning_rate': 0.061388079540134345, 'depth': 9, 'l2_leaf_reg': 4.044490864164882, 'border_count': 104}. Best is trial 17 with value: -0.943125410298701.
[I 2025-08-05 01:51:20,617] Trial 28 finished with value: -0.9431280356061487 and parameters: {'learning_rate': 0.10193738211993074, 'depth': 10, 'l2_leaf_reg': 3.352983792434749, 'border_count': 231}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:51:46,914] Trial 29 finished with value: -0.9394648249420079 and parameters: {'learning_rate': 0.16212942052989116, 'depth': 12, 'l2_leaf_reg': 6.469803623854161, 'border_count': 231}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:51:54,645] Trial 30 finished with value: -0.9405714805423837 and parameters: {'learning_rate': 0.22805828040319062, 'depth': 8, 'l2_leaf_reg': 4.969925751644316, 'border_count': 229}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:52:09,838] Trial 31 finished with value: -0.9423795812722362 and parameters: {'learning_rate': 0.09970028855539532, 'depth': 10, 'l2_leaf_reg': 3.2647467098466447, 'border_count': 213}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:52:44,254] Trial 32 finished with value: -0.9428806086539023 and parameters: {'learning_rate': 0.03768031893458419, 'depth': 11, 'l2_leaf_reg': 1.7885011487259037, 'border_count': 195}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:53:00,333] Trial 33 finished with value: -0.943126135707853 and parameters: {'learning_rate': 0.0868937349679417, 'depth': 9, 'l2_leaf_reg': 3.304026138121671, 'border_count': 243}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:53:11,941] Trial 34 finished with value: -0.9427427989240821 and parameters: {'learning_rate': 0.12326088306155994, 'depth': 9, 'l2_leaf_reg': 4.123214684240512, 'border_count': 240}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:53:24,652] Trial 35 finished with value: -0.9424541556794017 and parameters: {'learning_rate': 0.0885295722362556, 'depth': 8, 'l2_leaf_reg': 3.26740254390009, 'border_count': 216}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:53:35,752] Trial 36 finished with value: -0.9413664596632815 and parameters: {'learning_rate': 0.18049477993564428, 'depth': 9, 'l2_leaf_reg': 5.0374262233132026, 'border_count': 241}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:53:49,475] Trial 37 finished with value: -0.9393299871588138 and parameters: {'learning_rate': 0.06652519784921596, 'depth': 6, 'l2_leaf_reg': 3.7723653658651672, 'border_count': 253}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:54:03,162] Trial 38 finished with value: -0.9417667638232385 and parameters: {'learning_rate': 0.08493730318034638, 'depth': 8, 'l2_leaf_reg': 4.51277132131785, 'border_count': 162}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:54:44,025] Trial 39 finished with value: -0.9428975062331315 and parameters: {'learning_rate': 0.02991120025264205, 'depth': 11, 'l2_leaf_reg': 2.040263775996904, 'border_count': 183}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:54:50,535] Trial 40 finished with value: -0.9388661250899547 and parameters: {'learning_rate': 0.2992799583173479, 'depth': 10, 'l2_leaf_reg': 3.2896559874214337, 'border_count': 224}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:55:11,570] Trial 41 finished with value: -0.9429248582116591 and parameters: {'learning_rate': 0.05298840165656651, 'depth': 10, 'l2_leaf_reg': 2.4143528093565445, 'border_count': 244}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:55:34,662] Trial 42 finished with value: -0.9425791180823625 and parameters: {'learning_rate': 0.040080255021436376, 'depth': 9, 'l2_leaf_reg': 1.6547870712533388, 'border_count': 203}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:55:54,518] Trial 43 finished with value: -0.9428335877331607 and parameters: {'learning_rate': 0.05812689266493824, 'depth': 10, 'l2_leaf_reg': 2.923695794306846, 'border_count': 85}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:56:39,640] Trial 44 finished with value: -0.9427175980561865 and parameters: {'learning_rate': 0.02298384347018129, 'depth': 11, 'l2_leaf_reg': 2.4869577114624533, 'border_count': 235}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:56:55,746] Trial 45 finished with value: -0.9424393675889066 and parameters: {'learning_rate': 0.07713745958428486, 'depth': 9, 'l2_leaf_reg': 3.815460530201026, 'border_count': 221}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:57:05,902] Trial 46 finished with value: -0.9423185835289042 and parameters: {'learning_rate': 0.10658292435344957, 'depth': 10, 'l2_leaf_reg': 1.262527844934136, 'border_count': 133}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:57:31,941] Trial 47 finished with value: -0.9396628638481023 and parameters: {'learning_rate': 0.14016359035453274, 'depth': 12, 'l2_leaf_reg': 4.557085536671287, 'border_count': 170}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:57:55,340] Trial 48 finished with value: -0.94270401803817 and parameters: {'learning_rate': 0.04287474209323773, 'depth': 10, 'l2_leaf_reg': 3.020282830969709, 'border_count': 210}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:58:38,559] Trial 49 finished with value: -0.9422522558450602 and parameters: {'learning_rate': 0.024797944516010192, 'depth': 11, 'l2_leaf_reg': 5.299579368404125, 'border_count': 254}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:58:57,108] Trial 50 finished with value: -0.9429848410224052 and parameters: {'learning_rate': 0.05129150172298022, 'depth': 9, 'l2_leaf_reg': 3.6319313660583874, 'border_count': 49}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:59:16,287] Trial 51 finished with value: -0.9428219506750534 and parameters: {'learning_rate': 0.05086898450516008, 'depth': 9, 'l2_leaf_reg': 3.512263065898063, 'border_count': 48}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:59:34,168] Trial 52 finished with value: -0.9421024435034532 and parameters: {'learning_rate': 0.04814333495165513, 'depth': 8, 'l2_leaf_reg': 4.1820418188040165, 'border_count': 61}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 01:59:57,763] Trial 53 finished with value: -0.9425775534109407 and parameters: {'learning_rate': 0.034003659085575434, 'depth': 9, 'l2_leaf_reg': 2.632879035482573, 'border_count': 79}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:00:10,533] Trial 54 finished with value: -0.9423347046435115 and parameters: {'learning_rate': 0.06368786948011068, 'depth': 8, 'l2_leaf_reg': 3.7454747123193677, 'border_count': 33}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:00:29,152] Trial 55 finished with value: -0.9430651386800506 and parameters: {'learning_rate': 0.0766076480071888, 'depth': 10, 'l2_leaf_reg': 6.0101255975370655, 'border_count': 107}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:00:48,771] Trial 56 finished with value: -0.9428053460574889 and parameters: {'learning_rate': 0.07534041984072042, 'depth': 9, 'l2_leaf_reg': 6.163486909887137, 'border_count': 113}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:01:03,824] Trial 57 finished with value: -0.9428221777631428 and parameters: {'learning_rate': 0.11948456608880467, 'depth': 10, 'l2_leaf_reg': 7.538042161867778, 'border_count': 126}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:01:28,287] Trial 58 finished with value: -0.9425502945739195 and parameters: {'learning_rate': 0.09188882632116548, 'depth': 11, 'l2_leaf_reg': 6.810498748080285, 'border_count': 156}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:01:47,795] Trial 59 finished with value: -0.9429541199139049 and parameters: {'learning_rate': 0.06868771069172894, 'depth': 10, 'l2_leaf_reg': 5.326968766919445, 'border_count': 100}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:02:02,345] Trial 60 finished with value: -0.9404441678766056 and parameters: {'learning_rate': 0.05495985978423373, 'depth': 7, 'l2_leaf_reg': 5.903486082961492, 'border_count': 153}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:02:22,003] Trial 61 finished with value: -0.9430133127224529 and parameters: {'learning_rate': 0.07024631490336256, 'depth': 10, 'l2_leaf_reg': 5.21069730890777, 'border_count': 104}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:02:40,505] Trial 62 finished with value: -0.9427624233465259 and parameters: {'learning_rate': 0.0819995376563252, 'depth': 10, 'l2_leaf_reg': 4.785462189649322, 'border_count': 109}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:03:05,937] Trial 63 finished with value: -0.9419796594453228 and parameters: {'learning_rate': 0.07167441096408604, 'depth': 11, 'l2_leaf_reg': 4.3287968090079225, 'border_count': 135}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:03:19,446] Trial 64 finished with value: -0.9424069591181727 and parameters: {'learning_rate': 0.1002457334812009, 'depth': 9, 'l2_leaf_reg': 5.838125453387559, 'border_count': 87}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:03:42,883] Trial 65 finished with value: -0.9428035341327339 and parameters: {'learning_rate': 0.0418838713109863, 'depth': 9, 'l2_leaf_reg': 5.119059320259712, 'border_count': 122}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:04:04,624] Trial 66 finished with value: -0.9429760520583745 and parameters: {'learning_rate': 0.05721538475099747, 'depth': 10, 'l2_leaf_reg': 6.237011840690992, 'border_count': 72}. Best is trial 28 with value: -0.9431280356061487.
[I 2025-08-05 02:04:16,167] Trial 67 finished with value: -0.9431342588656383 and parameters: {'learning_rate': 0.12977656999309892, 'depth': 10, 'l2_leaf_reg': 6.815051080052627, 'border_count': 71}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 02:04:33,181] Trial 68 finished with value: -0.9407991478465565 and parameters: {'learning_rate': 0.14764692288492812, 'depth': 11, 'l2_leaf_reg': 8.064572669937355, 'border_count': 62}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 02:04:43,300] Trial 69 finished with value: -0.9416214428791576 and parameters: {'learning_rate': 0.12812942948326303, 'depth': 10, 'l2_leaf_reg': 7.1332676144181155, 'border_count': 44}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 02:05:13,410] Trial 70 finished with value: -0.9405767156919153 and parameters: {'learning_rate': 0.18819216148186574, 'depth': 12, 'l2_leaf_reg': 9.987768393033573, 'border_count': 81}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 02:05:27,396] Trial 71 finished with value: -0.9423918493261363 and parameters: {'learning_rate': 0.10730454674229138, 'depth': 10, 'l2_leaf_reg': 6.379414148456539, 'border_count': 75}. Best is trial 67 with value: -0.9431342588656383.
[I 2025-08-05 02:05:42,313] Trial 72 finished with value: -0.9431724553869149 and parameters: {'learning_rate': 0.09061655070754851, 'depth': 10, 'l2_leaf_reg': 6.637166053315614, 'border_count': 57}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:06:02,122] Trial 73 finished with value: -0.9416226796582267 and parameters: {'learning_rate': 0.08931225875537213, 'depth': 11, 'l2_leaf_reg': 6.781555217188022, 'border_count': 55}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:06:15,265] Trial 74 finished with value: -0.9424568054956659 and parameters: {'learning_rate': 0.1524681257389112, 'depth': 10, 'l2_leaf_reg': 7.855577959535804, 'border_count': 98}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:06:44,072] Trial 75 finished with value: -0.9422461419013828 and parameters: {'learning_rate': 0.08135883873177156, 'depth': 11, 'l2_leaf_reg': 7.051280565422536, 'border_count': 91}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:06:57,025] Trial 76 finished with value: -0.9428545577733068 and parameters: {'learning_rate': 0.11321027429519863, 'depth': 10, 'l2_leaf_reg': 6.618497780058233, 'border_count': 52}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:07:07,544] Trial 77 finished with value: -0.9426015665104407 and parameters: {'learning_rate': 0.13343502574213445, 'depth': 9, 'l2_leaf_reg': 5.654331188521088, 'border_count': 68}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:07:24,058] Trial 78 finished with value: -0.9419372506063353 and parameters: {'learning_rate': 0.06452175076932594, 'depth': 11, 'l2_leaf_reg': 3.0463616934958737, 'border_count': 42}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:07:38,664] Trial 79 finished with value: -0.9428383820113909 and parameters: {'learning_rate': 0.09525717944134543, 'depth': 10, 'l2_leaf_reg': 7.4620707801943285, 'border_count': 62}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:07:49,358] Trial 80 finished with value: -0.889224050085159 and parameters: {'learning_rate': 0.013943116780134197, 'depth': 4, 'l2_leaf_reg': 4.0048314240293745, 'border_count': 106}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:08:12,710] Trial 81 finished with value: -0.9428126977897081 and parameters: {'learning_rate': 0.04640554617523816, 'depth': 10, 'l2_leaf_reg': 6.089649819028433, 'border_count': 73}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:08:32,369] Trial 82 finished with value: -0.9425547718971069 and parameters: {'learning_rate': 0.07283106960318442, 'depth': 10, 'l2_leaf_reg': 6.269874730206288, 'border_count': 93}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:08:53,447] Trial 83 finished with value: -0.9428537346577295 and parameters: {'learning_rate': 0.060556143473870686, 'depth': 9, 'l2_leaf_reg': 6.574484364737053, 'border_count': 118}. Best is trial 72 with value: -0.9431724553869149.
[I 2025-08-05 02:09:11,524] Trial 84 finished with value: -0.943229884598642 and parameters: {'learning_rate': 0.05449934549264481, 'depth': 10, 'l2_leaf_reg': 3.543291636846423, 'border_count': 58}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:09:22,620] Trial 85 finished with value: -0.9426832072431612 and parameters: {'learning_rate': 0.10678906550059873, 'depth': 10, 'l2_leaf_reg': 3.5864566774984783, 'border_count': 50}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:09:45,801] Trial 86 finished with value: -0.9423335418750725 and parameters: {'learning_rate': 0.08255613548956028, 'depth': 11, 'l2_leaf_reg': 3.2209920365384903, 'border_count': 141}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:10:07,925] Trial 87 finished with value: -0.9426158956820011 and parameters: {'learning_rate': 0.038656758609665, 'depth': 9, 'l2_leaf_reg': 3.9599373465884122, 'border_count': 60}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:10:27,160] Trial 88 finished with value: -0.942846759454714 and parameters: {'learning_rate': 0.05318549632296007, 'depth': 10, 'l2_leaf_reg': 2.7764896343126493, 'border_count': 247}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:10:44,854] Trial 89 finished with value: -0.9405470727933704 and parameters: {'learning_rate': 0.031106757226604862, 'depth': 8, 'l2_leaf_reg': 8.840158603959413, 'border_count': 38}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:11:01,374] Trial 90 finished with value: -0.9424300788862601 and parameters: {'learning_rate': 0.06666992463008417, 'depth': 9, 'l2_leaf_reg': 2.151746346146333, 'border_count': 180}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:11:21,432] Trial 91 finished with value: -0.9429522796551687 and parameters: {'learning_rate': 0.05651233368664576, 'depth': 10, 'l2_leaf_reg': 6.853356290767176, 'border_count': 67}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:11:41,652] Trial 92 finished with value: -0.9429690034783336 and parameters: {'learning_rate': 0.0472823396712481, 'depth': 10, 'l2_leaf_reg': 6.075829480462228, 'border_count': 56}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:12:17,653] Trial 93 finished with value: -0.9412227647501858 and parameters: {'learning_rate': 0.07843879804411949, 'depth': 12, 'l2_leaf_reg': 3.4767743521360535, 'border_count': 72}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:12:31,863] Trial 94 finished with value: -0.9421490171985646 and parameters: {'learning_rate': 0.11442366792795264, 'depth': 10, 'l2_leaf_reg': 7.289608220287802, 'border_count': 80}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:12:48,149] Trial 95 finished with value: -0.9420007137564822 and parameters: {'learning_rate': 0.08784067553619183, 'depth': 11, 'l2_leaf_reg': 5.74245736817175, 'border_count': 47}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:13:00,917] Trial 96 finished with value: -0.9423191542335732 and parameters: {'learning_rate': 0.09883090965406585, 'depth': 8, 'l2_leaf_reg': 5.442065163185126, 'border_count': 86}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:13:18,489] Trial 97 finished with value: -0.9427212523565147 and parameters: {'learning_rate': 0.04413581712336465, 'depth': 9, 'l2_leaf_reg': 4.620611894714477, 'border_count': 32}. Best is trial 84 with value: -0.943229884598642.
[I 2025-08-05 02:13:43,239] Trial 98 finished with value: -0.9432778819343897 and parameters: {'learning_rate': 0.035517987785120005, 'depth': 10, 'l2_leaf_reg': 4.33299092921435, 'border_count': 66}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:14:07,868] Trial 99 finished with value: -0.9429484621274125 and parameters: {'learning_rate': 0.035125663557533736, 'depth': 10, 'l2_leaf_reg': 4.423656928370156, 'border_count': 64}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:14:51,623] Trial 100 finished with value: -0.9428114598843784 and parameters: {'learning_rate': 0.025409591576293796, 'depth': 11, 'l2_leaf_reg': 3.8426427952551063, 'border_count': 149}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:15:14,934] Trial 101 finished with value: -0.9429104634174699 and parameters: {'learning_rate': 0.04019229055268166, 'depth': 10, 'l2_leaf_reg': 4.176910313977138, 'border_count': 57}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:15:35,836] Trial 102 finished with value: -0.942961237939658 and parameters: {'learning_rate': 0.049423408095883865, 'depth': 10, 'l2_leaf_reg': 3.149775383908324, 'border_count': 75}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:15:48,879] Trial 103 finished with value: -0.939134035841008 and parameters: {'learning_rate': 0.0585825127844495, 'depth': 6, 'l2_leaf_reg': 3.3766436949465577, 'border_count': 67}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:16:11,734] Trial 104 finished with value: -0.9429165303118641 and parameters: {'learning_rate': 0.032175557928832484, 'depth': 10, 'l2_leaf_reg': 4.689664771442583, 'border_count': 46}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:16:30,447] Trial 105 finished with value: -0.9427519644007406 and parameters: {'learning_rate': 0.0690200314389651, 'depth': 9, 'l2_leaf_reg': 5.205363090856304, 'border_count': 234}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:16:45,031] Trial 106 finished with value: -0.943014166616595 and parameters: {'learning_rate': 0.07593739056281919, 'depth': 10, 'l2_leaf_reg': 3.649946989589488, 'border_count': 52}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:17:00,609] Trial 107 finished with value: -0.9417937321418751 and parameters: {'learning_rate': 0.07563427000783991, 'depth': 11, 'l2_leaf_reg': 2.7601791575064043, 'border_count': 41}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:17:13,080] Trial 108 finished with value: -0.9425610218235851 and parameters: {'learning_rate': 0.09447654932980647, 'depth': 10, 'l2_leaf_reg': 4.293811052104646, 'border_count': 54}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:17:32,850] Trial 109 finished with value: -0.9422682990220691 and parameters: {'learning_rate': 0.061637346338844656, 'depth': 9, 'l2_leaf_reg': 3.7006642267437058, 'border_count': 190}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:17:55,421] Trial 110 finished with value: -0.9422161568153312 and parameters: {'learning_rate': 0.08603774076882283, 'depth': 11, 'l2_leaf_reg': 3.4487176428763218, 'border_count': 167}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:18:17,937] Trial 111 finished with value: -0.9425965256036231 and parameters: {'learning_rate': 0.0367959953998531, 'depth': 10, 'l2_leaf_reg': 3.6517961190539077, 'border_count': 51}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:18:40,566] Trial 112 finished with value: -0.9431369631075869 and parameters: {'learning_rate': 0.053833905920568755, 'depth': 10, 'l2_leaf_reg': 6.32293449511947, 'border_count': 79}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:18:58,589] Trial 113 finished with value: -0.942942784409257 and parameters: {'learning_rate': 0.07321194969174849, 'depth': 10, 'l2_leaf_reg': 3.9247323735019646, 'border_count': 102}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:19:20,851] Trial 114 finished with value: -0.9428633390853897 and parameters: {'learning_rate': 0.053249734896678544, 'depth': 10, 'l2_leaf_reg': 6.4901572802605925, 'border_count': 58}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:19:38,183] Trial 115 finished with value: -0.9423574192136629 and parameters: {'learning_rate': 0.06510363826951646, 'depth': 10, 'l2_leaf_reg': 3.001841811974714, 'border_count': 112}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:20:00,691] Trial 116 finished with value: -0.9423380345084726 and parameters: {'learning_rate': 0.02919397346072728, 'depth': 9, 'l2_leaf_reg': 4.869293463263759, 'border_count': 65}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:20:23,900] Trial 117 finished with value: -0.9428062735065369 and parameters: {'learning_rate': 0.04535174683928676, 'depth': 10, 'l2_leaf_reg': 4.121685852851939, 'border_count': 77}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:20:44,527] Trial 118 finished with value: -0.9429736729040112 and parameters: {'learning_rate': 0.12272841530239693, 'depth': 11, 'l2_leaf_reg': 5.9242103126212005, 'border_count': 94}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:21:07,744] Trial 119 finished with value: -0.9431927166231345 and parameters: {'learning_rate': 0.04973416505091599, 'depth': 9, 'l2_leaf_reg': 6.7149024098668235, 'border_count': 85}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:21:34,785] Trial 120 finished with value: -0.9428783975502899 and parameters: {'learning_rate': 0.04159770073796744, 'depth': 10, 'l2_leaf_reg': 6.968457977748343, 'border_count': 89}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:21:53,244] Trial 121 finished with value: -0.9431471992421183 and parameters: {'learning_rate': 0.07823014481681492, 'depth': 9, 'l2_leaf_reg': 6.6647862066540915, 'border_count': 71}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:22:06,704] Trial 122 finished with value: -0.9423164002937664 and parameters: {'learning_rate': 0.10124743297701463, 'depth': 8, 'l2_leaf_reg': 6.657588205168641, 'border_count': 81}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:22:25,330] Trial 123 finished with value: -0.942802772302777 and parameters: {'learning_rate': 0.0800564829455161, 'depth': 9, 'l2_leaf_reg': 6.359457004955955, 'border_count': 82}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:22:42,920] Trial 124 finished with value: -0.9428167719492236 and parameters: {'learning_rate': 0.08848842106156932, 'depth': 9, 'l2_leaf_reg': 7.314061893815277, 'border_count': 69}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:23:03,158] Trial 125 finished with value: -0.9426080994679872 and parameters: {'learning_rate': 0.07122685311797354, 'depth': 10, 'l2_leaf_reg': 6.714688246803224, 'border_count': 95}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:23:17,458] Trial 126 finished with value: -0.942259855635626 and parameters: {'learning_rate': 0.11205606297018973, 'depth': 9, 'l2_leaf_reg': 6.905125423264679, 'border_count': 86}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:23:33,718] Trial 127 finished with value: -0.9421733238403436 and parameters: {'learning_rate': 0.09294567345250399, 'depth': 10, 'l2_leaf_reg': 6.021334482495175, 'border_count': 241}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:24:09,707] Trial 128 finished with value: -0.9423923031497614 and parameters: {'learning_rate': 0.06259501399825497, 'depth': 11, 'l2_leaf_reg': 7.7789893362749645, 'border_count': 106}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:24:34,785] Trial 129 finished with value: -0.9430059524188994 and parameters: {'learning_rate': 0.04943379021265671, 'depth': 10, 'l2_leaf_reg': 6.377333539324442, 'border_count': 127}. Best is trial 98 with value: -0.9432778819343897.
[I 2025-08-05 02:24:52,413] Trial 130 finished with value: -0.9432855629248562 and parameters: {'learning_rate': 0.07796570568432348, 'depth': 9, 'l2_leaf_reg': 6.509637576100484, 'border_count': 138}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:25:10,174] Trial 131 finished with value: -0.9429528760926467 and parameters: {'learning_rate': 0.07779193279689399, 'depth': 9, 'l2_leaf_reg': 5.569498823220516, 'border_count': 119}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:25:26,001] Trial 132 finished with value: -0.9428914357906695 and parameters: {'learning_rate': 0.10426475691304454, 'depth': 9, 'l2_leaf_reg': 6.567130347964062, 'border_count': 143}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:25:47,403] Trial 133 finished with value: -0.9429498565221636 and parameters: {'learning_rate': 0.07019858740767233, 'depth': 10, 'l2_leaf_reg': 7.194948680112485, 'border_count': 131}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:26:07,873] Trial 134 finished with value: -0.9427815615597552 and parameters: {'learning_rate': 0.05511002867282696, 'depth': 9, 'l2_leaf_reg': 6.22800975701849, 'border_count': 138}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:26:27,055] Trial 135 finished with value: -0.942565454607665 and parameters: {'learning_rate': 0.08355105831893535, 'depth': 10, 'l2_leaf_reg': 6.737580892285387, 'border_count': 148}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:26:43,705] Trial 136 finished with value: -0.9429126145183947 and parameters: {'learning_rate': 0.07594761542842202, 'depth': 9, 'l2_leaf_reg': 5.7458025554307, 'border_count': 71}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:27:01,349] Trial 137 finished with value: -0.9426575092578686 and parameters: {'learning_rate': 0.09233243289913749, 'depth': 10, 'l2_leaf_reg': 6.496377376235971, 'border_count': 155}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:27:13,632] Trial 138 finished with value: -0.9424835310686976 and parameters: {'learning_rate': 0.0838171356601687, 'depth': 8, 'l2_leaf_reg': 7.010344801621821, 'border_count': 64}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:27:31,064] Trial 139 finished with value: -0.9425251219069601 and parameters: {'learning_rate': 0.06602752717727155, 'depth': 10, 'l2_leaf_reg': 3.220749409375599, 'border_count': 74}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:27:41,099] Trial 140 finished with value: -0.9414494133535743 and parameters: {'learning_rate': 0.1662324813118718, 'depth': 9, 'l2_leaf_reg': 7.411313806945813, 'border_count': 59}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:28:04,668] Trial 141 finished with value: -0.9429386555294903 and parameters: {'learning_rate': 0.05124377499623269, 'depth': 10, 'l2_leaf_reg': 6.3928997083840455, 'border_count': 126}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:28:29,905] Trial 142 finished with value: -0.9429005447200032 and parameters: {'learning_rate': 0.04427469599043805, 'depth': 10, 'l2_leaf_reg': 6.120510083246771, 'border_count': 128}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:28:54,214] Trial 143 finished with value: -0.9424091254435469 and parameters: {'learning_rate': 0.04799422745196114, 'depth': 10, 'l2_leaf_reg': 6.291123032548472, 'border_count': 123}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:29:21,157] Trial 144 finished with value: -0.9427824151548034 and parameters: {'learning_rate': 0.038875205192210334, 'depth': 10, 'l2_leaf_reg': 6.01105435995857, 'border_count': 140}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:29:48,355] Trial 145 finished with value: -0.9423732233560911 and parameters: {'learning_rate': 0.034044689306740296, 'depth': 10, 'l2_leaf_reg': 6.91196289423486, 'border_count': 133}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:30:22,690] Trial 146 finished with value: -0.9427397784365825 and parameters: {'learning_rate': 0.0570202944380588, 'depth': 11, 'l2_leaf_reg': 7.108119889072677, 'border_count': 78}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:30:43,743] Trial 147 finished with value: -0.9424991308848686 and parameters: {'learning_rate': 0.06143131818149311, 'depth': 10, 'l2_leaf_reg': 3.4797887731622725, 'border_count': 225}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:31:06,713] Trial 148 finished with value: -0.9429119142209933 and parameters: {'learning_rate': 0.05190911947599111, 'depth': 9, 'l2_leaf_reg': 6.38075404442762, 'border_count': 116}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:31:18,579] Trial 149 finished with value: -0.9418915688140016 and parameters: {'learning_rate': 0.1322969090415345, 'depth': 10, 'l2_leaf_reg': 3.745639383504758, 'border_count': 249}. Best is trial 130 with value: -0.9432855629248562.
[I 2025-08-05 02:31:21,117] A new study created in memory with name: no-name-d3dad872-33cc-4f9a-986a-098294539b00
[I 2025-08-05 02:31:37,530] Trial 0 finished with value: -0.9358323247514468 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 64, 'feature_fraction': 0.5780093202212182, 'bagging_fraction': 0.5779972601681014, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893}. Best is trial 0 with value: -0.9358323247514468.
[I 2025-08-05 02:31:40,637] Trial 1 finished with value: -0.9064751894816988 and parameters: {'learning_rate': 0.06054365855469246, 'num_leaves': 184, 'max_depth': 3, 'min_child_samples': 98, 'feature_fraction': 0.9162213204002109, 'bagging_fraction': 0.6061695553391381, 'reg_alpha': 4.329370014459266e-07, 'reg_lambda': 4.4734294104626844e-07}. Best is trial 0 with value: -0.9358323247514468.
[I 2025-08-05 02:31:51,071] Trial 2 finished with value: -0.9386360144747428 and parameters: {'learning_rate': 0.024878734419814436, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 36, 'feature_fraction': 0.8059264473611898, 'bagging_fraction': 0.569746930326021, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:31:56,613] Trial 3 finished with value: -0.9303290569351471 and parameters: {'learning_rate': 0.03920673972242137, 'num_leaves': 203, 'max_depth': 5, 'min_child_samples': 56, 'feature_fraction': 0.7962072844310213, 'bagging_fraction': 0.5232252063599989, 'reg_alpha': 0.0029369981104377003, 'reg_lambda': 3.425445902633376e-07}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:11,613] Trial 4 finished with value: -0.9303133884712121 and parameters: {'learning_rate': 0.012151617026673379, 'num_leaves': 244, 'max_depth': 15, 'min_child_samples': 83, 'feature_fraction': 0.6523068845866853, 'bagging_fraction': 0.5488360570031919, 'reg_alpha': 0.014391207615728067, 'reg_lambda': 9.148975058772307e-05}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:14,783] Trial 5 finished with value: -0.8544275616296588 and parameters: {'learning_rate': 0.014413697528610409, 'num_leaves': 131, 'max_depth': 3, 'min_child_samples': 92, 'feature_fraction': 0.6293899908000085, 'bagging_fraction': 0.831261142176991, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:23,832] Trial 6 finished with value: -0.9352955368669097 and parameters: {'learning_rate': 0.05143828405076928, 'num_leaves': 54, 'max_depth': 15, 'min_child_samples': 80, 'feature_fraction': 0.9697494707820946, 'bagging_fraction': 0.9474136752138245, 'reg_alpha': 0.002404915432737351, 'reg_lambda': 1.9809253750493907}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:27,034] Trial 7 finished with value: -0.840740931036518 and parameters: {'learning_rate': 0.01303561122512888, 'num_leaves': 56, 'max_depth': 3, 'min_child_samples': 39, 'feature_fraction': 0.6943386448447411, 'bagging_fraction': 0.6356745158869479, 'reg_alpha': 0.28749982347407854, 'reg_lambda': 1.6247252885719427e-05}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:31,578] Trial 8 finished with value: -0.9071091862428273 and parameters: {'learning_rate': 0.023200867504756827, 'num_leaves': 143, 'max_depth': 4, 'min_child_samples': 82, 'feature_fraction': 0.5372753218398854, 'bagging_fraction': 0.9934434683002586, 'reg_alpha': 0.08916674715636537, 'reg_lambda': 6.143857495033091e-07}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:46,725] Trial 9 finished with value: -0.933741776643824 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 211, 'max_depth': 12, 'min_child_samples': 76, 'feature_fraction': 0.8856351733429728, 'bagging_fraction': 0.5370223258670452, 'reg_alpha': 1.683416412018213e-05, 'reg_lambda': 1.1036250149900698e-07}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:49,660] Trial 10 finished with value: -0.9363597177561258 and parameters: {'learning_rate': 0.13388899274129873, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 11, 'feature_fraction': 0.7846562513261506, 'bagging_fraction': 0.721539898400351, 'reg_alpha': 4.344469108550396, 'reg_lambda': 0.010039786460205695}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:52,076] Trial 11 finished with value: -0.9352133014197529 and parameters: {'learning_rate': 0.17061837680423544, 'num_leaves': 9, 'max_depth': 7, 'min_child_samples': 10, 'feature_fraction': 0.7930679183446125, 'bagging_fraction': 0.7171781358782056, 'reg_alpha': 4.188416507348498, 'reg_lambda': 0.008427137829973095}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:32:56,391] Trial 12 finished with value: -0.9370543645493743 and parameters: {'learning_rate': 0.1252539331847696, 'num_leaves': 119, 'max_depth': 8, 'min_child_samples': 15, 'feature_fraction': 0.760313173810765, 'bagging_fraction': 0.70412092456293, 'reg_alpha': 5.610661224399163e-05, 'reg_lambda': 0.01686118861017418}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:33:02,600] Trial 13 finished with value: -0.9382938176495343 and parameters: {'learning_rate': 0.09547520802157841, 'num_leaves': 122, 'max_depth': 9, 'min_child_samples': 30, 'feature_fraction': 0.7259348037363833, 'bagging_fraction': 0.8304278626461433, 'reg_alpha': 4.6852145960758174e-05, 'reg_lambda': 0.030276821312472436}. Best is trial 2 with value: -0.9386360144747428.
[I 2025-08-05 02:33:08,339] Trial 14 finished with value: -0.9391376167980623 and parameters: {'learning_rate': 0.07544873381168117, 'num_leaves': 95, 'max_depth': 10, 'min_child_samples': 32, 'feature_fraction': 0.8649174147658507, 'bagging_fraction': 0.8633753186051892, 'reg_alpha': 7.828404334305551e-07, 'reg_lambda': 1.6413474196163053e-05}. Best is trial 14 with value: -0.9391376167980623.
[I 2025-08-05 02:33:14,238] Trial 15 finished with value: -0.9386518630652123 and parameters: {'learning_rate': 0.08019736966659374, 'num_leaves': 80, 'max_depth': 11, 'min_child_samples': 38, 'feature_fraction': 0.8620313930247292, 'bagging_fraction': 0.8383609747044727, 'reg_alpha': 5.482417813288472e-07, 'reg_lambda': 1.2069191644341846e-08}. Best is trial 14 with value: -0.9391376167980623.
[I 2025-08-05 02:33:20,796] Trial 16 finished with value: -0.9377470366565971 and parameters: {'learning_rate': 0.07277037581026277, 'num_leaves': 82, 'max_depth': 11, 'min_child_samples': 46, 'feature_fraction': 0.8805304594988683, 'bagging_fraction': 0.8429080872801051, 'reg_alpha': 1.103217333805366e-08, 'reg_lambda': 1.4298887258730937e-08}. Best is trial 14 with value: -0.9391376167980623.
[I 2025-08-05 02:33:25,933] Trial 17 finished with value: -0.9392903590852875 and parameters: {'learning_rate': 0.08866125118089212, 'num_leaves': 89, 'max_depth': 11, 'min_child_samples': 24, 'feature_fraction': 0.992704701660188, 'bagging_fraction': 0.9041308029382291, 'reg_alpha': 3.784188519300372e-07, 'reg_lambda': 1.4441197528339097e-08}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 02:33:30,672] Trial 18 finished with value: -0.9383805005420875 and parameters: {'learning_rate': 0.10643375865859607, 'num_leaves': 90, 'max_depth': 13, 'min_child_samples': 25, 'feature_fraction': 0.9995275195880237, 'bagging_fraction': 0.9070821469417789, 'reg_alpha': 5.814069983326867e-07, 'reg_lambda': 4.09223724608313e-06}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 02:33:34,183] Trial 19 finished with value: -0.9372928990771137 and parameters: {'learning_rate': 0.19840774893517626, 'num_leaves': 166, 'max_depth': 10, 'min_child_samples': 22, 'feature_fraction': 0.9448890776027741, 'bagging_fraction': 0.9134336554829188, 'reg_alpha': 8.990994523866224e-08, 'reg_lambda': 0.00022163473160045644}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 02:33:42,528] Trial 20 finished with value: -0.9381493291981198 and parameters: {'learning_rate': 0.041843890469109725, 'num_leaves': 37, 'max_depth': 13, 'min_child_samples': 50, 'feature_fraction': 0.8380549877235325, 'bagging_fraction': 0.7807851013064275, 'reg_alpha': 0.00042162894510326974, 'reg_lambda': 0.0011132716012388656}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 02:33:48,752] Trial 21 finished with value: -0.9382176435795024 and parameters: {'learning_rate': 0.07368156611132125, 'num_leaves': 95, 'max_depth': 10, 'min_child_samples': 41, 'feature_fraction': 0.8589517181763427, 'bagging_fraction': 0.8720669794373067, 'reg_alpha': 9.126583215501419e-07, 'reg_lambda': 2.932791619952162e-08}. Best is trial 17 with value: -0.9392903590852875.
[I 2025-08-05 02:33:55,193] Trial 22 finished with value: -0.9393197152980373 and parameters: {'learning_rate': 0.08095518480259396, 'num_leaves': 73, 'max_depth': 11, 'min_child_samples': 31, 'feature_fraction': 0.9251147764908157, 'bagging_fraction': 0.7852009740611057, 'reg_alpha': 1.1879001646291583e-07, 'reg_lambda': 1.0050960158345228e-08}. Best is trial 22 with value: -0.9393197152980373.
[I 2025-08-05 02:34:02,470] Trial 23 finished with value: -0.9391112380967274 and parameters: {'learning_rate': 0.059240884942971896, 'num_leaves': 109, 'max_depth': 10, 'min_child_samples': 22, 'feature_fraction': 0.9312404495902853, 'bagging_fraction': 0.7629131725299532, 'reg_alpha': 9.395699080914442e-08, 'reg_lambda': 1.8962942178825404e-06}. Best is trial 22 with value: -0.9393197152980373.
[I 2025-08-05 02:34:06,498] Trial 24 finished with value: -0.9395822963651197 and parameters: {'learning_rate': 0.10778592671166555, 'num_leaves': 61, 'max_depth': 13, 'min_child_samples': 31, 'feature_fraction': 0.9851899024509025, 'bagging_fraction': 0.7887957332693476, 'reg_alpha': 1.0584596216672896e-07, 'reg_lambda': 1.0081402798277421e-07}. Best is trial 24 with value: -0.9395822963651197.
[I 2025-08-05 02:34:10,404] Trial 25 finished with value: -0.9372158266429611 and parameters: {'learning_rate': 0.14145556446180368, 'num_leaves': 48, 'max_depth': 14, 'min_child_samples': 59, 'feature_fraction': 0.9786689607083605, 'bagging_fraction': 0.6709821158612296, 'reg_alpha': 1.606457901282244e-08, 'reg_lambda': 7.636974371947272e-08}. Best is trial 24 with value: -0.9395822963651197.
[I 2025-08-05 02:34:14,910] Trial 26 finished with value: -0.9399258312624517 and parameters: {'learning_rate': 0.09957543478569024, 'num_leaves': 65, 'max_depth': 13, 'min_child_samples': 28, 'feature_fraction': 0.9223884211161939, 'bagging_fraction': 0.7936347090519561, 'reg_alpha': 8.277723185778568e-08, 'reg_lambda': 3.416245730281718e-08}. Best is trial 26 with value: -0.9399258312624517.
[I 2025-08-05 02:34:18,848] Trial 27 finished with value: -0.93822463948998 and parameters: {'learning_rate': 0.11189626912133305, 'num_leaves': 30, 'max_depth': 13, 'min_child_samples': 48, 'feature_fraction': 0.9145942595193253, 'bagging_fraction': 0.7934594537884057, 'reg_alpha': 5.570907652570733e-08, 'reg_lambda': 9.69364939394014e-08}. Best is trial 26 with value: -0.9399258312624517.
[I 2025-08-05 02:34:22,655] Trial 28 finished with value: -0.9386851235869397 and parameters: {'learning_rate': 0.15646306800202422, 'num_leaves': 70, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.9492122723181817, 'bagging_fraction': 0.791870495386907, 'reg_alpha': 3.572651935413191e-06, 'reg_lambda': 3.5107060432680136e-06}. Best is trial 26 with value: -0.9399258312624517.
[I 2025-08-05 02:34:32,294] Trial 29 finished with value: -0.940229361438551 and parameters: {'learning_rate': 0.03248873723539237, 'num_leaves': 27, 'max_depth': 12, 'min_child_samples': 31, 'feature_fraction': 0.9057757750324127, 'bagging_fraction': 0.667795884634778, 'reg_alpha': 1.105217367695826e-07, 'reg_lambda': 9.2063093507131e-08}. Best is trial 29 with value: -0.940229361438551.
[I 2025-08-05 02:34:40,316] Trial 30 finished with value: -0.9377234088725122 and parameters: {'learning_rate': 0.03580770217284296, 'num_leaves': 26, 'max_depth': 12, 'min_child_samples': 66, 'feature_fraction': 0.8280573305037836, 'bagging_fraction': 0.6800005880881586, 'reg_alpha': 3.2961158326960234e-08, 'reg_lambda': 7.606009819443854e-07}. Best is trial 29 with value: -0.940229361438551.
[I 2025-08-05 02:34:52,864] Trial 31 finished with value: -0.9406841204422504 and parameters: {'learning_rate': 0.025418382687662035, 'num_leaves': 57, 'max_depth': 12, 'min_child_samples': 29, 'feature_fraction': 0.9074927932645798, 'bagging_fraction': 0.640221170996667, 'reg_alpha': 9.30089964424005e-08, 'reg_lambda': 6.645254492681197e-08}. Best is trial 31 with value: -0.9406841204422504.
[I 2025-08-05 02:35:05,513] Trial 32 finished with value: -0.9407802360459827 and parameters: {'learning_rate': 0.020488981456792527, 'num_leaves': 47, 'max_depth': 14, 'min_child_samples': 31, 'feature_fraction': 0.9089379155645243, 'bagging_fraction': 0.6240633959161376, 'reg_alpha': 1.735933982308285e-07, 'reg_lambda': 1.365832943500582e-07}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 02:35:17,006] Trial 33 finished with value: -0.9393493018207615 and parameters: {'learning_rate': 0.022192689867975957, 'num_leaves': 42, 'max_depth': 14, 'min_child_samples': 43, 'feature_fraction': 0.9046442881610571, 'bagging_fraction': 0.6096905896771859, 'reg_alpha': 2.476965113393979e-06, 'reg_lambda': 2.709572509762068e-07}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 02:35:26,205] Trial 34 finished with value: -0.939252423002402 and parameters: {'learning_rate': 0.018609576794590695, 'num_leaves': 27, 'max_depth': 15, 'min_child_samples': 34, 'feature_fraction': 0.836726891130765, 'bagging_fraction': 0.6491225946823016, 'reg_alpha': 2.2404451529478362e-07, 'reg_lambda': 4.678834163459716e-08}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 02:35:32,401] Trial 35 finished with value: -0.9389949962154247 and parameters: {'learning_rate': 0.03325255721697557, 'num_leaves': 19, 'max_depth': 12, 'min_child_samples': 27, 'feature_fraction': 0.8995582282887592, 'bagging_fraction': 0.5830617308602539, 'reg_alpha': 1.0240160435877175e-08, 'reg_lambda': 2.626566773361515e-07}. Best is trial 32 with value: -0.9407802360459827.
[I 2025-08-05 02:35:42,400] Trial 36 finished with value: -0.9414279581870597 and parameters: {'learning_rate': 0.027582314726127974, 'num_leaves': 42, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.9356175081930885, 'bagging_fraction': 0.6180192191856357, 'reg_alpha': 1.8194127844478728e-06, 'reg_lambda': 1.5030766348639562e-06}. Best is trial 36 with value: -0.9414279581870597.
[I 2025-08-05 02:35:51,520] Trial 37 finished with value: -0.9417902265749312 and parameters: {'learning_rate': 0.029551432366818276, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.9527979513972848, 'bagging_fraction': 0.6082041083331982, 'reg_alpha': 1.839540243414165e-06, 'reg_lambda': 1.2412290940965426e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:36:03,593] Trial 38 finished with value: -0.9411554880377537 and parameters: {'learning_rate': 0.017793714923269734, 'num_leaves': 42, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.9440541379222797, 'bagging_fraction': 0.5013339806386407, 'reg_alpha': 1.0491591910252639e-05, 'reg_lambda': 4.380753011507096e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:36:15,972] Trial 39 finished with value: -0.940888691395142 and parameters: {'learning_rate': 0.01593244524866308, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9582664347831222, 'bagging_fraction': 0.5200172892774267, 'reg_alpha': 1.2060167102548226e-05, 'reg_lambda': 5.572454712924675e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:36:27,524] Trial 40 finished with value: -0.9410448718538481 and parameters: {'learning_rate': 0.016577358530439255, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9549192626806521, 'bagging_fraction': 0.5022489289105885, 'reg_alpha': 0.0002615038412915418, 'reg_lambda': 5.6810579360492794e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:36:38,172] Trial 41 finished with value: -0.9406980544541378 and parameters: {'learning_rate': 0.017107517739663066, 'num_leaves': 36, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9557207725989134, 'bagging_fraction': 0.5066085019066588, 'reg_alpha': 0.0002651361683944071, 'reg_lambda': 0.0001063483463457663}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:36:44,353] Trial 42 finished with value: -0.9347579784956845 and parameters: {'learning_rate': 0.01482994561337221, 'num_leaves': 15, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.9699897623816666, 'bagging_fraction': 0.564286035042707, 'reg_alpha': 1.044965849488448e-05, 'reg_lambda': 4.095625882071673e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:36:56,103] Trial 43 finished with value: -0.9411529516479682 and parameters: {'learning_rate': 0.0272321530264781, 'num_leaves': 56, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.9621113717037826, 'bagging_fraction': 0.507182386329085, 'reg_alpha': 5.370645816430037e-05, 'reg_lambda': 0.0009173840234092669}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:37:11,547] Trial 44 finished with value: -0.934671370765944 and parameters: {'learning_rate': 0.027348194987809802, 'num_leaves': 55, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.5007250058963767, 'bagging_fraction': 0.5463215536736619, 'reg_alpha': 0.0004536772969541355, 'reg_lambda': 0.0006667011413596759}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:37:28,402] Trial 45 finished with value: -0.9305989355323178 and parameters: {'learning_rate': 0.04873691578976296, 'num_leaves': 150, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.6608583747057708, 'bagging_fraction': 0.580460474209689, 'reg_alpha': 4.7211493977100184e-05, 'reg_lambda': 0.003015537486351291}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:38:04,154] Trial 46 finished with value: -0.9380381153095009 and parameters: {'learning_rate': 0.01196235369432732, 'num_leaves': 214, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.932828117314998, 'bagging_fraction': 0.5026642369227838, 'reg_alpha': 0.000132918012488016, 'reg_lambda': 7.52139355173863e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:38:08,026] Trial 47 finished with value: -0.9080781814279175 and parameters: {'learning_rate': 0.02713021919386878, 'num_leaves': 8, 'max_depth': 5, 'min_child_samples': 94, 'feature_fraction': 0.5764779065133137, 'bagging_fraction': 0.5306300475259297, 'reg_alpha': 0.0011136998875651031, 'reg_lambda': 0.05378130377146102}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:38:24,968] Trial 48 finished with value: -0.9362269091040423 and parameters: {'learning_rate': 0.020656432392174854, 'num_leaves': 104, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.9714632145831618, 'bagging_fraction': 0.558282717877489, 'reg_alpha': 1.6278623696190164e-06, 'reg_lambda': 0.24873336187090317}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:38:36,583] Trial 49 finished with value: -0.941248261775919 and parameters: {'learning_rate': 0.029267408073804388, 'num_leaves': 72, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.8888518717361471, 'bagging_fraction': 0.5985740086544475, 'reg_alpha': 0.009885089249127793, 'reg_lambda': 1.214528944303415e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:38:55,648] Trial 50 finished with value: -0.9367872517627915 and parameters: {'learning_rate': 0.02859764349536189, 'num_leaves': 253, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.885422621206246, 'bagging_fraction': 0.6005441065092483, 'reg_alpha': 0.010667593630787783, 'reg_lambda': 9.393624153570897e-07}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:39:04,766] Trial 51 finished with value: -0.9407839940562269 and parameters: {'learning_rate': 0.0389892131665008, 'num_leaves': 72, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.9441041125913971, 'bagging_fraction': 0.5254312608215007, 'reg_alpha': 2.348818776153583e-05, 'reg_lambda': 8.85325127545241e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:39:17,862] Trial 52 finished with value: -0.9410508084819378 and parameters: {'learning_rate': 0.017923685594281806, 'num_leaves': 53, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.9976982229003776, 'bagging_fraction': 0.6006055940422969, 'reg_alpha': 0.007997338081599673, 'reg_lambda': 2.97631700042988e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:39:28,992] Trial 53 finished with value: -0.9410502291341812 and parameters: {'learning_rate': 0.024170495956602034, 'num_leaves': 54, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.9886129427109516, 'bagging_fraction': 0.5982458766516078, 'reg_alpha': 0.06069925456844537, 'reg_lambda': 0.0002122567066046376}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:39:41,440] Trial 54 finished with value: -0.9395055932382379 and parameters: {'learning_rate': 0.030315094213408268, 'num_leaves': 83, 'max_depth': 13, 'min_child_samples': 25, 'feature_fraction': 0.9990519139240002, 'bagging_fraction': 0.618254320502799, 'reg_alpha': 0.0074826671146528655, 'reg_lambda': 1.695231698812241e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:39:59,915] Trial 55 finished with value: -0.9391781602326947 and parameters: {'learning_rate': 0.013339499329131636, 'num_leaves': 66, 'max_depth': 13, 'min_child_samples': 20, 'feature_fraction': 0.7717047516591609, 'bagging_fraction': 0.5807497702910516, 'reg_alpha': 0.08339888649480151, 'reg_lambda': 2.453993542900561e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:40:10,446] Trial 56 finished with value: -0.9405941226929395 and parameters: {'learning_rate': 0.019040308955270657, 'num_leaves': 34, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.8116881409924636, 'bagging_fraction': 0.5496263084746699, 'reg_alpha': 0.021736317067727044, 'reg_lambda': 0.001245869919736421}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:40:20,023] Trial 57 finished with value: -0.9393500074331002 and parameters: {'learning_rate': 0.03879697273376695, 'num_leaves': 49, 'max_depth': 13, 'min_child_samples': 24, 'feature_fraction': 0.7254655500314888, 'bagging_fraction': 0.6529150678286154, 'reg_alpha': 0.9151336436729196, 'reg_lambda': 8.751787782783505e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:40:33,691] Trial 58 finished with value: -0.9402163476231655 and parameters: {'learning_rate': 0.02223200289486612, 'num_leaves': 75, 'max_depth': 12, 'min_child_samples': 13, 'feature_fraction': 0.9746206788599002, 'bagging_fraction': 0.7002328409375498, 'reg_alpha': 0.002496340297897863, 'reg_lambda': 0.00013425401921537887}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:40:39,145] Trial 59 finished with value: -0.9330464639300784 and parameters: {'learning_rate': 0.04714380640073784, 'num_leaves': 18, 'max_depth': 6, 'min_child_samples': 71, 'feature_fraction': 0.8778123371452727, 'bagging_fraction': 0.7366140415208658, 'reg_alpha': 4.804303510982372e-06, 'reg_lambda': 6.298245854416226}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:40:54,545] Trial 60 finished with value: -0.9398477714883813 and parameters: {'learning_rate': 0.010472739166202503, 'num_leaves': 63, 'max_depth': 9, 'min_child_samples': 19, 'feature_fraction': 0.9350699437350039, 'bagging_fraction': 0.5962713014637445, 'reg_alpha': 0.27252629699878106, 'reg_lambda': 2.4564061034354106e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:41:05,623] Trial 61 finished with value: -0.9410292655197324 and parameters: {'learning_rate': 0.024217081433350763, 'num_leaves': 53, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.985560484353206, 'bagging_fraction': 0.6244418758740675, 'reg_alpha': 0.03506997695868906, 'reg_lambda': 0.0004891693812902077}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:41:15,920] Trial 62 finished with value: -0.9408481590094666 and parameters: {'learning_rate': 0.02535915537085988, 'num_leaves': 52, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.9658125527588133, 'bagging_fraction': 0.5949940018003871, 'reg_alpha': 0.005837417163241207, 'reg_lambda': 0.00021977622423524293}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:41:23,163] Trial 63 finished with value: -0.9401084921326179 and parameters: {'learning_rate': 0.05548124008520944, 'num_leaves': 80, 'max_depth': 15, 'min_child_samples': 13, 'feature_fraction': 0.9383186819293876, 'bagging_fraction': 0.5639650426327242, 'reg_alpha': 0.0011181506163954985, 'reg_lambda': 0.004404786892593394}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:41:32,577] Trial 64 finished with value: -0.9410305948360291 and parameters: {'learning_rate': 0.035250277573057806, 'num_leaves': 60, 'max_depth': 14, 'min_child_samples': 23, 'feature_fraction': 0.9884821415694035, 'bagging_fraction': 0.5230876333541195, 'reg_alpha': 0.00010522612634101224, 'reg_lambda': 1.716253252437858e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:41:41,005] Trial 65 finished with value: -0.9415221480410473 and parameters: {'learning_rate': 0.02973125240148336, 'num_leaves': 41, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.9989516455010894, 'bagging_fraction': 0.5428483969629028, 'reg_alpha': 0.057216745349472735, 'reg_lambda': 0.00025804929460616465}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:41:47,025] Trial 66 finished with value: -0.9402248291910554 and parameters: {'learning_rate': 0.043101125456723406, 'num_leaves': 41, 'max_depth': 13, 'min_child_samples': 36, 'feature_fraction': 0.966205218702277, 'bagging_fraction': 0.5414862263582935, 'reg_alpha': 0.3778575408772894, 'reg_lambda': 0.001616010703981843}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:41:54,448] Trial 67 finished with value: -0.938369957257251 and parameters: {'learning_rate': 0.01840435560614111, 'num_leaves': 22, 'max_depth': 11, 'min_child_samples': 26, 'feature_fraction': 0.9981867572004042, 'bagging_fraction': 0.5702679200028696, 'reg_alpha': 2.2762943469330862e-05, 'reg_lambda': 3.17443080124801e-05}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:42:08,045] Trial 68 finished with value: -0.9383397221737788 and parameters: {'learning_rate': 0.03143760290498216, 'num_leaves': 194, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.9246974124145739, 'bagging_fraction': 0.5355426475907419, 'reg_alpha': 1.7764939352811158e-06, 'reg_lambda': 4.320122928600514e-07}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:42:18,404] Trial 69 finished with value: -0.9365617225844387 and parameters: {'learning_rate': 0.028899476532791527, 'num_leaves': 32, 'max_depth': 12, 'min_child_samples': 87, 'feature_fraction': 0.8606154683379011, 'bagging_fraction': 0.5173098032175094, 'reg_alpha': 7.697737483297444e-06, 'reg_lambda': 1.1139174047495622e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:42:34,400] Trial 70 finished with value: -0.9358340384715879 and parameters: {'learning_rate': 0.020797579182067243, 'num_leaves': 100, 'max_depth': 13, 'min_child_samples': 22, 'feature_fraction': 0.9518304052683318, 'bagging_fraction': 0.9935245282369738, 'reg_alpha': 9.30699889481333, 'reg_lambda': 5.227655785267302e-06}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:42:44,075] Trial 71 finished with value: -0.9417099257658424 and parameters: {'learning_rate': 0.02562425521094912, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.9771612098370345, 'bagging_fraction': 0.6334339241047626, 'reg_alpha': 0.058856899198349334, 'reg_lambda': 0.00029636913220294244}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:42:52,462] Trial 72 finished with value: -0.9415959949301824 and parameters: {'learning_rate': 0.035568302370797514, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 16, 'feature_fraction': 0.9452703762489151, 'bagging_fraction': 0.6363865356566889, 'reg_alpha': 0.02256179178734538, 'reg_lambda': 0.0007258173371299605}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:00,465] Trial 73 finished with value: -0.9412437186039837 and parameters: {'learning_rate': 0.03527300033504935, 'num_leaves': 41, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.8952596920404443, 'bagging_fraction': 0.6385363493018672, 'reg_alpha': 0.2212686569959798, 'reg_lambda': 0.002764312306117732}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:08,521] Trial 74 finished with value: -0.9416134346459095 and parameters: {'learning_rate': 0.03506542529696509, 'num_leaves': 43, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9189882487498834, 'bagging_fraction': 0.6350063341457729, 'reg_alpha': 0.19117251291037346, 'reg_lambda': 0.0003550676992463446}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:13,634] Trial 75 finished with value: -0.9380835269816847 and parameters: {'learning_rate': 0.03564121206770721, 'num_leaves': 14, 'max_depth': 15, 'min_child_samples': 15, 'feature_fraction': 0.8919886230028756, 'bagging_fraction': 0.6379706258846081, 'reg_alpha': 0.1527664171814712, 'reg_lambda': 0.0022948049593900046}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:19,870] Trial 76 finished with value: -0.9403881144044071 and parameters: {'learning_rate': 0.041175297834593574, 'num_leaves': 31, 'max_depth': 15, 'min_child_samples': 27, 'feature_fraction': 0.8708653791254122, 'bagging_fraction': 0.6571684316259844, 'reg_alpha': 1.034790711290251, 'reg_lambda': 0.000327363769194104}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:26,376] Trial 77 finished with value: -0.9398240590129714 and parameters: {'learning_rate': 0.03361278574210592, 'num_leaves': 23, 'max_depth': 15, 'min_child_samples': 16, 'feature_fraction': 0.9180168740253157, 'bagging_fraction': 0.6923928569586306, 'reg_alpha': 0.03682129108256342, 'reg_lambda': 0.007187119041228315}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:34,529] Trial 78 finished with value: -0.9384571671114363 and parameters: {'learning_rate': 0.03804424737328183, 'num_leaves': 44, 'max_depth': 15, 'min_child_samples': 52, 'feature_fraction': 0.8947998733429902, 'bagging_fraction': 0.626576762464837, 'reg_alpha': 0.1661027290931875, 'reg_lambda': 0.03533987286488324}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:43,486] Trial 79 finished with value: -0.9390174271998347 and parameters: {'learning_rate': 0.03065541710029634, 'num_leaves': 67, 'max_depth': 8, 'min_child_samples': 22, 'feature_fraction': 0.8422884338658384, 'bagging_fraction': 0.685277514147042, 'reg_alpha': 1.0043379496101699, 'reg_lambda': 0.0164969221190406}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:50,008] Trial 80 finished with value: -0.9381100310983008 and parameters: {'learning_rate': 0.05092378661690799, 'num_leaves': 36, 'max_depth': 12, 'min_child_samples': 59, 'feature_fraction': 0.9228655704965926, 'bagging_fraction': 0.666391630591921, 'reg_alpha': 0.5695719008946426, 'reg_lambda': 0.0005143141349202528}. Best is trial 37 with value: -0.9417902265749312.
[I 2025-08-05 02:43:57,228] Trial 81 finished with value: -0.9418288677397963 and parameters: {'learning_rate': 0.04546279311257447, 'num_leaves': 46, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.941666701161769, 'bagging_fraction': 0.6118642664387898, 'reg_alpha': 0.021749542597992465, 'reg_lambda': 8.096570967798265e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:04,991] Trial 82 finished with value: -0.9413747245258364 and parameters: {'learning_rate': 0.04591933827905851, 'num_leaves': 48, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.9134346797660532, 'bagging_fraction': 0.6118309448354052, 'reg_alpha': 0.041585276815809064, 'reg_lambda': 0.00012675530437792945}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:12,307] Trial 83 finished with value: -0.9417416862626578 and parameters: {'learning_rate': 0.04543298712488206, 'num_leaves': 47, 'max_depth': 13, 'min_child_samples': 19, 'feature_fraction': 0.9800875882414494, 'bagging_fraction': 0.6141967221606958, 'reg_alpha': 0.017303993261789625, 'reg_lambda': 9.079186451802048e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:19,886] Trial 84 finished with value: -0.9413861649318612 and parameters: {'learning_rate': 0.0452009478515881, 'num_leaves': 47, 'max_depth': 14, 'min_child_samples': 20, 'feature_fraction': 0.9814486995824696, 'bagging_fraction': 0.6144915460696456, 'reg_alpha': 0.020233905159067776, 'reg_lambda': 7.794833484215587e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:25,776] Trial 85 finished with value: -0.9401439214863432 and parameters: {'learning_rate': 0.06710930227069696, 'num_leaves': 60, 'max_depth': 13, 'min_child_samples': 29, 'feature_fraction': 0.9844448297570059, 'bagging_fraction': 0.6303030921551039, 'reg_alpha': 0.004291123627855172, 'reg_lambda': 8.700614312458632e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:31,640] Trial 86 finished with value: -0.941273720971205 and parameters: {'learning_rate': 0.05858249125827002, 'num_leaves': 29, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.9732206071602314, 'bagging_fraction': 0.5863446705012324, 'reg_alpha': 0.020216994653673326, 'reg_lambda': 7.559864753576245e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:41,383] Trial 87 finished with value: -0.938601815053536 and parameters: {'learning_rate': 0.05428092102479892, 'num_leaves': 166, 'max_depth': 13, 'min_child_samples': 24, 'feature_fraction': 0.9484170913074125, 'bagging_fraction': 0.6452533746008096, 'reg_alpha': 0.12626662954182333, 'reg_lambda': 0.00018315435349542376}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:48,391] Trial 88 finished with value: -0.9412697174612022 and parameters: {'learning_rate': 0.04441257777787204, 'num_leaves': 48, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.957500428464932, 'bagging_fraction': 0.613069254109234, 'reg_alpha': 0.02034622790231323, 'reg_lambda': 0.0003356422923075626}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:55,951] Trial 89 finished with value: -0.9389076846062199 and parameters: {'learning_rate': 0.06317956456366983, 'num_leaves': 120, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.9788364609892463, 'bagging_fraction': 0.7140103891383276, 'reg_alpha': 0.08250530097292245, 'reg_lambda': 0.0008259446408430205}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:44:59,124] Trial 90 finished with value: -0.9023511304597781 and parameters: {'learning_rate': 0.039954535581386515, 'num_leaves': 231, 'max_depth': 3, 'min_child_samples': 26, 'feature_fraction': 0.9374744479738298, 'bagging_fraction': 0.6738731867412078, 'reg_alpha': 2.488820172124153, 'reg_lambda': 6.625094996066022e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:45:05,330] Trial 91 finished with value: -0.9411156293804227 and parameters: {'learning_rate': 0.04696478986248002, 'num_leaves': 37, 'max_depth': 14, 'min_child_samples': 13, 'feature_fraction': 0.9105618789285764, 'bagging_fraction': 0.6146219746799967, 'reg_alpha': 0.03301420039080733, 'reg_lambda': 0.00011238770900379432}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:45:12,281] Trial 92 finished with value: -0.941052870580822 and parameters: {'learning_rate': 0.04383527335446995, 'num_leaves': 47, 'max_depth': 14, 'min_child_samples': 19, 'feature_fraction': 0.9590731678623642, 'bagging_fraction': 0.6619533957876103, 'reg_alpha': 0.056336777764661755, 'reg_lambda': 0.00015173300017751307}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:45:18,660] Trial 93 finished with value: -0.9397391513701171 and parameters: {'learning_rate': 0.03286818779531348, 'num_leaves': 23, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.9795234884625362, 'bagging_fraction': 0.6106637417524885, 'reg_alpha': 0.013515752566790919, 'reg_lambda': 1.2690152102347626e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:45:25,063] Trial 94 finished with value: -0.9409824905861346 and parameters: {'learning_rate': 0.05172631407658755, 'num_leaves': 47, 'max_depth': 15, 'min_child_samples': 17, 'feature_fraction': 0.9327231098388252, 'bagging_fraction': 0.5896578274163666, 'reg_alpha': 0.0015769694138772267, 'reg_lambda': 0.00033279080793392014}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:45:33,820] Trial 95 finished with value: -0.9415416386513902 and parameters: {'learning_rate': 0.03718478831103735, 'num_leaves': 59, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9444535949798054, 'bagging_fraction': 0.6326828400462451, 'reg_alpha': 0.04668563284560682, 'reg_lambda': 0.0005723319172989484}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:45:38,943] Trial 96 finished with value: -0.9340696988406583 and parameters: {'learning_rate': 0.0371714228551595, 'num_leaves': 13, 'max_depth': 15, 'min_child_samples': 100, 'feature_fraction': 0.9475961154398244, 'bagging_fraction': 0.5720047102061454, 'reg_alpha': 0.09483191530599723, 'reg_lambda': 0.0004800790192202235}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:45:49,921] Trial 97 finished with value: -0.9408497245713402 and parameters: {'learning_rate': 0.0262437303664068, 'num_leaves': 57, 'max_depth': 14, 'min_child_samples': 22, 'feature_fraction': 0.9653077959643738, 'bagging_fraction': 0.6511582857789295, 'reg_alpha': 0.003962703643542552, 'reg_lambda': 0.001675594093571268}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:46:02,087] Trial 98 finished with value: -0.9383587836440175 and parameters: {'learning_rate': 0.0332633624479184, 'num_leaves': 131, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.989412351148449, 'bagging_fraction': 0.6323715253851381, 'reg_alpha': 0.018030568562337992, 'reg_lambda': 0.0006975825354721934}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:46:12,782] Trial 99 finished with value: -0.9411705580860739 and parameters: {'learning_rate': 0.022680094789917234, 'num_leaves': 38, 'max_depth': 15, 'min_child_samples': 20, 'feature_fraction': 0.9265237266493138, 'bagging_fraction': 0.5553032631512244, 'reg_alpha': 0.05821274415421943, 'reg_lambda': 0.005077864388067773}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:46:21,601] Trial 100 finished with value: -0.9401829095848147 and parameters: {'learning_rate': 0.04150061331642383, 'num_leaves': 64, 'max_depth': 14, 'min_child_samples': 33, 'feature_fraction': 0.9408358432352684, 'bagging_fraction': 0.965477610711941, 'reg_alpha': 0.4602214679327334, 'reg_lambda': 0.0002767179831287173}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:46:28,018] Trial 101 finished with value: -0.9410521396698972 and parameters: {'learning_rate': 0.04548470560670436, 'num_leaves': 31, 'max_depth': 14, 'min_child_samples': 15, 'feature_fraction': 0.9150890520695728, 'bagging_fraction': 0.6210795006363646, 'reg_alpha': 0.03212639737329704, 'reg_lambda': 4.682997408566125e-05}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:46:38,192] Trial 102 finished with value: -0.941580660385284 and parameters: {'learning_rate': 0.028007183827138002, 'num_leaves': 51, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9696721708379259, 'bagging_fraction': 0.6085868175272102, 'reg_alpha': 0.013496190189730587, 'reg_lambda': 0.00012883426256462107}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:46:46,833] Trial 103 finished with value: -0.9417033305689244 and parameters: {'learning_rate': 0.029722357464833236, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9779433642003886, 'bagging_fraction': 0.6454218581761882, 'reg_alpha': 0.011782236321882867, 'reg_lambda': 0.0008540316457848248}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:46:57,453] Trial 104 finished with value: -0.9409681530166436 and parameters: {'learning_rate': 0.027676206321740424, 'num_leaves': 59, 'max_depth': 12, 'min_child_samples': 16, 'feature_fraction': 0.9668409692347048, 'bagging_fraction': 0.6501515275898682, 'reg_alpha': 0.012043012271468041, 'reg_lambda': 0.0009990401845226182}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:47:08,341] Trial 105 finished with value: -0.9404763718712145 and parameters: {'learning_rate': 0.031681971619297096, 'num_leaves': 76, 'max_depth': 13, 'min_child_samples': 11, 'feature_fraction': 0.9548276124561582, 'bagging_fraction': 0.6410225261412424, 'reg_alpha': 2.978251555215324e-07, 'reg_lambda': 0.00046881215230706457}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:47:17,749] Trial 106 finished with value: -0.9416391293851442 and parameters: {'learning_rate': 0.029124691109022244, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.9770015007825816, 'bagging_fraction': 0.6806648316134859, 'reg_alpha': 1.032636184109934e-06, 'reg_lambda': 0.0014831720335725504}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:47:27,797] Trial 107 finished with value: -0.9410545467730806 and parameters: {'learning_rate': 0.030517048310321968, 'num_leaves': 52, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.97356842847626, 'bagging_fraction': 0.6774725983957607, 'reg_alpha': 0.005985852859831901, 'reg_lambda': 0.0017419447653584203}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:47:35,529] Trial 108 finished with value: -0.939779191354661 and parameters: {'learning_rate': 0.02444395407605811, 'num_leaves': 26, 'max_depth': 11, 'min_child_samples': 14, 'feature_fraction': 0.9953915540024075, 'bagging_fraction': 0.6061885657922471, 'reg_alpha': 1.0051448300402312e-06, 'reg_lambda': 0.0011951129358538715}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:47:44,204] Trial 109 finished with value: -0.9407485755094921 and parameters: {'learning_rate': 0.029001532446848305, 'num_leaves': 33, 'max_depth': 12, 'min_child_samples': 10, 'feature_fraction': 0.947966795944733, 'bagging_fraction': 0.6904571457761418, 'reg_alpha': 0.10334781538672401, 'reg_lambda': 0.0032586581576772933}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:47:53,056] Trial 110 finished with value: -0.9376953943429474 and parameters: {'learning_rate': 0.03723418265462467, 'num_leaves': 39, 'max_depth': 7, 'min_child_samples': 18, 'feature_fraction': 0.6357810297899738, 'bagging_fraction': 0.657633061123459, 'reg_alpha': 0.2284321957946056, 'reg_lambda': 0.000216072364598582}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:48:01,079] Trial 111 finished with value: -0.9416210208264155 and parameters: {'learning_rate': 0.03457022570422576, 'num_leaves': 44, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.957614275037941, 'bagging_fraction': 0.630020568461294, 'reg_alpha': 5.337028192628446e-07, 'reg_lambda': 0.0007092416014047398}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:48:10,917] Trial 112 finished with value: -0.9405515773749501 and parameters: {'learning_rate': 0.035434780645906834, 'num_leaves': 68, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9625441309633914, 'bagging_fraction': 0.6304081880463005, 'reg_alpha': 0.06005684079582378, 'reg_lambda': 0.0006057484725072105}. Best is trial 81 with value: -0.9418288677397963.
[I 2025-08-05 02:48:20,515] Trial 113 finished with value: -0.9418609628706509 and parameters: {'learning_rate': 0.030389720447187185, 'num_leaves': 43, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.9770251728706926, 'bagging_fraction': 0.6462416258255956, 'reg_alpha': 1.6557878613974955e-07, 'reg_lambda': 0.00033929563481297084}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:48:30,175] Trial 114 finished with value: -0.9413680203657748 and parameters: {'learning_rate': 0.025857823028328755, 'num_leaves': 45, 'max_depth': 12, 'min_child_samples': 12, 'feature_fraction': 0.979320997731518, 'bagging_fraction': 0.643072347651638, 'reg_alpha': 5.26339804826714e-07, 'reg_lambda': 0.0008490005128119421}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:48:39,625] Trial 115 finished with value: -0.9412920388614905 and parameters: {'learning_rate': 0.0343769077609445, 'num_leaves': 52, 'max_depth': 13, 'min_child_samples': 10, 'feature_fraction': 0.9688579293958346, 'bagging_fraction': 0.6647669383284569, 'reg_alpha': 1.795353092537743e-07, 'reg_lambda': 0.00034532123979391036}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:48:45,936] Trial 116 finished with value: -0.9391439082204867 and parameters: {'learning_rate': 0.03228323138335701, 'num_leaves': 19, 'max_depth': 14, 'min_child_samples': 14, 'feature_fraction': 0.9531283792884417, 'bagging_fraction': 0.6246617498018386, 'reg_alpha': 2.397467889508964e-08, 'reg_lambda': 0.0019523033725672902}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:48:54,102] Trial 117 finished with value: -0.9400646391646603 and parameters: {'learning_rate': 0.03996362062611078, 'num_leaves': 36, 'max_depth': 12, 'min_child_samples': 24, 'feature_fraction': 0.6833577066194692, 'bagging_fraction': 0.6022923240285515, 'reg_alpha': 4.2974108140456055e-08, 'reg_lambda': 0.0012410410412828443}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:49:05,592] Trial 118 finished with value: -0.9416945055285035 and parameters: {'learning_rate': 0.02692368790080795, 'num_leaves': 62, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.9409165783026651, 'bagging_fraction': 0.6380056241982917, 'reg_alpha': 4.7079778534244607e-07, 'reg_lambda': 0.004440606439939018}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:49:27,499] Trial 119 finished with value: -0.9343276172455705 and parameters: {'learning_rate': 0.02650050302539038, 'num_leaves': 112, 'max_depth': 13, 'min_child_samples': 15, 'feature_fraction': 0.592208809351627, 'bagging_fraction': 0.591476409259345, 'reg_alpha': 6.711268213705858e-07, 'reg_lambda': 0.013103747025439557}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:49:32,260] Trial 120 finished with value: -0.9210573851199966 and parameters: {'learning_rate': 0.023427601557237738, 'num_leaves': 28, 'max_depth': 4, 'min_child_samples': 19, 'feature_fraction': 0.9897599749457483, 'bagging_fraction': 0.5786290897205896, 'reg_alpha': 1.282524695335608e-06, 'reg_lambda': 0.006746900995491931}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:49:42,346] Trial 121 finished with value: -0.94127541843452 and parameters: {'learning_rate': 0.030667805098881357, 'num_leaves': 61, 'max_depth': 13, 'min_child_samples': 13, 'feature_fraction': 0.942129526721237, 'bagging_fraction': 0.6325305939558561, 'reg_alpha': 2.198754661361339e-06, 'reg_lambda': 0.003874530200580619}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:49:53,062] Trial 122 finished with value: -0.9413896260756489 and parameters: {'learning_rate': 0.028241300105073863, 'num_leaves': 56, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9307033640581501, 'bagging_fraction': 0.6472543150995906, 'reg_alpha': 4.242755882196157e-07, 'reg_lambda': 0.0001461223172526605}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:50:00,308] Trial 123 finished with value: -0.941247807481067 and parameters: {'learning_rate': 0.03833347063033471, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9705321612697254, 'bagging_fraction': 0.6209803469720319, 'reg_alpha': 3.085183633554746e-06, 'reg_lambda': 0.0005143547070621311}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:50:08,599] Trial 124 finished with value: -0.9412342451120536 and parameters: {'learning_rate': 0.036577066163174354, 'num_leaves': 50, 'max_depth': 14, 'min_child_samples': 18, 'feature_fraction': 0.9596151408090733, 'bagging_fraction': 0.6581006580016445, 'reg_alpha': 2.067831920041956e-07, 'reg_lambda': 1.6825993301779986e-07}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:50:21,405] Trial 125 finished with value: -0.9397025836413431 and parameters: {'learning_rate': 0.02526830066598765, 'num_leaves': 56, 'max_depth': 12, 'min_child_samples': 10, 'feature_fraction': 0.7466158401204286, 'bagging_fraction': 0.6722792060475365, 'reg_alpha': 6.60777103821436e-08, 'reg_lambda': 0.000791291981403811}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:50:33,003] Trial 126 finished with value: -0.9411621864720908 and parameters: {'learning_rate': 0.02121422747032016, 'num_leaves': 44, 'max_depth': 14, 'min_child_samples': 21, 'feature_fraction': 0.9447210412452486, 'bagging_fraction': 0.6366715978832949, 'reg_alpha': 9.051406788473839e-07, 'reg_lambda': 0.002713511306481763}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:50:43,654] Trial 127 finished with value: -0.9361719293741062 and parameters: {'learning_rate': 0.033175091960517496, 'num_leaves': 86, 'max_depth': 13, 'min_child_samples': 79, 'feature_fraction': 0.9790842642658001, 'bagging_fraction': 0.7630914453565837, 'reg_alpha': 2.465366696320277e-07, 'reg_lambda': 0.00043332873549089033}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:50:54,432] Trial 128 finished with value: -0.9408686498135443 and parameters: {'learning_rate': 0.029308590272084163, 'num_leaves': 64, 'max_depth': 15, 'min_child_samples': 14, 'feature_fraction': 0.9251222988544505, 'bagging_fraction': 0.6990021638695283, 'reg_alpha': 3.9783041987243557e-07, 'reg_lambda': 0.005179009969465581}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:51:00,011] Trial 129 finished with value: -0.9411111452103237 and parameters: {'learning_rate': 0.04200610663746894, 'num_leaves': 33, 'max_depth': 13, 'min_child_samples': 12, 'feature_fraction': 0.9546872691387122, 'bagging_fraction': 0.6010662240717591, 'reg_alpha': 1.2367850399403483e-07, 'reg_lambda': 0.00019671283454689745}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:51:10,961] Trial 130 finished with value: -0.9385842573803401 and parameters: {'learning_rate': 0.027100829371521713, 'num_leaves': 50, 'max_depth': 14, 'min_child_samples': 44, 'feature_fraction': 0.9859214025493073, 'bagging_fraction': 0.6073308635855272, 'reg_alpha': 0.008951194496075954, 'reg_lambda': 0.0018507308016440904}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:51:19,726] Trial 131 finished with value: -0.9412409836478656 and parameters: {'learning_rate': 0.02990708093409143, 'num_leaves': 42, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9909384601875043, 'bagging_fraction': 0.6225195736397969, 'reg_alpha': 0.02918961246178873, 'reg_lambda': 0.0002806476371681514}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:51:27,944] Trial 132 finished with value: -0.9415079543144405 and parameters: {'learning_rate': 0.031661021397864544, 'num_leaves': 39, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.9986304378469958, 'bagging_fraction': 0.6417727475789076, 'reg_alpha': 0.014129570354046437, 'reg_lambda': 0.0011272964632993308}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:51:36,681] Trial 133 finished with value: -0.9411804247630821 and parameters: {'learning_rate': 0.03504560259712822, 'num_leaves': 44, 'max_depth': 12, 'min_child_samples': 19, 'feature_fraction': 0.9733415307373128, 'bagging_fraction': 0.6328961754219576, 'reg_alpha': 0.056452685223699166, 'reg_lambda': 0.00010987308141226382}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:51:45,741] Trial 134 finished with value: -0.9409029490951151 and parameters: {'learning_rate': 0.02844571450063856, 'num_leaves': 35, 'max_depth': 14, 'min_child_samples': 23, 'feature_fraction': 0.9998945077642134, 'bagging_fraction': 0.6833744723044677, 'reg_alpha': 0.02482421569675005, 'reg_lambda': 0.00021298974403867178}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:51:54,627] Trial 135 finished with value: -0.94120930963908 and parameters: {'learning_rate': 0.03330040935938463, 'num_leaves': 53, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.9608698104934336, 'bagging_fraction': 0.6556973227824444, 'reg_alpha': 0.13797788572181546, 'reg_lambda': 0.0006382144273361707}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:52:07,498] Trial 136 finished with value: -0.9403533083814827 and parameters: {'learning_rate': 0.023870972595473418, 'num_leaves': 69, 'max_depth': 14, 'min_child_samples': 17, 'feature_fraction': 0.9401039674202992, 'bagging_fraction': 0.8210752755618793, 'reg_alpha': 0.043472623565982325, 'reg_lambda': 3.5325580721419037e-05}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:52:16,047] Trial 137 finished with value: -0.9410761542794365 and parameters: {'learning_rate': 0.030501328134081455, 'num_leaves': 39, 'max_depth': 15, 'min_child_samples': 21, 'feature_fraction': 0.9796665055916361, 'bagging_fraction': 0.5871684302714105, 'reg_alpha': 0.0023666405791397697, 'reg_lambda': 0.0003106523884792572}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:52:27,816] Trial 138 finished with value: -0.9414493018591384 and parameters: {'learning_rate': 0.025889026009336805, 'num_leaves': 59, 'max_depth': 14, 'min_child_samples': 12, 'feature_fraction': 0.9690350467328342, 'bagging_fraction': 0.6172477346776644, 'reg_alpha': 0.07713234276207356, 'reg_lambda': 0.00922748052818966}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:52:34,076] Trial 139 finished with value: -0.9400266394302376 and parameters: {'learning_rate': 0.03956783657135613, 'num_leaves': 24, 'max_depth': 13, 'min_child_samples': 14, 'feature_fraction': 0.9504327419193417, 'bagging_fraction': 0.6638644105395825, 'reg_alpha': 0.014712362486547888, 'reg_lambda': 0.10999329448669808}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:52:42,518] Trial 140 finished with value: -0.9363846343644002 and parameters: {'learning_rate': 0.05036998138889732, 'num_leaves': 48, 'max_depth': 12, 'min_child_samples': 67, 'feature_fraction': 0.9055340116028376, 'bagging_fraction': 0.5724766119586, 'reg_alpha': 0.004591934265030492, 'reg_lambda': 8.750334821955049e-05}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:52:50,316] Trial 141 finished with value: -0.940733516002133 and parameters: {'learning_rate': 0.03239390716412573, 'num_leaves': 30, 'max_depth': 13, 'min_child_samples': 18, 'feature_fraction': 0.9915405888075072, 'bagging_fraction': 0.6481180208819163, 'reg_alpha': 0.012658397118357572, 'reg_lambda': 0.001292021556851783}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:53:03,661] Trial 142 finished with value: -0.9380232988165828 and parameters: {'learning_rate': 0.030533592538732477, 'num_leaves': 138, 'max_depth': 13, 'min_child_samples': 16, 'feature_fraction': 0.9994938749965926, 'bagging_fraction': 0.639347241377714, 'reg_alpha': 0.006469708298942156, 'reg_lambda': 0.0009390740654258066}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:53:12,294] Trial 143 finished with value: -0.9410670777633984 and parameters: {'learning_rate': 0.027972984708103076, 'num_leaves': 37, 'max_depth': 13, 'min_child_samples': 17, 'feature_fraction': 0.9806345713329271, 'bagging_fraction': 0.7365911777421843, 'reg_alpha': 0.024727106068662574, 'reg_lambda': 0.00015623205508511406}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:53:20,364] Trial 144 finished with value: -0.9415307585091431 and parameters: {'learning_rate': 0.03656184571563131, 'num_leaves': 43, 'max_depth': 14, 'min_child_samples': 10, 'feature_fraction': 0.9666078635252431, 'bagging_fraction': 0.6271938198312466, 'reg_alpha': 0.00898506824122446, 'reg_lambda': 0.0024570529627921576}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:53:28,710] Trial 145 finished with value: -0.941582768978902 and parameters: {'learning_rate': 0.03541240759375283, 'num_leaves': 44, 'max_depth': 9, 'min_child_samples': 10, 'feature_fraction': 0.9619285570616701, 'bagging_fraction': 0.6274223230483524, 'reg_alpha': 0.04287394188041347, 'reg_lambda': 0.0024230665731424816}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:53:37,084] Trial 146 finished with value: -0.9416116347204422 and parameters: {'learning_rate': 0.0362643898700982, 'num_leaves': 53, 'max_depth': 10, 'min_child_samples': 11, 'feature_fraction': 0.9363441417551431, 'bagging_fraction': 0.6287022303972769, 'reg_alpha': 0.0007139930954215022, 'reg_lambda': 0.0026980289248545587}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:53:44,606] Trial 147 finished with value: -0.9414930271596763 and parameters: {'learning_rate': 0.04254012696751035, 'num_leaves': 51, 'max_depth': 10, 'min_child_samples': 12, 'feature_fraction': 0.9318850942507745, 'bagging_fraction': 0.6161127476279856, 'reg_alpha': 0.0007935852921869855, 'reg_lambda': 0.0053810662406549295}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:53:53,502] Trial 148 finished with value: -0.9409230928233004 and parameters: {'learning_rate': 0.03455793222523523, 'num_leaves': 62, 'max_depth': 10, 'min_child_samples': 10, 'feature_fraction': 0.9188501834144309, 'bagging_fraction': 0.6063217533334329, 'reg_alpha': 6.905310387720419e-07, 'reg_lambda': 0.025364272800144045}. Best is trial 113 with value: -0.9418609628706509.
[I 2025-08-05 02:54:01,659] Trial 149 finished with value: -0.9414163894102263 and parameters: {'learning_rate': 0.03736612206934189, 'num_leaves': 54, 'max_depth': 11, 'min_child_samples': 14, 'feature_fraction': 0.9372837132416338, 'bagging_fraction': 0.6281087084943482, 'reg_alpha': 9.598713210631733e-05, 'reg_lambda': 0.003301085087415755}. Best is trial 113 with value: -0.9418609628706509.
2025-08-05 02:54:03 [INFO] Model selection complete. Validation metrics: {'val_catboost': 0.9375011304354043, 'val_lightgbm': 0.9281419377538525, 'val_ensemble': 0.9351304650969318}
2025-08-05 02:54:03 [INFO] Selected best model 'catboost' with validation R²=0.9375
2025-08-05 02:54:03 [INFO] Retraining best model 'catboost' on full dataset
2025-08-05 02:54:05 [INFO] Retraining completed in 2.55s
2025-08-05 02:54:06 [INFO] Saved final model to '/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/final_catboost.pkl'
2025-08-05 02:54:06 [INFO] Tree-based → /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/final_catboost.pkl (R²=0.9375)
2025-08-05 02:54:06 [INFO] Training TabNet model...
[I 2025-08-05 02:54:06,245] A new study created in memory with name: no-name-4589d546-13e3-4d3e-bbde-1ceb1da3d179
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:55:07,137] Trial 0 finished with value: 0.8926452142966156 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 8, 'gamma': 1.1162758132435469, 'lambda_sparse': 0.004937309847346859, 'lr': 0.030095892519825106, 'weight_decay': 0.00010193805484753564}. Best is trial 0 with value: 0.8926452142966156.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:56:08,578] Trial 1 finished with value: 0.9079911263838905 and parameters: {'n_d': 34, 'n_a': 59, 'n_steps': 9, 'gamma': 1.0085362864400924, 'lambda_sparse': 4.800611125574672e-05, 'lr': 0.034931997055150474, 'weight_decay': 7.252741029934894e-06}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:56:48,766] Trial 2 finished with value: 0.5051946776144052 and parameters: {'n_d': 55, 'n_a': 32, 'n_steps': 5, 'gamma': 1.7815729654592625, 'lambda_sparse': 0.00014232860907374424, 'lr': 0.00024254870971357462, 'weight_decay': 5.291489830757928e-05}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:58:01,933] Trial 3 finished with value: -1.5576184550061205 and parameters: {'n_d': 31, 'n_a': 32, 'n_steps': 10, 'gamma': 1.7737619712275983, 'lambda_sparse': 0.0005855958348127595, 'lr': 0.00033678905666611125, 'weight_decay': 0.0003243964937639516}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:59:08,624] Trial 4 finished with value: 0.44147587207003947 and parameters: {'n_d': 60, 'n_a': 42, 'n_steps': 9, 'gamma': 1.3573055579529512, 'lambda_sparse': 0.0011830284227521755, 'lr': 0.0003357283191550254, 'weight_decay': 0.00014867350522890273}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 02:59:37,276] Trial 5 finished with value: 0.9016123778383933 and parameters: {'n_d': 56, 'n_a': 23, 'n_steps': 3, 'gamma': 1.318664987062949, 'lambda_sparse': 0.005138428078727899, 'lr': 0.024551086958563947, 'weight_decay': 5.6031599083879985e-06}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:00:33,198] Trial 6 finished with value: 0.6403547005692836 and parameters: {'n_d': 8, 'n_a': 13, 'n_steps': 7, 'gamma': 1.7528106213555807, 'lambda_sparse': 6.249082739845119e-05, 'lr': 0.0038973769675086705, 'weight_decay': 3.308404037868171e-06}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:01:06,879] Trial 7 finished with value: 0.8960705305458452 and parameters: {'n_d': 45, 'n_a': 36, 'n_steps': 4, 'gamma': 1.3365695706336542, 'lambda_sparse': 0.0001773895335176986, 'lr': 0.0027334101884612157, 'weight_decay': 0.0001227628494773275}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:01:45,991] Trial 8 finished with value: 0.7834607853575036 and parameters: {'n_d': 64, 'n_a': 45, 'n_steps': 5, 'gamma': 1.991996404166174, 'lambda_sparse': 0.003991432960058801, 'lr': 0.002982950499290818, 'weight_decay': 6.816276092968781e-06}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:02:13,567] Trial 9 finished with value: 0.8920414080749738 and parameters: {'n_d': 64, 'n_a': 33, 'n_steps': 3, 'gamma': 1.962045267424648, 'lambda_sparse': 0.0013794887761518018, 'lr': 0.016882081602392057, 'weight_decay': 6.124794771644986e-05}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:03:13,508] Trial 10 finished with value: 0.8924027746143284 and parameters: {'n_d': 26, 'n_a': 64, 'n_steps': 10, 'gamma': 1.036183248666688, 'lambda_sparse': 1.5481030030086663e-05, 'lr': 0.06535313798621155, 'weight_decay': 1.845014544466493e-05}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:04:05,011] Trial 11 finished with value: 0.8840734011126897 and parameters: {'n_d': 43, 'n_a': 16, 'n_steps': 7, 'gamma': 1.2229406693907816, 'lambda_sparse': 2.4773754012823504e-05, 'lr': 0.01268814192545805, 'weight_decay': 1.0973028637946521e-05}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:04:48,356] Trial 12 finished with value: 0.8758672743006888 and parameters: {'n_d': 17, 'n_a': 22, 'n_steps': 6, 'gamma': 1.5040085838036028, 'lambda_sparse': 0.008524159225099592, 'lr': 0.0985387695443617, 'weight_decay': 1.1084893559342082e-06}. Best is trial 1 with value: 0.9079911263838905.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:05:16,597] Trial 13 finished with value: 0.9213538027998243 and parameters: {'n_d': 42, 'n_a': 52, 'n_steps': 3, 'gamma': 1.4506127424693684, 'lambda_sparse': 4.523419901084868e-05, 'lr': 0.008991162197583056, 'weight_decay': 3.069825783821816e-06}. Best is trial 13 with value: 0.9213538027998243.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:06:19,525] Trial 14 finished with value: 0.6866003330455657 and parameters: {'n_d': 41, 'n_a': 53, 'n_steps': 8, 'gamma': 1.5673579837153764, 'lambda_sparse': 3.6610144494281174e-05, 'lr': 0.0066212364418513055, 'weight_decay': 1.7117799790048524e-06}. Best is trial 13 with value: 0.9213538027998243.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:07:22,699] Trial 15 finished with value: 0.5371787167772348 and parameters: {'n_d': 34, 'n_a': 51, 'n_steps': 9, 'gamma': 1.6326432879330173, 'lambda_sparse': 1.0150362140529262e-05, 'lr': 0.0011713395406040778, 'weight_decay': 2.2635665325816375e-05}. Best is trial 13 with value: 0.9213538027998243.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:08:05,254] Trial 16 finished with value: 0.8906816467145482 and parameters: {'n_d': 25, 'n_a': 55, 'n_steps': 6, 'gamma': 1.1596214605146933, 'lambda_sparse': 6.792996544045891e-05, 'lr': 0.04233818170629692, 'weight_decay': 3.138587882858816e-06}. Best is trial 13 with value: 0.9213538027998243.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:08:38,175] Trial 17 finished with value: 0.9024115036644145 and parameters: {'n_d': 49, 'n_a': 59, 'n_steps': 4, 'gamma': 1.0139563282643749, 'lambda_sparse': 0.0002325344678471968, 'lr': 0.006794759758209224, 'weight_decay': 1.0851823429580487e-05}. Best is trial 13 with value: 0.9213538027998243.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:09:36,246] Trial 18 finished with value: 0.6458390721339122 and parameters: {'n_d': 37, 'n_a': 46, 'n_steps': 8, 'gamma': 1.272896800850599, 'lambda_sparse': 7.48217694800248e-05, 'lr': 0.001206666025072131, 'weight_decay': 2.9647218956019606e-06}. Best is trial 13 with value: 0.9213538027998243.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:10:41,340] Trial 19 finished with value: 0.1524953151567625 and parameters: {'n_d': 49, 'n_a': 58, 'n_steps': 9, 'gamma': 1.4270209470367254, 'lambda_sparse': 0.000439231092687321, 'lr': 0.00010805262245926123, 'weight_decay': 1.172965000413402e-06}. Best is trial 13 with value: 0.9213538027998243.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:11:24,534] A new study created in memory with name: no-name-d7594d6a-cd9a-40b6-a8ee-a4e74c2f6070
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:12:28,395] Trial 0 finished with value: 0.475365390367003 and parameters: {'n_d': 53, 'n_a': 59, 'n_steps': 9, 'gamma': 1.4058353966711938, 'lambda_sparse': 0.0016032465633129538, 'lr': 0.0005795104591664607, 'weight_decay': 2.098508487254361e-06}. Best is trial 0 with value: 0.475365390367003.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:12:58,522] Trial 1 finished with value: 0.9221544326435496 and parameters: {'n_d': 23, 'n_a': 45, 'n_steps': 3, 'gamma': 1.2118733524202152, 'lambda_sparse': 0.0019737382196317295, 'lr': 0.028536995218645268, 'weight_decay': 5.612057782585075e-06}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:13:59,161] Trial 2 finished with value: 0.7400748335732794 and parameters: {'n_d': 31, 'n_a': 21, 'n_steps': 8, 'gamma': 1.0035379645201368, 'lambda_sparse': 0.0020191139420225185, 'lr': 0.0007933104996997634, 'weight_decay': 0.00044695831805455753}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:14:54,770] Trial 3 finished with value: 0.846056723823048 and parameters: {'n_d': 22, 'n_a': 27, 'n_steps': 6, 'gamma': 1.2950279678352654, 'lambda_sparse': 0.00044527116552041987, 'lr': 0.0022341539089065668, 'weight_decay': 0.00010214746953099017}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:15:44,742] Trial 4 finished with value: 0.902042977652333 and parameters: {'n_d': 57, 'n_a': 35, 'n_steps': 6, 'gamma': 1.371542961034989, 'lambda_sparse': 0.00045494702145649547, 'lr': 0.029541402315549754, 'weight_decay': 0.0001804092440868332}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:16:12,994] Trial 5 finished with value: 0.6301591288963225 and parameters: {'n_d': 60, 'n_a': 43, 'n_steps': 3, 'gamma': 1.1313747927780646, 'lambda_sparse': 3.6166075132183195e-05, 'lr': 0.00015662738987613903, 'weight_decay': 4.2549380107250155e-06}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:17:09,591] Trial 6 finished with value: 0.8012023937538535 and parameters: {'n_d': 61, 'n_a': 22, 'n_steps': 8, 'gamma': 1.8004924243020344, 'lambda_sparse': 2.362756523150743e-05, 'lr': 0.011765405946071382, 'weight_decay': 9.782732465374524e-06}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:17:43,995] Trial 7 finished with value: 0.9116540628098817 and parameters: {'n_d': 21, 'n_a': 31, 'n_steps': 4, 'gamma': 1.5618387956203537, 'lambda_sparse': 0.00010583575643661405, 'lr': 0.05249804474280781, 'weight_decay': 4.045798298193348e-06}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:18:34,421] Trial 8 finished with value: 0.4359527171687949 and parameters: {'n_d': 20, 'n_a': 23, 'n_steps': 7, 'gamma': 1.766176037711439, 'lambda_sparse': 0.0035475384706281014, 'lr': 0.00037358379125310175, 'weight_decay': 2.462976663121421e-06}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:19:02,420] Trial 9 finished with value: 0.9050754551297941 and parameters: {'n_d': 43, 'n_a': 30, 'n_steps': 3, 'gamma': 1.890315209083877, 'lambda_sparse': 0.0027804113151806975, 'lr': 0.00627768114557377, 'weight_decay': 6.406341756279513e-05}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:19:36,015] Trial 10 finished with value: 0.8864573086060745 and parameters: {'n_d': 13, 'n_a': 10, 'n_steps': 5, 'gamma': 1.600230602517195, 'lambda_sparse': 0.008214864740004095, 'lr': 0.08821086803375304, 'weight_decay': 2.2109246751487818e-05}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:20:11,697] Trial 11 finished with value: 0.9063701055379404 and parameters: {'n_d': 31, 'n_a': 47, 'n_steps': 4, 'gamma': 1.590819554684347, 'lambda_sparse': 0.00016753083966260381, 'lr': 0.06899380639449952, 'weight_decay': 1.1172843308515193e-05}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:20:43,528] Trial 12 finished with value: 0.9216026031070053 and parameters: {'n_d': 8, 'n_a': 49, 'n_steps': 4, 'gamma': 1.177665023146679, 'lambda_sparse': 9.090950550183606e-05, 'lr': 0.020715175994048766, 'weight_decay': 1.059335207101219e-06}. Best is trial 1 with value: 0.9221544326435496.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:21:17,209] Trial 13 finished with value: 0.9285521497969988 and parameters: {'n_d': 9, 'n_a': 56, 'n_steps': 4, 'gamma': 1.1761992276447368, 'lambda_sparse': 6.809895648842604e-05, 'lr': 0.01467588148309975, 'weight_decay': 1.2523506506601618e-06}. Best is trial 13 with value: 0.9285521497969988.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:21:44,775] Trial 14 finished with value: 0.9026197551819621 and parameters: {'n_d': 13, 'n_a': 63, 'n_steps': 3, 'gamma': 1.0095863096235158, 'lambda_sparse': 0.0010524178710027722, 'lr': 0.00265696182384523, 'weight_decay': 8.39708489149005e-06}. Best is trial 13 with value: 0.9285521497969988.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:22:22,524] Trial 15 finished with value: 0.9181881371200182 and parameters: {'n_d': 40, 'n_a': 55, 'n_steps': 5, 'gamma': 1.210905066960611, 'lambda_sparse': 1.0095848828583183e-05, 'lr': 0.008036274420974078, 'weight_decay': 1.0093218582282287e-06}. Best is trial 13 with value: 0.9285521497969988.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:22:58,866] Trial 16 finished with value: 0.9098440322874931 and parameters: {'n_d': 28, 'n_a': 42, 'n_steps': 5, 'gamma': 1.4439001658735426, 'lambda_sparse': 0.009704255965975076, 'lr': 0.02318144247120609, 'weight_decay': 4.28335236464574e-06}. Best is trial 13 with value: 0.9285521497969988.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:23:32,777] Trial 17 finished with value: 0.9105593842565859 and parameters: {'n_d': 8, 'n_a': 53, 'n_steps': 4, 'gamma': 1.1198249800056823, 'lambda_sparse': 0.0006222605935576863, 'lr': 0.004945202388156079, 'weight_decay': 2.4559643684461824e-05}. Best is trial 13 with value: 0.9285521497969988.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:24:46,187] Trial 18 finished with value: 0.8185760413631554 and parameters: {'n_d': 15, 'n_a': 40, 'n_steps': 10, 'gamma': 1.276209671449226, 'lambda_sparse': 4.574309330453219e-05, 'lr': 0.013023205047285078, 'weight_decay': 1.6391838912132185e-06}. Best is trial 13 with value: 0.9285521497969988.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:25:16,989] Trial 19 finished with value: 0.8569561666086132 and parameters: {'n_d': 26, 'n_a': 62, 'n_steps': 3, 'gamma': 1.3368233858275689, 'lambda_sparse': 0.00019821252559092228, 'lr': 0.03461324153123817, 'weight_decay': 0.0008625710607623967}. Best is trial 13 with value: 0.9285521497969988.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:26:05,835] A new study created in memory with name: no-name-f5402ab0-aed7-444f-b298-f7a5b182df18
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:27:15,662] Trial 0 finished with value: 0.7246427754713964 and parameters: {'n_d': 55, 'n_a': 37, 'n_steps': 10, 'gamma': 1.7397255256654258, 'lambda_sparse': 8.469604246993305e-05, 'lr': 0.008700609507235717, 'weight_decay': 0.0001376287147960577}. Best is trial 0 with value: 0.7246427754713964.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:27:50,206] Trial 1 finished with value: 0.8699940270930144 and parameters: {'n_d': 37, 'n_a': 54, 'n_steps': 5, 'gamma': 1.6743558158786218, 'lambda_sparse': 5.927387539745812e-05, 'lr': 0.06316150309366776, 'weight_decay': 2.36356234331663e-05}. Best is trial 1 with value: 0.8699940270930144.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:28:53,700] Trial 2 finished with value: 0.5979410752031917 and parameters: {'n_d': 14, 'n_a': 24, 'n_steps': 8, 'gamma': 1.7998932562592938, 'lambda_sparse': 1.549954721250252e-05, 'lr': 0.0011846559210163406, 'weight_decay': 1.781686096603058e-05}. Best is trial 1 with value: 0.8699940270930144.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:29:28,947] Trial 3 finished with value: 0.8178472354720666 and parameters: {'n_d': 64, 'n_a': 14, 'n_steps': 7, 'gamma': 1.35738527542932, 'lambda_sparse': 0.0008586465713634844, 'lr': 0.04070644815594993, 'weight_decay': 2.6280884953978603e-05}. Best is trial 1 with value: 0.8699940270930144.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:30:08,297] Trial 4 finished with value: 0.6717153220187235 and parameters: {'n_d': 18, 'n_a': 61, 'n_steps': 5, 'gamma': 1.7809276595818682, 'lambda_sparse': 0.0022642640009789042, 'lr': 0.0005945989287502356, 'weight_decay': 6.132802078366675e-06}. Best is trial 1 with value: 0.8699940270930144.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:30:35,111] Trial 5 finished with value: 0.9204565926322374 and parameters: {'n_d': 32, 'n_a': 24, 'n_steps': 3, 'gamma': 1.1378332070638664, 'lambda_sparse': 0.00021469723106028605, 'lr': 0.007340316236047606, 'weight_decay': 2.67842936539493e-06}. Best is trial 5 with value: 0.9204565926322374.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:31:13,660] Trial 6 finished with value: 0.500145008104648 and parameters: {'n_d': 44, 'n_a': 33, 'n_steps': 9, 'gamma': 1.63274906347494, 'lambda_sparse': 0.00019989337950799359, 'lr': 0.001162307408903487, 'weight_decay': 2.4786931993230586e-05}. Best is trial 5 with value: 0.9204565926322374.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:32:01,799] Trial 7 finished with value: 0.654408336773451 and parameters: {'n_d': 28, 'n_a': 58, 'n_steps': 6, 'gamma': 1.4404520550081599, 'lambda_sparse': 0.008798934458104753, 'lr': 0.0004169783492670881, 'weight_decay': 0.00014824737044907358}. Best is trial 5 with value: 0.9204565926322374.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:33:09,150] Trial 8 finished with value: 0.6962433119744652 and parameters: {'n_d': 37, 'n_a': 41, 'n_steps': 10, 'gamma': 1.7090342414613486, 'lambda_sparse': 0.000565507689830807, 'lr': 0.005472525814262306, 'weight_decay': 1.1411506690610614e-06}. Best is trial 5 with value: 0.9204565926322374.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:33:54,796] Trial 9 finished with value: 0.865361590713132 and parameters: {'n_d': 8, 'n_a': 57, 'n_steps': 6, 'gamma': 1.9083237373878186, 'lambda_sparse': 2.3355975037682703e-05, 'lr': 0.00808060439762483, 'weight_decay': 2.3789055962314185e-05}. Best is trial 5 with value: 0.9204565926322374.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:34:22,411] Trial 10 finished with value: 0.4771367733768027 and parameters: {'n_d': 29, 'n_a': 11, 'n_steps': 3, 'gamma': 1.024145018282658, 'lambda_sparse': 0.0023499683683879152, 'lr': 0.00011177383644229065, 'weight_decay': 1.1996885737321356e-06}. Best is trial 5 with value: 0.9204565926322374.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:34:47,400] Trial 11 finished with value: 0.9153028107343192 and parameters: {'n_d': 45, 'n_a': 48, 'n_steps': 3, 'gamma': 1.2037970778018743, 'lambda_sparse': 5.691921205660045e-05, 'lr': 0.08140555984238183, 'weight_decay': 4.753201850435208e-06}. Best is trial 5 with value: 0.9204565926322374.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:35:14,911] Trial 12 finished with value: 0.921310935521246 and parameters: {'n_d': 50, 'n_a': 45, 'n_steps': 3, 'gamma': 1.151273611976912, 'lambda_sparse': 0.00014865865329182008, 'lr': 0.02325361212752567, 'weight_decay': 4.368920888206401e-06}. Best is trial 12 with value: 0.921310935521246.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:35:48,270] Trial 13 finished with value: 0.926140683063175 and parameters: {'n_d': 51, 'n_a': 25, 'n_steps': 4, 'gamma': 1.0177212734082928, 'lambda_sparse': 0.00025370827789536796, 'lr': 0.01956544506887989, 'weight_decay': 3.623646196960983e-06}. Best is trial 13 with value: 0.926140683063175.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:36:18,371] Trial 14 finished with value: 0.8968289055937413 and parameters: {'n_d': 55, 'n_a': 27, 'n_steps': 4, 'gamma': 1.01845307407903, 'lambda_sparse': 0.0005102455692596309, 'lr': 0.02048808849423669, 'weight_decay': 0.0006417664592217428}. Best is trial 13 with value: 0.926140683063175.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:36:51,625] Trial 15 finished with value: 0.9097470742113638 and parameters: {'n_d': 49, 'n_a': 44, 'n_steps': 4, 'gamma': 1.2685713844088333, 'lambda_sparse': 0.0001320149532921373, 'lr': 0.021383005864702136, 'weight_decay': 7.407099863389385e-06}. Best is trial 13 with value: 0.926140683063175.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:37:24,808] Trial 16 finished with value: 0.9220851696542026 and parameters: {'n_d': 63, 'n_a': 17, 'n_steps': 4, 'gamma': 1.1208460763792456, 'lambda_sparse': 0.0017261364035332399, 'lr': 0.02195955101173201, 'weight_decay': 2.3874183703760476e-06}. Best is trial 13 with value: 0.926140683063175.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:38:03,228] Trial 17 finished with value: 0.794541235534027 and parameters: {'n_d': 62, 'n_a': 16, 'n_steps': 5, 'gamma': 1.4952866931220627, 'lambda_sparse': 0.001929103530443286, 'lr': 0.002535152931661268, 'weight_decay': 2.1128644188618687e-06}. Best is trial 13 with value: 0.926140683063175.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:38:40,212] Trial 18 finished with value: 0.9216316796942983 and parameters: {'n_d': 57, 'n_a': 19, 'n_steps': 4, 'gamma': 1.3514581122831835, 'lambda_sparse': 0.008029913704965592, 'lr': 0.014770838301895078, 'weight_decay': 9.75881995738724e-06}. Best is trial 13 with value: 0.926140683063175.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:39:30,594] Trial 19 finished with value: 0.894279029609777 and parameters: {'n_d': 58, 'n_a': 9, 'n_steps': 7, 'gamma': 1.075182584083662, 'lambda_sparse': 0.0015057792824310005, 'lr': 0.003326106192746153, 'weight_decay': 5.91797103567473e-05}. Best is trial 13 with value: 0.926140683063175.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:40:22,220] A new study created in memory with name: no-name-05da527e-0c53-4931-874d-f9430d330c46
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:41:31,796] Trial 0 finished with value: 0.2783016359345426 and parameters: {'n_d': 31, 'n_a': 12, 'n_steps': 9, 'gamma': 1.176681015496504, 'lambda_sparse': 2.5388662387666928e-05, 'lr': 0.00021801816480137537, 'weight_decay': 4.961975823220104e-06}. Best is trial 0 with value: 0.2783016359345426.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:42:31,475] Trial 1 finished with value: 0.45097106752950844 and parameters: {'n_d': 19, 'n_a': 22, 'n_steps': 8, 'gamma': 1.435318915587968, 'lambda_sparse': 3.533784023680643e-05, 'lr': 0.0005739558424634537, 'weight_decay': 6.586356888896694e-05}. Best is trial 1 with value: 0.45097106752950844.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:43:22,828] Trial 2 finished with value: 0.6776833056796641 and parameters: {'n_d': 12, 'n_a': 32, 'n_steps': 7, 'gamma': 1.012410082519291, 'lambda_sparse': 0.0001463559711242318, 'lr': 0.0005198083204720404, 'weight_decay': 2.4199666721690237e-06}. Best is trial 2 with value: 0.6776833056796641.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:43:58,056] Trial 3 finished with value: 0.6947625129363857 and parameters: {'n_d': 15, 'n_a': 10, 'n_steps': 4, 'gamma': 1.8616361533942514, 'lambda_sparse': 0.003055826128717139, 'lr': 0.0013305522071397767, 'weight_decay': 0.000550055735133048}. Best is trial 3 with value: 0.6947625129363857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:44:25,019] Trial 4 finished with value: 0.6469780025893748 and parameters: {'n_d': 50, 'n_a': 44, 'n_steps': 3, 'gamma': 1.2654255662969245, 'lambda_sparse': 0.003064679952486164, 'lr': 0.00033914951129384045, 'weight_decay': 0.00013768817609807442}. Best is trial 3 with value: 0.6947625129363857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:45:30,855] Trial 5 finished with value: -0.4794239585735318 and parameters: {'n_d': 41, 'n_a': 63, 'n_steps': 9, 'gamma': 1.9373814286945379, 'lambda_sparse': 1.373749805344077e-05, 'lr': 0.00018861656545870792, 'weight_decay': 0.00022515495536097862}. Best is trial 3 with value: 0.6947625129363857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:46:28,287] Trial 6 finished with value: 0.6686125225264874 and parameters: {'n_d': 55, 'n_a': 45, 'n_steps': 10, 'gamma': 1.492649236915165, 'lambda_sparse': 1.7744167991266312e-05, 'lr': 0.01189708127581887, 'weight_decay': 3.0427433003902247e-05}. Best is trial 3 with value: 0.6947625129363857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:47:35,851] Trial 7 finished with value: -0.01145003463436245 and parameters: {'n_d': 10, 'n_a': 32, 'n_steps': 10, 'gamma': 1.4554721881642796, 'lambda_sparse': 0.001734076038526241, 'lr': 0.00014045635078457365, 'weight_decay': 1.930550412475764e-05}. Best is trial 3 with value: 0.6947625129363857.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:48:39,051] Trial 8 finished with value: 0.6995425987083113 and parameters: {'n_d': 64, 'n_a': 63, 'n_steps': 8, 'gamma': 1.107446018570475, 'lambda_sparse': 9.029802704998822e-05, 'lr': 0.0006046161515787051, 'weight_decay': 5.7401987654527105e-06}. Best is trial 8 with value: 0.6995425987083113.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:49:34,795] Trial 9 finished with value: 0.44148549013130145 and parameters: {'n_d': 19, 'n_a': 28, 'n_steps': 6, 'gamma': 1.7266433337055846, 'lambda_sparse': 0.002100734632731144, 'lr': 0.0002453146056929941, 'weight_decay': 2.2608571563033367e-05}. Best is trial 8 with value: 0.6995425987083113.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:50:26,178] Trial 10 finished with value: 0.8972274689648159 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 6, 'gamma': 1.0353684959825324, 'lambda_sparse': 0.00021809919907936064, 'lr': 0.08866091605445339, 'weight_decay': 1.0167121174189264e-06}. Best is trial 10 with value: 0.8972274689648159.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:51:16,920] Trial 11 finished with value: 0.9069992075240518 and parameters: {'n_d': 63, 'n_a': 61, 'n_steps': 6, 'gamma': 1.026692175253228, 'lambda_sparse': 0.0002931980710244197, 'lr': 0.09901079182271345, 'weight_decay': 1.212879485304673e-06}. Best is trial 11 with value: 0.9069992075240518.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:51:55,916] Trial 12 finished with value: 0.9156736965576424 and parameters: {'n_d': 62, 'n_a': 53, 'n_steps': 5, 'gamma': 1.2752588691911988, 'lambda_sparse': 0.0004202877724800388, 'lr': 0.09070315557346413, 'weight_decay': 1.0321005398510553e-06}. Best is trial 12 with value: 0.9156736965576424.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:52:35,550] Trial 13 finished with value: 0.9039125025986368 and parameters: {'n_d': 53, 'n_a': 51, 'n_steps': 5, 'gamma': 1.2723370211760507, 'lambda_sparse': 0.000648072556004214, 'lr': 0.09554039659088738, 'weight_decay': 1.0206814261520094e-06}. Best is trial 12 with value: 0.9156736965576424.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:53:14,013] Trial 14 finished with value: 0.8967115576004785 and parameters: {'n_d': 39, 'n_a': 53, 'n_steps': 5, 'gamma': 1.2942744631471423, 'lambda_sparse': 0.000642304812935696, 'lr': 0.021468946775610186, 'weight_decay': 6.641571953821953e-06}. Best is trial 12 with value: 0.9156736965576424.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:53:48,531] Trial 15 finished with value: 0.9157429906431827 and parameters: {'n_d': 58, 'n_a': 54, 'n_steps': 4, 'gamma': 1.700578042983305, 'lambda_sparse': 0.009136421201706988, 'lr': 0.027016157271737527, 'weight_decay': 2.4295972950082967e-06}. Best is trial 15 with value: 0.9157429906431827.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:54:15,975] Trial 16 finished with value: 0.929966592734781 and parameters: {'n_d': 45, 'n_a': 41, 'n_steps': 3, 'gamma': 1.63620648304147, 'lambda_sparse': 0.00664932840418863, 'lr': 0.017481319986644196, 'weight_decay': 3.0725102175684937e-06}. Best is trial 16 with value: 0.929966592734781.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:54:45,915] Trial 17 finished with value: 0.9260975432894799 and parameters: {'n_d': 47, 'n_a': 40, 'n_steps': 3, 'gamma': 1.6570130259969278, 'lambda_sparse': 0.006631522431750598, 'lr': 0.01016900840276147, 'weight_decay': 1.100632532997131e-05}. Best is trial 16 with value: 0.929966592734781.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:55:13,472] Trial 18 finished with value: 0.9204432259735355 and parameters: {'n_d': 46, 'n_a': 41, 'n_steps': 3, 'gamma': 1.6183942847660142, 'lambda_sparse': 0.009001059158299978, 'lr': 0.005032146825854119, 'weight_decay': 1.2101611627529066e-05}. Best is trial 16 with value: 0.929966592734781.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:55:41,394] Trial 19 finished with value: 0.9137738864644748 and parameters: {'n_d': 32, 'n_a': 39, 'n_steps': 3, 'gamma': 1.6214617999097598, 'lambda_sparse': 0.005053418065365349, 'lr': 0.004874006271264528, 'weight_decay': 1.2322776327618379e-05}. Best is trial 16 with value: 0.929966592734781.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:56:32,404] A new study created in memory with name: no-name-629b7e2f-5d26-4c00-b07a-a3190a3305b6
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:57:14,217] Trial 0 finished with value: 0.866855943651565 and parameters: {'n_d': 61, 'n_a': 52, 'n_steps': 5, 'gamma': 1.407314403550323, 'lambda_sparse': 0.0002969786790511771, 'lr': 0.0013442369936756055, 'weight_decay': 0.000752119907608055}. Best is trial 0 with value: 0.866855943651565.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:57:48,400] Trial 1 finished with value: 0.775756352187957 and parameters: {'n_d': 38, 'n_a': 14, 'n_steps': 4, 'gamma': 1.0140214812984336, 'lambda_sparse': 1.623547836407724e-05, 'lr': 0.0010944293339699622, 'weight_decay': 0.00027012052573258545}. Best is trial 0 with value: 0.866855943651565.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:58:53,751] Trial 2 finished with value: 0.7342842679345806 and parameters: {'n_d': 20, 'n_a': 58, 'n_steps': 9, 'gamma': 1.4265140354529973, 'lambda_sparse': 0.0002638185234932472, 'lr': 0.004100907343705678, 'weight_decay': 0.00027322557606339207}. Best is trial 0 with value: 0.866855943651565.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 03:59:43,947] Trial 3 finished with value: 0.9090825190821642 and parameters: {'n_d': 8, 'n_a': 16, 'n_steps': 5, 'gamma': 1.2191412027415998, 'lambda_sparse': 0.004626837002785708, 'lr': 0.05917262545052043, 'weight_decay': 2.9167782580345343e-06}. Best is trial 3 with value: 0.9090825190821642.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:00:34,712] Trial 4 finished with value: 0.8400994444614767 and parameters: {'n_d': 41, 'n_a': 27, 'n_steps': 7, 'gamma': 1.5536854400338869, 'lambda_sparse': 0.0010580286170149167, 'lr': 0.007129064560438694, 'weight_decay': 2.4600292679459134e-05}. Best is trial 3 with value: 0.9090825190821642.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:01:10,501] Trial 5 finished with value: 0.5404210510369657 and parameters: {'n_d': 31, 'n_a': 23, 'n_steps': 4, 'gamma': 1.2786895275589463, 'lambda_sparse': 0.0008924569078378238, 'lr': 0.0002587869200931658, 'weight_decay': 6.699185123152297e-05}. Best is trial 3 with value: 0.9090825190821642.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:02:00,871] Trial 6 finished with value: 0.8880626055354537 and parameters: {'n_d': 10, 'n_a': 13, 'n_steps': 7, 'gamma': 1.2514770397285075, 'lambda_sparse': 1.4573411084974645e-05, 'lr': 0.03590333474161036, 'weight_decay': 4.307278099715129e-05}. Best is trial 3 with value: 0.9090825190821642.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:02:58,270] Trial 7 finished with value: 0.5947547022860524 and parameters: {'n_d': 45, 'n_a': 54, 'n_steps': 8, 'gamma': 1.3343430242750984, 'lambda_sparse': 0.005447862144478243, 'lr': 0.0005526346458286352, 'weight_decay': 0.0005652109721129164}. Best is trial 3 with value: 0.9090825190821642.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:03:49,063] Trial 8 finished with value: 0.9152633919317227 and parameters: {'n_d': 15, 'n_a': 35, 'n_steps': 7, 'gamma': 1.0957464222832085, 'lambda_sparse': 0.004032567950788057, 'lr': 0.01707741696342524, 'weight_decay': 3.459753377162638e-05}. Best is trial 8 with value: 0.9152633919317227.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:04:53,779] Trial 9 finished with value: 0.6108417320418542 and parameters: {'n_d': 31, 'n_a': 30, 'n_steps': 8, 'gamma': 1.6636845267577849, 'lambda_sparse': 0.00014222248066071702, 'lr': 0.0010106893094558736, 'weight_decay': 0.00032585920312946004}. Best is trial 8 with value: 0.9152633919317227.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:06:02,167] Trial 10 finished with value: 0.6818041273801787 and parameters: {'n_d': 20, 'n_a': 42, 'n_steps': 10, 'gamma': 1.9791677335526132, 'lambda_sparse': 0.009136728782079514, 'lr': 0.014744258196767028, 'weight_decay': 5.534259759103377e-06}. Best is trial 8 with value: 0.9152633919317227.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:06:46,368] Trial 11 finished with value: 0.9245712596009495 and parameters: {'n_d': 8, 'n_a': 41, 'n_steps': 6, 'gamma': 1.0058705744799374, 'lambda_sparse': 0.002227575457622054, 'lr': 0.07000342112484849, 'weight_decay': 1.5366265190286278e-06}. Best is trial 11 with value: 0.9245712596009495.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:07:30,516] Trial 12 finished with value: 0.9146671297742701 and parameters: {'n_d': 18, 'n_a': 41, 'n_steps': 6, 'gamma': 1.005749557888348, 'lambda_sparse': 0.0015419341607818982, 'lr': 0.07973081916985697, 'weight_decay': 1.1214141480579655e-06}. Best is trial 11 with value: 0.9245712596009495.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:08:15,673] Trial 13 finished with value: 0.9208874731516334 and parameters: {'n_d': 14, 'n_a': 45, 'n_steps': 6, 'gamma': 1.1202016384630706, 'lambda_sparse': 0.0026482470782844374, 'lr': 0.019836965410486844, 'weight_decay': 1.1486644192432413e-05}. Best is trial 11 with value: 0.9245712596009495.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:08:42,150] Trial 14 finished with value: 0.9250998299541845 and parameters: {'n_d': 26, 'n_a': 46, 'n_steps': 3, 'gamma': 1.1467216806114184, 'lambda_sparse': 0.0018938592935810836, 'lr': 0.025238279858835512, 'weight_decay': 9.50335436998672e-06}. Best is trial 14 with value: 0.9250998299541845.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:09:12,638] Trial 15 finished with value: 0.9251621536279161 and parameters: {'n_d': 53, 'n_a': 49, 'n_steps': 3, 'gamma': 1.694657845767675, 'lambda_sparse': 9.231248445304062e-05, 'lr': 0.03515072523983818, 'weight_decay': 1.1059028448120513e-06}. Best is trial 15 with value: 0.9251621536279161.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:09:39,984] Trial 16 finished with value: 0.9153703045049115 and parameters: {'n_d': 56, 'n_a': 62, 'n_steps': 3, 'gamma': 1.7788330666062027, 'lambda_sparse': 5.949566507234073e-05, 'lr': 0.006880782499512995, 'weight_decay': 7.853878432189308e-06}. Best is trial 15 with value: 0.9251621536279161.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:10:07,703] Trial 17 finished with value: 0.9324292741718418 and parameters: {'n_d': 50, 'n_a': 50, 'n_steps': 3, 'gamma': 1.8311042318096578, 'lambda_sparse': 4.826923810101399e-05, 'lr': 0.030819117755768566, 'weight_decay': 2.1467095952028046e-06}. Best is trial 17 with value: 0.9324292741718418.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:10:42,818] Trial 18 finished with value: 0.4830992074716385 and parameters: {'n_d': 50, 'n_a': 52, 'n_steps': 4, 'gamma': 1.8458219721073486, 'lambda_sparse': 4.593500487501553e-05, 'lr': 0.00011285355645021815, 'weight_decay': 2.684523737888988e-06}. Best is trial 17 with value: 0.9324292741718418.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:11:10,690] Trial 19 finished with value: 0.9296024234739168 and parameters: {'n_d': 52, 'n_a': 34, 'n_steps': 3, 'gamma': 1.6245130420861595, 'lambda_sparse': 5.9127817782357306e-05, 'lr': 0.008823305139427936, 'weight_decay': 2.5863202455420017e-06}. Best is trial 17 with value: 0.9324292741718418.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:12:00,989] A new study created in memory with name: no-name-db53c7c0-b78a-464e-be58-e2f89fceeec7
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:12:45,624] Trial 0 finished with value: 0.37804865029327483 and parameters: {'n_d': 33, 'n_a': 12, 'n_steps': 4, 'gamma': 1.9377018969160518, 'lambda_sparse': 0.001246723966270311, 'lr': 0.00012301151975903038, 'weight_decay': 5.749282788349458e-05}. Best is trial 0 with value: 0.37804865029327483.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:13:32,198] Trial 1 finished with value: 0.9156144083201193 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 6, 'gamma': 1.000821583204724, 'lambda_sparse': 4.611367788363257e-05, 'lr': 0.05931930566486555, 'weight_decay': 1.1907918806219684e-05}. Best is trial 1 with value: 0.9156144083201193.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:13:56,438] Trial 2 finished with value: 0.895113928250031 and parameters: {'n_d': 23, 'n_a': 61, 'n_steps': 3, 'gamma': 1.7527770107517042, 'lambda_sparse': 0.0026446064446968578, 'lr': 0.029262088609919305, 'weight_decay': 1.4333346438433676e-05}. Best is trial 1 with value: 0.9156144083201193.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:14:24,361] Trial 3 finished with value: 0.908269274837455 and parameters: {'n_d': 55, 'n_a': 30, 'n_steps': 3, 'gamma': 1.760577095512511, 'lambda_sparse': 1.398005510395475e-05, 'lr': 0.00283481184263908, 'weight_decay': 0.000548017271607106}. Best is trial 1 with value: 0.9156144083201193.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:14:57,369] Trial 4 finished with value: 0.8858753361010228 and parameters: {'n_d': 26, 'n_a': 13, 'n_steps': 4, 'gamma': 1.4780864757892913, 'lambda_sparse': 7.050830017961445e-05, 'lr': 0.006371190268021496, 'weight_decay': 6.184552480270298e-05}. Best is trial 1 with value: 0.9156144083201193.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:15:26,613] Trial 5 finished with value: 0.9219226373280877 and parameters: {'n_d': 19, 'n_a': 10, 'n_steps': 3, 'gamma': 1.7977525926179885, 'lambda_sparse': 0.00041313613357047124, 'lr': 0.011874235525431839, 'weight_decay': 8.09814386636194e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:15:53,540] Trial 6 finished with value: 0.8766678798923411 and parameters: {'n_d': 64, 'n_a': 47, 'n_steps': 3, 'gamma': 1.8543557642947226, 'lambda_sparse': 0.0001779362603234712, 'lr': 0.0010608256179087787, 'weight_decay': 0.00010820477318169443}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:17:03,812] Trial 7 finished with value: 0.40897195325110813 and parameters: {'n_d': 54, 'n_a': 53, 'n_steps': 10, 'gamma': 1.0350222185649376, 'lambda_sparse': 0.0005144158802955516, 'lr': 0.00023943769448035084, 'weight_decay': 2.3657876533909638e-05}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:17:49,707] Trial 8 finished with value: 0.7121521001227246 and parameters: {'n_d': 17, 'n_a': 28, 'n_steps': 6, 'gamma': 1.653193473752701, 'lambda_sparse': 5.318446928809821e-05, 'lr': 0.0018291973773868107, 'weight_decay': 1.0627691760203244e-05}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:18:34,813] Trial 9 finished with value: 0.3649240274836316 and parameters: {'n_d': 18, 'n_a': 9, 'n_steps': 6, 'gamma': 1.0874443276359873, 'lambda_sparse': 0.0028388748291860075, 'lr': 0.00019657483115047294, 'weight_decay': 3.823141235497094e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:19:36,708] Trial 10 finished with value: 0.8093886789673841 and parameters: {'n_d': 9, 'n_a': 22, 'n_steps': 9, 'gamma': 1.385478503579232, 'lambda_sparse': 0.008752741366376163, 'lr': 0.013442708029764933, 'weight_decay': 1.2322017353932436e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:20:33,855] Trial 11 finished with value: 0.8182375129356654 and parameters: {'n_d': 43, 'n_a': 42, 'n_steps': 8, 'gamma': 1.3051138907129636, 'lambda_sparse': 1.4410887327192438e-05, 'lr': 0.08985224667425602, 'weight_decay': 3.5556437313600523e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:21:13,938] Trial 12 finished with value: 0.8567615616665578 and parameters: {'n_d': 39, 'n_a': 64, 'n_steps': 7, 'gamma': 1.2045632959866337, 'lambda_sparse': 0.00027280375783540853, 'lr': 0.08876319356094271, 'weight_decay': 5.520043583280004e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:21:46,325] Trial 13 finished with value: 0.8912428222203015 and parameters: {'n_d': 8, 'n_a': 38, 'n_steps': 5, 'gamma': 1.5614214303384994, 'lambda_sparse': 6.0669661537058665e-05, 'lr': 0.03379725451745661, 'weight_decay': 1.2146777217930358e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:22:25,392] Trial 14 finished with value: 0.8892517559013916 and parameters: {'n_d': 48, 'n_a': 50, 'n_steps': 5, 'gamma': 1.2016880742028355, 'lambda_sparse': 0.0006556614034346847, 'lr': 0.012620326175451784, 'weight_decay': 0.000270585644395903}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:23:24,850] Trial 15 finished with value: 0.885898970865567 and parameters: {'n_d': 33, 'n_a': 22, 'n_steps': 7, 'gamma': 1.5701381961534402, 'lambda_sparse': 0.0001613250043927814, 'lr': 0.03617455093397331, 'weight_decay': 8.370186133554602e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:24:13,295] Trial 16 finished with value: 0.9114141075365898 and parameters: {'n_d': 62, 'n_a': 55, 'n_steps': 5, 'gamma': 1.4030686765059452, 'lambda_sparse': 3.061491836828773e-05, 'lr': 0.0074474439774376774, 'weight_decay': 2.4868555338868586e-05}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:25:26,572] Trial 17 finished with value: 0.8244350893073262 and parameters: {'n_d': 27, 'n_a': 43, 'n_steps': 9, 'gamma': 1.985186295061058, 'lambda_sparse': 0.00010815849695250586, 'lr': 0.018515325829463657, 'weight_decay': 3.2477523325708108e-06}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:26:00,432] Trial 18 finished with value: 0.7397978525302569 and parameters: {'n_d': 46, 'n_a': 31, 'n_steps': 4, 'gamma': 1.6714151951619134, 'lambda_sparse': 0.00046228335280326866, 'lr': 0.0005439413062686342, 'weight_decay': 4.263930334882186e-05}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:26:56,992] Trial 19 finished with value: 0.8701337926569032 and parameters: {'n_d': 15, 'n_a': 21, 'n_steps': 8, 'gamma': 1.180417854517681, 'lambda_sparse': 2.990477982794764e-05, 'lr': 0.005301825586630993, 'weight_decay': 0.00011416162026831767}. Best is trial 5 with value: 0.9219226373280877.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:27:30,895] A new study created in memory with name: no-name-79da536f-861c-4fd6-85cd-117a4cce3998
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:28:27,266] Trial 0 finished with value: 0.43447286692994913 and parameters: {'n_d': 60, 'n_a': 21, 'n_steps': 8, 'gamma': 1.6982321042753785, 'lambda_sparse': 0.0005321501193339755, 'lr': 0.00035828917161296795, 'weight_decay': 4.60993121591483e-06}. Best is trial 0 with value: 0.43447286692994913.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:29:16,762] Trial 1 finished with value: 0.7089313955284393 and parameters: {'n_d': 15, 'n_a': 32, 'n_steps': 7, 'gamma': 1.2576947242204863, 'lambda_sparse': 0.00036082730080117426, 'lr': 0.0012413159517178807, 'weight_decay': 1.2268724200043203e-06}. Best is trial 1 with value: 0.7089313955284393.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:30:23,936] Trial 2 finished with value: 0.703062316210957 and parameters: {'n_d': 10, 'n_a': 39, 'n_steps': 9, 'gamma': 1.6237074425365976, 'lambda_sparse': 0.0014048787297506044, 'lr': 0.00339017309003839, 'weight_decay': 0.0005183854642674448}. Best is trial 1 with value: 0.7089313955284393.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:31:07,480] Trial 3 finished with value: 0.8455961188635681 and parameters: {'n_d': 30, 'n_a': 26, 'n_steps': 5, 'gamma': 1.9736055096102447, 'lambda_sparse': 1.7433800717278815e-05, 'lr': 0.009176881281396583, 'weight_decay': 2.408200025104876e-05}. Best is trial 3 with value: 0.8455961188635681.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:32:21,463] Trial 4 finished with value: 0.7681355915576953 and parameters: {'n_d': 64, 'n_a': 17, 'n_steps': 10, 'gamma': 1.2760525768990096, 'lambda_sparse': 1.4252461083880918e-05, 'lr': 0.007001108231560668, 'weight_decay': 1.2776355505181253e-05}. Best is trial 3 with value: 0.8455961188635681.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:32:50,463] Trial 5 finished with value: 0.8962459014942585 and parameters: {'n_d': 40, 'n_a': 22, 'n_steps': 4, 'gamma': 1.428718308464584, 'lambda_sparse': 1.675262773281317e-05, 'lr': 0.04302319302395312, 'weight_decay': 2.302865671611056e-05}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:33:35,645] Trial 6 finished with value: 0.6245356158494846 and parameters: {'n_d': 20, 'n_a': 38, 'n_steps': 9, 'gamma': 1.9110521613646902, 'lambda_sparse': 0.0001067834860655795, 'lr': 0.005161403225844937, 'weight_decay': 7.952051134446416e-05}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:34:37,985] Trial 7 finished with value: 0.8663840596104881 and parameters: {'n_d': 13, 'n_a': 35, 'n_steps': 9, 'gamma': 1.7570204281944433, 'lambda_sparse': 4.615896605924975e-05, 'lr': 0.04236582019261611, 'weight_decay': 7.864149270508192e-06}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:35:32,297] Trial 8 finished with value: 0.8534160676166158 and parameters: {'n_d': 57, 'n_a': 56, 'n_steps': 8, 'gamma': 1.3800488451221145, 'lambda_sparse': 1.1075513563041936e-05, 'lr': 0.02263588415773207, 'weight_decay': 0.0004900312009006256}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:36:40,391] Trial 9 finished with value: 0.47780814188274023 and parameters: {'n_d': 29, 'n_a': 64, 'n_steps': 8, 'gamma': 1.5328223181443885, 'lambda_sparse': 0.0021800477926986702, 'lr': 0.0003896441747102886, 'weight_decay': 5.675112198694462e-06}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:37:10,675] Trial 10 finished with value: 0.8747023026906701 and parameters: {'n_d': 44, 'n_a': 8, 'n_steps': 3, 'gamma': 1.0050446609472532, 'lambda_sparse': 0.009134808257517906, 'lr': 0.07447630177695903, 'weight_decay': 8.424609981528517e-05}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:37:37,797] Trial 11 finished with value: 0.861736432471148 and parameters: {'n_d': 46, 'n_a': 8, 'n_steps': 3, 'gamma': 1.01703117970604, 'lambda_sparse': 0.009533179787820215, 'lr': 0.08664855674009049, 'weight_decay': 8.838010171127989e-05}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:38:14,440] Trial 12 finished with value: 0.8642904619508782 and parameters: {'n_d': 43, 'n_a': 8, 'n_steps': 3, 'gamma': 1.012418067617733, 'lambda_sparse': 0.009140002896815375, 'lr': 0.09840683535158644, 'weight_decay': 0.00012188614866331871}. Best is trial 5 with value: 0.8962459014942585.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:39:01,853] Trial 13 finished with value: 0.901369643422841 and parameters: {'n_d': 47, 'n_a': 17, 'n_steps': 5, 'gamma': 1.1841603853116913, 'lambda_sparse': 9.511637443375427e-05, 'lr': 0.021122102801200537, 'weight_decay': 3.1418931547735715e-05}. Best is trial 13 with value: 0.901369643422841.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:39:47,270] Trial 14 finished with value: 0.9041367161092481 and parameters: {'n_d': 51, 'n_a': 21, 'n_steps': 5, 'gamma': 1.19405263748257, 'lambda_sparse': 8.48904468639116e-05, 'lr': 0.021769470511636673, 'weight_decay': 3.685142673696263e-05}. Best is trial 14 with value: 0.9041367161092481.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:40:36,638] Trial 15 finished with value: 0.8969983077167999 and parameters: {'n_d': 52, 'n_a': 47, 'n_steps': 5, 'gamma': 1.165795230092126, 'lambda_sparse': 0.0001139545660701532, 'lr': 0.01887134423737928, 'weight_decay': 0.00021119670636877811}. Best is trial 14 with value: 0.9041367161092481.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:41:30,799] Trial 16 finished with value: 0.8284501284141194 and parameters: {'n_d': 51, 'n_a': 16, 'n_steps': 6, 'gamma': 1.1732061646067806, 'lambda_sparse': 7.961527361772695e-05, 'lr': 0.0012976131956222397, 'weight_decay': 3.872692937122775e-05}. Best is trial 14 with value: 0.9041367161092481.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:42:16,976] Trial 17 finished with value: 0.9144812005528604 and parameters: {'n_d': 34, 'n_a': 28, 'n_steps': 5, 'gamma': 1.1670897603184196, 'lambda_sparse': 4.1606660714381496e-05, 'lr': 0.021073884048983665, 'weight_decay': 2.001031306876326e-06}. Best is trial 17 with value: 0.9144812005528604.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:43:12,864] Trial 18 finished with value: 0.879895709994831 and parameters: {'n_d': 36, 'n_a': 29, 'n_steps': 6, 'gamma': 1.3077716269010944, 'lambda_sparse': 3.551293759691198e-05, 'lr': 0.011218228860889032, 'weight_decay': 1.029152291137409e-06}. Best is trial 17 with value: 0.9144812005528604.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:43:52,049] Trial 19 finished with value: 0.5218969937726172 and parameters: {'n_d': 28, 'n_a': 48, 'n_steps': 4, 'gamma': 1.1097477213375693, 'lambda_sparse': 0.00020569269988696885, 'lr': 0.0001294278352222602, 'weight_decay': 2.859251299828593e-06}. Best is trial 17 with value: 0.9144812005528604.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:44:45,742] A new study created in memory with name: no-name-36bf1258-63db-40cf-af29-225f0513dcf0
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:46:03,406] Trial 0 finished with value: 0.864316264770661 and parameters: {'n_d': 52, 'n_a': 41, 'n_steps': 10, 'gamma': 1.0296453757944175, 'lambda_sparse': 0.0003536326978773153, 'lr': 0.0027031738292475098, 'weight_decay': 0.00011466940018281661}. Best is trial 0 with value: 0.864316264770661.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:46:44,642] Trial 1 finished with value: 0.8872757077085673 and parameters: {'n_d': 31, 'n_a': 64, 'n_steps': 3, 'gamma': 1.0105134129758793, 'lambda_sparse': 0.0037185824983372246, 'lr': 0.0303514143278687, 'weight_decay': 0.0006553849805172885}. Best is trial 1 with value: 0.8872757077085673.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:47:49,595] Trial 2 finished with value: 0.7731066384574385 and parameters: {'n_d': 36, 'n_a': 14, 'n_steps': 8, 'gamma': 1.0382605214675613, 'lambda_sparse': 0.00015609542084032006, 'lr': 0.001808411011309866, 'weight_decay': 6.267920342111109e-06}. Best is trial 1 with value: 0.8872757077085673.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:48:27,985] Trial 3 finished with value: 0.8851552142038054 and parameters: {'n_d': 22, 'n_a': 46, 'n_steps': 7, 'gamma': 1.0036761881097638, 'lambda_sparse': 0.004723573102161624, 'lr': 0.04930010508879311, 'weight_decay': 5.608704877850584e-05}. Best is trial 1 with value: 0.8872757077085673.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:49:14,706] Trial 4 finished with value: 0.9189487798668614 and parameters: {'n_d': 55, 'n_a': 61, 'n_steps': 5, 'gamma': 1.3103536190228904, 'lambda_sparse': 1.2139589331013826e-05, 'lr': 0.032256753023265125, 'weight_decay': 6.203290870474739e-06}. Best is trial 4 with value: 0.9189487798668614.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:49:58,601] Trial 5 finished with value: 0.8303738634131841 and parameters: {'n_d': 36, 'n_a': 47, 'n_steps': 5, 'gamma': 1.8525699182936766, 'lambda_sparse': 0.0028449090249164336, 'lr': 0.001914302935319678, 'weight_decay': 0.0007306999162923352}. Best is trial 4 with value: 0.9189487798668614.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:51:06,777] Trial 6 finished with value: -0.19764811268022808 and parameters: {'n_d': 13, 'n_a': 23, 'n_steps': 9, 'gamma': 1.7216330911331328, 'lambda_sparse': 1.8219625026444402e-05, 'lr': 0.0001334842705525143, 'weight_decay': 1.7534716101984352e-06}. Best is trial 4 with value: 0.9189487798668614.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:51:53,346] Trial 7 finished with value: 0.510022395607783 and parameters: {'n_d': 50, 'n_a': 32, 'n_steps': 5, 'gamma': 1.8236087991996026, 'lambda_sparse': 1.9569345983520034e-05, 'lr': 0.00030220337829713295, 'weight_decay': 9.025349863415383e-05}. Best is trial 4 with value: 0.9189487798668614.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:52:41,196] Trial 8 finished with value: -0.4495320402872305 and parameters: {'n_d': 16, 'n_a': 8, 'n_steps': 6, 'gamma': 1.0474363208650277, 'lambda_sparse': 0.00015783991079112698, 'lr': 0.00010674888181638147, 'weight_decay': 1.7757304511622253e-05}. Best is trial 4 with value: 0.9189487798668614.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:53:57,046] Trial 9 finished with value: 0.8757859900758066 and parameters: {'n_d': 45, 'n_a': 44, 'n_steps': 9, 'gamma': 1.9637011714983932, 'lambda_sparse': 0.0030740132220966427, 'lr': 0.039232018745185546, 'weight_decay': 4.924502251869563e-05}. Best is trial 4 with value: 0.9189487798668614.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:54:34,428] Trial 10 finished with value: 0.9219404338670028 and parameters: {'n_d': 63, 'n_a': 59, 'n_steps': 3, 'gamma': 1.3443875740321078, 'lambda_sparse': 1.106769239386203e-05, 'lr': 0.01032834437866554, 'weight_decay': 1.0454717378371187e-06}. Best is trial 10 with value: 0.9219404338670028.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:55:15,421] Trial 11 finished with value: 0.9092817051552013 and parameters: {'n_d': 64, 'n_a': 59, 'n_steps': 3, 'gamma': 1.3455650724113042, 'lambda_sparse': 1.0680292701424265e-05, 'lr': 0.011998207537650699, 'weight_decay': 1.0395968281015905e-06}. Best is trial 10 with value: 0.9219404338670028.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:55:54,065] Trial 12 finished with value: 0.9060434890943088 and parameters: {'n_d': 63, 'n_a': 57, 'n_steps': 4, 'gamma': 1.355674092543601, 'lambda_sparse': 4.642735964160343e-05, 'lr': 0.010010876093112164, 'weight_decay': 4.401315823892977e-06}. Best is trial 10 with value: 0.9219404338670028.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:56:32,622] Trial 13 finished with value: 0.9223876495406056 and parameters: {'n_d': 56, 'n_a': 53, 'n_steps': 4, 'gamma': 1.2833100592964577, 'lambda_sparse': 5.1017080966096325e-05, 'lr': 0.008309268332342403, 'weight_decay': 3.5972214720641907e-06}. Best is trial 13 with value: 0.9223876495406056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:57:07,039] Trial 14 finished with value: 0.91102238156982 and parameters: {'n_d': 58, 'n_a': 54, 'n_steps': 3, 'gamma': 1.5062429034027762, 'lambda_sparse': 5.1002918100301435e-05, 'lr': 0.00931085898427248, 'weight_decay': 2.5093656705868022e-06}. Best is trial 13 with value: 0.9223876495406056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:57:48,017] Trial 15 finished with value: 0.838318645902114 and parameters: {'n_d': 50, 'n_a': 52, 'n_steps': 4, 'gamma': 1.2032862679775764, 'lambda_sparse': 5.376631648666519e-05, 'lr': 0.0007165677612457816, 'weight_decay': 1.5515347038753508e-05}. Best is trial 13 with value: 0.9223876495406056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:58:26,310] Trial 16 finished with value: 0.8771181401034768 and parameters: {'n_d': 43, 'n_a': 33, 'n_steps': 4, 'gamma': 1.5714016772538923, 'lambda_sparse': 0.0006278526914501946, 'lr': 0.005739950614094907, 'weight_decay': 1.2583103020672296e-06}. Best is trial 13 with value: 0.9223876495406056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:59:11,557] Trial 17 finished with value: 0.8772996782675492 and parameters: {'n_d': 59, 'n_a': 51, 'n_steps': 6, 'gamma': 1.1889372721564127, 'lambda_sparse': 3.2826340456167965e-05, 'lr': 0.08527103008049537, 'weight_decay': 3.223726211859496e-06}. Best is trial 13 with value: 0.9223876495406056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 04:59:57,460] Trial 18 finished with value: 0.8806138350325506 and parameters: {'n_d': 44, 'n_a': 38, 'n_steps': 4, 'gamma': 1.4252240362917756, 'lambda_sparse': 0.0001639851395444527, 'lr': 0.005174765195230338, 'weight_decay': 1.2422693326283969e-05}. Best is trial 13 with value: 0.9223876495406056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:00:59,445] Trial 19 finished with value: 0.8251122798897004 and parameters: {'n_d': 26, 'n_a': 27, 'n_steps': 7, 'gamma': 1.6029112686998053, 'lambda_sparse': 9.13259065649346e-05, 'lr': 0.018472811478966723, 'weight_decay': 2.1865243693804215e-06}. Best is trial 13 with value: 0.9223876495406056.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:01:57,632] A new study created in memory with name: no-name-0ca3a378-ca7d-401c-8ee2-adba51099317
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:02:44,092] Trial 0 finished with value: 0.8810321720502265 and parameters: {'n_d': 12, 'n_a': 52, 'n_steps': 5, 'gamma': 1.419243721617655, 'lambda_sparse': 0.0003457906726204985, 'lr': 0.0035186863858576015, 'weight_decay': 0.00020302008445302887}. Best is trial 0 with value: 0.8810321720502265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:03:42,385] Trial 1 finished with value: -0.00558855271741221 and parameters: {'n_d': 9, 'n_a': 16, 'n_steps': 7, 'gamma': 1.5583303267117077, 'lambda_sparse': 0.00012513191573457867, 'lr': 0.00012603071556781286, 'weight_decay': 1.6063788635120968e-05}. Best is trial 0 with value: 0.8810321720502265.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:04:24,576] Trial 2 finished with value: 0.9130940582654843 and parameters: {'n_d': 27, 'n_a': 49, 'n_steps': 3, 'gamma': 1.8291445468948337, 'lambda_sparse': 0.0017940836873187455, 'lr': 0.0094539227889201, 'weight_decay': 1.4709805630338033e-05}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:05:27,523] Trial 3 finished with value: 0.7270555131777632 and parameters: {'n_d': 44, 'n_a': 36, 'n_steps': 8, 'gamma': 1.9620994402055039, 'lambda_sparse': 0.0053637926397661125, 'lr': 0.009017533360628098, 'weight_decay': 2.914984256942075e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:06:09,271] Trial 4 finished with value: 0.6822697836198615 and parameters: {'n_d': 56, 'n_a': 15, 'n_steps': 5, 'gamma': 1.784226839071185, 'lambda_sparse': 0.0035952943218263323, 'lr': 0.001170836836889436, 'weight_decay': 5.616969360691492e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:06:50,848] Trial 5 finished with value: 0.8310222068988247 and parameters: {'n_d': 44, 'n_a': 19, 'n_steps': 6, 'gamma': 1.7629133245022146, 'lambda_sparse': 0.00012924407140155235, 'lr': 0.02157255825191095, 'weight_decay': 0.0007029880423478291}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:07:31,187] Trial 6 finished with value: 0.5751734966543844 and parameters: {'n_d': 63, 'n_a': 53, 'n_steps': 4, 'gamma': 1.1437199148760624, 'lambda_sparse': 0.0002616735825687469, 'lr': 0.00017667347313989702, 'weight_decay': 5.852488650614252e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:08:14,227] Trial 7 finished with value: 0.8833636588148958 and parameters: {'n_d': 45, 'n_a': 45, 'n_steps': 4, 'gamma': 1.7713271100141523, 'lambda_sparse': 0.0004892056249408765, 'lr': 0.03768827085667892, 'weight_decay': 0.00020792569812855204}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:09:22,901] Trial 8 finished with value: 0.640677186757139 and parameters: {'n_d': 21, 'n_a': 62, 'n_steps': 8, 'gamma': 1.1293638993613722, 'lambda_sparse': 3.5811528255116096e-05, 'lr': 0.0005401153251854852, 'weight_decay': 0.0003107922442237147}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:10:14,965] Trial 9 finished with value: 0.7675311089971792 and parameters: {'n_d': 41, 'n_a': 10, 'n_steps': 6, 'gamma': 1.111244905543101, 'lambda_sparse': 0.005332211403047733, 'lr': 0.0009359119078948018, 'weight_decay': 1.8296502913102827e-05}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:11:33,572] Trial 10 finished with value: 0.8854463865481427 and parameters: {'n_d': 27, 'n_a': 32, 'n_steps': 10, 'gamma': 1.985632571628727, 'lambda_sparse': 0.0013520651744146942, 'lr': 0.09300805312638936, 'weight_decay': 1.0360272251020623e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:12:27,818] Trial 11 finished with value: 0.6855010354211415 and parameters: {'n_d': 28, 'n_a': 31, 'n_steps': 10, 'gamma': 1.9925284606271247, 'lambda_sparse': 0.0012800015842686194, 'lr': 0.08803482314325899, 'weight_decay': 1.2511480739950712e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:13:42,677] Trial 12 finished with value: 0.7259958885133271 and parameters: {'n_d': 28, 'n_a': 29, 'n_steps': 10, 'gamma': 1.6232372206754313, 'lambda_sparse': 0.0017086959285756021, 'lr': 0.009013770902340611, 'weight_decay': 5.281860264595069e-05}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:14:11,277] Trial 13 finished with value: 0.8778934291207126 and parameters: {'n_d': 28, 'n_a': 43, 'n_steps': 3, 'gamma': 1.893602924251778, 'lambda_sparse': 0.0011765887222762127, 'lr': 0.09646947438905908, 'weight_decay': 6.224650083963799e-05}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:15:12,540] Trial 14 finished with value: 0.7465296046543636 and parameters: {'n_d': 20, 'n_a': 29, 'n_steps': 9, 'gamma': 1.3770864537049166, 'lambda_sparse': 0.008584883252816707, 'lr': 0.016499200961219446, 'weight_decay': 1.0896366284451497e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:15:49,010] Trial 15 finished with value: 0.9032573489796282 and parameters: {'n_d': 34, 'n_a': 42, 'n_steps': 3, 'gamma': 1.6630772990945006, 'lambda_sparse': 0.0021800663057247992, 'lr': 0.003433113534220981, 'weight_decay': 3.4115469136006794e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:16:32,295] Trial 16 finished with value: 0.8858446304936342 and parameters: {'n_d': 35, 'n_a': 63, 'n_steps': 3, 'gamma': 1.6616149394083024, 'lambda_sparse': 1.45802566972033e-05, 'lr': 0.0034766138414777446, 'weight_decay': 7.5527751183175845e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:17:10,203] Trial 17 finished with value: 0.8955746624913667 and parameters: {'n_d': 36, 'n_a': 44, 'n_steps': 4, 'gamma': 1.4578093932434601, 'lambda_sparse': 0.002398180259392924, 'lr': 0.002240660792079286, 'weight_decay': 2.7471206696012446e-06}. Best is trial 2 with value: 0.9130940582654843.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:17:50,137] Trial 18 finished with value: 0.913383367569548 and parameters: {'n_d': 19, 'n_a': 53, 'n_steps': 3, 'gamma': 1.2704659949622008, 'lambda_sparse': 0.0006351917811097352, 'lr': 0.006554455595390167, 'weight_decay': 2.014061092271133e-05}. Best is trial 18 with value: 0.913383367569548.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:18:30,939] Trial 19 finished with value: 0.9107780568087849 and parameters: {'n_d': 16, 'n_a': 55, 'n_steps': 5, 'gamma': 1.2880777372592223, 'lambda_sparse': 0.0006470939848829604, 'lr': 0.010343375914410369, 'weight_decay': 2.6483813976536863e-05}. Best is trial 18 with value: 0.913383367569548.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:19:19,841] A new study created in memory with name: no-name-a9636bb7-8794-4628-b6e1-17702c8b6533
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:19:50,113] Trial 0 finished with value: 0.9187405892382786 and parameters: {'n_d': 47, 'n_a': 8, 'n_steps': 3, 'gamma': 1.4604962589772983, 'lambda_sparse': 4.907285695073573e-05, 'lr': 0.0064929073964719, 'weight_decay': 1.3608892960203928e-05}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:21:03,366] Trial 1 finished with value: 0.7314908034111123 and parameters: {'n_d': 12, 'n_a': 63, 'n_steps': 10, 'gamma': 1.4692241968990847, 'lambda_sparse': 1.5595166112915126e-05, 'lr': 0.013375201314801704, 'weight_decay': 2.906985865349215e-05}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:22:03,982] Trial 2 finished with value: 0.8644642368076099 and parameters: {'n_d': 19, 'n_a': 45, 'n_steps': 9, 'gamma': 1.5440728762468012, 'lambda_sparse': 4.6971681629052783e-05, 'lr': 0.04371714970040635, 'weight_decay': 0.0005307636000900198}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:22:53,016] Trial 3 finished with value: 0.9083222556383024 and parameters: {'n_d': 46, 'n_a': 24, 'n_steps': 5, 'gamma': 1.0865770160076216, 'lambda_sparse': 0.003751063348911546, 'lr': 0.005151399010706598, 'weight_decay': 1.4219972916835864e-06}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:23:38,153] Trial 4 finished with value: 0.8767665125224999 and parameters: {'n_d': 11, 'n_a': 45, 'n_steps': 5, 'gamma': 1.0506320948306644, 'lambda_sparse': 1.8091600905044694e-05, 'lr': 0.09189012944887127, 'weight_decay': 0.0001400075268276497}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:24:19,134] Trial 5 finished with value: 0.8052668520475577 and parameters: {'n_d': 26, 'n_a': 61, 'n_steps': 4, 'gamma': 1.201215461609268, 'lambda_sparse': 0.0005221587936962563, 'lr': 0.0009509853558392639, 'weight_decay': 2.5061280570345402e-05}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:25:24,862] Trial 6 finished with value: 0.42304182312296057 and parameters: {'n_d': 23, 'n_a': 12, 'n_steps': 8, 'gamma': 1.716432562292874, 'lambda_sparse': 0.0008049549842896797, 'lr': 0.000610627178684161, 'weight_decay': 9.820847209212508e-05}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:26:16,391] Trial 7 finished with value: 0.8499530993262142 and parameters: {'n_d': 61, 'n_a': 56, 'n_steps': 6, 'gamma': 1.662283317758059, 'lambda_sparse': 0.00037318298486440894, 'lr': 0.03636391288650426, 'weight_decay': 9.887135600723974e-05}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:27:07,854] Trial 8 finished with value: 0.7886665719854508 and parameters: {'n_d': 35, 'n_a': 23, 'n_steps': 6, 'gamma': 1.5991356646260544, 'lambda_sparse': 2.8432183160873517e-05, 'lr': 0.005441926451230098, 'weight_decay': 6.964301961000105e-06}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:28:12,810] Trial 9 finished with value: 0.8250059258757885 and parameters: {'n_d': 13, 'n_a': 32, 'n_steps': 7, 'gamma': 1.3253995955491265, 'lambda_sparse': 1.3530221151724276e-05, 'lr': 0.07349960265073241, 'weight_decay': 4.793212548400648e-06}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:28:54,704] Trial 10 finished with value: 0.45242528371587076 and parameters: {'n_d': 54, 'n_a': 10, 'n_steps': 3, 'gamma': 1.9418366462229613, 'lambda_sparse': 0.00011195657829306636, 'lr': 0.0001903710897405174, 'weight_decay': 1.0920071883053921e-06}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:29:36,762] Trial 11 finished with value: 0.9007681140111553 and parameters: {'n_d': 47, 'n_a': 23, 'n_steps': 3, 'gamma': 1.0137235273549086, 'lambda_sparse': 0.0068594380873280725, 'lr': 0.0027160013948567163, 'weight_decay': 1.2545310403069749e-06}. Best is trial 0 with value: 0.9187405892382786.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:30:20,247] Trial 12 finished with value: 0.9288260526820703 and parameters: {'n_d': 42, 'n_a': 20, 'n_steps': 4, 'gamma': 1.3496369173721534, 'lambda_sparse': 0.007062004608727682, 'lr': 0.007803103826721434, 'weight_decay': 5.655768197921605e-06}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:30:57,440] Trial 13 finished with value: 0.9218345306725998 and parameters: {'n_d': 37, 'n_a': 8, 'n_steps': 4, 'gamma': 1.3793776864344607, 'lambda_sparse': 0.00012563945297309716, 'lr': 0.01898121487481467, 'weight_decay': 7.206929245913337e-06}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:31:42,905] Trial 14 finished with value: 0.8995308967140061 and parameters: {'n_d': 33, 'n_a': 17, 'n_steps': 5, 'gamma': 1.2940492138905086, 'lambda_sparse': 0.0014312501621108887, 'lr': 0.01737903981295612, 'weight_decay': 3.910421612340669e-06}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:32:21,801] Trial 15 finished with value: 0.8732752147947886 and parameters: {'n_d': 40, 'n_a': 31, 'n_steps': 4, 'gamma': 1.3644378352243314, 'lambda_sparse': 0.00015700656341773156, 'lr': 0.0016463089113623183, 'weight_decay': 1.086590530544903e-05}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:33:03,917] Trial 16 finished with value: 0.9221237410781484 and parameters: {'n_d': 30, 'n_a': 16, 'n_steps': 4, 'gamma': 1.2020857939555762, 'lambda_sparse': 0.0017800661455757974, 'lr': 0.013310626129478908, 'weight_decay': 2.910029790458279e-06}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:34:05,103] Trial 17 finished with value: 0.9184589248394609 and parameters: {'n_d': 29, 'n_a': 17, 'n_steps': 7, 'gamma': 1.1832916843150658, 'lambda_sparse': 0.0022802304362699263, 'lr': 0.013210827237193558, 'weight_decay': 2.6522259392161e-06}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:34:45,044] Trial 18 finished with value: 0.6432117197150977 and parameters: {'n_d': 56, 'n_a': 41, 'n_steps': 4, 'gamma': 1.1765376313947298, 'lambda_sparse': 0.0071251651157050325, 'lr': 0.0002400562226447964, 'weight_decay': 2.5729171728397324e-06}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
[I 2025-08-05 05:35:26,867] Trial 19 finished with value: 0.7973437415899998 and parameters: {'n_d': 40, 'n_a': 17, 'n_steps': 5, 'gamma': 1.7886088791073362, 'lambda_sparse': 0.003028002239119587, 'lr': 0.002670911182857525, 'weight_decay': 1.6614250580726667e-05}. Best is trial 12 with value: 0.9288260526820703.
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!
  warnings.warn(wrn_msg)
2025-08-05 05:36:16 [INFO] TabNet →      /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/tabnet (mean R²=0.9274)
2025-08-05 05:36:16 [INFO] Ensemble weights: TabPFN=0.336, Tree=0.334, TabNet=0.330
2025-08-05 05:36:16 [INFO] Loading individual models into memory...
/work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/automl-tabular-env/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda
  warnings.warn(f"Device used : {self.device}")
2025-08-05 05:36:30 [INFO] Saved weighted ensemble to /work/dlclarge2/latifajr-dl_lab_project/autoML/automl-exam-ss25-tabular-freiburg-template/modelsFinal-bike_sharing_demand/final_model.pkl
